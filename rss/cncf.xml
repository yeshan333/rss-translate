<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>CNCF - 博客</title><link>https://www.cncf.io/blog/</link><description>CNCF - 博客 - RSSHub 用爱制作(https://github.com/DIYgod/RSSHub)</description><lastBuildDate>Tue, 23 Apr 2024 16:04:27 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>回顾：KubeCon + CloudNativeCon Europe 2024</title><link>https://www.cncf.io/blog/2024/04/23/a-recap-kubecon-cloudnativecon-europe-2024/</link><description>&lt;p&gt;&lt;em&gt;社区帖子最初由 Ryan Gough 和 Majid Att 发表在&lt;a href="https://jysk.tech/kubecon-cloudnativecon-europe-2024-694f4b95e99e"&gt;Medium&lt;/a&gt;上&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://miro.medium.com/v2/resize:fit:700/1*mIhpY9bK-ITgsmBXYdkBIg.jpeg" /&gt;&lt;/figure&gt;&lt;p id="d7d8"&gt;今年，我们（JYSK tech）前往巴黎参加 KubeCon + CloudNativeCon Europe 2024。经过三天的会谈、交流和研讨会。我们整理了一小部分观察结果，将我们带入云原生领域。 JYSK 是&lt;a href="https://www.cncf.io/enduser/" rel="noreferrer noopener" target="_blank"&gt;CNCF 最终用户&lt;/a&gt;成员，这意味着我们能够观察社区并为塑造作为我们运营基础设施核心的云原生技术做出贡献。我们的团队对 Kubernetes 生态系统的发展印象特别深刻，它反映了超越单纯容器编排的成熟度。 &lt;/p&gt;&lt;blockquote class="wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p id="40ba"&gt;产品有184个， &lt;strong&gt;Kubernetes&lt;/strong&gt;只是CNCF的一小部分。 CNCF 已对超过 30 万人进行了 Kubernetes 认证培训，并且正在考虑针对“第二天”培训的投资，即不再是 Kubernetes，而是与开放遥测、安全等元素相关的工具。&lt;/p&gt;&lt;p id="7009"&gt;现在的焦点集中在参与培训的社区成员身上。社区贡献的内容是关键，应该得到认可。&lt;/p&gt; &lt;cite&gt;&lt;a href="https://www.youtube.com/watch?v=c-Ys4qR41e4&amp;amp;list=PLenh213llmcZ0LfAsKPCeKOUKoHoAkuc8&amp;amp;index=30"&gt;– theCUBE 与&lt;strong&gt;Christophe Sauthier 和 Chris Aniszczyk&lt;/strong&gt;&lt;/a&gt;&lt;/cite&gt;&lt;/blockquote&gt;&lt;p id="3a91"&gt; JYSK 与社区的互动并不仅限于使用技术，还延伸到积极参与推动创新的对话。这种协作精神真正定义了 CNCF 的精神，确保像我们这样的最终用户的需求和观点能够帮助引导云原生项目的未来方向。展望未来，我们很高兴能够实施我们学到的一些前沿实践，并将我们自己的经验回馈给 CNCF 社区。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="dad3"&gt;&lt;strong&gt;我们发现有趣的主题：&lt;/strong&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;树内云提供商消失了！&lt;/li&gt;&lt;li&gt;人工智能当然正在获得关注，但从操作的角度来看也面临着挑战。&lt;/li&gt;&lt;li&gt;对“DevOps”和平台工程思维的关注较少。现在很明显，该行业已经适应了。&lt;/li&gt;&lt;li&gt;多集群、混合拓扑。&lt;/li&gt;&lt;li&gt;炸毁东西是好事——用混沌工程正确地做到这一点甚至更好（感谢乐高）&lt;/li&gt;&lt;li&gt;令人印象深刻的社区并注重包容性。&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="0661"&gt; Kubernetes 最终删除树内云提供商&lt;/h3&gt;&lt;p id="606a"&gt;经过多年的开发和许多贡献者的协作，Kubernetes 项目最终删除了树内云提供商。这是 Kubernetes 的一个重要里程碑，因为所有组件现在完全独立于云提供商。&lt;/p&gt;&lt;p id="d082"&gt;如果您在 AWS、Azure、GCE、OpenStack 或 vSphere 上运行 Kubernetes，您可能会受到影响。&lt;strong&gt;从 Kubernetes 1.30 版本开始，只有 GCE 上的用户会受到影响&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;演讲： &lt;a href="https://www.youtube.com/watch?v=IIxQHQHOXs4"&gt;Kubernetes 最终删除树内云提供商 — Bridget Kromhout 和 Chris Privitere&lt;/a&gt;&lt;/li&gt;&lt;li&gt;链接： &lt;a href="https://github.com/kubernetes/enhancements/blob/master/keps/sig-cloud-provider/2395-removing-in-tree-cloud-providers/README.md#summary"&gt;KEP-2395：删除树内云提供商代码&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading" id="8c45"&gt;&lt;strong&gt;房间里的大象——大规模人工智能&lt;/strong&gt;&lt;/h2&gt;&lt;p id="4532"&gt;除非你在过去的一年里一直生活在岩石下，否则 ChatGPT 和其他领域的努力推动了人工智能的发展并不奇怪。 KubeCon 举办了一系列令人印象深刻的人工智能演讲；是不是太多了？在我看来，不，它只是表明人工智能正在为 IT 思维新方式铺平道路。今年，至少对我来说，有趣的是看到人们对运营状态的关注。如何合理扩展人工智能以适应需要它的工作负载。 GPU 已成为处理密集计算不可或缺的一部分。然而，在 Kubernetes 环境中集成 GPU 加速会带来资源管理和复杂配置等障碍。&lt;/p&gt;&lt;p id="8013"&gt;公司和社区正在为实现资源共享、高级调度和加速器配置等功能铺平道路。通过克服这些挑战，Kubernetes 将成为 AI/ML 工作负载的领先平台，&lt;strong&gt;类似于 Linux 在现代数据中心中的角色。&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;主题演讲： &lt;a href="https://www.youtube.com/watch?v=gn5SZWyaZ34" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;在 Kubernetes 中使用 GPU 加速 AI 工作负载 — Kevin Klues 和 Sanjay Chatterjee&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;演讲&lt;strong&gt;：&lt;/strong&gt; &lt;a href="https://www.youtube.com/watch?v=Q5a1v_ShPew&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=55" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;分布式人工智能：使用 NATS.Io 无缝连接从云端到边缘的人工智能应用&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;演讲： &lt;a href="https://www.youtube.com/watch?v=u8pCyZFDX_g&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=90" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;边缘人工智能：云原生技术如何推动下一波智能应用&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading" id="768b"&gt;&lt;strong&gt;从 DevOps 到平台工程：关键转变？&lt;/strong&gt;&lt;/h2&gt;&lt;p id="928b"&gt;最近，围绕从 DevOps 到平台工程转型的热潮是不可否认的。在海量（阅读……混乱）的讨论和数百篇讨论该&lt;em&gt;学科&lt;/em&gt;发展的文章中，有一件事&lt;em&gt;非常&lt;/em&gt;清楚：平台工程远不是一种转瞬即逝的趋势或一个晦涩的话题。它已成为当今不断发展且复杂的 IT 环境中扩展、管理和促进创新的新标准。当我们深入研究 FinOps、可持续计算和即时部署等领域时，重新思考我们的系统管理方法变得非常重要。 &lt;/p&gt;&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;blockquote class="wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p id="320f"&gt;现在，比以往任何时候&lt;strong&gt;都更需要采用平台工程作为充分利用现代技术和方法潜力的手段。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;p id="0932"&gt;在会议期间，我特别被 CERN 主办的会议所吸引，重点讨论了他们在其平台上使用 Keycloak 进行单点登录 (SSO) 的情况。他们选择 Keycloak 的理由很明确，但最突出的方面是他们的实施方法。他们成功地制定了一个解决方案，不仅为整个组织服务，而且已成为他们研究工作不可或缺的一部分。这反映了彭博社等领先实体和挪威公共部门各个团队观察到的更广泛趋势。这些团体通过进行有意义的研究来准确地确定其“客户”的需求，从而体现了平台工程的本质。这种方法对于在当今的竞争格局中建立相关性并获得吸引力至关重要&lt;/p&gt;&lt;p id="dde2"&gt;越来越明显的是，平台工程正在演变成一门独特的学科，未经仔细考虑就不应采用。&lt;/p&gt;&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p id="2522"&gt;这波变革的浪潮是强大的，但驾驭它需要清晰的愿景和深思熟虑的策略，而不是盲目跟风。&lt;/p&gt;&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;演讲： &lt;a href="https://www.youtube.com/watch?v=3WFZhETlS9s&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=18" rel="noreferrer noopener" target="_blank"&gt;挪威公共部门的平台成熟度状况 — Hans Kristian Flaatten&lt;/a&gt;&lt;/li&gt;&lt;li&gt;主题演讲： &lt;a href="https://www.youtube.com/watch?v=rHJxdheLNwY&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=7" rel="noreferrer noopener" target="_blank"&gt;平台构建模块：如何使用 CNCF 项目构建机器学习基础设施&lt;/a&gt;&lt;/li&gt;&lt;li&gt;演讲： &lt;a href="https://www.youtube.com/watch?v=rqDrrTKzNd8&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=183" rel="noreferrer noopener" target="_blank"&gt;保护粒子加速器的艰辛 — Antonio Nappi 和 Sebastian Lopienski，CERN&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading" id="6db5"&gt;&lt;strong&gt;拥抱多集群、混合环境&lt;/strong&gt;&lt;/h2&gt;&lt;p id="80de"&gt;我们拥有几个心爱的集群的日子已经一去不复返了，我们会像对待宠物一样精心管理它们。今天的现实有很大不同。我们在各种环境中运营各种集群——无论是在多个超大规模、大型和小型数据中心的私有云设置上，还是在紧凑的边缘位置。这就是&lt;em&gt;“您的 Kubernetes 节点在哪里运行？”&lt;/em&gt;这个问题的答案。在当今的科技中&lt;em&gt;，“嗯，我们是混合动力”&lt;/em&gt;正在变得直截了当——它们在价格便宜和/或距离客户最近的地方运行。&lt;/p&gt;&lt;p id="de32"&gt;这种转变意味着集群不再需要像以前那样的溺爱、个性化关注。现在的重点是浏览复杂的、有时令人困惑的多集群环境。然而，为了给这种混乱带来一些秩序，我们正在采取一些举措，例如 ClusterInventoryAPI（尽管我听说这个名字可能有争议）等旨在建立通用标准的努力。&lt;/p&gt;&lt;p id="2222"&gt; &lt;strong&gt;ClusterAPI&lt;/strong&gt;等技术正在成为无缝扩展和管理运营的主要技术。然后还有推出可投入生产的迷你集群（例如 SideroLabs 的&lt;strong&gt;Talos）&lt;/strong&gt;的奇迹。这证明了 Kubernetes 的弹性及其对快速部署的最低要求。还记得我们花几个小时设置集群，然后庆祝每次升级的时候吗？虽然怀旧很有趣，但那些日子已经过去了。&lt;/p&gt;&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p id="b07a"&gt;现在，如果升级失败，该方法非常有效：终止集群并重新开始。&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="09aa"&gt;这种演变引出了一个问题： &lt;strong&gt;“升级”的概念本身是否已经过时了？难道我们不应该推出额外的多集群设置并转移我们的工作负载吗？&lt;/strong&gt;这个问题的答案确实取决于人们所拥有的设置类型，无论哪种方式，在当今时代，这无疑是一个可行的选择。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;演讲： &lt;a href="https://www.youtube.com/watch?v=ntSGFk0290w&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=21" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;Bloomberg 的多集群工作流程编排平台之旅 — Yao Lin 和 Reinhard Tartler&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;演讲： &lt;a href="https://www.youtube.com/watch?v=qbB3TEiOb24&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=94" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;使用 Cilium 简化多集群和多云部署 – Liz Rice，Isovalent&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;演讲： &lt;a href="https://www.youtube.com/watch?v=Xt1cuHKjKg8&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=108" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;ClusterInventory 和 ClusterFeature API 简介 — Eduardo Arango Gutierrez 和 Ryan Zhang&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading" id="4032"&gt;&lt;strong&gt;混沌工程&lt;/strong&gt;&lt;/h2&gt;&lt;p id="8a78"&gt;一段时间以来，这种关系一直是我又爱又恨的关系。想要做到这一点的想法很棒，但实际上做起来可能会令人畏惧。我是一名运营人员，我喜欢能够让我的“客户”满意并且不受干扰。 &lt;/p&gt;&lt;blockquote class="wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p id="d176"&gt;乐高的人就此发表了一次非常鼓舞人心的演讲，我很高兴听到他们&lt;strong&gt;给出了正确的方法和良好的计划。这可以是一个持续的过程。从小事做起，很快就能获得收益。&lt;/strong&gt;在整个会议期间以及闲聊中，我越来越多地听到这样的说法。这即使不是一个热门话题，也绝对是我觉得有必要调查的事情。&lt;/p&gt;&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;演讲： &lt;a href="https://www.youtube.com/watch?v=SmeekXGYuFU&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=109" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;保持积木流动：乐高集团的制造平台工程方法&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading" id="4e49"&gt;&lt;strong&gt;社区和包容性&lt;/strong&gt;&lt;/h2&gt;&lt;p id="1dc2"&gt;从适合儿童的课程到听力障碍人士的突破。看到为实现这一目标付出了多少努力和努力，我印象非常深刻。这些概念让人感觉非常熟悉——是会议不可或缺的一部分。我什至尝试参加学习手语！&lt;/p&gt;&lt;p id="bf42"&gt;有些概念可以帮助新手提交代码、无代码并学习如何参与的诀窍。我本人在 KubeCon 前几个月首次提交了 Kubernetes SIG 项目，维护人员在指导完成棘手部分以确保代码与项目保持一致并正确记录方面所提供的帮助给我留下了深刻的印象。在开发方面，我不是一个“强硬的人”，我用它来自动化、工具化等——但它感觉充满力量。虽然我喜欢开发，但我会坚持我的日常工作，运维才是未来！你首先从我那里听到的。 😉&lt;/p&gt;&lt;p id="f06b"&gt;在今年的 KubeCon 上，无论我走到哪里，脸上都洋溢着笑容。脱离同事让我们能够独立探索更多曲目，并计划稍后重新组合。与志同道合的新人交往和建立联系的机会令人兴奋。然而，这一次对我来说最引人注目的是北欧社区的非凡存在。感觉就像是一次重聚；我认出了许多熟悉的面孔，相互之间的热情问候证明了当时的云原生北欧社区的成长。&lt;/p&gt;&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p id="6946"&gt;&lt;strong&gt;这次经历衷心地提醒我们，我们的社区已经变得多么紧密相连和充满活力！&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="4122"&gt;最后，在等待演讲或在咖啡桌前排队时与我交谈过的许多人都是第一次参加。他们中的许多人对 Kubernetes 或云原生领域了解不多，但非常有兴趣了解其他公司的经验，甚至我从与这些人的交谈中也学到了一些东西。我们可以从每个角落学到一些东西。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;主题演讲： &lt;a href="https://www.youtube.com/watch?v=vwZANXuYdRI" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;主题小组讨论：多样性中的统一&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading" id="a370"&gt;&lt;strong&gt;我们发现有趣的其他相关演讲：&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="cd75"&gt;&lt;strong&gt;从 CNI 零到 CNI 英雄：实践教程&lt;/strong&gt;&lt;/h3&gt;&lt;p id="f2b0"&gt;Doug 和 Tomo 的“K8s CNI 从零到英雄”演讲是一次进入容器网络接口 (CNI) 世界的旅程。从零开始，我们对 CNI 的世界有了全面的了解。&lt;/p&gt;&lt;p id="9600"&gt;演讲结束后，我们对 CNI 的内部运作有了更深入的了解，也对解决问题和向集群引入新功能有了了解。对于那些对演讲感兴趣的人，随附的 Git 存储库和演示视频提供了一个了解并深入研究 Kubernetes CNI 世界的机会。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;视频和 GIT ： &lt;a href="https://github.com/dougbtv/cni-hero-hands-on" rel="noreferrer noopener" target="_blank"&gt;https://github.com/dougbtv/cni-hero-hands-on&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;演讲&lt;/strong&gt;：&lt;a href="https://www.youtube.com/watch?v=YumoKGhuZ2o" rel="noreferrer noopener" target="_blank"&gt;教程：从 CNI 零到 CNI 英雄：使用 CNI 的 Kubernetes 网络教程&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="b4a7"&gt;&lt;strong&gt;你的镜像真的是无Distroless的吗？ — 劳伦特·戈德尔，Docker&lt;/strong&gt;&lt;/h3&gt;&lt;p id="b832"&gt; Laurent Goderre 的演讲“你的图像真的没有 Distroless 吗？”深入研究使用多阶段构建和 distroless 容器概念制作简约 Docker 镜像的复杂性。演讲强调了 Docker 中多阶段构建的重要性，强调构建时依赖项与运行时依赖项的分离。&lt;/p&gt;&lt;p id="7b51"&gt;许多应用程序需要额外的工具（例如 shell）来有效配置运行时环境。 Goderre 建议使用&lt;strong&gt;init 容器&lt;/strong&gt;来应对这一挑战。通过将配置运行时环境所需的逻辑与环境本身分离，开发人员可以创建没有 shell 或脚本功能的镜像，从而增强容器的安全性。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;谈话&lt;/strong&gt;：&lt;a href="https://www.youtube.com/watch?v=1iJTyf4O8T8" rel="noreferrer noopener" target="_blank"&gt;你的镜像真的是 Distroless 吗？ — 劳伦特·戈德尔，Docker&lt;/a&gt;&lt;/li&gt;&lt;li&gt; &lt;strong&gt;GIT&lt;/strong&gt; ： &lt;a href="https://github.com/LaurentGoderre/kubecon-cloudnative-eu-2024-distroless" rel="noreferrer noopener" target="_blank"&gt;https://github.com/LaurentGoderre/kubecon-cloudnative-eu-2024-distroless&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="c0c6"&gt;&lt;strong&gt;为什么 Kubernetes 不适合平台，以及如何让它变得更好&lt;/strong&gt;&lt;/h3&gt;&lt;p id="5513"&gt;当前的趋势是生态系统在 Kubernetes 上构建平台，从“中心集群”开始，集成 GitOps、应用程序描述和基础设施管理的各种工具。然而，随着这些平台的发展，它们很快就会遇到 Kubernetes 作为框架的固有限制。&lt;br /&gt;&lt;br /&gt;在本次演讲中，重点强调了三个关键维度，以增强 Kubernetes 的平台工程、工作空间层次结构、跨工作空间 API 导出和集群安装。&lt;/p&gt;&lt;p id="ddc0"&gt; KCP，被描述为类似 Kubernetes 的控制平面，是作为满足这些维度的解决方案而引入的。它可以管理多个独立、隔离的“集群”（称为工作区），允许 API 服务提供商提供集中管理的 API，同时确保用户在各自的工作区中轻松使用。这种方法被定位为 SaaS 服务提供商和企业 IT 部门的构建块，旨在为孤立的租户提供 Kubernetes 原生 API。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;视频： &lt;a href="https://www.youtube.com/watch?v=7op_r9R0fCo" rel="noreferrer noopener" target="_blank"&gt;https://www.youtube.com/watch?v&lt;/a&gt; =7op_r9R0fCo&lt;/li&gt;&lt;li&gt;项目： &lt;a href="https://github.com/kcp-dev/kcp" rel="noreferrer noopener" target="_blank"&gt;https://github.com/kcp-dev/kcp&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading" id="e866"&gt;需要关注的项目：&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="7f95"&gt; KCL：基于约束的记录和函数语言&lt;/h3&gt;&lt;p id="81a1"&gt;KCL 是最终用户提交数量排名前 10 的 CNCF 项目中的第二个项目，表明根据用户贡献，云原生计算基金会 (CNCF) 生态系统中最活跃的项目。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://miro.medium.com/v2/resize:fit:700/1*c8r0BYHn3OU21OmfYJLIzg.jpeg" /&gt;&lt;/figure&gt;&lt;p id="0915"&gt; KCL 是一种开源的、基于约束的记录和函数语言，可以增强复杂配置的编写，包括云原生场景的配置。凭借其先进的编程语言技术和实践，KCL 致力于促进更好的模块化、可扩展性和配置稳定性。它支持更简单的逻辑编写，并提供易于自动化的 API 以及与本土系统的集成。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;项目： &lt;a href="https://github.com/kcl-lang/kcl" rel="noreferrer noopener" target="_blank"&gt;https://github.com/kcl-lang/kcl&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="ba25"&gt;&lt;strong&gt;维特斯&lt;/strong&gt;&lt;/h3&gt;&lt;p id="1dbf"&gt;Vitess 是一个数据库集群系统，通过通用分片来水平扩展 MySQL。&lt;/p&gt;&lt;p id="2fbb"&gt;通过封装分片路由逻辑，Vitess 允许应用程序代码和数据库查询与多个分片上的数据分布无关。借助 Vitess，您甚至可以根据需求的增长来拆分和合并分片，原子切换步骤只需几秒钟。&lt;/p&gt;&lt;p id="b8de"&gt;自 2011 年以来，Vitess 一直是&lt;strong&gt;YouTube&lt;/strong&gt;数据库基础设施的核心组件，并已发展到包含数万个 MySQL 节点。 Vitess 2010 年&lt;a href="https://vitess.io/docs/overview/history/" rel="noreferrer noopener" target="_blank"&gt;出生于 YouTube&lt;/a&gt; ， &lt;a href="https://www.cncf.io/blog/2018/02/05/cncf-host-vitess/" rel="noreferrer noopener" target="_blank"&gt;2018 年 2 月&lt;/a&gt;加入 CNCF。&lt;/p&gt;&lt;p id="326c"&gt; Vitess 的一些功能包括&lt;strong&gt;在线模式更改&lt;/strong&gt;，Vitess 解决了最古老的 MySQL 模式阻塞问题之一， &lt;a href="https://vitess.io/docs/archive/13.0/user-guides/schema-changes/" rel="noreferrer noopener" target="_blank"&gt;请参阅文档&lt;/a&gt;- 其他值得注意的功能包括可扩展性、性能、连接池、可管理性等等！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;项目&lt;/strong&gt;： &lt;a href="https://vitess.io/" rel="noreferrer noopener" target="_blank"&gt;vitess.io&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;演讲&lt;/strong&gt;： &lt;a href="https://www.youtube.com/watch?v=uRB-Qni_bCM&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=40" rel="noreferrer noopener" target="_blank"&gt;Vitess：简介、新功能和 Vinted 用户故事&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="7929"&gt;集群库存 API&lt;/h3&gt;&lt;p id="0398"&gt; ClusterInventory API 为任何多集群应用程序（框架、工具集）提供可靠、一致且自动化的方法，以发现可用集群并采取相应的操作，其方式类似于微服务架构中的服务发现工作方式。通过清单，应用程序可以查询要访问的集群列表，或者监视不断流动的集群生命周期事件流，应用程序可以及时采取行动，例如自动扩展、升级、故障和连接问题。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;项目&lt;/strong&gt;： &lt;a href="https://github.com/kubernetes-sigs/cluster-inventory-api" rel="noreferrer noopener" target="_blank"&gt;https://github.com/kubernetes-sigs/cluster-inventory-api&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="628c"&gt;韩国共产党&lt;/h3&gt;&lt;p id="94a4"&gt;kcp 可以成为 SaaS 服务提供商的构建块，这些服务提供商需要大规模多租户平台，以便使用 Kubernetes 原生 API 为大量完全隔离的租户提供服务。目标是对云提供商以及在公司内部提供 API 的企业 IT 部门有用。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;项目&lt;/strong&gt;： &lt;a href="https://github.com/kcp-dev/kcp" rel="noreferrer noopener" target="_blank"&gt;https://github.com/kcp-dev/kcp&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="17b5"&gt;薄荷工具包&lt;/h3&gt;&lt;p id="7153"&gt;Mint 工具包，以前称为 DockerSlim。 &lt;strong&gt;Mint&lt;/strong&gt;允许开发人员使用&lt;code&gt;xray&lt;/code&gt; 、 &lt;code&gt;lint&lt;/code&gt; 、 &lt;code&gt;build&lt;/code&gt; 、 &lt;code&gt;debug&lt;/code&gt; 、 &lt;code&gt;run&lt;/code&gt; 、 &lt;code&gt;images&lt;/code&gt; 、 &lt;code&gt;merge&lt;/code&gt; 、 &lt;code&gt;registry&lt;/code&gt; 、 &lt;code&gt;vulnerability&lt;/code&gt; （和其他）命令检查、优化和调试他们的容器。&lt;strong&gt;它简化并改善了开发人员构建、定制和使用容器的体验&lt;/strong&gt;。&lt;strong&gt;它使您的容器更好、更小、更安全，&lt;/strong&gt;同时提供高级可见性并提高与原始容器和缩小容器一起使用的可用性。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;项目&lt;/strong&gt;： &lt;a href="https://github.com/mintoolkit/mint" rel="noreferrer noopener" target="_blank"&gt;https://github.com/mintoolkit/mint&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="6684"&gt;塔洛斯&lt;/h3&gt;&lt;p id="83ae"&gt;&lt;strong&gt;Talos&lt;/strong&gt;是一个用于运行 Kubernetes 的现代操作系统：安全、不可变且最小化。 Talos 完全开源，可投入生产，并由&lt;a href="https://www.siderolabs.com/" rel="noreferrer noopener" target="_blank"&gt;Sidero Labs&lt;/a&gt;的人员提供支持。所有系统管理均通过 API 完成 -&lt;strong&gt;没有 shell 或交互式控制台&lt;/strong&gt;。好处包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;安全性&lt;/strong&gt;：Talos 减少了您的攻击面：它是最小的、强化的且不可变的。所有 API 访问均通过相互 TLS (mTLS) 身份验证进行保护。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可预测性&lt;/strong&gt;：Talos 消除了配置漂移，通过采用不可变的基础设施理念减少未知因素，并提供原子更新。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可进化性&lt;/strong&gt;：Talos 简化了您的架构，提高了敏捷性，并始终提供当前稳定的 Kubernetes 和 Linux 版本。&lt;/li&gt;&lt;/ul&gt;&lt;p id="1fab"&gt;&lt;strong&gt;项目&lt;/strong&gt;： &lt;a href="https://github.com/siderolabs/talos" rel="noreferrer noopener" target="_blank"&gt;https://github.com/siderolabs/talos&lt;/a&gt;&lt;/p&gt;&lt;h2 class="wp-block-heading" id="7785"&gt;所有 KubeCon + CloudNativeCon 2024 演讲&lt;/h2&gt;&lt;p id="3e92"&gt;CNCF 很快就在 YouTube 上获得了几乎所有的内容，他们提供了一个包含所有内容的漂亮播放列表。 &lt;/p&gt;&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;/div&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading" id="a190"&gt;最后的评论&lt;/h2&gt;&lt;p id="6855"&gt;以上绝不是 KubeCon + CloudNativeCon 2024 的全部综述，只是我们的观点——活动中还有数百场演讲、研讨会和会议。如果您有兴趣，我强烈建议您参加。保持开放的心态，做好计划。我发现随机挑选一些演讲也很令人耳目一新，也许那些与你当前的兴趣和/或职位并不100%相关的演讲，想法可以来自任何角落！&lt;/p&gt;&lt;p id="4578"&gt;下次 KubeCon 再见，如果您不能坚持到那时，今年&lt;strong&gt;丹麦&lt;/strong&gt;总会有&lt;strong&gt;Kubernetes 社区日&lt;/strong&gt;！请继续关注或访问&lt;a href="https://kcddenmark.dk/" rel="noreferrer noopener" target="_blank"&gt;https://kcddenmark.dk/&lt;/a&gt; ！！！ &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Mon, 22 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/23/a-recap-kubecon-cloudnativecon-europe-2024/</guid></item><item><title>使用 GreptimeDB 和 Streamlit 解码您的日常打字习惯</title><link>https://www.cncf.io/blog/2024/04/23/decoding-your-daily-typing-habits-with-greptimedb-and-streamlit/</link><description>&lt;p&gt;&lt;em&gt;会员帖子最初由 Tison 发布在&lt;a href="https://medium.com/greptime/keyboard-monitoring-and-visualization-with-greptimedb-and-streamlit-489b45764cf6"&gt;Greptime 的博客&lt;/a&gt;上&lt;/em&gt;&lt;/p&gt;&lt;p id="9e63"&gt;如今，打字对于大多数人来说几乎是每天都会发生的事情。有趣的是，您的打字习惯可能与您想象的有很大不同。下面，您将找到一个仪表板，它提供了我自己的打字倾向的可视化。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://miro.medium.com/v2/resize:fit:1400/0*fLdhaOa4bajXPbDb" /&gt;&lt;/figure&gt;&lt;p id="566d"&gt;预计我总是使用&lt;code&gt;Key.space&lt;/code&gt;来确认我的输入，并使用&lt;code&gt;Key.cmd + Key.tab&lt;/code&gt;在窗口之间切换，因为我只有一台显示器。但令人惊讶的是，我输入&lt;code&gt;Key.cmd + v&lt;/code&gt;频率比输入&lt;code&gt;Key.cmd + c&lt;/code&gt;频率要高得多，而且我总是无意识地输入&lt;code&gt;Key.cmd + s&lt;/code&gt; ，尽管我的大多数编辑器现在都可以自动保存。&lt;/p&gt;&lt;p id="7529"&gt;如果您觉得有趣，本文将告诉您如何为您构建这样的仪表板。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="9b01"&gt;先决条件&lt;/h2&gt;&lt;p id="86f8"&gt;构建此仪表板所需的所有源代码都可以在 GreptimeTeam/demo-scene 存储库中找到。&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt; &lt;a href="https://www.cncf.io/blog/2024/04/23/decoding-your-daily-typing-habits-with-greptimedb-and-streamlit/demo-scene/keyboard-monitor%20at%20main%20%C2%B7%20GreptimeTeam/demo-scene"&gt;&lt;img alt="附有超链接的 Github 图像" class="wp-image-105736" height="374" src="https://www.cncf.io/wp-content/uploads/2024/04/image-17.png" width="1390" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading" id="b1a5"&gt;什么是 Streamlit？&lt;/h2&gt;&lt;p id="69b0"&gt;在本演示中，我们使用 Streamlit 来显示输入频率。&lt;/p&gt;&lt;p id="92d3"&gt; &lt;a href="https://streamlit.io/" rel="noreferrer noopener" target="_blank"&gt;Streamlit&lt;/a&gt;是一个免费的开源框架，用于快速构建和共享精美的数据科学 Web 应用程序。它是一个专门为数据工程师设计的基于Python的库。 Streamlit 可以轻松显示数据并收集建模所需的参数，使用户只需几行代码即可创建令人惊叹的应用程序。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="c8c4"&gt;什么是 GreptimeDB？&lt;/h2&gt;&lt;p id="5525"&gt;在此演示中，我们将键盘输入事件存储到 GreptimeDB 集群中。&lt;/p&gt;&lt;p id="16ef"&gt; &lt;a href="https://github.com/GreptimeTeam/greptimedb" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;GreptimeDB&lt;/strong&gt;&lt;/a&gt;是一个开源时间序列数据库，专注于效率、可扩展性和分析能力。 GreptimeDB 专为云时代的基础设施而设计，以其弹性和商品存储为用户带来好处，&lt;strong&gt;为 InfluxDB 提供快速且经济高效的替代方案&lt;/strong&gt;，并&lt;strong&gt;为 Prometheus 提供长期存储&lt;/strong&gt;。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="b8b0"&gt;准备环境&lt;/h2&gt;&lt;p id="710e"&gt;现在，克隆源代码并安装所有依赖项：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;git clone https://github.com/GreptimeTeam/demo-scene.git&lt;br /&gt; cd demo-scene/keyboard-monitor&lt;br /&gt; pip3 install -r requirements.txt&lt;/code&gt;&lt;/pre&gt;&lt;p id="03eb"&gt;您将安装 Streamlit、SQLAlchemy 以连接到 GreptimeDB，并&lt;a href="https://pynput.readthedocs.io/en/latest/" rel="noreferrer noopener" target="_blank"&gt;安装 pynput&lt;/a&gt;以监视键盘事件。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="9871"&gt;免费获取GreptimeDB集群&lt;/h2&gt;&lt;p id="5634"&gt;获得 GreptimeDB 集群的最快方法是在&lt;a href="https://console.greptime.cloud/" rel="noreferrer noopener" target="_blank"&gt;GreptimeCloud&lt;/a&gt;上启动爱好计划（完全免费，无需信用卡信息）服务。&lt;/p&gt;&lt;p id="a15f"&gt;按照说明获取新的 GreptimeDB 服务，前往其“连接”选项卡并找到正在使用的 MySQL 连接字符串。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://miro.medium.com/v2/resize:fit:1400/0*HDLQO4_uPCG3lyOg" /&gt;&lt;figcaption class="wp-element-caption"&gt;转到服务的“连接”选项卡&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="3ad5"&gt;创建一个名为&lt;code&gt;.env&lt;/code&gt;的文件，其中包含以下内容（将相应字段替换为连接字符串）：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;DATABASE_URL=mysql://[username]:[password]@[hostname]:4002/[database]&lt;/code&gt;&lt;/pre&gt;&lt;p id="be82"&gt;现在，所有设置都已完成。转到下一步以捕获您的打字行为。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="a0a1"&gt;启动键盘监视器&lt;/h2&gt;&lt;p id="65cb"&gt;运行代理脚本以监听键盘输入：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;python3 agent.py&lt;/code&gt;&lt;/pre&gt;&lt;p id="b232"&gt;您应该看到如下日志：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;2024-03-07 20:57:53,799 INFO listener_thread Listening...&lt;/code&gt;&lt;/pre&gt;&lt;p id="8463"&gt;然后，像往常一样在任何窗口中继续输入，您将发现终端运行代理脚本日志，如下所示：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;2024-03-07 20:58:01,510 INFO sender_thread sent: Key.backspace&lt;br /&gt; 2024-03-07 20:58:01,947 INFO sender_thread sent: Key.enter&lt;br /&gt; 2024-03-07 20:58:02,498 INFO sender_thread sent: Key.shift+&amp;#39;#&amp;#39;&lt;br /&gt; 2024-03-07 20:58:02,938 INFO sender_thread sent: Key.space&lt;br /&gt; 2024-03-07 20:58:03,377 INFO sender_thread sent: Key.cmd+Key.right&lt;br /&gt; 2024-03-07 20:58:04,052 INFO sender_thread sent: Key.cmd+&amp;#39;s&amp;#39;&lt;br /&gt; ...&lt;/code&gt;&lt;/pre&gt;&lt;h2 class="wp-block-heading" id="a47a"&gt;查询键盘输入统计信息&lt;/h2&gt;&lt;p id="f0fc"&gt;当您看到“sender_thread sent”日志时，这意味着 GreptimeDB 服务现在正在接收键入事件。您可以在 GreptimeCloud Web Dashboard 上查询输入统计信息： &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://miro.medium.com/v2/resize:fit:1400/0*N6hbicDZ8od_x4qm" /&gt;&lt;figcaption class="wp-element-caption"&gt;门户 → 网络仪表板&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="单击 + 按钮创建查询" src="https://miro.medium.com/v2/resize:fit:1400/0*AX7MZmHbyN6t1R1t" /&gt;&lt;figcaption class="wp-element-caption"&gt;单击“+”按钮创建查询&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="f298"&gt;例如，您可以使用标准 SQL 查找最常见的键：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;SELECT hits, COUNT(*) as times&lt;br /&gt; FROM keyboard_monitor&lt;br /&gt; WHERE hits NOT LIKE &amp;#39;%+%&amp;#39;&lt;br /&gt; GROUP BY hits&lt;br /&gt; ORDER BY times DESC limit 10;&lt;/code&gt;&lt;/pre&gt;&lt;p id="b235"&gt;要计算每分钟的点击量，您可以利用 GreptimeDB 强大的&lt;a href="https://docs.greptime.com/reference/sql/range" rel="noreferrer noopener" target="_blank"&gt;RANGE QUERY&lt;/a&gt; ：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;SELECT ts, COUNT(1) RANGE &amp;#39;1h&amp;#39; as times FROM keyboard_monitor ALIGN &amp;#39;1h&amp;#39; ORDER BY ts DESC LIMIT 10;&lt;/code&gt;&lt;/pre&gt;&lt;h2 class="wp-block-heading" id="0b95"&gt;使用 Streamlit 进行可视化&lt;/h2&gt;&lt;p id="28c1"&gt;将 GreptimeDB 与 Streamlit 集成非常容易，因为它可以被视为 SQL 后端，无需开发额外的集成层。因此，您可以轻松地利用 Streamlit 来可视化您的输入频率。&lt;/p&gt;&lt;p id="f6d2"&gt;运行以下脚本：streamlit run display.py&lt;/p&gt;&lt;p id="f56a"&gt;它将在浏览器中打开一个窗口 (http://localhost:8501/) 并显示数据框： &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="键盘监视器" src="https://miro.medium.com/v2/resize:fit:1400/0*t2hoX5f6TX8tSBMM" /&gt;&lt;/figure&gt;&lt;p id="0947"&gt;就这样！&lt;/p&gt;&lt;p id="ef07"&gt;总而言之，在本指南中，我们向您展示了如何创建仪表板来监控您的打字习惯。我们邀请您亲自踏上这段发现和实验之旅。您可能会发现有关您的行为的有趣见解，这是您以前从未考虑过的。此外，请随意使用 GreptimeDB 探索其他行为，并在 X (Twitter) 或我们的讨论论坛上分享您的发现和演示。&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt; &lt;a href="https://github.com/orgs/GreptimeTeam/discussions?source=post_page-----489b45764cf6--------------------------------"&gt;&lt;img alt="GreptimeDB 讨论论坛" class="wp-image-105737" height="358" src="https://www.cncf.io/wp-content/uploads/2024/04/image-18.png" width="1390" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading" id="4290"&gt;&lt;strong&gt;关于Greptime&lt;/strong&gt;&lt;/h2&gt;&lt;p id="db26"&gt;我们帮助生成大量时序数据的行业，例如车联网 (CV)、物联网和可观测性，实时有效地发现数据的隐藏价值。&lt;/p&gt;&lt;p id="1e18"&gt;从任何设备访问&lt;a href="https://www.greptime.com/resources" rel="noreferrer noopener" target="_blank"&gt;最新版本 v0.7&lt;/a&gt;即可开始并充分利用您的数据。&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;a href="https://github.com/GreptimeTeam/greptimedb" rel="noreferrer noopener" target="_blank"&gt;GreptimeDB&lt;/a&gt;用 Rust 编写，是一个分布式开源时间序列数据库，专为可扩展性、效率和强大的分析而设计。&lt;/li&gt;&lt;li&gt; &lt;a href="https://www.greptime.com/product/cloud" rel="noreferrer noopener" target="_blank"&gt;GreptimeCloud&lt;/a&gt;提供完全托管的 DBaaS，与可观测性和物联网领域完美集成。&lt;/li&gt;&lt;li&gt; &lt;a href="https://www.greptime.com/product/ai" rel="noreferrer noopener" target="_blank"&gt;GreptimeAI&lt;/a&gt;是专为 LLM 应用程序量身定制的可观察性解决方案。&lt;/li&gt;&lt;/ul&gt;&lt;p id="6ccf"&gt;如果以上任何内容引起了您的注意，请随时在&lt;a href="https://github.com/GreptimeTeam/greptimedb" rel="noreferrer noopener" target="_blank"&gt;GitHub&lt;/a&gt;上为我们加注星标或加入&lt;a href="https://www.greptime.com/slack" rel="noreferrer noopener" target="_blank"&gt;Slack&lt;/a&gt;上的 GreptimeDB 社区。此外，您还可以访问我们的&lt;a href="https://github.com/GreptimeTeam/greptimedb/contribute" rel="noreferrer noopener" target="_blank"&gt;贡献页面&lt;/a&gt;来查找一些有趣的问题。 &lt;/p&gt;&lt;p&gt;&lt;a href="https://medium.com/@tisonkun?source=post_page-----489b45764cf6--------------------------------"&gt;&lt;/a&gt;&lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Mon, 22 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/23/decoding-your-daily-typing-habits-with-greptimedb-and-streamlit/</guid></item><item><title>Cloud Custodian 完成审核以加强安全态势并实现持续评估</title><link>https://www.cncf.io/blog/2024/04/19/cloud-custodian-completes-audit-to-strengthen-security-posture-and-enable-continuous-assessment/</link><description>&lt;p&gt;&lt;em&gt;Cloud Custodian 维护人员发布的项目&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Cloud Custodian 维护人员很高兴通过 Ada Logics 成功完成安全审核。开源技术改进基金 (OSTIF) 促进了此次审计，并由云原生计算基金会 (CNCF) 慷慨资助。此次审核标志着我们持续致力于加强 Cloud Custodian 安全状况的重要一步。&lt;/p&gt;&lt;p&gt;多年来，Cloud Custodian 已成为云治理事实上的标准。该项目允许您对治理的各个方面进行编码和自动化，包括运营、成本、安全性和语言。数千个全球品牌使用 Cloud Custodian，其贡献者超过 400 名。在审核之前，Cloud Custodian 实施了强大的安全措施来保障其运营：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;静态分析：&lt;/strong&gt;使用 Semgrep 和 Bandit 工具扫描所有拉取请求，确保在开发过程的早期识别并纠正代码漏洞。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;安全工件：&lt;/strong&gt; Docker 镜像工件通过使用 Cosign 签名的源元数据进行发布，从而增强了我们发行版的完整性。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;安全发布&lt;/strong&gt;：每次发布都使用冻结的依赖关系图进行，这可以防止注入攻击并确保可重复性。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;审计的目标和过程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Ada Logics 发起的审计的主要目标是加强 Cloud Custodian 的安全框架。该过程始于开发一个全面的威胁模型，作为审计的路线图。该模型在整个审计过程中不断完善，增强了我们对潜在安全威胁的理解和响应。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;主要活动&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;威胁模型形式化：&lt;/strong&gt;建立正式的威胁模型是至关重要的第一步，它提供了识别和减轻风险的结构化方法。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;代码审计：&lt;/strong&gt;对 Cloud Custodian 代码库的审查导致了各种安全漏洞的识别和修复。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Fuzzing 集成：&lt;/strong&gt;一个重要的里程碑是将 Cloud Custodian 集成到 OSS-Fuzz 中。此举有利于持续的安全测试，从而能够持续发现和解决漏洞。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模糊测试套件开发：&lt;/strong&gt; Ada 团队专门为 Cloud Custodian 开发了一个有针对性的模糊测试套件。该套件不仅测试 Cloud Custodian 抵御攻击的能力，还为持续的安全评估建立了可持续的基础设施。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;审计增强功能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;审计后，进行了几项关键改进：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;安全修复：&lt;/strong&gt;进行了调整以纠正与临时文件和 URL 处理相关的不安全做法。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;增强测试：&lt;/strong&gt; OSS-Fuzz测试的引入进一步增强了我们的安全测试能力，确保对潜在威胁的持续警惕。&lt;/p&gt;&lt;p&gt;从这次审计中获得的见解非常宝贵，并且对增强 Cloud Custodian 的安全状况做出了重大贡献。我们仍然致力于持续改进 Cloud Custodian，确保其安全并领先于现代安全威胁。&lt;/p&gt;&lt;p&gt;我们感谢 Ada Logics 的细致工作、OSTIF 的协助以及 CNCF 的支持。这种协作努力强调了我们致力于提供满足云治理不断变化的需求的安全工具的承诺。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://cloudcustodian.io/"&gt;云托管网站&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://github.com/cloud-custodian/cloud-custodian"&gt;云托管 Github&lt;/a&gt;&lt;/p&gt;&lt;p&gt; OSTIF 博客文章： &lt;a href="http://ostif.org/cc-audit-complete/"&gt;ostif.org/cc-audit-complete/&lt;/a&gt; &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Thu, 18 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/19/cloud-custodian-completes-audit-to-strengthen-security-posture-and-enable-continuous-assessment/</guid></item><item><title>KubeCon + CloudNativeCon 2024 回顾：亮点和要点</title><link>https://www.cncf.io/blog/2024/04/19/kubecon-cloudnativecon-2024-recap-highlights-and-takeaways/</link><description>&lt;p&gt;&lt;em&gt;社区帖子最初由 Maryam Tavakkoli 发表在&lt;a href="https://medium.com/womenintechnology/kubecon-cloudnativecon-2024-recap-highlights-and-takeaways-dfe4b6dd7159"&gt;Medium&lt;/a&gt;上&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="KubeCon 巴黎" src="https://miro.medium.com/v2/resize:fit:1400/1*WntJArILgmosjRr2DB0Ghw.jpeg" /&gt;&lt;/figure&gt;&lt;p id="7525"&gt;今年，我有机会参加了在巴黎举行的 KubeCon + CloudNativeCon Europe。虽然这标志着我第二次亲自参加 KubeCon，但这是我作为大使和社区成员的第一次经历（您可以在这里找到&lt;a href="https://medium.com/@maryam.tavakoli.3/a-comprehensive-report-on-my-first-in-person-attendance-at-kubecon-cloudnativecon-2023-europe-cbabee1bb313"&gt;我第一次 KubeCon 2023 经历的&lt;/a&gt;见解。）。在本文中，我旨在总结我在该活动中的经历和观察，希望为云原生技术和社区协作的动态世界提供见解。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="46e3"&gt;云原生拒绝&lt;/h2&gt;&lt;p id="03f5"&gt;无论是过去还是今年，我都没有亲自参加过&lt;a href="https://cloud-native.rejekts.io/" rel="noreferrer noopener" target="_blank"&gt;Cloud Native Rejekts&lt;/a&gt;活动。然而，通过与 KubeCon 与会者的交谈，我注意到有些人并不知道这一事件。因此，我想简单介绍一下 Cloud Native Rejekts 事件。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="拒绝事件" src="https://miro.medium.com/v2/resize:fit:1400/1*XEToPhFpVts5szKQdFKdfg.png" /&gt;&lt;figcaption class="wp-element-caption"&gt; &lt;a href="https://cloud-native.rejekts.io/" rel="noreferrer noopener" target="_blank"&gt;https://cloud-native.rejekts.io/&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="9796"&gt;正如会议网站所述：&lt;/p&gt;&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p id="4a64"&gt; Cloud Native Rejekts 是一个 B 端会议，为 KubeCon + CloudNativeCon 拒绝的许多精彩演讲提供了第二次机会。&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="af5c"&gt;这种现场会议通常在 KubeCon 主要活动前几天举行，今年于 3 月 17 日至 18 日举行。 &lt;a href="https://www.youtube.com/watch?v=qTBHjTQ4KWc&amp;amp;list=PLnfCaIV4aZe86GBQ0GWT3JA4IG6Z7gpH_" rel="noreferrer noopener" target="_blank"&gt;会议录音&lt;/a&gt;可供查看。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="d38c"&gt;欧洲贡献者峰会&lt;/h2&gt;&lt;p id="7077"&gt;3 月 19 日在巴黎与 KubeCon + CloudNativeCon 一起举行的 &lt;a href="https://www.kubernetes.dev/events/2024/kcseu/" rel="noreferrer noopener" target="_blank"&gt;贡献者峰会&lt;/a&gt;是我第一次参加该活动。如需参加，注册仅限&lt;a href="https://www.kubernetes.dev/events/2024/kcseu/faq/#why-do-i-need-to-be-a-kubernetes-org-member-to-attend-in-person" rel="noreferrer noopener" target="_blank"&gt;Kubernetes 组织&lt;/a&gt;之一的成员或赞助的与会者。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="KubeCon 巴黎" src="https://miro.medium.com/v2/resize:fit:1400/1*CA-VZ7Rb8quPbZ_jUEZ5tg.jpeg" /&gt;&lt;figcaption class="wp-element-caption"&gt; &lt;a href="https://www.flickr.com/photos/143247548@N03/albums/with/72177720315666206" rel="noreferrer noopener" target="_blank"&gt;CNCF Flickr 帐户&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="4bfc"&gt;贡献者峰会通常包括会谈、非会议会议以及 SIG 和 WG 会议。尽管我是中午抵达巴黎，但我还是按照计划享用了专属午餐并履行了峰会志愿者职责。与社区成员一起吃饭提供了一个宝贵的机会，可以与我以前只在网上认识的人建立联系，这是这一天的一个很好的开始！&lt;/p&gt;&lt;h3 class="wp-block-heading" id="0b25"&gt;志愿服务&lt;/h3&gt;&lt;p id="68d9"&gt;贡献者峰会很大程度上取决于社区内志愿者的出色努力。我对这个过程很感兴趣，决定亲自体验一下，并自愿主持两场演讲。我强烈鼓励 Kubernetes 组织的成员参加本次活动，并考虑自愿承担任何力所能及的任务，因为正是这些贡献使本次活动成为可能。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="a9b5"&gt;同期举办活动&lt;/h2&gt;&lt;p id="0a56"&gt;我在之前的文章中讨论了 KubeCon 的布局，您可以在这里找到该文章： &lt;a href="https://faun.pub/get-the-most-out-of-kubecon-cloudnativecon-eu-2024-essential-tips-for-an-exceptional-experience-bba406537774" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;充分利用 KubeCon + CloudNativeCon EU 2024：获得卓越体验的基本技巧&lt;/strong&gt;&lt;/a&gt;。如前所述，KubeCon 的第一天致力于同期举办的活动。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="欧洲ArgoCon" src="https://miro.medium.com/v2/resize:fit:1400/1*kLRylEKG8zxWbRW8jFCsIg.jpeg" /&gt;&lt;figcaption class="wp-element-caption"&gt; &lt;a href="https://www.flickr.com/photos/143247548@N03/albums/with/72177720315666206" rel="noreferrer noopener" target="_blank"&gt;CNCF Flickr 帐户&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="4194"&gt;由于贡献者峰会与同期举办的活动同时进行，我无法参加很多演讲。然而，我特别热衷于参加&lt;a href="https://colocatedeventseu2024.sched.com/overview/type/Platform+Engineering+Day?iframe=no" rel="noreferrer noopener" target="_blank"&gt;Platform Engineering Day&lt;/a&gt;和&lt;a href="https://colocatedeventseu2024.sched.com/overview/type/ArgoCon?iframe=no" rel="noreferrer noopener" target="_blank"&gt;ArgoCon&lt;/a&gt; 。我的同事和朋友的反馈凸显了这两次活动中大量引人入胜的讨论。值得庆幸的是，所有演讲都及时发表，让我和其他人能够跟上。您可以&lt;a href="https://www.youtube.com/@cncf/playlists" rel="noreferrer noopener" target="_blank"&gt;在这里&lt;/a&gt;探索它们。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="66a4"&gt;主题演讲&lt;/h2&gt;&lt;p id="5242"&gt;今年，KubeCon 似乎采取了不同的方法，每天围绕特定主题组织主题演讲和演讲。第一天完全专注于人工智能，主题演讲和大部分演讲都聚焦于人工智能相关主题。 3 月 20 日星期三，KubeCon 的讨论气氛十分活跃。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="KubeCon 欧洲" src="https://miro.medium.com/v2/resize:fit:1400/1*lc8QrDhlZGmO7nQj0EYxWA.jpeg" /&gt;&lt;figcaption class="wp-element-caption"&gt; &lt;a href="https://www.flickr.com/photos/143247548@N03/albums/with/72177720315666206" rel="noreferrer noopener" target="_blank"&gt;CNCF Flickr 帐户&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="2c38"&gt;CNCF 工作人员今年的工作非常出色，并提供了有关每天活动的详细博客文章。我强烈建议您阅读它们以获取更多见解，您可以&lt;a href="https://www.cncf.io/blog/2024/03/20/kubecon-cloudnativecon-europe-2024-day-two-how-cloud-native-is-powering-the-ai-movement-and-other-news/" rel="noreferrer noopener" target="_blank"&gt;在此处&lt;/a&gt;找到第 2 天的博客。&lt;/p&gt;&lt;p id="369e"&gt;第二天的主题是可持续发展，尽管会谈并没有像第一天的人工智能那样完全围绕这个主题。您可以&lt;a href="https://www.cncf.io/blog/2024/03/21/kubecon-cloudnativecon-europe-2024-day-three-the-power-of-sustainable-computing/" rel="noreferrer noopener" target="_blank"&gt;在此处&lt;/a&gt;找到有关第 2 天的更多信息。&lt;/p&gt;&lt;p id="8552"&gt;不幸的是，我本人未能参加第 3 天，但根据 CNCF 博客，主题是反思 Kubernetes 的过去并展望未来。这个主题很可能源于即将到来的&lt;a href="https://events.linuxfoundation.org/kuber10es-birthday-bash/" rel="noreferrer noopener" target="_blank"&gt;Kubernetes 10 周年纪念日&lt;/a&gt;，该周年纪念日定于今年 6 月 6 日举行。现在正是回顾过去十年并展望下一个十年的最佳时机。请&lt;a href="https://www.cncf.io/blog/2024/03/22/kubecon-cloudnativecon-europe-2024-day-four-how-cloud-native-is-powering-the-ai-movement-and-other-news/" rel="noreferrer noopener" target="_blank"&gt;在此处&lt;/a&gt;阅读 CNCF 博客文章。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="KubeCon 欧洲" src="https://miro.medium.com/v2/resize:fit:1400/1*Yvn_k29so0AwIldtAW0E7w.jpeg" /&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading" id="aa0f"&gt;解决方案展示&lt;/h2&gt;&lt;p id="73e5"&gt;与我之前参加过多次演讲的 KubeCon 经历相比，今年我选择将大部分时间花在解决方案展示上并与其他与会者互动 - 我一点也不后悔！&lt;/p&gt;&lt;p id="5a40"&gt;解决方案展示是来自不同公司和项目的专家聚集的中心，提供了与合适的个人联系并交流见解的绝佳机会。特别值得注意的是社区内人们的开放和乐于助人，促进了丰富的对话和新的发现。我很高兴与老朋友重新建立联系并结交新朋友，参与有趣的讨论并扩展我的知识。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="KubeCon 欧洲" src="https://miro.medium.com/v2/resize:fit:1400/1*_DZ13UZyTErcIx_Xn7SoWw.jpeg" /&gt;&lt;figcaption class="wp-element-caption"&gt; &lt;a href="https://www.flickr.com/photos/143247548@N03/albums/with/72177720315666206" rel="noreferrer noopener" target="_blank"&gt;CNCF Flickr 帐户&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="3dc2"&gt;我什至有机会见到了 ArgoCD 的工作人员，我对这个话题有一些具体的问题。他们慷慨地分享了他们的专业知识，花时间展示解决方案并与我深入讨论。&lt;/p&gt;&lt;p id="75f3"&gt;我对未来 KubeCon 与会者的建议是什么？优先参加符合您兴趣的演讲，并提供与演讲者直接接触的机会。然后，将大部分时间用于扩展你的网络、参与对话和培养新的联系。您会发现这些互动本身就是宝贵的学习经历。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="a9d1"&gt;英特尔多元化 + 公平 + 包容性午餐&lt;/h2&gt;&lt;p id="3c94"&gt;去年，我有幸参加了 KubeCon 的多元化午餐，给我留下了深刻的印象。自然，今年我毫不犹豫地再次加入了。顾名思义，该活动提供了一个亲密的环境，参与者可以参与有关多样性和包容性的讨论。与一小群人坐在一起可以促进有意义的联系并可以丰富对话。今年的会议也不例外，我非常享受在那里的时光。我们深入研究了女性在科技行业中的角色，并探讨了导致女性在这些领域代表性不足的因素。听到参与者分享不同的观点和个人故事，揭示这个问题的复杂性，真是令人着迷。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="eb65"&gt;其他相关博客文章&lt;/h2&gt;&lt;p id="835e"&gt;您可以在以下链接中了解其他人在 KubeCon EU 2024 上的体验：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;a href="https://blog.mb-consulting.dev/kubecon-rejekts-kubetrain-kcd-dd68804e9e3e" rel="noreferrer noopener" target="_blank"&gt;https://blog.mb-consulting.dev/kubecon-rejekts-kubetrain-kcd-dd68804e9e3e&lt;/a&gt;&lt;/li&gt;&lt;li&gt; &lt;a href="https://medium.com/@mabenoit/platform-engineering-kubecon-paris-2024-1da02e6247e2"&gt;https://medium.com/@mabenoit/platform-engineering-kubecon-paris-2024-1da02e6247e2&lt;/a&gt;&lt;/li&gt;&lt;li&gt; &lt;a href="https://danielbryantuk.medium.com/kubecon-eu-2024-paris-key-takeaways-ad4c1bb7fbfe"&gt;https://danielbryantuk.medium.com/kubecon-eu-2024-paris-key-takeaways-ad4c1bb7fbfe&lt;/a&gt;&lt;/li&gt;&lt;li&gt; &lt;a href="https://jysk.tech/kubecon-cloudnativecon-europe-2024-694f4b95e99e" rel="noreferrer noopener" target="_blank"&gt;https://jysk.tech/kubecon-cloudnativecon-europe-2024-694f4b95e99e&lt;/a&gt;&lt;/li&gt;&lt;li&gt; &lt;a href="https://www.salaboy.com/2024/03/25/kubecon-eu-2024/" rel="noreferrer noopener" target="_blank"&gt;https://www.salaboy.com/2024/03/25/kubecon-eu-2024/&lt;/a&gt;&lt;/li&gt;&lt;li&gt; &lt;a href="https://www.cncf.io/blog/2024/03/28/missed-kubecon-cloudnativecon-europe-2024-heres-everything-you-need-to-know/" rel="noreferrer noopener" target="_blank"&gt;https://www.cncf.io/blog/2024/03/28/missed-kubecon-cloudnativecon-europe-2024-heres-everything-you-need-to-know/&lt;/a&gt; &lt;/li&gt;&lt;/ul&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="" src="https://miro.medium.com/v2/resize:fit:1400/0*MkqJ5sIq0gIMGHHQ.png" /&gt;&lt;/figure&gt;&lt;p id="08e9"&gt;&lt;em&gt;我很想听听您对本文的想法和反馈。&lt;br /&gt;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;让我们一起继续学习、分享、共同进步！&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;&lt;br /&gt;直到下一次！&lt;/em&gt; &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Thu, 18 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/19/kubecon-cloudnativecon-2024-recap-highlights-and-takeaways/</guid></item><item><title>MTTR 不断上升的挑战——以及该怎么做</title><link>https://www.cncf.io/blog/2024/04/18/the-challenges-of-rising-mttr-and-what-to-do/</link><description>&lt;p&gt;&lt;em&gt;成员帖子，作者： &lt;a href="https://logz.io/author/jake-odonnell/" rel="noreferrer noopener" target="_blank"&gt;Jake O&amp;#39;Donnell&lt;/a&gt; ，Logz.io&lt;/em&gt;&lt;/p&gt;&lt;p&gt;数据量正在飙升。环境变得越来越复杂。应用程序和系统遇到故障的风险非常高，生产事件的平均恢复时间 (MTTR) 正朝着错误的方向发展。&lt;/p&gt;&lt;p&gt;中断不仅会危及关键基础设施，还会直接影响组织的利润。受影响服务的快速恢复变得至关重要，因为它与业务连续性和弹性直接相关。&lt;/p&gt;&lt;p&gt; MTTR 是可观察性的关键指标。它是组织在生产事故后恢复正常能力的晴雨表。事实上，解决这些问题的周转时间越快，企业的航行就越顺利。&lt;/p&gt;&lt;p&gt;从本质上讲，MTTR 不仅是可观察性有效性的关键指标，也是组织整体运营效率的关键指标。&lt;/p&gt;&lt;p&gt;尽管对可观测性解决方案的投资不断增加并且可用工具不断增加，但 MTTR 的轨迹讲述了一个发人深省的故事。对 500 多名 IT 专业人员进行的&lt;a href="https://logz.io/observability-pulse-2024/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;2024 年可观察性脉搏调查&lt;/a&gt;结果表明，他们的组织的 MTTR 正在变长。&lt;/p&gt;&lt;p&gt;这就提出了有关现有可观测系统的有效性以及复杂环境中管理操作事件所采用的策略的相关问题。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt; 2024 年 MTTR 的令人不安的趋势&lt;/h2&gt;&lt;p&gt;我们向 Pulse 受访者询问了几个有关其组织 MTTR 的问题，结果显示组织要么进展甚微，要么倒退。&lt;/p&gt;&lt;p&gt;近 23% 的受访者表示，他们在缩短 MTTR 方面取得了长足进步，另有 9% 的受访者表示，他们已大幅缩短了 MTTR。然而，近五分之一的人表示他们的 MTTR 需要改进，并且大量受访者（41%）表示他们在这一领域进展缓慢。&lt;/p&gt;&lt;p&gt;最重要的是，我们要求受访者描述他们当前生产事故期间的 MTTR。不到五分之一 (18%) 的人表示他们的时间不到一个小时。 44% 的人表示需要几个小时，四分之一的人表示半天。超过十分之一的人表示，从生产事故中恢复需要一天多的时间。一小部分人（2%）表示他们的 MTTR 可能是几周或更长时间。&lt;/p&gt;&lt;p&gt;尽管如此，这意味着 82% 的受访者正在处理超过一个小时的 MTTR。我们的调查结果延续了令人不安的同比趋势。 2021 年，47% 的受访者表示他们的 MTTR 超过 1 小时，2022 年这一比例为 64%，2023 年这一比例将增长至 74%。&lt;/p&gt;&lt;p&gt;这意味着，尽管人们越来越重视可观察性，并且有许多可用的工具和流程旨在帮助从生产事故中恢复，但 MTTR 正朝着错误的方向前进。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;为什么组织的 MTTR 可能会延长？&lt;/h2&gt;&lt;p&gt;组织的 MTTR 持续延长的原因可能因团队而异。然而，2024 年 Pulse 调查的其他一些统计数据提供了有关环境挑战以及这些挑战如何对 MTTR 产生影响的线索。&lt;/p&gt;&lt;p&gt;该调查的另一个主要收获是关于获得云原生环境的可观察性的主要挑战的问题。最常见的反应是团队缺乏知识（48%）。如果近一半的团队在可观察性方面存在&lt;a href="https://logz.io/blog/reduce-mttr-talent-gap-logzio-alert-recommendations/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;知识差距&lt;/a&gt;，那么不难看出这与生产事件导致的 MTTR 缓慢之间存在联系。&lt;/p&gt;&lt;p&gt;此外，42% 的受访者将总拥有成本和大数据量视为云原生可观测性挑战。环境的复杂性以及环境产生的大量数据肯定是 MTTR 缓慢的罪魁祸首。&lt;/p&gt;&lt;p&gt;在思考 MTTR 延长的原因时， &lt;a href="https://logz.io/blog/tracing-your-steps-toward-full-kubernetes-observability/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;Kubernetes&lt;/a&gt;是另一个需要考虑的领域。大约 70% 的组织表示他们已经实施了 Kubernetes、正在开始测试它或将在未来六个月内实施。对于那些运行 Kubernetes 的人来说，40% 的受访者认为监控/故障排除是在生产环境中运行 Kubernetes 的最大挑战。安全性位居第二，为 37%。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;可以采取哪些措施来减少 MTTR？&lt;/h2&gt;&lt;p&gt;降低复杂性可能是&lt;a href="https://logz.io/blog/5-tips-for-faster-troubleshooting-to-reduce-mttr/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;减少 MTTR&lt;/a&gt;的答案之一。作为该战略的一部分，团队可以考虑整合服务。近十分之三 (28%) 的 Pulse 受访者表示，他们计划转向更多可观察性和安全监控的共享模型，这一比例高于 2023 年的 15%。&lt;/p&gt;&lt;p&gt; MTTR 问题还应该激励团队考虑更聪明地工作，而不是更努力地工作。组织可以考虑围绕自动化、人工智能/机器学习和增强监控的技术选项，以实现当今许多团队需要手动操作的流程自动化。&lt;/p&gt;&lt;p&gt; &lt;a href="https://logz.io/platform/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;Logz.io 的 Open 360™ 可观测性平台&lt;/a&gt;旨在帮助组织充分发挥关键系统和应用程序的潜力并缩短 MTTR。借助&lt;a href="https://logz.io/platform/kubernetes-360/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;Kubernetes 360&lt;/a&gt;等解决方案来全面了解基础设施，并&lt;a href="https://logz.io/blog/how-to-implement-app-360/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;使用 App 360&lt;/a&gt;作为传统 APM 的经济高效替代方案，Logz.io 可以帮助&lt;a href="https://logz.io/solutions/accelerate-cloud-monitoring/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;加速您的云监控&lt;/a&gt;并获得更好的立足点以从生产事件中恢复。&lt;/p&gt;&lt;p&gt;借助 Open 360，组织可以利用这些功能来缩短 MTTR，并在出现问题时使生产环境恢复正常：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;a href="https://logz.io/blog/logzio-service-overview-simplify-observability/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;服务概述&lt;/a&gt;将基础设施和应用程序中的遥测数据和见解统一到一个界面中。&lt;/li&gt;&lt;li&gt; &lt;a href="https://logz.io/blog/service-map/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;服务地图&lt;/a&gt;可视化整个微服务架构中的数据流、依赖关系和关键性能指标，以便于调查和故障排除。服务地图会自动发现并映射服务以及它们之间的互连，从而在服务性能的背景下提供整个分布式系统的单一视图。&lt;/li&gt;&lt;li&gt;如果您在跟踪中发现 CPU 指标或延迟出现峰值，您可以通过关联您的日志、指标和跟踪，立即获得有关问题的上下文，并通过我们的&lt;a href="https://logz.io/solutions/accelerate-cloud-monitoring/#correlate?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;事件关联&lt;/a&gt;功能调查生产问题的根本原因。&lt;/li&gt;&lt;li&gt; &lt;a href="https://logz.io/blog/anomaly-detection-application-observability/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;App 360 的异常检测&lt;/a&gt;可让用户自动监控特定服务和微服务中发生的任何问题并发出警报，这些问题是他们认为直接影响业务或 SLO 相关需求的。&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt; &lt;a href="https://logz.io/blog/reduce-mttr-talent-gap-logzio-alert-recommendations/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;警报建议&lt;/a&gt;对平台用户采取的操作进行建模，然后通过监督机器学习建议后续用户在遇到类似问题时该怎么做。&lt;/li&gt;&lt;li&gt; Logz.io 的&lt;a href="https://logz.io/solutions/reduce-observability-costs/#noisy?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;数据优化中心&lt;/a&gt;功能可以轻松删除干扰数据，这些数据会掩盖快速排除故障所需的关键见解。客户可以利用 Logz.io 自助服务工具或我们支持工程师的直接支持来识别和删除噪音数据。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt; &lt;a href="https://logz.io/freetrial/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;立即注册 Open 360 免费试用版，&lt;/a&gt;了解它如何帮助您的组织更好地应对 MTTR。 &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Wed, 17 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/18/the-challenges-of-rising-mttr-and-what-to-do/</guid></item><item><title>Triton Server 加速基于 Dragonfly 的模型分发</title><link>https://www.cncf.io/blog/2024/04/15/triton-server-accelerates-distribution-of-models-based-on-dragonfly/</link><description>&lt;p&gt;&lt;em&gt;项目帖子，作者：Yufei Chen、Miaohao 和 Min Huang，Dragonfly 项目&lt;/em&gt;&lt;/p&gt;&lt;p&gt;本文档将帮助您体验如何将 Dragonfly 与&lt;a href="https://github.com/pytorch/serve"&gt;TritonServe&lt;/a&gt;结合使用。模型下载过程中，文件大小较大，同时有多个服务在下载文件。存储的带宽将达到极限，下载速度会很慢。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://lh7-us.googleusercontent.com/R1HVNQwGrc00vK2y_E9StRHZuF2KezxRXobvDYaSPGW77IySZ1ewLg9aL2RgBjOc6dCXJ5YCPq1ULLCB2m3E3h0E1hwzz6EryTGnQ7M5Dvb3VArP5SOlcJHB_-CymQ2i4XAMJw3xO2Nse4F-inJFbw" /&gt;&lt;/figure&gt;&lt;p&gt; Dragonfly可以通过P2P技术消除存储的带宽限制，从而加速文件下载。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://lh7-us.googleusercontent.com/MgrCqgKJqLXuB9Hq053tzCulbZRBEjpTxxdRy2j3j6Z0VJf3rI7nywINB5rZUv0o2LhSNGizxs58r_-nNMVGLOLURGBfI9p0c7xtf5MHqnPnFOlh6Qzn2Za-nyceVWgJWvccXKYEoONRNT9aLwD9ag" /&gt;&lt;/figure&gt;&lt;h1 class="wp-block-heading"&gt;&lt;strong&gt;安装&lt;/strong&gt;&lt;strong&gt;​&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;通过将 Dragonfly Repository Agent 集成到 Triton 中，通过 Dragonfly 下载流量来拉取存储在 S3、OSS、GCS 和 ABS 中的模型，并在 Triton 中注册模型。 Dragonfly 存储库代理位于&lt;a href="https://github.com/dragonflyoss/dragonfly-repository-agent"&gt;Dragonfly-repository-agent&lt;/a&gt;存储库中。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;先决条件&lt;/strong&gt;&lt;/h2&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;姓名&lt;/td&gt;&lt;td&gt;版本&lt;/td&gt;&lt;td&gt;文档&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Kubernetes集群&lt;/td&gt;&lt;td&gt;1.20+&lt;/td&gt;&lt;td&gt; &lt;a href="https://kubernetes.io/"&gt;kubernetes.io&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;舵&lt;/td&gt;&lt;td&gt;3.8.0+&lt;/td&gt;&lt;td&gt;&lt;a href="https://helm.sh/"&gt;舵机sh&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;海卫一服务器&lt;/td&gt;&lt;td&gt;23.08-py3&lt;/td&gt;&lt;td&gt;&lt;a href="https://github.com/triton-inference-server/server"&gt;海卫一服务器&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;如果没有 kubernetes 集群可供测试，建议使用&lt;a href="https://kind.sigs.k8s.io/"&gt;Kind&lt;/a&gt; 。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt; &lt;strong&gt;Dragonfly Kubernetes 集群设置&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;详细安装文档请参考&lt;a href="https://d7y.io/zh/docs/getting-started/quick-start/kubernetes/"&gt;quick-start-kubernetes&lt;/a&gt; 。&lt;/p&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;准备 Kubernetes 集群&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;创建kind多节点集群配置文件kind-config.yaml，配置内容如下：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kind: Cluster&lt;br /&gt; apiVersion: kind.x-k8s.io/v1alpha4&lt;br /&gt; nodes:&lt;br /&gt;  - role: control-plane&lt;br /&gt;  - role: worker&lt;br /&gt;  - role: worker&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用配置文件创建一个多节点集群：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kind create cluster --config kind-config.yaml&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将 kubectl 的上下文切换到 kind cluster：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kubectl config use-context kind-kind&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;种类加载蜻蜓图像&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;拉蜻蜓最新图片：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;docker pull dragonflyoss/scheduler:latest&lt;br /&gt; docker pull dragonflyoss/manager:latest&lt;br /&gt; docker pull dragonflyoss/dfdaemon:latest&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;类集群加载蜻蜓最新图像：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kind load docker-image dragonflyoss/scheduler:latest&lt;br /&gt; kind load docker-image dragonflyoss/manager:latest&lt;br /&gt; kind load docker-image dragonflyoss/dfdaemon:latest&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;基于helm Charts创建Dragonfly集群&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;创建helm图表配置文件charts-config.yam并设置dfdaemon.config.agents.regx以匹配对象存储的下载路径。示例：添加 regx:.*models.* 以匹配对象存储桶模型的下载请求。配置内容如下：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;scheduler:&lt;br /&gt;  image: dragonflyoss/scheduler&lt;br /&gt;  tag: latest&lt;br /&gt;  replicas: 1&lt;br /&gt;  metrics:&lt;br /&gt;    enable: true&lt;br /&gt;  config:&lt;br /&gt;    verbose: true&lt;br /&gt;    pprofPort: 18066&lt;br /&gt;&lt;br /&gt; seedPeer:&lt;br /&gt;  image: dragonflyoss/dfdaemon&lt;br /&gt;  tag: latest&lt;br /&gt;  replicas: 1&lt;br /&gt;  metrics:&lt;br /&gt;    enable: true&lt;br /&gt;  config:&lt;br /&gt;    verbose: true&lt;br /&gt;    pprofPort: 18066&lt;br /&gt;&lt;br /&gt; dfdaemon:&lt;br /&gt;  image: dragonflyoss/dfdaemon&lt;br /&gt;  tag: latest&lt;br /&gt;  metrics:&lt;br /&gt;    enable: true&lt;br /&gt;  config:&lt;br /&gt;    verbose: true&lt;br /&gt;    pprofPort: 18066&lt;br /&gt;    proxy:&lt;br /&gt;      defaultFilter: &amp;#39;Expires&amp;amp;Signature&amp;amp;ns&amp;#39;&lt;br /&gt;      security:&lt;br /&gt;        insecure: true&lt;br /&gt;        cacert: &amp;#39;&amp;#39;&lt;br /&gt;        cert: &amp;#39;&amp;#39;&lt;br /&gt;        key: &amp;#39;&amp;#39;&lt;br /&gt;      tcpListen:&lt;br /&gt;        namespace: &amp;#39;&amp;#39;&lt;br /&gt;        port: 65001&lt;br /&gt;      registryMirror:&lt;br /&gt;        url: https://index.docker.io&lt;br /&gt;        insecure: true&lt;br /&gt;        certs: []&lt;br /&gt;        direct: false&lt;br /&gt;      proxies:&lt;br /&gt;        - regx: blobs/sha256.*&lt;br /&gt;        # Proxy all http downlowd requests of model bucket path.&lt;br /&gt;        - regx: .*models.*&lt;br /&gt;&lt;br /&gt; manager:&lt;br /&gt;  image: dragonflyoss/manager&lt;br /&gt;  tag: latest&lt;br /&gt;  replicas: 1&lt;br /&gt;  metrics:&lt;br /&gt;    enable: true&lt;br /&gt;  config:&lt;br /&gt;    verbose: true&lt;br /&gt;    pprofPort: 18066&lt;br /&gt;&lt;br /&gt; jaeger:&lt;br /&gt;  enable: true&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用配置文件创建蜻蜓集群：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;$ helm repo add dragonfly https://dragonflyoss.github.io/helm-charts/&lt;br /&gt; $ helm install --wait --create-namespace --namespace dragonfly-system dragonfly dragonfly/dragonfly -f charts-config.yaml&lt;br /&gt; LAST DEPLOYED: Wed Nov 29 21:23:48 2023&lt;br /&gt; NAMESPACE: dragonfly-system&lt;br /&gt; STATUS: deployed&lt;br /&gt; REVISION: 1&lt;br /&gt; TEST SUITE: None&lt;br /&gt; NOTES:&lt;br /&gt; 1. Get the scheduler address by running these commands:&lt;br /&gt;  export SCHEDULER_POD_NAME=$(kubectl get pods --namespace dragonfly-system -l &amp;quot;app=dragonfly,release=dragonfly,component=scheduler&amp;quot; -o jsonpath={.items[0].metadata.name})&lt;br /&gt;  export SCHEDULER_CONTAINER_PORT=$(kubectl get pod --namespace dragonfly-system $SCHEDULER_POD_NAME -o jsonpath=&amp;quot;{.spec.containers[0].ports[0].containerPort}&amp;quot;)&lt;br /&gt;  kubectl --namespace dragonfly-system port-forward $SCHEDULER_POD_NAME 8002:$SCHEDULER_CONTAINER_PORT&lt;br /&gt;  echo &amp;quot;Visit http://127.0.0.1:8002 to use your scheduler&amp;quot;&lt;br /&gt;&lt;br /&gt; 2. Get the dfdaemon port by running these commands:&lt;br /&gt;  export DFDAEMON_POD_NAME=$(kubectl get pods --namespace dragonfly-system -l &amp;quot;app=dragonfly,release=dragonfly,component=dfdaemon&amp;quot; -o jsonpath={.items[0].metadata.name})&lt;br /&gt;  export DFDAEMON_CONTAINER_PORT=$(kubectl get pod --namespace dragonfly-system $DFDAEMON_POD_NAME -o jsonpath=&amp;quot;{.spec.containers[0].ports[0].containerPort}&amp;quot;)&lt;br /&gt;  You can use $DFDAEMON_CONTAINER_PORT as a proxy port in Node.&lt;br /&gt;&lt;br /&gt; 3. Configure runtime to use dragonfly:&lt;br /&gt;  https://d7y.io/docs/getting-started/quick-start/kubernetes/&lt;br /&gt;&lt;br /&gt;&lt;br /&gt; 4. Get Jaeger query URL by running these commands:&lt;br /&gt;  export JAEGER_QUERY_PORT=$(kubectl --namespace dragonfly-system get services dragonfly-jaeger-query -o jsonpath=&amp;quot;{.spec.ports[0].port}&amp;quot;)&lt;br /&gt;  kubectl --namespace dragonfly-system port-forward service/dragonfly-jaeger-query 16686:$JAEGER_QUERY_PORT&lt;br /&gt;  echo &amp;quot;Visit http://127.0.0.1:16686/search?limit=20&amp;amp;lookback=1h&amp;amp;maxDuration&amp;amp;minDuration&amp;amp;service=dragonfly to query download events&amp;quot;&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;检查蜻蜓是否部署成功：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;$ kubectl get pods -n dragonfly-system&lt;br /&gt; NAME                                 READY   STATUS    RESTARTS       AGE&lt;br /&gt; dragonfly-dfdaemon-8qcpd             1/1     Running   4 (118s ago)   2m45s&lt;br /&gt; dragonfly-dfdaemon-qhkn8             1/1     Running   4 (108s ago)   2m45s&lt;br /&gt; dragonfly-jaeger-6c44dc44b9-dfjfv    1/1     Running   0              2m45s&lt;br /&gt; dragonfly-manager-549cd546b9-ps5tf   1/1     Running   0              2m45s&lt;br /&gt; dragonfly-mysql-0                    1/1     Running   0              2m45s&lt;br /&gt; dragonfly-redis-master-0             1/1     Running   0              2m45s&lt;br /&gt; dragonfly-redis-replicas-0           1/1     Running   0              2m45s&lt;br /&gt; dragonfly-redis-replicas-1           1/1     Running   0              2m7s&lt;br /&gt; dragonfly-redis-replicas-2           1/1     Running   0              101s&lt;br /&gt; dragonfly-scheduler-0                1/1     Running   0              2m45s&lt;br /&gt; dragonfly-seed-peer-0                1/1     Running   1 (52s ago)    2m45s&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;暴露Proxy服务端口&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;创建 dfstore.yaml 配置文件以公开 Dragonfly Peer 的 HTTP 代理侦听的端口。默认端口为 65001，将 targetPort 设置为 65001。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kind: Service&lt;br /&gt; apiVersion: v1&lt;br /&gt; metadata:&lt;br /&gt;  name: dfstore&lt;br /&gt; spec:&lt;br /&gt;  selector:&lt;br /&gt;    app: dragonfly&lt;br /&gt;    component: dfdaemon&lt;br /&gt;    release: dragonfly&lt;br /&gt;&lt;br /&gt;  ports:&lt;br /&gt;    - protocol: TCP&lt;br /&gt;      port: 65001&lt;br /&gt;      targetPort: 65001&lt;br /&gt;&lt;br /&gt;  type: NodePort&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;创建服务：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kubectl --namespace dragonfly-system apply -f dfstore.yaml&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将请求转发到 Dragonfly Peer 的 HTTP 代理：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kubectl --namespace dragonfly-system port-forward service/dfstore 65001:65001&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;安装 Dragonfly 存储库代理&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;设置 Dragonfly 存储库代理配置&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;创建dragonfly_config.json配置文件，配置如下：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;{&lt;br /&gt;  &amp;quot;proxy&amp;quot;: &amp;quot;http://127.0.0.1:65001&amp;quot;,&lt;br /&gt; &amp;quot;header&amp;quot;: {&lt;br /&gt; },&lt;br /&gt; &amp;quot;filter&amp;quot;: [&lt;br /&gt;  &amp;quot;X-Amz-Algorithm&amp;quot;,&lt;br /&gt;  &amp;quot;X-Amz-Credential&amp;amp;X-Amz-Date&amp;quot;,&lt;br /&gt;  &amp;quot;X-Amz-Expires&amp;quot;,&lt;br /&gt;  &amp;quot;X-Amz-SignedHeaders&amp;quot;,&lt;br /&gt;  &amp;quot;X-Amz-Signature&amp;quot;&lt;br /&gt; ]&lt;br /&gt; }&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&lt;li&gt; proxy：Dragonfly Peer 的 HTTP 代理的地址。&lt;/li&gt;&lt;li&gt; header：为请求添加请求头。&lt;/li&gt;&lt;li&gt;过滤器：用于生成唯一的任务并过滤URL中不必要的查询参数。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在配置的过滤器中，使用不同的对象存储时设置不同的值：&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;类型&lt;/td&gt;&lt;td&gt;价值&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;开放源码软件&lt;/td&gt;&lt;td&gt;[“过期”，“签名”，“ns”]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; S3&lt;/td&gt;&lt;td&gt; [“X-Amz-算法”、“X-Amz-凭证”、“X-Amz-日期”、“X-Amz-过期”、“X-Amz-SignedHeaders”、“X-Amz-签名”]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; OBS&lt;/td&gt;&lt;td&gt; [“X-Amz-算法”、“X-Amz-凭证”、“X-Amz-日期”、“X-Obs-日期”、“X-Amz-过期”、“X-Amz-SignedHeaders”、“ X-Amz-签名”]&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;设置模型存储库配置&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;创建cloud_credential.json云存储凭证，配置如下：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;{&lt;br /&gt;  &amp;quot;gs&amp;quot;: {&lt;br /&gt;    &amp;quot;&amp;quot;: &amp;quot;PATH_TO_GOOGLE_APPLICATION_CREDENTIALS&amp;quot;,&lt;br /&gt;    &amp;quot;gs://gcs-bucket-002&amp;quot;: &amp;quot;PATH_TO_GOOGLE_APPLICATION_CREDENTIALS_2&amp;quot;&lt;br /&gt;  },&lt;br /&gt;  &amp;quot;s3&amp;quot;: {&lt;br /&gt;    &amp;quot;&amp;quot;: {&lt;br /&gt;      &amp;quot;secret_key&amp;quot;: &amp;quot;AWS_SECRET_ACCESS_KEY&amp;quot;,&lt;br /&gt;      &amp;quot;key_id&amp;quot;: &amp;quot;AWS_ACCESS_KEY_ID&amp;quot;,&lt;br /&gt;      &amp;quot;region&amp;quot;: &amp;quot;AWS_DEFAULT_REGION&amp;quot;,&lt;br /&gt;      &amp;quot;session_token&amp;quot;: &amp;quot;&amp;quot;,&lt;br /&gt;      &amp;quot;profile&amp;quot;: &amp;quot;&amp;quot;&lt;br /&gt;    },&lt;br /&gt;    &amp;quot;s3://s3-bucket-002&amp;quot;: {&lt;br /&gt;      &amp;quot;secret_key&amp;quot;: &amp;quot;AWS_SECRET_ACCESS_KEY_2&amp;quot;,&lt;br /&gt;      &amp;quot;key_id&amp;quot;: &amp;quot;AWS_ACCESS_KEY_ID_2&amp;quot;,&lt;br /&gt;      &amp;quot;region&amp;quot;: &amp;quot;AWS_DEFAULT_REGION_2&amp;quot;,&lt;br /&gt;      &amp;quot;session_token&amp;quot;: &amp;quot;AWS_SESSION_TOKEN_2&amp;quot;,&lt;br /&gt;      &amp;quot;profile&amp;quot;: &amp;quot;AWS_PROFILE_2&amp;quot;&lt;br /&gt;    }&lt;br /&gt;  },&lt;br /&gt;  &amp;quot;as&amp;quot;: {&lt;br /&gt;    &amp;quot;&amp;quot;: {&lt;br /&gt;      &amp;quot;account_str&amp;quot;: &amp;quot;AZURE_STORAGE_ACCOUNT&amp;quot;,&lt;br /&gt;      &amp;quot;account_key&amp;quot;: &amp;quot;AZURE_STORAGE_KEY&amp;quot;&lt;br /&gt;    },&lt;br /&gt;    &amp;quot;as://Account-002/Container&amp;quot;: {&lt;br /&gt;      &amp;quot;account_str&amp;quot;: &amp;quot;&amp;quot;,&lt;br /&gt;      &amp;quot;account_key&amp;quot;: &amp;quot;&amp;quot;&lt;br /&gt;    }&lt;br /&gt;  }&lt;br /&gt; }&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;为了通过 Dragonfly 拉取模型，需要在模型配置文件 config.pbtxt 文件中添加以下代码：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;model_repository_agents&lt;br /&gt; {&lt;br /&gt;  agents [&lt;br /&gt;    {&lt;br /&gt;      name: &amp;quot;dragonfly&amp;quot;,&lt;br /&gt;    }&lt;br /&gt;  ]&lt;br /&gt; }&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; &lt;a href="https://github.com/dragonflyoss/dragonfly-repository-agent/tree/main/examples/model_repository/densenet_onnx"&gt;ensenet_onnx 示例&lt;/a&gt;包含修改后的配置和模型文件。修改config.pbtxt如：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;name: &amp;quot;densenet_onnx&amp;quot;&lt;br /&gt; platform: &amp;quot;onnxruntime_onnx&amp;quot;&lt;br /&gt; max_batch_size : 0&lt;br /&gt; input [&lt;br /&gt;  {&lt;br /&gt;    name: &amp;quot;data_0&amp;quot;&lt;br /&gt;    data_type: TYPE_FP32&lt;br /&gt;    format: FORMAT_NCHW&lt;br /&gt;    dims: [ 3, 224, 224 ]&lt;br /&gt;    reshape { shape: [ 1, 3, 224, 224 ] }&lt;br /&gt;  }&lt;br /&gt; ]&lt;br /&gt; output [&lt;br /&gt;  {&lt;br /&gt;    name: &amp;quot;fc6_1&amp;quot;&lt;br /&gt;    data_type: TYPE_FP32&lt;br /&gt;    dims: [ 1000 ]&lt;br /&gt;    reshape { shape: [ 1, 1000, 1, 1 ] }&lt;br /&gt;    label_filename: &amp;quot;densenet_labels.txt&amp;quot;&lt;br /&gt;  }&lt;br /&gt; ]&lt;br /&gt; model_repository_agents&lt;br /&gt; {&lt;br /&gt;  agents [&lt;br /&gt;    {&lt;br /&gt;      name: &amp;quot;dragonfly&amp;quot;,&lt;br /&gt;    }&lt;br /&gt;  ]&lt;br /&gt; }&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 class="wp-block-heading"&gt; &lt;strong&gt;Triton Server 集成 Dragonfly Repository Agent 插件&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;使用 Docker 安装 Triton 服务器&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;拉取 Dragonflyoss/dragonfly-repository-agent 镜像，该镜像是 Triton Server 中集成的 Dragonfly Repository Agent 插件，请参阅&lt;a href="https://github.com/dragonflyoss/dragonfly-repository-agent/blob/main/Dockerfile"&gt;Dockerfile&lt;/a&gt; 。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;docker pull dragonflyoss/dragonfly-repository-agent:latest&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行容器并挂载配置目录：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;docker run --network host --rm \&lt;br /&gt;  -v ${path-to-config-dir}:/home/triton/ \&lt;br /&gt;  dragonflyoss/dragonfly-repository-agent:latest tritonserver \&lt;br /&gt;  --model-repository=${model-repository-path}&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&lt;li&gt; path-to-config-dir：dragonfly_config.json&amp;amp;cloud_credential.json的文件路径。&lt;/li&gt;&lt;li&gt; model-repository-path：远程模型存储库的路径。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;正确的输出如下：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;=============================&lt;br /&gt; == Triton Inference Server ==&lt;br /&gt; =============================&lt;br /&gt; successfully loaded &amp;#39;densenet_onnx&amp;#39;&lt;br /&gt; I1130 09:43:22.595672 1 server.cc:604]&lt;br /&gt; +------------------+------------------------------------------------------------------------+&lt;br /&gt; | Repository Agent | Path                                                                   |&lt;br /&gt; +------------------+------------------------------------------------------------------------+&lt;br /&gt; | dragonfly        | /opt/tritonserver/repoagents/dragonfly/libtritonrepoagent_dragonfly.so |&lt;br /&gt; +------------------+------------------------------------------------------------------------+&lt;br /&gt;&lt;br /&gt; I1130 09:43:22.596011 1 server.cc:631]&lt;br /&gt; +-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt; | Backend     | Path                                                            | Config                                                                                                                                                        |&lt;br /&gt; +-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt; | pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {}                                                                                                                                                            |&lt;br /&gt; | onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {&amp;quot;cmdline&amp;quot;:{&amp;quot;auto-complete-config&amp;quot;:&amp;quot;true&amp;quot;,&amp;quot;backend-directory&amp;quot;:&amp;quot;/opt/tritonserver/backends&amp;quot;,&amp;quot;min-compute-capability&amp;quot;:&amp;quot;6.000000&amp;quot;,&amp;quot;default-max-batch-size&amp;quot;:&amp;quot;4&amp;quot;}} |&lt;br /&gt; +-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt;&lt;br /&gt; I1130 09:43:22.596112 1 server.cc:674]&lt;br /&gt; +---------------+---------+--------+&lt;br /&gt; | Model         | Version | Status |&lt;br /&gt; +---------------+---------+--------+&lt;br /&gt; | densenet_onnx | 1       | READY  |&lt;br /&gt; +---------------+---------+--------+&lt;br /&gt;&lt;br /&gt; I1130 09:43:22.598318 1 metrics.cc:703] Collecting CPU metrics&lt;br /&gt; I1130 09:43:22.599373 1 tritonserver.cc:2435]&lt;br /&gt; +----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt; | Option                           | Value                                                                                                                                                                                                           |&lt;br /&gt; +----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt; | server_id                        | triton                                                                                                                                                                                                          |&lt;br /&gt; | server_version                   | 2.37.0                                                                                                                                                                                                          |&lt;br /&gt; | server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data parameters statistics trace logging |&lt;br /&gt; | model_repository_path[0]         | s3://192.168.36.128:9000/models                                                                                                                                                                                 |&lt;br /&gt; | model_control_mode               | MODE_NONE                                                                                                                                                                                                       |&lt;br /&gt; | strict_model_config              | 0                                                                                                                                                                                                               |&lt;br /&gt; | rate_limit                       | OFF                                                                                                                                                                                                             |&lt;br /&gt; | pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                                       |&lt;br /&gt; | min_supported_compute_capability | 6.0                                                                                                                                                                                                             |&lt;br /&gt; | strict_readiness                 | 1                                                                                                                                                                                                               |&lt;br /&gt; | exit_timeout                     | 30                                                                                                                                                                                                              |&lt;br /&gt; | cache_enabled                    | 0                                                                                                                                                                                                               |&lt;br /&gt; +----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt;&lt;br /&gt; I1130 09:43:22.610334 1 grpc_server.cc:2451] Started GRPCInferenceService at 0.0.0.0:8001&lt;br /&gt; I1130 09:43:22.612623 1 http_server.cc:3558] Started HTTPService at 0.0.0.0:8000&lt;br /&gt; I1130 09:43:22.695843 1 http_server.cc:187] Started Metrics Service at 0.0.0.0:8002&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;执行以下命令查看 Dragonfly 日志：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kubectl exec -it -n dragonfly-system dragonfly-dfdaemon-&amp;lt;id&amp;gt; -- tail -f /var/log/dragonfly/daemon/core.log&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;检查通过Dragonfly下载是否成功：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;{&lt;br /&gt; &amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:&amp;quot;2024-02-02 05:28:02.631&amp;quot;,&lt;br /&gt; &amp;quot;caller&amp;quot;:&amp;quot;peer/peertask_conductor.go:1349&amp;quot;,&lt;br /&gt; &amp;quot;msg&amp;quot;:&amp;quot;peer task done, cost: 352ms&amp;quot;,&lt;br /&gt; &amp;quot;peer&amp;quot;:&amp;quot;10.244.2.3-1-4398a429-d780-423a-a630-57d765f1ccfc&amp;quot;,&lt;br /&gt; &amp;quot;task&amp;quot;:&amp;quot;974aaf56d4877cc65888a4736340fb1d8fecc93eadf7507f531f9fae650f1b4d&amp;quot;,&lt;br /&gt; &amp;quot;component&amp;quot;:&amp;quot;PeerTask&amp;quot;,&lt;br /&gt; &amp;quot;trace&amp;quot;:&amp;quot;4cca9ce80dbf5a445d321cec593aee65&amp;quot;&lt;br /&gt; }&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;核实&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;调用推理API：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;docker run -it --rm --net=host nvcr.io/nvidia/tritonserver:23.08-py3-sdk /workspace/install/bin/image_client -m densenet_onnx -c 3 -s INCEPTION /workspace/images/mug.jpg&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;检查响应是否成功：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;Request 01&lt;br /&gt; Image &amp;#39;/workspace/images/mug.jpg&amp;#39;:&lt;br /&gt;    15.349563 (504) = COFFEE MUG&lt;br /&gt;    13.227461 (968) = CUP&lt;br /&gt;    10.424893 (505) = COFFEEPOT&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;性能测试&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;测试集成 Dragonfly P2P 后通过 Triton API 下载单机模型的性能。由于机器本身网络环境的影响，实际下载时间并不重要，但不同场景下下载速度的比例更有意义： &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://lh7-us.googleusercontent.com/wFGp6qxEQvNWh5ZADtHZaZzASh6Cnf_vYoHTWF7rvyyVHV6aSzr3mtYe_bLJdrN9EXSgYmyXbusCYwqVKiUmayWnx8LCI4IuVXUme958nfjx6IJwpkFvtoVZy82P8Drf_BB_5wMdGOvw7qfaWx5_YA" /&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt; Triton API：使用对象存储提供的签名URL直接下载模型。&lt;/li&gt;&lt;li&gt; Triton API 和 Dragonfly 冷启动：使用 Triton Serve API 通过 Dragonfly P2P 网络下载模型，并且没有缓存命中。&lt;/li&gt;&lt;li&gt;命中远程对等点：使用 Triton Serve API 通过 Dragonfly P2P 网络下载模型并命中远程对等点缓存。&lt;/li&gt;&lt;li&gt;命中本地对等点：使用 Triton Serve API 通过 Dragonfly P2P 网络下载模型并命中本地对等点缓存。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;测试结果显示 Triton 和 Dragonfly 集成。可以有效减少文件下载时间。注意，本次测试是单机测试，这意味着在缓存命中的情况下，性能限制在磁盘上。如果Dragonfly部署在多台机器上进行P2P下载，模型下载速度会更快。&lt;/p&gt;&lt;h1 class="wp-block-heading"&gt;&lt;strong&gt;相关链接&lt;/strong&gt;&lt;/h1&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;蜻蜓社区&lt;/strong&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;网站： &lt;a href="https://d7y.io/"&gt;https://d7y.io/&lt;/a&gt;&lt;/li&gt;&lt;li&gt; Github 仓库： &lt;a href="https://github.com/dragonflyoss/Dragonfly2"&gt;https://github.com/dragonflyoss/Dragonfly2&lt;/a&gt;&lt;/li&gt;&lt;li&gt; Dragonfly 存储库代理 Github 存储库： &lt;a href="https://github.com/dragonflyoss/dragonfly-repository-agent"&gt;https://github.com/dragonflyoss/dragonfly-repository-agent&lt;/a&gt;&lt;/li&gt;&lt;li&gt; Slack 频道： &lt;a href="https://cloud-native.slack.com/messages/dragonfly/"&gt;#dragonfly&lt;/a&gt; on &lt;a href="https://slack.cncf.io/"&gt;CNCF Slack&lt;/a&gt;&lt;/li&gt;&lt;li&gt;讨论组： &lt;a href="mailto:dragonfly-discuss@googlegroups.com"&gt;dragonfly-discuss@googlegroups.com&lt;/a&gt;&lt;/li&gt;&lt;li&gt;推特： &lt;a href="https://twitter.com/dragonfly_oss"&gt;@dragonfly_oss&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading"&gt; &lt;strong&gt;NVIDIA Triton 推理服务器&lt;/strong&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;网站： &lt;a href="https://developer.nvidia.com/triton-inference-server"&gt;https://developer.nvidia.com/triton-inference-server&lt;/a&gt;&lt;/li&gt;&lt;li&gt; Github 存储库： &lt;a href="https://github.com/triton-inference-server/server"&gt;https://github.com/triton-inference-server/server&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;二维码&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Dragonfly Github仓库： &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="二维码" src="https://lh7-us.googleusercontent.com/dHuRcLXUyidFEw_iLig1WmDHNOtGGUEwVObfDjbupoVCKV1tvZ7bLv38018mFX0umVHxqRyZEGe0jBPcjJS9wEBJjQbxAlB0DAiZQs1EL27DrgdyAnhjQLsfNVR8wFavNJgNtyz6xOPqJ8_md8rF3A" /&gt;&lt;/figure&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Sun, 14 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/15/triton-server-accelerates-distribution-of-models-based-on-dragonfly/</guid></item><item><title>使用开源本地法学硕士简化日志</title><link>https://www.cncf.io/blog/2024/04/12/streamlining-logs-with-open-source-local-llms/</link><description>&lt;p&gt;&lt;em&gt;Anup Ghatage 的社区帖子&lt;/em&gt;&lt;/p&gt;&lt;p&gt;日志消息对于调试和监视应用程序至关重要，但它们通常过于冗长和混乱，导致难以快速识别和理解关键信息。随着时间的推移，在具有多个贡献者的大型代码库中尤其如此，由于员工流失和短暂的开源贡献，导致日志行格式、长度和语言不一致。&lt;/p&gt;&lt;p&gt;大多数组织都“对人工智能感到好奇”，希望利用它来解决一些现有的工作流程和问题，但都面临着共同的难题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;训练和托管自定义大型语言模型的成本极其昂贵。&lt;/li&gt;&lt;li&gt;从法学硕士获得确定性、结构化的输出具有挑战性，因为这些输出本质上是概率性的且冗长的。&lt;/li&gt;&lt;li&gt;最后，所有企业&lt;strong&gt;都不&lt;/strong&gt;希望将其专有数据和代码暴露给外部法学硕士提供商。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br /&gt;仅这些原因就足以让大多数企业“静观其变”。确实，人工智能的所有事物都在以惊人的速度发展，而且肯定会变得更好，但今天的客户要求企业提供同样的好处来提高他们的生产力。这使得等待变得更加不稳定，因为公司将失去在新技术周期开始时获取大部分价值的机会。&lt;br /&gt;&lt;/p&gt;&lt;p&gt;在这篇文章中，我们将探讨如何使用开源、Apache 2.0 许可的本地 LLM 来解决简化日志行的任务。通过减少日志行的冗长性，同时保留上下文和细节，我们不仅可以提高和维护其可读性，而且可以在使用 Splunk 等日志管理工具时实现成本节省。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;那么我们如何开始呢？&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;在企业级工作时，必须谨慎使用第三方软件，主要是因为许可限制。最流行的开源许可证之一是&lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;Apache 2.0 许可证&lt;/a&gt;。该许可证非常宽松，允许该软件不受限制地用于商业用途。其他许可证（例如&lt;a href="https://opensource.org/license/mit"&gt;MIT 许可证）&lt;/a&gt;也是宽松的，允许免费商业使用。所以现在我们知道，无论我们使用什么工具和模型，我们都必须确保它们是 Apache 2.0 或 MIT 许可的。&lt;br /&gt;&lt;br /&gt;仍然存在的另一个问题是，如果我们没有任何 GPU，如何使用它们（或对它们进行推理）。这里的答案是量化。&lt;/p&gt;&lt;p&gt;大型语言模型 (LLM) 是极其强大的工具，但它们的计算需求通常限制它们只能在云环境中使用强大的 GPU。对于许多用户来说，这可能是一个障碍，尤其是那些无法使用昂贵的硬件或没有管理硬件的专业知识的用户。&lt;/p&gt;&lt;p&gt;这就是量化的用武之地。这是一种通过降低权重精度来优化 LLM 局部推理的技术。传统上，这些权重存储为高精度浮点数。量化将它们转换为较低精度的格式，例如我们示例中的 8 位整数。这显着减少了模型的大小和内存占用。&lt;/p&gt;&lt;p&gt;好处？通过使用 8 位量化，我们可以在标准服务器 CPU 上运行 LLM。这为更广泛的采用打开了大门，特别是对于企业而言。量化提供：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;经济高效的解决方案：&lt;/strong&gt;大多数企业已经拥有现成的服务器 CPU。这消除了对昂贵 GPU 集群的需求，从而降低了硬件成本。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可访问性：&lt;/strong&gt;在 CPU 上本地运行 LLM 不需要管理 GPU 的专业知识，这使得它们对于组织内的各个团队来说更加用户友好。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;隐私和安全：&lt;/strong&gt;本地推理将数据保留在本地，可能解决基于云的解决方案可能出现的隐私和安全问题。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;从本质上讲，量化充当了一座桥梁，即使那些没有顶级硬件的人也可以直接在自己的机器上利用法学硕士的强大功能。&lt;/p&gt;&lt;p&gt;然而，在这种情况下，需要在性能和速度之间进行权衡。较低的量化（例如 4 位或 2 位）会使模型文件非常小，但输出的质量也会降低。因此，在本地托管这些数据时，使用 8 位量化为我们提供了相对较慢但相对更准确的选择。&lt;/p&gt;&lt;p&gt;有几种不同的量化格式：&lt;a href="https://arxiv.org/html/2401.00503v1"&gt;即&lt;/a&gt;、 &lt;a href="https://medium.com/@bnjmn_marie/gguf-quantization-for-fast-and-memory-efficient-inference-on-your-cpu-d10fbe58fbca"&gt;GGUF&lt;/a&gt; 、 &lt;a href="https://github.com/mit-han-lab/llm-awq"&gt;AWQ&lt;/a&gt;和&lt;a href="https://arxiv.org/abs/2210.17323"&gt;GPTQ&lt;/a&gt; 。&lt;br /&gt;出于本文的目的，我们将使用 GGUF 模型，因为它们周围有最活跃的社区。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我在哪里可以获得这些模型？我如何接待他们？我如何查询它们？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt; &lt;a href="https://huggingface.co/"&gt;HuggingFace&lt;/a&gt;是互联网上最流行的机器学习模型和数据集存储库之一。许多公司和用户都在那里上传他们的模型和实验，任何人都可以使用。 HuggingFace 上的每个模型都附带一张“模型卡”——类似于如何使用模型、其提示格式、许可要求和限制的说明。&lt;br /&gt;&lt;br /&gt;在查看模型时，我们必须寻找提供 Apache 2.0 或 MIT 许可证的 GGUF 量化。即使这样，也请务必阅读细则。最流行的开源 LLM 之一是 Mistral-7b v0.2。该模型及其权重是在 Apache 2.0 许可证下发布的。&lt;br /&gt;我们将在我们的示例用例中使用它。让我们转到 HuggingFace 页面，了解&lt;a href="https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF"&gt;该模型的 GGUF 量化&lt;/a&gt;并尝试理解它。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;许可&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;量化必须自动遵循原始模型的许可要求。在我们的例子中， &lt;a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2"&gt;Mistral-ai 的模型具有 Apache 2.0 许可证&lt;/a&gt;，该许可证也可以在量化模型页面的顶部看到。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;提示模板&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&amp;lt;s&amp;gt;[INST] {提示} [/INST]&lt;/p&gt;&lt;p&gt;提示模板是模型期望获得输入的方式。这是因为该模型可能是使用这些特殊字符和标记进行训练的。在这种情况下，我们必须将查询打包以代替模板中的“{prompt}”，如上所示。举例来说，如果我们问“为什么海是蓝色的？”我们想要发送的实际指令是：&lt;br /&gt;&lt;br /&gt; &amp;lt;s&amp;gt;[INST] 海水为什么是蓝色的？ [/插入]&lt;br /&gt;&lt;br /&gt;可以通过多种方式在本地托管这些模型，但今天我们将讨论两个最简单的选项。&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;Llama.cpp&lt;/a&gt; （&lt;a href="https://github.com/ggerganov/llama.cpp/tree/master/examples/server"&gt;服务器示例&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href="https://ollama.com/"&gt;奥拉马&lt;/a&gt;（ &lt;a href="https://github.com/ollama/ollama/blob/main/docs/api.md"&gt;API 参考&lt;/a&gt;）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这两个项目都是免费的、开源的并获得麻省理工学院的许可。您可以从上面提到的链接中了解如何构建和运行它们。&lt;/p&gt;&lt;p&gt;一旦启动并运行，它们都提供符合 OpenAI 的 API 访问。我们可以通过标准 REST API 调用查询它们的端点。&lt;/p&gt;&lt;p&gt;总之，到目前为止，我们已经获得了商业上可行的开源 LLM 模型文件以及托管和查询它们的方法 - 全部在本地，无需 GPU 并且免费。现在让我们进入本文开头的用例。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;通过简洁的日志降低 Splunk 成本&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;像 Splunk 这样的日志管理平台的运营成本可能很高，其成本通常与摄取和存储的日志数据量相关。通过使用 LLM 缩小日志行，我们可以显着减少需要处理和保留的数据量，从而节省成本。&lt;/p&gt;&lt;p&gt;更短、更简洁的日志行不仅消耗更少的存储空间，而且需要更少的传输带宽，并减少 Splunk 索引器和搜索头上的计算负载。这可以降低基础设施要求并减少运营费用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;利用 llama.cpp 进行本地 LLM 推理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了在我们本地的 LLM 上运行推理，我们将使用 llama.cpp。但是，我们希望将 llama.cpp 服务器端点视为“推理和智能”端点，而不是标准 REST 端点。以这种方式使用它将使我们能够围绕它构建应用程序。&lt;/p&gt;&lt;p&gt;&lt;br /&gt;首先，让我们使用下载的模型启动 llama.cpp 服务器。&lt;br /&gt;&lt;br /&gt; ./server -m /Users/aghatage/mistral-7b-instruct-v0.2.Q8_0.gguf -c 2048&lt;/p&gt;&lt;p&gt;上述命令使用 Mistral-7b v0.2 8 位量化模型启动服务器。我们现在可以对&lt;a href="http://localhost:8000/"&gt;http://localhost:8000/&lt;/a&gt;上托管的端点进行 REST API 调用。我们将利用 http://localhost:8000/completion 端点。大多数企业可以在自己的环境中甚至在开发人员笔记本电脑上安全地托管此类服务器。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Log Line 收缩过程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如前所述，如果我们想使用 LLM 作为情报端点，我们必须使用它的语言，我们将必须编写一些脚本来手动提供我们希望 LLM 处理的确切信息。&lt;/p&gt;&lt;p&gt; 1. **日志行提取**：我们将首先使用 Python 脚本从代码库中提取所有单行日志行。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;import os import re def find_log_lines(codebase_path): # Regex to match a log line, modified to be case-insensitive log_line_pattern = re.compile(r&amp;#39;\b(log\.\w+)\(.*?\);&amp;#39;, re.IGNORECASE) for root, dirs, files in os.walk(codebase_path): for file in files: if file.endswith(&amp;quot;.java&amp;quot;): file_path = os.path.join(root, file) with open(file_path, &amp;#39;r&amp;#39;) as f: lines = f.readlines() for i, line in enumerate(lines): if log_line_pattern.search(line): print(f&amp;quot;{file_path} : {i+1} : {line.strip()}&amp;quot;) # Replace &amp;#39;/path/to/java/codebase&amp;#39; with the actual path to your Java codebase codebase_path = &amp;#39;/path/to/java/codebase&amp;#39; find_log_lines(codebase_path)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上面的脚本按以下格式打印所有日志行：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;&amp;lt;file path&amp;gt; : &amp;lt;line number&amp;gt; : &amp;lt;actual log line&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; 2. **及时准备**：对于每个日志行，我们将查询本地 LLM 以尝试使其“更短”。每个 REST 调用都需要一个提示，其中包括日志行本身以及在保留关键详细信息的同时减少其冗长性的请求。这里的提示还用一个例子进行了解释，又名&lt;em&gt;1 shot Learning&lt;/em&gt; 。举例说明法学硕士的期望内容以及输出应该如何。每次调用时，提示的 CODE_LINE 部分都会替换为新的日志行。最后，我们通过重申结构来确保输出应该是 JSON。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;base_prompt = &amp;quot;&amp;quot;&amp;quot;&amp;lt;s&amp;gt; [INST] Here is an example of shortening a log line input: log.error(&amp;quot;Encountered error at writing records&amp;quot;, t); output: { &amp;quot;fixed&amp;quot; : &amp;quot;log.error(&amp;quot;Write error&amp;quot;, t);&amp;quot; } Now reword the following log line to be shorter if possible: ``` CODE_LINE ``` Please rewrite the log line to be shorter, do not add anything else. Make sure response is in JSON format like this: ``` { &amp;quot;fixed&amp;quot; : &amp;quot;&amp;lt;actual shortened log line&amp;gt;&amp;quot; } ```[/INST] &amp;quot;&amp;quot;&amp;quot;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; 3. **通过 llama.cpp 进行推理**：我们会将这些提示发送到运行我们的量化 LLM 模型的本地 llama.cpp 服务器。为了限制输出格式，我们将使用 llama.cpp 的 JSON 限制语法功能，确保模型的响应采用 JSON 结构。&lt;/p&gt;&lt;p&gt;我们将使用的语法的“GBNF”形式是 llama.cpp 附带的标准 JSON 语法。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;root ::= object value ::= object | array | string | number | (&amp;quot;true&amp;quot; | &amp;quot;false&amp;quot; | &amp;quot;null&amp;quot;) ws object ::= &amp;quot;{&amp;quot; ws ( string &amp;quot;:&amp;quot; ws value (&amp;quot;,&amp;quot; ws string &amp;quot;:&amp;quot; ws value)* )? &amp;quot;}&amp;quot; ws array ::= &amp;quot;[&amp;quot; ws ( value (&amp;quot;,&amp;quot; ws value)* )? &amp;quot;]&amp;quot; ws string ::= &amp;quot;\&amp;quot;&amp;quot; ( [^&amp;quot;\\\x7F\x00-\x1F] | &amp;quot;\\&amp;quot; ([&amp;quot;\\/bfnrt] | &amp;quot;u&amp;quot; [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F]) # escapes )* &amp;quot;\&amp;quot;&amp;quot; ws number ::= (&amp;quot;-&amp;quot;? ([0-9] | [1-9] [0-9]*)) (&amp;quot;.&amp;quot; [0-9]+)? ([eE] [-+]? [0-9]+)? ws # Optional space: by convention, applied in this grammar after literal chars when allowed ws ::= ([ \t\n] ws)?&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;最后，当将提示发送到 llama.cpp 服务器时，我们还必须包含语法作为推理的指示，以便按照我们最初提示的那样仅生成 JSON。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;def get_log_fix_response(code_line): final_prompt = base_prompt.replace(&amp;quot;CODE_LINE&amp;quot;, code_line) data = {&amp;quot;prompt&amp;quot;: final_prompt, &amp;quot;n_predict&amp;quot;: -1, &amp;quot;grammar&amp;quot;: list_grammar} try: response = requests.post(url, headers=headers, json=data) response.raise_for_status() json_input = json.loads(response.json().get(&amp;quot;content&amp;quot;)) content = json_input[&amp;quot;fixed&amp;quot;] return content except requests.RequestException as e: print(f&amp;quot;Error making HTTP request: {e}&amp;quot;) return None&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;最后，我们现在可以使用 LLM 的 JSON 响应来重写源文件中的原始日志行，有效地缩小它们，同时保留关键信息。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;优点和缺点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;使用本地法学硕士来缩小日志行数有几个优点：&lt;/p&gt;&lt;p&gt; – **提高可读性**：通过减少日志行的冗长性，我们可以使它们更易于阅读和理解，从而促进更有效的调试和监控。&lt;/p&gt;&lt;p&gt; – **成本节省**：较短的日志行意味着 Splunk 等日志管理平台的存储、带宽和计算要求减少，从而显着节省成本。&lt;/p&gt;&lt;p&gt; – **本地化处理**：使用本地法学硕士，所有处理都在本地进行，无需将敏感数据发送到外部服务。&lt;/p&gt;&lt;p&gt; – **成本效益**：通过利用开源工具并在 CPU 上运行，这种方法比使用基于云的 LLM 服务更具成本效益。&lt;/p&gt;&lt;p&gt;然而，也有一些潜在的缺点需要考虑：&lt;/p&gt;&lt;p&gt; – **模型质量**：虽然开源法学硕士的能力很强，但其性能可能无法与专有的最先进模型相媲美。&lt;/p&gt;&lt;p&gt; – **维护**：随着法学硕士模型和框架的发展，维护和更新本地设置可能需要持续的努力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结一下……&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过结合开源本地法学硕士、量化技术和 llama.cpp/ollama 等工具，我们可以开发满足企业级需求的经济高效的解决方案。&lt;br /&gt;对于此示例，除了提高日志可读性和效率之外，这种方法还可以在使用 Splunk 等日志管理平台时节省大量成本。虽然需要考虑权衡，但潜在的好处使其成为寻求优化日志基础设施和降低运营费用的组织的一个令人信服的选择。这篇文章还为希望将大型语言模型融入现有工作流程的组织提供了一个具有成本效益且低风险的蓝图。&lt;/p&gt;&lt;p&gt; &lt;em&gt;Anup 在大型企业构建数据基础设施方面拥有超过 10 年的经验。他的专长是数据库内部结构、数据存储和生成人工智能。&lt;/em&gt; &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Thu, 11 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/12/streamlining-logs-with-open-source-local-llms/</guid></item><item><title>绘制新领域：OpenTelemetry 拥抱分析</title><link>https://www.cncf.io/blog/2024/04/11/charting-new-territory-opentelemetry-embraces-profiling/</link><description>&lt;p&gt;&lt;em&gt;大使帖子最初由 Dotan Horovits 在&lt;a href="https://logz.io/blog/opentelemetry-embraces-profiling/"&gt;Logz.io 博客&lt;/a&gt;上发布&lt;/em&gt;&lt;/p&gt;&lt;p&gt;一段时间以来，连续分析的主题一直是可观察性世界中持续讨论的话题。我早在 2021 年就说过， &lt;a href="https://logz.io/blog/continuous-profiling-new-observability-signal-in-opentelemetry/?utm_medium=referral&amp;amp;utm_source=cncf"&gt;剖析将成为可观测性领域的下一个主要遥测信号&lt;/a&gt;，事实上，从那时起，人们对剖析的兴趣与日俱增。&lt;/p&gt;&lt;p&gt;初创公司和大型可观测性供应商已经进入这个领域。最近的一个重要步骤是&lt;a href="https://logz.io/learn/opentelemetry-guide/?utm_medium=referral&amp;amp;utm_source=cncf"&gt;OpenTelemetry 项目&lt;/a&gt;决定向其核心信号添加配置文件，并为此正式制定开放统一规范。&lt;/p&gt;&lt;p&gt;我主持了 OpenObservability Talks 的特别小组式一集，以研究分析的状态以及 OpenTelemetry 在这方面的工作。我的嘉宾都是为此主题成立的 OpenTelemetry 特别兴趣小组 (SIG) 的成员 Felix Geisendörfer 和 Ryan Perry。 &lt;/p&gt;&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;/div&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading" id="the-rise-of-continuous-profiling"&gt;连续分析的兴起&lt;/h2&gt;&lt;p&gt;我首先反思了人们对持续分析日益增长的兴趣，初创公司和主要供应商都关注这个领域。 Ryan 分享了他的创业历程，从认识到持续分析尚未开发的潜力，到创立 Pyrscope，再到后来加入 Grafana Labs。在这个热闹的市场中，这个故事与英特尔收购 Granulate、Elastic 收购 Optimyze 等公司一起发生。&lt;/p&gt;&lt;p&gt;历史上与性能和成本分析相关的分析，现已发展到涵盖更广泛的用例，包括信号相关性、事件响应和资源消耗分析。&lt;/p&gt;&lt;p&gt; Ryan 强调了向连续分析的转变，并行日志、指标和跟踪的轨迹。当与其他信号相关时，分析数据可以更深入地了解应用程序行为，从而促进根本原因分析和性能优化。用例涵盖从识别 CPU 峰值和内存问题到了解互斥争用、网络抖动和 goroutine 行为。 eBPF 技术在该领域也获得了很大的关注。&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt; &lt;a href="https://www.linkedin.com/embed/feed/update/urn:li:share:7170847249416052736"&gt;&lt;img alt="Dotan 的 Linkedin 帖子" class="wp-image-105643" height="1168" src="https://www.cncf.io/wp-content/uploads/2024/04/Screenshot-2024-04-15-at-09.48.27.png" style="width: 488px; height: auto;" width="1104" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading" id="runtime-and-ebpf-full-host-approaches-to-profiling"&gt;运行时和 eBPF 全主机分析方法&lt;/h2&gt;&lt;p&gt;Felix 深入研究了不同分析方法的细微差别，将运行时分析器与完整主机分析器进行了对比。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;运行时分析器&lt;/strong&gt;基于带有 SDK 的编程语言特定&lt;a href="https://logz.io/blog/where-are-apps-traces-instrumentation/?utm_medium=referral&amp;amp;utm_source=cncf"&gt;检测&lt;/a&gt;，因此提供有关 CPU、内存分配、堆、锁争用、与各个跨度的关联以及针对特定编程语言定制的类似功能的深层数据。然而，这些可能需要用户进行一些手动仪器工作才能充分发挥潜力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;全主机分析器&lt;/strong&gt;基于&lt;a href="https://logz.io/blog/ebpf-auto-instrumentation-pixie-kubernetes-observability/?utm_medium=referral&amp;amp;utm_source=cncf"&gt;eBPF 自动检测&lt;/a&gt;，因此它们提供整个系统的全面可见性，同时减少用户端的检测工作。然而，符号管理和运行时兼容性等挑战凸显了 eBPF 方法的复杂性。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="turning-profiling-data-into-observability-insights"&gt;将分析数据转化为可观察性见解&lt;/h2&gt;&lt;p&gt;讨论扩展到探索传统火焰图之外的新颖可视化技术。时间线视图描述了程序中各个线程或 goroutine 随时间的活动，提供了对资源利用率和线程交互的精细洞察。 Felix 描述了粒度调查流程的类型：“如果它在 CPU 上，它会在那里执行多长时间，如果它不在 CPU 上，它会等待什么？它在等待计时器吗？是在等待网络吗？它是否在等待被阻塞的互斥锁？”这还可以扩展到调查这些 goroutine 之间的连接以及它们如何通信。&lt;/p&gt;&lt;p&gt;我们还讨论了将分析数据转换为指标的潜力，因为某些事情只能通过分析来真正衡量。一个很好的例子是测量 Go 上垃圾收集器完成的工作量。虽然 Go 运行时没有有关垃圾收集器（或其他）goroutine 的操作系统调度的信息，但可以通过分析轻松获得此时间。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="opentelemetry-adds-support-for-continuous-profiling"&gt; OpenTelemetry 添加了对连续分析的支持&lt;/h2&gt;&lt;p&gt;随着 OpenTelemetry 的第一个章程在 2022 年底接近全面上市，社区开始探索路线图，并将持续分析确定为日志、指标和跟踪之外的下一个信号。这是 Sean Marciniak（又名 MovieStoreGuy）在 2020 年提出的一项早期&lt;a href="https://github.com/open-telemetry/oteps/issues/139"&gt;提案&lt;/a&gt;的延续。&lt;/p&gt;&lt;p&gt;然后以 OpenTelemetry 增强提案 (OTEP) 的形式正式化，并随后形成 SIG 配置文件，致力于如何在 OpenTelemetry 中实施连续分析。&lt;/p&gt;&lt;p&gt;一开始存在一些基本问题，即如何在 OpenTelemetry 中实施连续分析。它应该搭载现有的日志或其他信号模型，还是应该从头开始构建一个全新的模型？ &lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="Dotan 的 linkedin 帖子" class="wp-image-105644" height="960" src="https://www.cncf.io/wp-content/uploads/2024/04/image-16.png" style="width: 581px; height: auto;" width="1044" /&gt;&lt;/figure&gt;&lt;p&gt; SIG 需要在特定于领域的分析约定和特定于框架的 OpenTelemetry 约定之间取得平衡。他们需要弄清楚数据模型和规范是否应该从&lt;a href="https://profilerpedia.markhansen.co.nz/"&gt;现有的许多分析格式&lt;/a&gt;之一或新的格式中派生出来。&lt;/p&gt;&lt;p&gt;正如 Felix 解释的那样，“我们需要一种格式来完全指定火焰图中需要包含的所有内容，而 pprof 确实是我们可以作为基础的唯一选择。 JFR 是一种很棒的格式，但 JFR 不是标准化格式。它基本上没有文档记录，仅存在于 Java 平台的运行时内部。”&lt;/p&gt;&lt;p&gt;另一方面，SIG 必须解决如何以符合现有 OpenTelemetry 信号所采用的现有方法的方式进行分析。在考虑到所需的性能目标的情况下实现这种平衡是一项艰巨的任务。&lt;/p&gt;&lt;p&gt;最后，决定采用扩展&lt;strong&gt;pprof&lt;/strong&gt;规范的数据模型，该小组称之为“pprof 扩展”。 &lt;a href="https://github.com/google/pprof"&gt;pprof&lt;/a&gt;是 Google 推出的一款开源工具，用于可视化和分析分析数据。 SIG 的选择并不完全与 pprof 一致，而是对其进行了扩展。&lt;/p&gt;&lt;p&gt;实际上，这是一个分叉，在我看来这并不理想。我希望我们能够看到 Google 加入这一计划，捐赠 pprof 并将其纳入 OpenTelemetry，以造福于这两个项目的开源生态系统。&lt;/p&gt;&lt;p&gt;然后，当配置文件数据到达&lt;a href="https://logz.io/learn/opentelemetry-guide/#collector?utm_medium=referral&amp;amp;utm_source=cncf"&gt;OpenTelemetry Collector&lt;/a&gt;时，它会以类似于其他信号的统一方式被摄取和处理。这意味着数据被解构为收集器的 pdata 内部数据格式。然后，接收器之后的处理器可以对数据做一些有趣的事情。&lt;/p&gt;&lt;p&gt;重大消息是 OTEP 已合并， &lt;a href="https://www.cncf.io/blog/2024/03/19/opentelemetry-announces-support-for-profiling/"&gt;&lt;strong&gt;OpenTelemetry 现在正式支持连续分析&lt;/strong&gt;&lt;/a&gt;，尽管仍处于实验阶段。为实现这一重要里程碑的 SIG 成员和所有贡献者鼓掌。&lt;/p&gt;&lt;p&gt;想了解更多吗？查看 OpenObservability Talks 剧集： &lt;em&gt;&lt;a href="https://podcasters.spotify.com/pod/show/openobservability/episodes/Charting-New-Territory-OpenTelemetry-Embraces-Profiling---OpenObservability-Talks-S4E10-e2gtttb"&gt;绘制新领域：OpenTelemetry 拥抱分析&lt;/a&gt;。&lt;/em&gt; &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Wed, 10 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/11/charting-new-territory-opentelemetry-embraces-profiling/</guid></item><item><title>什么是代码基础设施？</title><link>https://www.cncf.io/blog/2024/04/10/what-is-infrastructure-from-code/</link><description>&lt;p&gt;&lt;em&gt;会员帖子最初由 Lauren Rother 发布在&lt;a href="https://blog.appcd.com/what-is-infrastructure-from-code"&gt;AppCD 的博客&lt;/a&gt;上&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="装饰形象" class="wp-image-105575" height="630" src="https://www.cncf.io/wp-content/uploads/2024/04/image-7.png" width="1260" /&gt;&lt;/figure&gt;&lt;p&gt;也许您听说过&lt;a href="https://en.wikipedia.org/wiki/Infrastructure_as_code"&gt;基础设施即代码&lt;/a&gt;(IaC)，这是通过版本控制的、机器可读的定义文件（或配置）来管理和配置计算机数据中心资源（主要但不完全在云中）的过程，而不是而不是通过源头的手动硬件配置或 Web 控制台。但什么是代码基础设施 (IfC)？在这篇文章中，我们将讨论 IfC 的含义、它的不同实现如何工作以及它与 IaC 有何不同。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;什么是代码基础设施？&lt;/h2&gt;&lt;p&gt;来自代码的基础设施是一种思考和使用基础设施配置的新方式，它将应用程序代码置于一切的核心。您无需根据您（或您的公司）对如何最好地构建基础架构的想法从头开始创建基础架构配置，而是根据应用程序代码的特定版本生成应用程序所需的基础架构。&lt;/p&gt;&lt;p&gt; IfC 的优点是使基础架构适应应用程序不断变化的需求，而不是让您的应用程序适应您的基础架构，然后尝试像软件一样对待基础架构。 “代码基础架构”方法显着改善了开发人员体验，有助于简化流程并加速交付，而无需任何人学习全新的专业知识领域。根据您选择的 IfC 方法，您还可以使用 IfC 来应用必要的体系结构和安全标准，同时保留版本控制的优势。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;从代码到基础设施的不同方法&lt;/h2&gt;&lt;p&gt;来自代码的基础设施出现的时间并不长，因此一直在发现和开发实现它的新方法。目前IfC的使用方式主要有四种：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;基于SDK的解决方案&lt;/li&gt;&lt;li&gt;基于代码注释的解决方案&lt;/li&gt;&lt;li&gt;新的编程语言&lt;/li&gt;&lt;li&gt;静态扫码&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;a href="https://www.infoq.com/news/2023/02/infrastructure-code-cloud-manage/"&gt;InfoQ&lt;/a&gt;对前三种方法有一个很好、快速的概述，值得一看。基本思想是，目前，您可以尝试以考虑 IfC（SDK 和编程语言）的方式构建应用程序，也可以使用现有代码来提出 IfC（代码注释和代码扫描）。&lt;/p&gt;&lt;p&gt;哪种方法最适合您将取决于您团队的时间限制、经验、兴趣以及公司和应用程序的需求。每个都有自己的优点和缺点，SDK 和编程语言方法确保从构建应用程序的一开始就集成 IfC，并且代码注释和代码扫描方法从代码构建适合应用程序的基础设施，而无需切换语言或工具。也许 IaC 对于您的整个组织来说工作得很好，并且您认为不需要 IfC。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt; IaC 与 IfC&lt;/h2&gt;&lt;p&gt; IaC 真正诞生是在 2010 年代。使用 IaC 的方法有很多，从 Helm 到 Terraform，再到 CloudFormation 等等。为了帮助用户，许多提供相关 IaC 解决方案的工具如雨后春笋般涌现，例如 Spacelift、Rancher、Pulumi 和 AWS CDK。&lt;/p&gt;&lt;p&gt;随着时间的推移以及行业的发展和变化，IaC 方法的&lt;a href="https://appcd.com/blog/7-challenges-infrastructure-as-code"&gt;缺点&lt;/a&gt;开始显现出来，并且出现了如何更好地合并应用程序代码和基础设施代码的问题。 IfC 是一个开始受到关注的答案。但它们如何比较呢？&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;基础设施&lt;strong&gt;即&lt;/strong&gt;代码&lt;/td&gt;&lt;td&gt;&lt;strong&gt;来自&lt;/strong&gt;代码的基础设施&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;将基础设施需求和实践放在首位。&lt;/td&gt;&lt;td&gt;将&lt;strong&gt;应用程序的基础设施需求放在首位。&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;创建一个基础设施的真实来源，理想情况下是 VCS 配置，但如果有人偏离该配置，可能会有点难以确定。&lt;/td&gt;&lt;td&gt;它的&lt;strong&gt;真实来源是应用程序版本&lt;/strong&gt;，因此 VCS 是内置的。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;实施架构和安全最佳实践。&lt;/td&gt;&lt;td&gt;根据应用程序需求进行扩展，确保基础设施具有最小特权和合理规模。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;随着时间的推移，管理和更新可能会变得困难。&lt;/td&gt;&lt;td&gt;每个应用程序的基础设施可能遵循相同的标准，但对于该应用程序来说是唯一的。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;往往是一刀切的。&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading"&gt;与 IfC 和 appCD 一起走向未来&lt;/h2&gt;&lt;p&gt;如果您有兴趣尝试“代码基础架构”方法，appCD 可以通过静态代码扫描以最新、最省力的方式提供 IfC，从而减少干预并加快交付速度。通过将 appCD 连接到您项目的存储库、静态扫描您的代码、检查建议的基础设施的可视化效果，然后生成用于部署的 IaC 文件来&lt;a href="https://www.appcd.com/get-started"&gt;尝试我们&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;有疑问、想法，或者只是想告诉我们我们有多酷？给我们发送&lt;a href="mailto:feedback@appcd.com"&gt;电子邮件&lt;/a&gt;或通过社交媒体与我们联系： &lt;a href="https://www.linkedin.com/company/appcd"&gt;LinkedIn&lt;/a&gt;或&lt;a href="https://twitter.com/appcd_io"&gt;X。&lt;/a&gt; &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Tue, 09 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/10/what-is-infrastructure-from-code/</guid></item><item><title>K8s 基准报告：组织是否满足 NSA 强化检查？</title><link>https://www.cncf.io/blog/2024/04/09/k8s-benchmark-report-are-organizations-meeting-nsa-hardening-checks/</link><description>&lt;p&gt;&lt;em&gt;会员帖子最初由 Joe Pelletier 在&lt;a href="https://www.fairwinds.com/blog/k8s-benchmark-report-nsa-hardening-checks"&gt;Fairwinds 博客&lt;/a&gt;上发布&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.nsa.gov/"&gt;国家安全局&lt;/a&gt;(NSA) 和&lt;a href="https://www.cisa.gov/"&gt;网络安全和基础设施安全局&lt;/a&gt;(CISA) 继续更新其 Kubernetes 强化指南，提出建议以帮助组织确保&lt;a href="https://media.defense.gov/2022/Aug/29/2003066362/-1/-1/0/CTR_KUBERNETES_HARDENING_GUIDANCE_1.2_20220829.PDF"&gt;强化 Kubernetes 集群&lt;/a&gt;。这种强大的深度防御方法可帮助组织确保当攻击者破坏集群时，影响范围尽可能小。在较高层面上，该指南对强化 Kubernetes 提出了以下建议：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href="https://www.fairwinds.com/blog/validating-container-security"&gt;扫描容器镜像&lt;/a&gt;和 Pod 是否存在漏洞和错误配置。&lt;/li&gt;&lt;li&gt;以尽可能最低的&lt;a href="https://www.fairwinds.com/blog/fairwinds-insights-basics-tutorial-check-kubernetes-configuration-for-privilege-escalation"&gt;权限&lt;/a&gt;运行容器和 Pod。&lt;/li&gt;&lt;li&gt;使用技术控制来实施最低级别的安全。&lt;/li&gt;&lt;li&gt;使用网络隔离和强化来最大程度地减少因妥协造成的损害。&lt;/li&gt;&lt;li&gt;尽可能使用防火墙限制网络连接，并使用加密来保护机密性。&lt;/li&gt;&lt;li&gt;使用强大的&lt;a href="https://rbac-manager.docs.fairwinds.com/"&gt;身份验证和授权&lt;/a&gt;来限制用户和管理员访问并最大限度地减少攻击面。&lt;/li&gt;&lt;li&gt;审核日志，以便管理员可以监控活动并获取潜在恶意活动的警报。&lt;/li&gt;&lt;li&gt;创建一个安全策略，要求定期审查所有 Kubernetes 设置并使用漏洞扫描。&lt;/li&gt;&lt;/ol&gt;&lt;h2 class="wp-block-heading"&gt;组织是否正在应用 NSA 强化检查？&lt;/h2&gt;&lt;p&gt; Fairwinds Insights 支持 NSA 的多项建议，添加了多项额外检查以帮助组织遵守 NSA 指南。今年的&lt;a href="https://www.fairwinds.com/blog/2024-kubernetes-benchmark-report-kubernetes-workload-analysis"&gt;Kubernetes 基准报告&lt;/a&gt;分析了来自超过 330,000 个工作负载的数据，使用来自数百个组织的数据来评估与&lt;a href="https://www.fairwinds.com/blog/kubernetes-benchmark-report-managing-k8s-workload-costs-2024"&gt;成本效率&lt;/a&gt;、&lt;a href="https://www.fairwinds.com/blog/2024-k8s-benchmark-report-workload-reliability"&gt;可靠性&lt;/a&gt;和&lt;a href="https://www.fairwinds.com/blog/k8s-benchmark-report-kubernetes-workloads-secure"&gt;安全性&lt;/a&gt;相关的最佳实践的一致性。最新报告还包括专门研究与 NSA 强化检查的一致性的部分。&lt;/p&gt;&lt;h3 class="wp-block-heading"&gt; Linux加固&lt;/h3&gt;&lt;p&gt;通常，工作负载拥有的权限比运行其应用程序所需的权限要多。调整容器的权限可以帮助您最大程度地降低容器泄露的速度和影响。 Fairwinds 检查工作负载是否使用 AppArmor、SELinux、Linux 功能或 seccomp 配置文件来授予工作负载运行所需的最低权限。最小化工作负载的权限还可以最大程度地减少攻击者访问其他工作负载或集群的能力。&lt;/p&gt;&lt;p&gt;在 2024 年基准中，分析显示 33% 的组织有超过 50% 的工作负载允许过多的权限。 12% 的组织仅 91-100% 的工作负载受到影响，其余分布在两者之间。这表明组织在实施 Linux 强化方面还有改进的空间。他们必须花一些时间来识别这些特权过高的工作负载，以使此更改符合 NSA 指南。 &lt;a href="https://polaris.docs.fairwinds.com/"&gt;Polaris&lt;/a&gt;是 Kubernetes 的开源策略引擎，可以帮助您识别此问题，以便您可以修复它。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示 2024 年 NSA 强化检查结果的条形图" class="wp-image-105578" height="204" src="https://www.cncf.io/wp-content/uploads/2024/04/image-8.png" width="523" /&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading"&gt;缺少网络策略&lt;/h3&gt;&lt;p&gt;Kubernetes 中的&lt;a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/"&gt;网络策略&lt;/a&gt;控制与其他 Pod、IP 地址或命名空间的流量。您可以将 Kubernetes NetworkPolicies 用于集群中的各个应用程序，以指定 Pod 如何通过网络与其他网络实体进行通信。如果 Pod 没有限制其出口和入口流量的 NetworkPolicy，则它可能允许访问外部资源或来自您不希望允许的其他 Pod 的访问。&lt;/p&gt;&lt;p&gt; Kubernetes 基准测试显示，37% 的组织制定了网络策略来保护工作负载免受不需要的流量的影响。不幸的是，分析还表明，58% 的组织在其 51% 或更多的工作负载上缺少网络策略。设置网络策略是保护容器安全的关键步骤，因此令人惊讶的是，如此多的组织没有实施这种强化措施。 Polaris 还包括一些策略，可帮助识别缺少网络策略的工作负载，以便您解决这些问题。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示 2024 年缺失网络政策的条形图" class="wp-image-105580" height="153" src="https://www.cncf.io/wp-content/uploads/2024/04/image-9.png" width="517" /&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading"&gt; NSA 强化指南合规性&lt;/h2&gt;&lt;p&gt;随着业界提供关于强化 Kubernetes 环境抵御恶意攻击的更多反馈以及威胁形势的发展，NSA 和 CISA 将继续更新 Kubernetes 强化指南。 Kubernetes和云原生生态系统也在快速发展，带来了新的解决方案和新的挑战。跟上这些变化是很困难的，特别是在复杂的环境中。&lt;/p&gt;&lt;p&gt;恶意行为者随时准备利用泄露的 kubeconfig、泄露的云凭证、供应链漏洞、暴露的仪表板或已知的安全漏洞。所有这些攻击途径都可能允许攻击者在您的集群中执行自己的代码、升级权限、掩盖他们的踪迹并建立持久的立足点。这使得恶意行为者可以窃取机密和敏感数据，消耗您的计算资源以谋取私利，或者以其他方式使您的业务面临风险。如果没有解决方案来帮助您识别权限过多或缺少网络策略的工作负载，则很难找到并修复这些问题以最大程度地减少攻击的潜在影响。&lt;/p&gt;&lt;p&gt; Polaris 和&lt;a href="https://www.fairwinds.com/insights"&gt;Fairwinds Insights&lt;/a&gt;是两种解决方案，可以帮助组织跟踪强化 Kubernetes 集群的建议并评估是否存在需要解决的差距。随着团队在更多环境中部署更多集群，能够持续大规模评估安全性并与 NSA 指导保持一致非常重要。 &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Mon, 08 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/09/k8s-benchmark-report-are-organizations-meeting-nsa-hardening-checks/</guid></item></channel></rss>