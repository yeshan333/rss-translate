<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>CNCF - 博客</title><link>https://www.cncf.io/blog/</link><description>CNCF - 博客 - RSSHub 用爱制作(https://github.com/DIYgod/RSSHub)</description><lastBuildDate>Tue, 30 Apr 2024 16:05:10 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>FinOps for Kubernetes：工程成本优化</title><link>https://www.cncf.io/blog/2024/04/29/finops-for-kubernetes-engineering-cost-optimization/</link><description>&lt;p&gt;&lt;em&gt;&lt;a href="https://linkedin.com/in/s-jan"&gt;Saqib Jan&lt;/a&gt;的社区帖子&lt;/em&gt;&lt;/p&gt;&lt;p&gt;云提供了对计算资源的按需访问，但高可用性也使成本成为一个更加动态的问题来预测。随着公司不断扩大其云足迹并采用更多云技术，这种情况会产生反响——浪费的可能性也会增加。&lt;/p&gt;&lt;p&gt; &lt;a href="https://data.finops.org/"&gt;2024 年金融运营状况报告&lt;/a&gt;强调，组织的重点是减少浪费。考虑到效率是首要考虑因素，对于考虑 Kubernetes 中的 FinOps 模型的工程领导者来说，节约和成本优化势在必行。由于了解如何估算成本和优化对于平台工程和财务团队来说是一个黑洞，因此​​利益相关者面临的最大挑战是弄清楚成本的来源。因此，为了解决这个问题，对所有权成本的一些了解很重要。&lt;/p&gt;&lt;p&gt;拥有成熟财务和产品管理实践的大型技术工程团队正在利用成本模型来解决这些挑战，帮助衡量其服务和应用程序的总拥有成本。云中立倡导者兼 Cast AI 联合创始人&lt;a href="https://www.linkedin.com/in/laurentgil"&gt;Laurent Gil&lt;/a&gt;指出，成本模型通常不足以提供任何信息，只能提供一个明智的起点——必须达到一个足够好的起点以避免过度投资。&lt;/p&gt;&lt;p&gt;首先要考虑的是成本驱动因素——影响总体成本的因素以及如何将它们纳入计算中。 Kubernetes 中为每个服务和执行分配了 CPU、内存和存储。随着时间的推移，工作负载也会变得越来越大，并且托管、集成、运行、管理和保护云工作负载会涉及各种成本。虽然有些费用与计算、数据传输和存储消耗直接相关，但其他因素增加了复杂性。此外，还必须将工具以及与其他云服务的集成纳入总拥有成本 (TCO) 计算中。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;高效云使用架构师&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;如果您自己运行 Kubernetes，则需要拥有一支强大的工程团队。除非您从事的业务接近容器化和微服务技术，否则它本质上只是一个成本中心和资源的低效利用。&lt;/p&gt;&lt;p&gt;自己构建 Kubernetes 并能够理解需要正确设置和配置的所有不同组件的所有不同细微差别，是一项非常具有挑战性的任务。任何不从事运行基础设施业务的人基本上都会从托管 Kubernetes 中受益。您不必为任何您想要以任何合理的可靠性水平运行的事情雇用一个团队。&lt;/p&gt;&lt;p&gt; &lt;a href="https://grafana.com/"&gt;Grafana Labs&lt;/a&gt;首席技术官 Richard Hartmann 分享了高效使用云的两种基本方法。一是“全力以赴定制服务，尽一切努力减少无差别的繁重工作，专注于解决推动业务发展的问题。”或者，您可以“使用尽可能少的定制服务，仅依赖所有提供商的基线。”这种方法使您能够保持对平台运行方式的控制，并促进云之间的轻松迁移。 “这两种方法都有优点，”但他警告说，介于两者之间通常并不理想，因为它会让你面临两种权衡的缺点。&lt;/p&gt;&lt;p&gt;两种解决方案都有类似的问题。云计算价格昂贵，云提供商提供出色的成本控制的动力为零。哈特曼指出了固有的利益冲突，并强调，“这实际上会让用户支付更少的费用”，这是云提供商不希望看到的，特别是在当前宏观经济不确定的情况下，这给已经在应对预算缩减的工程领导者增加了更多压力，并加剧了对成本效率的期望。&lt;/p&gt;&lt;p&gt;因此，公司也非常有兴趣尝试找出正确的模型，以及如何在了解生产中运行的内容以及如何有效地建立开发测试环境之间找到良好的平衡。&lt;/p&gt;&lt;p&gt; “如今，我们的许多客户都在内部寻找通过托管 Kubernetes 产品在云中运行的项目的不同模型，无论是展示还是退款类型模型，” &lt;a href="https://about.gitlab.com/"&gt;GitLab&lt;/a&gt; Field 首席技术官 Lee Faus 评论道。他提到，“我们有一些客户试图使用高水位、低水位标记来限制他们允许的支出。但在这样做的过程中&lt;strong&gt;，&lt;/strong&gt;他们意识到，由于大多数托管 Kubernetes 集群的工作方式，他们会激励你构建自动扩展之类的东西。”&lt;/p&gt;&lt;p&gt;组织最终陷入过度配置集群的情况还有很多原因，这不仅会导致 CPU 和内存的周期时间缩短，而且最终会导致最终用户与应用程序交互的负面体验。&lt;/p&gt;&lt;p&gt;为了应对支出不受控制的风险，哈特曼表示，“我们对我们的具体业务实施了深度控制，并为自我管理的集群和管理良好的平台建立了成本控制。”这种方法有助于审查运营情况，最终实施退款计划，鼓励利益相关者共同承担责任。&lt;/p&gt;&lt;p&gt; Hartmann 和 Faus 都强调了管理成本以及在控制和成本效率之间找到适当平衡的挑战。他们确认，FinOps 实践可以帮助组织主动和被动地预测、控制、检查和优化其云投资。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt; &lt;strong&gt;Kubernetes 成本控制策略的 FinOps&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;云端的成本管理可能会失控，但这很大程度上源于软件开发生命周期中没有足够的严谨性——在实际准备好之前，或者没有充分准备好时，就将其投入生产。从性能角度进行测试。考虑到商业价值，现在是采用 FinOps 原则“通知、运营和优化”的重要时刻，因为现有解决方案无法捕捉经济上实现成本与性能之间完美平衡所需的细微差别。&lt;/p&gt;&lt;p&gt; FinOps 是一门规劝共同责任并将所有利益相关者（技术、业务和财务人员）聚集在一起制定以编程方式执行的政策和最佳实践的学科。采用 FinOps 方法可以帮助平台工程团队大幅提高可见性，以找到在不影响性能的情况下降低成本的方法。&lt;/p&gt;&lt;p&gt;例如，当 DevOps 为开发人员提供构建、部署和完全拥有应用程序的工具和护栏时，对他们进行整体成本管理方面的教育也很重要。这是因为授权团队采取行动是最大的挑战。通常直到月底账单到期时，财务团队才会意识到成本突然飙升的问题。&lt;/p&gt;&lt;p&gt;我可以从支持客户的角度告诉您，大多数使用 Kubernetes 的组织都在努力管理其云费用，因为他们的流程没有适当的审查和完善周期，而且该领域的技术工人库非常干燥。&lt;/p&gt;&lt;p&gt; Faus 在我们的谈话中指出，“我们开始看到很多公司使用一个术语，它围绕着价值流。”价值流使我们能够映射回关键绩效指标 (KPI)。而且，这些 KPI 是在首席执行官、首席信息官和首席财务官级别定义的，在该级别制定预算、规划资源招聘并决定新产品线。 “这提供了返回到这些元素并围绕这些价值流的高级映射。当我们全年开车时，我们需要有一种方法来确保我们在整个 SDLC 和成本管理中积极跟踪这些方面。”&lt;/p&gt;&lt;p&gt;无论你怎么称呼它，在使用 Kubernetes 时，为开发团队提供支持就变得势在必行。承担做出明智决策的责任将使 Kubernetes 成本管理变得及时、主动且具有成本效益。随着预算变得更加紧张，非常需要成本控制策略 - 从知识渊博的基础上构建您自己的成本控制并实施第三方解决方案（无论是商业解决方案还是开源解决方案），以避免线性成本增加。它们对每个人都有效——对于任何云提供商，甚至是裸机基础设施上的 Kubernetes。&lt;/p&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;案例研究：LambdaTest&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt; &lt;a href="https://www.lambdatest.com/"&gt;LambdaTest&lt;/a&gt;是展示 FinOps 实践持久影响的完美示例。这家年轻的公司为在线浏览器和操作系统测试提供基础设施作为云平台，在获得初始资金后迅速扩大了服务规模，但在后续几轮融资中遇到了云成本突然飙升的挑战。&lt;/p&gt;&lt;p&gt;作为高级 DevOps 工程负责人， &lt;a href="https://www.linkedin.com/in/shahid-ali-khan-2aa084a3/"&gt;Shahid Ali Khan&lt;/a&gt;负责领导 LambdaTest 的 Kubernetes 基础设施和整体基础设施系统的开发。他分享了关于应对详尽的平台工程挑战以及采用在此过程中必不可少的 FinOps 原则以优化云资源和节省云成本的宝贵见解。&lt;/p&gt;&lt;p&gt;本案例研究重点介绍了 LambdaTest 的 FinOps 成熟之旅，强调成本优化。并根据著名领导者的见解概述了一种系统方法，以主动克服这些障碍。该研究讨论了我与这些领导者进行一对一访谈时得到的技术解决方案、策略、成果和经验教训。&lt;/p&gt;&lt;h4 class="wp-block-heading"&gt; &lt;strong&gt;— 管理基础设施的挑战&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;随着 LambdaTest 扩展其产品，其基础设施的复杂性也随之增加，依靠 AWS 和自我管理的 Kubernetes 来支持数据量大的客户。这种架构使他们能够快速扩展，增长与营销主管&lt;a href="https://www.linkedin.com/in/muditsingh5000/"&gt;Mudit Singh&lt;/a&gt;反映了他们最初的决定。 “当我们开始使用 Kubernetes 时，没有云提供商为其提供静态、稳定的解决方案。当时，也就是 2017 年左右，AWS 发布了 Managed Kubernetes，并在很长一段时间内处于测试阶段。作为一家人才短缺的初创公司，我们对管理自己的集群并不确定。”&lt;/p&gt;&lt;p&gt;随着使用量的增加，每个月都会出现成本突然飙升，从而引发更多有关支出的问题，例如“我们花了多少钱？” “这正常吗？” “成本应该如何在团队、应用程序和业务部门之间分配？”以及“问题是什么，过度配置，还是使用过多的计算或内存？”仍然没有得到答复。 Singh 表示，这种情况“让我们的 DevOps 领导者、平台工程和财务团队（包括创始人）投入大量时间和精力来了解巨额发票。”&lt;/p&gt;&lt;p&gt;这些问题甚至随着时间的推移而升级——随着使用量的增加，失去成本控制的风险也随之增加。该公司采购了工具来产生云消费，但难以识别和解决成本驱动因素。与许多公司一样，LambdaTest 在尝试建立一支具有 FinOps 文化的团队和努力提高成本可见性之间取得平衡也面临着挑战。&lt;/p&gt;&lt;p&gt;辛格强调，在管理跨大陆的数据中心时，识别和解决推高成本的根本问题对他们来说是一项艰巨的任务。 Khan 阐述了他们为明确成本驱动因素、实现支出和云使用情况的可见性和透明度而采取的跨职能举措。&lt;/p&gt;&lt;h4 class="wp-block-heading"&gt; &lt;strong&gt;— 创建标签框架&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;如果不深入了解工作负载分配，就很难使报告与业务环境保持一致，并且业界已经采用了更加结构化的资源管理方法。&lt;/p&gt;&lt;p&gt; Khan 详细介绍道：“我们有多个正在运行的产品，并且这些产品之间共享服务。我们越来越难以确定哪些服务或哪些特定服务对每种产品的成本产生了影响。”使用标签进行标记还有助于识别过度配置的资源。而且，“我们首先实施标记和标签，并利用不同的节点池。这使我们能够根据特定资源精确确定每种产品的成本分配，了解其需求如何随着时间的推移而变化，并有效地满足这些需求。”&lt;/p&gt;&lt;p&gt;现在，为 Kubernetes 中的每个产品或服务利用命名空间已成为一种常见做法，并且服务有明显的分叉。这种方法不仅为资源管理奠定了基础，还支持隔离、资源配额和简化的访问控制，从而提高了运营效率。最重要的是，使各个团队、服务或业务线的成本分析、报告和优化变得更加容易。&lt;/p&gt;&lt;h4 class="wp-block-heading"&gt; &lt;strong&gt;— 从数据到行动&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;用于成本优化分析的数据量总是相当大的。能够对数据进行矢量化并了解哪里存在错误、哪里可能存在内存峰值、CPU 峰值——您不仅可以在这些领域优化管理应用程序的成本结构，还可以向工程团队提供反馈。 Faus 强调，“这涉及到在产品方面自动推广问题或票证等行动，以确保作为当前冲刺的一部分，针对该成本采取措施。”&lt;/p&gt;&lt;p&gt;这个过程还应该涉及分析时间序列数据，这非常有助于识别效率低下的地方，做出有关资源分配的明智决策并找到潜在的自动化机会。您还可以采用其他策略和优化策略，但一般来说，在基本层面上，最好首先考虑您要优化的内容。&lt;/p&gt;&lt;p&gt;那么什么是成本优化呢？这实际上只是另一个需要考虑的指标。举例来说，我已经管理 CPU、Pod、内存、存储和计算能力。那么，每一个都是我正在拼凑的更大拼图中的一部分。因此，增加成本并不会改变基本方法；它只是将另一个元素集成到我们已经平衡的资源数组中。&lt;/p&gt;&lt;p&gt; Khan 强调，重点是让“我们的技术人员能够有效地提取和操作数据，以符合我们的业务目标，而不是相反。我们还在 LambdaTest 内部实施了这一战略，它强调了促进内部协作和知识交流以有效弥合我们组织内的技术和业务鸿沟的至关重要性。”&lt;/p&gt;&lt;h4 class="wp-block-heading"&gt; &lt;strong&gt;— 成本可见性&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;在不影响性能和使用的情况下优化成本和运行集群的一个非常重要的方面是监控。它是建立意识和告知 FinOps 优化策略目标的核心支柱。&lt;/p&gt;&lt;p&gt; “我们尝试了很多解决方案和多个插件，但我们无法清楚地了解请求量、集群性能或整体系统状态，”Khan 指出。 “我们在集群内部实施了分布式跟踪（和分布式跟踪）来监控每个请求，这有助于我们确定服务的使用方式并查明系统内的优化机会。这极大地帮助我们发现效率低下的地方，从而增加了责任感——通知服务所有者采取行动，同时还启用了内部退款和展示模型等功能。”&lt;/p&gt;&lt;p&gt;可见性是跟踪进度的 FinOps 指标（闲置资源、优化不足的基础设施）的基础。但要考虑的关键指标是标准化成本，当根据您的运营业务指标进行调整时，可以更全面地了解相对于您的业务活动的云支出。&lt;/p&gt;&lt;h4 class="wp-block-heading"&gt; &lt;strong&gt;— 钻取粒度&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;接下来你做什么将取决于你的基线在哪里。但随着时间的推移，让问题持续存在会使后期控制成本变得困难且具有挑战性。即使您稍后尝试控制它们，您的团队所需的努力也会非常困难，从而分散了实现功能的注意力。&lt;/p&gt;&lt;p&gt;正是在这里，带有 Kubernetes 成本管理工具的标记框架变得很有用。这可以帮助您深入了解环境的各个层次，以便您可以准确地了解每个应用程序如何影响您的成本，从而为节省成本提供主动建议。&lt;/p&gt;&lt;p&gt; Khan 分享了他们的方法，“我们开始观察影响定价的所有属性，并在此基础上，我们更深入地了解价格上涨的原因以及可能导致价格上涨的原因，然后采取相当困难的教育途径向各个团队展示如何他们的环境影响他们部门的资源。”&lt;/p&gt;&lt;p&gt;根据 Khan 的建议，理想的解决方案“应该提供节省时间的功能。”一个示例是环境中最昂贵组件的优先级列表，按成本排名。这使您能够首先关注能够带来最显着成本节省的领域。 “我们意识到了这一点，并在团队中实施了积极主动的方法，确保工作能够以不影响生产的方式进行。”&lt;/p&gt;&lt;h4 class="wp-block-heading"&gt; —&lt;strong&gt;实时警报&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;现在，在启用了自动扩展的云原生环境中，您的集群或节点可以向上或向下扩展。因此，在云系统中实施预算和警报势在必行，因为不跟踪可能会导致大量费用，而这些费用无法证明您所提供的解决方案是合理的。这就是为什么以编程方式应用自定义规则可以让您在成本增加时收到通知，从而使您能够针对特定请求采取纠正措施。&lt;/p&gt;&lt;p&gt; Khan 表示：“FinOps 实践极大地改变了我们的工作方式。”通过广泛的数据分析，“我们在很大程度上衡量成本并为每种产品设定预算。例如，每个产品都有集群，其中一些产品共享服务。通过简单的标记，我们可以为每个产品设置具体的预算。当我们为产品分配一定金额时，如果支出超过预定阈值，我们就会收到警报。”小幅增加会触发琥珀色警报，大幅增加会触发红色警报。&lt;/p&gt;&lt;p&gt;最佳解决方案还应该实时提醒您异常的成本峰值，以便您可以立即检查问题并进行修复，而不是等待每周或每月的报告。有时，这些峰值可能是网络攻击的早期预警信号，需要立即采取主动响应，以保护您的基础设施和数据完整性。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;鼓励金融运营实践&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;你采取的变革计划越有意识，你就会瞄准那些变革最快最有效的地方。但作为一个组织，你能做的最糟糕的事情就是说“我们要通知”，而不了解超支在你的运营中根深蒂固的程度，更重要的是，不了解一些关键驱动因素的来源。&lt;/p&gt;&lt;p&gt;大规模管理 Kubernetes 的最佳方法是采取整体、有目的的方法，这也有助于计算总拥有成本和分配预算，但这并不是大多数公司正在做的事情。资源分流也不是大多数公司正在做的事情。许多公司都在管理庞大的基础设施，但他们缺乏的是专门针对此类情况的 FinOps 团队。他们在成本管理方面对事件采取的反应性方法会导致巨大的财务负担。&lt;/p&gt;&lt;p&gt;云可以让您加速，但如果不采取积极主动的方法，它也可能是一把双刃剑。根据&lt;a href="https://www.cncf.io/wp-content/uploads/2023/12/CNCF_Finops-Microsurvey-2023.pdf"&gt;CNCF 微观调查报告&lt;/a&gt;，过度配置或拥有超过必要的资源是导致过度配置的最常见因素之一。&lt;/p&gt;&lt;p&gt; “我们分析了数千个应用程序的使用数据，发现公司超支的三个主要原因：过度配置、Pod 请求设置过高以及 Spot 实例使用率低，”Gil 列举道。然而，超支的最大根源是对实际 CPU/内存使用率的高估。 “对于我们分析的 97% 以上的应用程序，CPU 预优化利用率仅为 12%。这意味着，平均而言，近 90% 的计算已付费，但并未得到使用。”他指出，这些百分比“在不同的应用程序规模和云提供商之间是一致的”。&lt;/p&gt;&lt;p&gt;导致大多数公司超支的根本原因是缺乏教育和赋权。技术、DevOps 和基础设施团队通常缺乏成本意识。改变并不容易，因为建立透明和开放的文化需要与工程师共享定价信息并为开放沟通创造安全的空间。&lt;/p&gt;&lt;p&gt;这对几乎所有公司来说都很困难，因为人们首先担心的是不要踩到别人的脚趾。如果敢于参与的人越来越少，那可能会非常无益。关键是让每个人就业务目标达成共识。这意味着分享计划、近期的情况、计划更广泛地推出什么样的服务，甚至公司的毛利率。 “正是透明度促进了共同理解，”哈特曼说道。当每个人看到更大的图景时，他们都能感受到超支的“真正痛苦”以及他们的工作如何直接影响它。这种共同的理解使团队成员能够为成本控制策略做出贡献。&lt;/p&gt;&lt;p&gt;基于所讨论的策略，Kubernetes 治理平台可以作为第一步，让您清楚地了解资源利用率，并使您能够深入了解环境的各个层。它还可以为云原生环境提供基于策略的控制，使团队能够掌握并采用成本控制策略，从而做出有关 Kubernetes 的明智财务决策。&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;&lt;strong&gt;作者：&lt;/strong&gt;萨奇布·简&lt;/p&gt;&lt;p&gt;&lt;strong&gt;电子邮件：&lt;/strong&gt; &lt;a href="mailto:sakimjan8@gmail.com"&gt;sakimjan8@gmail.com&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;领英：&lt;/strong&gt; &lt;a href="https://linkedin.com/in/s-jan"&gt;https://linkedin.com/in/s-jan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;简介：&lt;/strong&gt; Saqib Jan 是一名自由分析师，在应用程序开发、云技术和咨询方面拥有丰富的经验。 &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Sun, 28 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/29/finops-for-kubernetes-engineering-cost-optimization/</guid></item><item><title>开源软件的隐性经济</title><link>https://www.cncf.io/blog/2024/04/26/the-hidden-economy-of-open-source-software/</link><description>&lt;p&gt;&lt;em&gt;会员帖子最初由 Nigel Douglas 发表在&lt;a href="https://sysdig.com/blog/hidden-economy-of-open-source-software/"&gt;Sysdig 的博客&lt;/a&gt;上&lt;/em&gt;&lt;/p&gt;&lt;p&gt;最近&lt;strong&gt;在 XZ Utils&lt;/strong&gt; ( &lt;a href="https://sysdig.com/blog/cve-2024-3094-detecting-the-sshd-backdoor-in-xz-utils/"&gt;CVE-2024-3094&lt;/a&gt; ) 中发现的后门强调了开源软件安全的重要性，XZ Utils 是一种数据压缩实用程序，被各种基于 Linux 的开源计算机应用程序使用。虽然开源软件通常不面向消费者，但它是计算和互联网功能（例如机器之间的安全通信）的关键组成部分。&lt;/p&gt;&lt;p&gt;开源软件（简称 OSS）已成为科技行业的基石，影响着从小型初创公司到跨国公司的一切事物。尽管 OSS 无处不在，并且在推动创新方面发挥着基础性作用，但迄今为止，OSS 的真正经济价值在很大程度上仍然是未知领域。哈佛商学院的研究人员曼努埃尔·霍夫曼 (Manuel Hoffmann)、弗兰克·内格尔 (Frank Nagle) 和周亚诺 (Yanuo Zhou) 进行了一项题为“ &lt;a href="https://www.hbs.edu/ris/Publication%20Files/24-038_51f8444f-502c-4139-8bf2-56eb4b65c58a.pdf"&gt;开源软件的价值&lt;/a&gt;”的开创性研究，深入研究了这个尚未探索的领域，揭示了开源软件对整个行业的惊人经济影响。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="h-a-priceless-foundation-with-a-trillion-dollar-impact"&gt;具有数万亿美元影响力的无价基金会&lt;/h2&gt;&lt;p&gt;该研究首先解决一个基本的悖论：如何衡量免费提供的东西的价值？传统上，经济价值是通过产品价格乘以销售数量来计算的。然而，当涉及到 OSS 时，这个公式遇到了障碍——免费的东西没有价格标签，而且由于 OSS 分布的去中心化性质，跟踪其使用情况是一项艰巨的任务。&lt;/p&gt;&lt;p&gt;该研究利用独特的全球数据源和新颖的方法，估计“供应方”价值（重新创建最广泛使用的 OSS 的成本）为 41.5 亿美元。但真正令人大开眼界的是“需求方”价值，高达 8.8 万亿美元。该数字代表了公司在内部开发同等软件时将面临的假设成本，突显了 OSS 为全球经济带来的巨大节省和效率提升。&lt;/p&gt;&lt;p&gt;例如，Falco 是一款开源云原生安全工具，&lt;a href="https://github.com/falcosecurity/falco/graphs/contributors"&gt;拥有 190 名致力于增强软件并确保其应对云计算中不断变化的威胁的个人的贡献&lt;/a&gt;。如果一个组织尝试从头开始用 Go 开发自定义威胁检测引擎，那么雇用 190 名员工来持续开发和维护该工具在经济上是不切实际的。尽管 190 名贡献者中的大多数人可能将 Falco 作为一个副项目而不是他们的主要工作，但了解积极参与该项目的人数可以提供对其集体人力投资的宝贵见解。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-unsung-heroes-of-oss"&gt; OSS 的无名英雄&lt;/h3&gt;&lt;p&gt;该研究最有趣的发现之一是价值创造集中在 OSS 社区内。仅仅 5% 的 OSS 开发者就贡献了 96% 的需求方价值。这个精英贡献者群体对软件领域有着不成比例的影响，强调需要科技行业和政策制定者的支持和认可。&lt;/p&gt;&lt;p&gt;回到最近的 XZ Utils 后门主题，为了防止类似事件再次发生，政策制定者和软件供应商必须采取积极措施来增强现有 OSS 项目的安全性和完整性。许多开源软件维护人员自愿参与这些项目，没有报酬，而且通常是在正常工作之外工作。这可能会导致过度劳累和倦怠，从而产生攻击者可以利用的漏洞来破坏软件。&lt;/p&gt;&lt;p&gt;如果没有足够的保障和支持系统，这些维护人员的工作环境就会低估他们的关键贡献，并使他们面临重大风险。为了应对这些挑战，迫切需要采取政策干预措施，认可并在财政上支持开源软件的开发，并在全行业范围内采用严格的安全实践。通过实施资助 OSS 项目、为维护人员提供安全培训以及制定全面审查流程等措施，政策制定者和供应商可以保护维护人员免受不当压力，并增强 OSS 的安全性。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-programming-languages-that-power-the-economy"&gt;推动经济发展的编程语言&lt;/h3&gt;&lt;p&gt;深入挖掘后，研究发现 OSS 价值的大部分实际上是由几种关键编程语言产生的，其中 Go、JavaScript 和 Java 处于领先地位。这些语言不仅在开发人员中流行，而且在开发人员中也很流行。它们在创造数十亿美元的价值方面发挥了重要作用，进一步强调了投资和培育 OSS 生态系统的战略重要性。&lt;/p&gt;&lt;p&gt;考虑到这种努力所需的广泛资源和专业知识，组织选择创建专有编程语言而不是利用 JavaScript 或 Python 库等现有开源选项的想法没有实际价值。&lt;/p&gt;&lt;p&gt;从头开始构建一种新的编程语言不仅需要巨大的初始开发工作，还需要持续的维护、库、工具的开发和社区支持，以使其能够用于生产。此外，围绕 JavaScript 和 Python 等流行语言的现有生态系统是全球社区多年集体努力和贡献的结果，包含大量有助于快速开发和部署应用程序的库和框架。&lt;/p&gt;&lt;p&gt;然而，这些广泛使用的语言并非没有漏洞，包括已知的&lt;a href="https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=python"&gt;常见漏洞和暴露&lt;/a&gt;(CVE)，如果不修补，这些漏洞会带来重大的安全风险。解决这些漏洞通常超出了单个组织的能力，特别是考虑到现代应用程序所依赖的开源依赖性的广度。这种情况凸显了大型软件供应商在增强开源生态系统的安全基础设施方面的关键作用。&lt;/p&gt;&lt;p&gt;通过直接贡献代码、资助或提供高级安全工具和服务，这些供应商可以显着减少全球组织的潜在攻击面，从而为这些语言和库的安全做出贡献。个人维护者、组织和大型供应商之间的这种协作努力对于增强支撑当今大部分数字基础设施的开源软件的整体安全态势至关重要。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="h-how-is-the-falco-project-staying-secure"&gt; Falco 项目如何保持安全？&lt;/h2&gt;&lt;p&gt; Falco 项目强调其对保持供应商独立性的承诺以及加强其安全态势的集体努力。 Falco 理念的一个基本支柱是其供应商中立的立场，确保该项目从广泛的贡献中受益，而不受任何单一公司利益的束缚。这种方法培育了一个多元化且强大的社区，并由多家领先公司提供了大量的工程资源。&lt;/p&gt;&lt;p&gt;为了证明项目的成熟度和可靠性，Falco 成功从&lt;a href="https://www.cncf.io/"&gt;云原生计算基金会&lt;/a&gt;（CNCF）孵化状态毕业。这一成就的标志是 CNCF 技术监督委员会 (TOC) 进行了相当严格的&lt;a href="https://docs.google.com/document/d/1Hkwp4qMoazqVhrODmJwDitvBI4chbsg0OBLQhRGmW3c/edit"&gt;尽职调查流程&lt;/a&gt;，包括全面的第三方安全审计。此次毕业不仅证明了Falco的成长和可持续性，也巩固了Falco作为开源运行时安全生态系统领导者的地位。&lt;/p&gt;&lt;p&gt;&lt;br /&gt; Falco 拥有 17 个积极致力于该项目的组织的贡献，体现了 Falco 对包容性开发环境的承诺。值得注意的是，大约 38% 的贡献来自 Amazon、Cisco、Chainguard、Clastix、IBM、Microsoft、RedHat、SecureWorks 等知名组织的不同提交者以及许多个人贡献者。这项集体努力还展示了 Falco 打造基础广泛且具有弹性的安全工具的使命是如何得到执行的。&lt;/p&gt;&lt;p&gt;治理实践进一步巩固了 Falco 对供应商中立性的承诺，并采取了具体措施来防止任何单一实体主导项目的方向。一项关键的治理规则将任何组织的合格投票权限制在 40%，以确保项目社区内的平衡代表性和决策。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="h-towards-a-sustainable-future-for-oss"&gt;走向 OSS 可持续发展的未来&lt;/h2&gt;&lt;p&gt;哈佛大学的研究报告明确呼吁各组织采取行动，反思开源软件在其业务中的价值，同时也强调了其中有多少项目正在采取适当的措施来审核其项目。论文进一步强调了OSS在推动技术创新和经济效率方面的重要作用。&lt;/p&gt;&lt;p&gt;然而，这种数字共享，就像它的物理对应物一样，很容易受到过度使用和投资不足的影响——正如 XZ Utils 后门所见。调查结果主张共同努力支持开源软件的发展，确保其可持续性并持续为全球经济做出贡献。&lt;br /&gt;&lt;br /&gt; “&lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4693148"&gt;开源软件的价值&lt;/a&gt;”研究重点关注了隐藏的经济动力——OSS。通过量化其价值，该研究不仅庆祝了 OSS 社区的贡献，还强调了为确保其未来而对战略投资和支持的迫切需求。当我们在数字时代前进时，OSS 的真正价值怎么强调都不为过——它是推动创新、提高效率和塑造技术格局不可或缺的资源。 &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Thu, 25 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/26/the-hidden-economy-of-open-source-software/</guid></item><item><title>2024 年值得关注的人工智能和云趋势中的开源软件：来自 Netris 社区的想法</title><link>https://www.cncf.io/blog/2024/04/26/open-source-software-in-ai-and-cloud-trends-to-watch-in-2024-thoughts-from-the-netris-community/</link><description>&lt;p&gt;&lt;em&gt;会员帖子最初发布于&lt;a href="https://www.netris.io/open-source-software-in-ai-and-cloud-trends-to-watch-in-2024/"&gt;Netris 的博客&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="2024 年值得关注的人工智能和云趋势开源软件" src="https://www.netris.io/wp-content/uploads/2024/03/OpenSource-in-AI-banner.jpg" /&gt;&lt;/figure&gt;&lt;p&gt;让我们面对现实吧：开源软件的世界可能会让人感到无聊——以一种好的方式。开源已经变得如此普遍，并且在现代软件堆栈和生态系统中根深蒂固，以至于人们很容易不去思考它。人工智能、云和大数据的时代已经到来——现在，开源比以往任何时候都更加发挥着关键作用。&lt;/p&gt;&lt;p&gt;然而，最近 Netris 与&lt;strong&gt;Kelsey Hightower&lt;/strong&gt;主持的&lt;a href="https://www.netris.io/recap-of-tech-trends-in-2023-and-predictions-for-2024-virtual-roundtable/"&gt;圆桌讨论&lt;/a&gt;提醒人们，对于开源软件和每个使用它的人来说，仍然有很多变化正在发生。该活动的目的并不是专门关注开源 - 参与者确实讨论了其他重要主题，例如&lt;a href="https://www.netris.io/the-2024-trends-on-cloud-computing-by-kelsey-hightower-and-alex-saroyan/"&gt;云计算趋势&lt;/a&gt;和云竞争对手之间的关系 - 但开源是对话的关键部分。&lt;/p&gt;&lt;p&gt;具体来说，Hightower 和其他参与者讨论了三个主题，这些主题将在 2024 年及以后对开源软件产生重大影响。&lt;/p&gt;&lt;h3 class="wp-block-heading"&gt; 1. 开源许可变更&lt;/h3&gt;&lt;p&gt;回顾过去的一年，Hightower 观察到，开源生态系统因围绕许可的一些混乱争论而受到震动，即 HashiCorp 决定&lt;a href="https://www.techtarget.com/searchitoperations/news/366555192/Terraform-Registry-TOS-change-stokes-open-source-ire"&gt;更改其某些产品未来版本的许可条款&lt;/a&gt;（包括 Terraform，一种流行的基础设施即服务） -代码工具）以及红帽将其基于 Linux 的操作系统的源代码置于&lt;a href="https://www.everand.com/article/661624560/The-Red-Hat-Paywall"&gt;批评者认为的“付费墙”后面的新政策。&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这些发展只影响了少数开源产品，并且没有将以前的开源解决方案转变为闭源软件。尽管如此，它们在开源生态系统中引发了关于&lt;a href="https://thenewstack.io/closure-is-open-source-licensing-suddenly-unsustainable/"&gt;开源许可证的长期可行性&lt;/a&gt;的大量争议。&lt;/p&gt;&lt;p&gt; Hightower 的观点是，许可证的变化可能并不意味着开源会出现大规模危机，但它们确实反映了一个新的现实，越来越多的公司如果想继续受益于开源，就需要接受这一现实：需要更大的灵活性。能够做出有意义贡献的公司对开源项目的投资。&lt;/p&gt;&lt;p&gt; “免费工作是不可持续的，”海塔尔说。 “开源的可持续性即将达到紧要关头。”&lt;/p&gt;&lt;p&gt;他补充说，“大多数人不知道这一点，但即使是 Kubernetes 也很难找到贡献者”，他指的是他作为 Google 杰出工程师帮助开发的开源容器编排平台。&lt;/p&gt;&lt;p&gt;在 Hightower 看来，解决方案很简单：想要使用开源软件的公司需要支付更多的开发人员费用来为其做出贡献。 “如果你想避免红帽‘付费墙’，就去帮忙编写代码，”他说。&lt;/p&gt;&lt;h3 class="wp-block-heading"&gt; 2. 开源、人工智能和网络基础设施&lt;/h3&gt;&lt;p&gt;圆桌会议参与者还讨论了过去一年中热门话题：开源软件在生成人工智能领域的作用。&lt;/p&gt;&lt;p&gt; Netris 联合创始人兼首席执行官 Alex Saroyan 指出，迄今为止，关于开源和生成式 AI 的大部分讨论都集中在 Mistral 这样的公司，这些公司的目标是构建开源生成式 AI 模型，其性能至少与来自其他公司的模型一样好。像 OpenAI 这样的供应商（尽管它的名字如此， &lt;a href="https://www.itprotoday.com/software-development/openai-not-open-source-neither-are-plenty-other-open-organizations"&gt;但并不生产开源产品&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;萨罗扬说，这是人工智能领域开源的一个重要方面。但另一个关键的考虑因素——也是一个尚未受到应有重视的因素——是为开源人工智能项目提供训练人工智能模型所需的云和网络基础设施资源的访问权限的重要性。&lt;/p&gt;&lt;p&gt;原因很简单：很少有开源项目拥有训练模型所需的大规模计算基础设施。相反，他们依靠云基础设施进行培训。对于人工智能模型训练和推理，利用三大公共云提供商（即亚马逊、Azure 和谷歌云平台）变得非常昂贵，尤其是在规模上。为了“做”人工智能，企业需要 AWS 替代品、GCP 替代品等等。&lt;/p&gt;&lt;p&gt; “这就是为什么我们看到&lt;strong&gt;许多新组织推出用于模型训练的人工智能云服务，以及部署用于人工智能推理的私有边缘云&lt;/strong&gt;，”萨罗扬说。&lt;/p&gt;&lt;p&gt;事实上，Saroyan 指出，通过替代公有云和私有云提供商让 AI 基础设施更容易访问是“我们看到 NVIDIA Spectrum-X 等新一代以太网技术的原因之一”。&lt;/p&gt;&lt;p&gt;他补充说：“&lt;strong&gt;人工智能需要更多以高度可扩展且极具成本效益的方式构建的网络和云基础设施。&lt;/strong&gt; Netris 帮助客户提供的新一代网络解决方案依赖于开源软件和商用硬件。 DPU 是这幅图景的重要组成部分，”他指的是被称为数据处理单元 (DPU) 的特殊加速硬件，它对于可扩展和高效的网络至关重要。&lt;/p&gt;&lt;p&gt;简而言之：开源在生成人工智能的未来中发挥着至关重要的作用，而且它不仅限于开源人工智能模型。预计开源会出现在&lt;strong&gt;人工智能生态系统&lt;/strong&gt;的其他角落——包括充当&lt;strong&gt;人工智能工作负载与其所依赖的基础设施&lt;/strong&gt;之间重要纽带的网络。&lt;/p&gt;&lt;h3 class="wp-block-heading"&gt; 3.可共享的开源AI模型&lt;/h3&gt;&lt;p&gt;Hightower 对生成式人工智能和开源将如何融合做出了另一个预测：“我们将像可共享库一样对待模型。”&lt;/p&gt;&lt;p&gt;他的意思是人工智能开发人员将使用开源示例来构建任何人都可以使用和改进的人工智能模型。他设想了一个世界，借用别人的模型就像将模块导入到您的代码库或从公共存储库部署容器一样简单。&lt;/p&gt;&lt;p&gt; Hightower 补充说，可共享的开源人工智能模型将需要一个“公司生态系统”来构建、共享和维护人工智能软件。 “任何私人实体都不能拿走这些东西，”他说。&lt;/p&gt;&lt;p&gt;当然，考虑到 Hightower 在圆桌会议上关于公司支持开源产品重要性的其他观察，任何围绕开源模型成长起来的生态系统将需要的不仅仅是志愿者劳动力。这需要有能力支持高质量模型开发和培训的组织进行承诺投资。&lt;/p&gt;&lt;h3 class="wp-block-heading"&gt;结论：开源的未来&lt;/h3&gt;&lt;p&gt;关于开源的发展方向还有很多话要说。但如果 Hightower 和 Netris 社区的其他成员能提供任何指导的话——我们认为他们就是！ – 预计资助开源的新策略以及在人工智能领域利用开源的新方法将成为 2024 年的关键开源趋势。&lt;/p&gt;&lt;p&gt;也不要再将开源视为开发人员认为理所当然的“无聊”资源。&lt;strong&gt;开源世界正在发生变化&lt;/strong&gt;，虽然我们不知道接下来会发生什么，但我们相信开源许可的变化和&lt;strong&gt;生成式人工智能的出现等发展将迫使开源项目和社区采取新的策略&lt;/strong&gt;。 &lt;/p&gt;&lt;p&gt;&lt;a href="https://www.netris.io/open-source-software-in-ai-and-cloud-trends-to-watch-in-2024/"&gt;&lt;/a&gt;&lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Thu, 25 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/26/open-source-software-in-ai-and-cloud-trends-to-watch-in-2024-thoughts-from-the-netris-community/</guid></item><item><title>Katalyst 如何保证共置应用程序的内存 QoS</title><link>https://www.cncf.io/blog/2024/04/25/how-katalyst-guarantees-memory-qos-for-colocated-applications/</link><description>&lt;p&gt;&lt;em&gt;会员帖子最初发布在&lt;a href="https://gokatalyst.io/blog/2024/03/22/how-katalyst-guarantees-memory-qos-for-colocated-applications/"&gt;Katalyst 的博客&lt;/a&gt;上&lt;/em&gt;&lt;/p&gt;&lt;p&gt;在上一篇文章[1]中，我们介绍了Katalyst——一个基于QoS的资源管理系统，帮助字节跳动通过在线和离线工作负载的共置来提高资源效率。在主机托管场景中，内存管理是一个至关重要的话题。一方面，当节点或容器内存紧张时，应用程序的性能可能会受到影响，导致延迟抖动或 OOM（内存不足）错误等问题。在内存过度使用的托管场景中，这个问题可能会变得更加严重。另一方面，节点上可能有一些内存使用频率较低但未释放，导致可分配给离线作业的可用内存较少，从而阻碍有效的复用。针对这些问题，字节跳动将其在大规模托管过程中实践的精细化内存管理策略总结为用户态 Kubernetes 内存管理解决方案 Memory Advisor，并已在资源管理系统 Katalyst 中开源。本文将重点介绍 Kubernetes 和 Linux 内核的原生内存管理机制及其局限性，以及 Katalyst 如何通过 Memory Advisor 提高内存利用率，同时保证业务应用的内存 QoS。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="limitations-of-native-memory-management"&gt;本机内存管理的局限性&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="memory-allocation-and-reclamation-of-linux-kernel"&gt;Linux内核的内存分配与回收&lt;/h3&gt;&lt;p&gt;由于内存的访问速度比访问磁盘快得多，因此Linux倾向于采用贪婪的内存分配策略，旨在最大化分配。仅当内存水位较高时才会触发回收。 Linux内核的内存分配有快速路径和慢速路径&lt;/p&gt;&lt;h4 class="wp-block-heading" id="memory-allocation"&gt;内存分配：&lt;/h4&gt;&lt;ol&gt;&lt;li&gt;快速路径：它首先尝试进行快速路径内存分配，然后评估分配后总体可用内存水平是否会低于低水位线。如果是，则在重新评估分配的可能性之前执行快速内存回收。如果仍然不满足条件，则进入慢速路径。&lt;/li&gt;&lt;li&gt;慢速路径：在慢速路径中，它会唤醒Kswapd执行异步内存回收，然后尝试另一轮快速内存分配。如果分配失败，它会尝试内存压缩。如果分配仍然不成功，则会尝试全局直接内存回收，这需要扫描所有区域并且非常耗时。如果这也失败，它会触发系统范围的 OOM 事件来释放一些内存，然后重试快速内存分配。&lt;/li&gt;&lt;/ol&gt;&lt;h4 class="wp-block-heading" id="memory-reclamation"&gt;内存回收&lt;/h4&gt;&lt;p&gt;内存回收根据目标可以分为两种类型：基于Memcg和基于Zone。内核的本机内存回收方法包括以下几种：&lt;/p&gt;&lt;ol&gt;&lt;li&gt; Memcg级直接内存回收：当某个cgroup的MemoryUsage达到阈值时，会触发memcg级同步内存回收，释放部分内存。如果不成功，则会触发 cgroup 级别的 OOM 事件。&lt;/li&gt;&lt;li&gt;快速路径内存回收：正如前面讨论快速路径内存分配时提到的，快速内存回收很快，因为它只需要回收当前分配所需的页数。 &lt;/li&gt;&lt;/ol&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="Image" src="https://gokatalyst.io/blog/2024/03/22/how-katalyst-guarantees-memory-qos-for-colocated-applications/memory-reclaim.png" title="Linux内存回收" /&gt;&lt;/figure&gt;&lt;ol start="3"&gt;&lt;li&gt;异步内存回收：如上图所示，当系统整体可用内存下降到Low Watermark时，Kswapd会被唤醒，在后台异步回收内存，直到达到High Watermark。&lt;/li&gt;&lt;li&gt;直接内存回收：如上图所示，如果系统整体可用内存下降到最小水位线，则会触发全局直接内存回收。由于该过程是同步的并且发生在进程内存分配的上下文中，因此它对系统的性能有重大影响。&lt;/li&gt;&lt;/ol&gt;&lt;h3 class="wp-block-heading" id="kubernetes-memory-management"&gt; Kubernetes 内存管理&lt;/h3&gt;&lt;h4 class="wp-block-heading" id="memory-limit"&gt;内存限制&lt;/h4&gt;&lt;p&gt;Kubelet 根据 pod 内每个容器声明的内存限制设置 cgroup 接口&lt;code&gt;memory.limit_in_bytes&lt;/code&gt; ，限制 pod 及其容器的最大内存使用量。当 Pod 或容器的内存使用量达到此限制时，会触发直接内存回收甚至 OOM 事件。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="eviction"&gt;驱逐&lt;/h4&gt;&lt;p&gt;当节点上的内存不足时，K8s 会选择驱逐某些 Pod，并用污点标记该节点&lt;code&gt;node.kubernetes.io/memory-pressure&lt;/code&gt; ，以防止在该节点上调度其他 Pod。内存驱逐的触发条件是当节点的工作集达到阈值时：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;memory.available := node.status.capacity[memory] - node.stats.memory.workingSet&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中&lt;code&gt;memory.available&lt;/code&gt;是用户配置的阈值。对 pod 进行排序以进行驱逐时，会考虑以下标准：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;首先，它检查 pod 的内存使用量是否超过其请求；如果是这样，则优先驱逐。&lt;/li&gt;&lt;li&gt;接下来，它根据 pod 的优先级进行比较，优先级较低的 pod 首先被驱逐。&lt;/li&gt;&lt;li&gt;最后，它比较了 pod 的内存使用情况和请求之间的差异；差异较大的 pod 将首先被驱逐。&lt;/li&gt;&lt;/ol&gt;&lt;h4 class="wp-block-heading" id="oom"&gt; OOM&lt;/h4&gt;&lt;p&gt;如果直接内存回收仍然无法满足节点上进程的内存需求，则会触发系统范围的OOM事件。当 Kubelet 启动容器时，它会根据容器关联 pod 的 QoS 级别及其内存请求来配置&lt;code&gt;/proc/&amp;lt;pid&amp;gt;/oom_score_adj&lt;/code&gt; 。这会影响为 OOM Kill 选择容器的顺序：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对于关键 Pod 或&lt;code&gt;Guaranteed&lt;/code&gt; Pod 中的容器，它们的&lt;code&gt;oom_score_adj&lt;/code&gt;设置为 -997。&lt;/li&gt;&lt;li&gt;对于&lt;code&gt;BestEffort&lt;/code&gt; Pod 中的容器，它们的&lt;code&gt;oom_score_adj&lt;/code&gt;设置为 1000。&lt;/li&gt;&lt;li&gt;对于&lt;code&gt;Burstable&lt;/code&gt; Pod 中的容器，其&lt;code&gt;oom_score_adj&lt;/code&gt;使用以下公式计算： &lt;code&gt;min{max[1000 - (1000 * memoryRequest) / memoryCapacity, 1000 + guaranteedOOM]}&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 class="wp-block-heading" id="memory-qos"&gt;内存服务质量&lt;/h4&gt;&lt;p&gt;从1.22版本开始，K8s引入了基于Cgroups v2的Memory QoS功能[2]。该特性保证了容器的内存请求保证，从而保证了 Pod 之间全局内存回收的公平性。具体Cgroups配置如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;code&gt;memory.min&lt;/code&gt; ：基于&lt;code&gt;requests.memory&lt;/code&gt;配置。&lt;/li&gt;&lt;li&gt; &lt;code&gt;memory.high&lt;/code&gt; ：基于&lt;code&gt;limits.memory * throttlingfactor&lt;/code&gt; （或&lt;code&gt;nodeallocatablememory * throttlingfactor&lt;/code&gt; ）配置。&lt;/li&gt;&lt;li&gt; &lt;code&gt;memory.max&lt;/code&gt; ：基于&lt;code&gt;limits.memory&lt;/code&gt; （或&lt;code&gt;nodeallocatablememory&lt;/code&gt; ）配置。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在 K8s 1.27 版本中，对内存 QoS 功能进行了增强，解决了以下问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;当容器请求和限制接近时，由于&lt;code&gt;memory.high &amp;gt; memory.min&lt;/code&gt;限制，在&lt;code&gt;memory.high&lt;/code&gt;中配置的限制阈值可能无效。&lt;/li&gt;&lt;li&gt;计算出的&lt;code&gt;memory.high&lt;/code&gt;可能过低，导致频繁限流，影响应用性能。&lt;/li&gt;&lt;li&gt; &lt;code&gt;throttlingfactor&lt;/code&gt;的默认值过于激进 (0.8)，导致某些通常使用超过 85% 内存的 Java 应用程序频繁受到限制。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;针对这些问题，进行了以下优化：&lt;/p&gt;&lt;ol&gt;&lt;li&gt; &lt;code&gt;memory.high&lt;/code&gt;计算方法的改进：&lt;/li&gt;&lt;/ol&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;memory.high = floor{[requests.memory + memory throttling factor(limits.memory or node allocatable memory - requests.memory)]/pageSize} * pageSize&lt;/code&gt;&lt;/pre&gt;&lt;ol start="2"&gt;&lt;li&gt; &lt;code&gt;throttlingfactor&lt;/code&gt;默认值调整为0.9。&lt;/li&gt;&lt;/ol&gt;&lt;h3 class="wp-block-heading" id="limitations"&gt;局限性&lt;/h3&gt;&lt;p&gt;通过前两节的介绍，我们可以发现K8s和Linux内核内存管理机制都存在以下局限性：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;全局内存回收缺乏公平机制：&lt;/strong&gt;在内存过量使用的场景下，即使所有容器的内存使用量明显低于限制，整个节点的内存仍然可能达到全局内存回收的阈值。在广泛使用的Cgroups v1环境中，容器声明的内存请求默认不会反映在Cgroups配置中，而仅作为调度的依据。因此，Pod 之间的全局内存回收缺乏公平性保证，并且容器的可用内存不像 CPU 资源那样根据请求按比例分配。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;全局内存回收缺乏优先级机制：&lt;/strong&gt;在主机托管场景中，低优先级的离线容器经常运行资源密集型任务，可能会请求大量内存。但内存回收没有考虑应用程序的优先级，导致节点上优先级高的在线容器进入直接内存回收的慢速路径，从而扰乱在线应用程序的内存QoS。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;延迟触发原生驱逐机制：&lt;/strong&gt; K8s主要通过kubelet驱动的驱逐来保证内存使用的优先级和公平性。然而，native eviction 机制的触发时机可能发生在全局内存回收之后，因此无法及时生效。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;memcg级直接内存回收对应用性能的影响：&lt;/strong&gt;当容器的内存使用达到阈值时，会触发memcg级直接内存回收，导致内存分配延迟，可能导致业务抖动。&lt;/li&gt;&lt;/ol&gt;&lt;h2 class="wp-block-heading" id="katalyst-memory-advisor"&gt; Katalyst 内存顾问&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="overall-architecture"&gt;整体架构&lt;/h3&gt;&lt;p&gt;Katalyst Memory Advisor的架构经历了多次讨论和迭代。它采用可插拔的设计，遵循插件模型的框架，使开发人员能够灵活地扩展功能和策略。每个组件或模块的范围如下： &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="Image" src="https://gokatalyst.io/blog/2024/03/22/how-katalyst-guarantees-memory-qos-for-colocated-applications/architecture.png" title="建筑学" /&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt; &lt;strong&gt;Katalyst Agent：&lt;/strong&gt;在每个节点上运行的资源管理代理。内存QoS管理涉及以下模块：&lt;ul&gt;&lt;li&gt; Eviction Manager：扩展 kubelet 原生驱逐策略的框架。它定期调用驱逐插件的接口，检索驱逐策略计算的结果，并执行驱逐操作。&lt;/li&gt;&lt;li&gt;内存逐出插件：逐出管理器的插件。内存 QoS 管理涉及以下插件：&lt;ul&gt;&lt;li&gt;系统内存压力插件：基于整体系统级内存压力的驱逐策略。&lt;/li&gt;&lt;li&gt; NUMA 内存压力插件：基于 NUMA 节点级内存压力的驱逐策略。&lt;/li&gt;&lt;li&gt; RSS Overuse Plugin：基于 Pod 级 RSS 过度使用的驱逐策略。&lt;/li&gt;&lt;li&gt;回收资源压力插件：基于离线 Pod 内存资源履行的驱逐策略。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt; Memory QRM Plugin：内存资源管理插件。对于内存 QoS 管理，它处理离线 Pod 的 Memcg 配置并实现 Drop Cache 操作。&lt;/li&gt;&lt;li&gt; SysAdvisor：运行在各节点上的算法模块，支持通过插件扩展算法策略。内存 QoS 管理涉及以下插件：&lt;ul&gt;&lt;li&gt; Cache Reaper 插件：计算 Drop Cache 操作的触发时间，并识别哪些 Pod 需要删除其缓存。&lt;/li&gt;&lt;li&gt; Memory Guard Plugin：计算离线 Pod 的实时内存限制。&lt;/li&gt;&lt;li&gt; Memset Binder Plugin：动态计算应该绑定哪个 NUMA Node 离线 Pod。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;记者：带外信息报告框架。对于内存 QoS 管理，它向节点或&lt;code&gt;CustomNodeResource&lt;/code&gt; CRD 报告与内存压力相关的污点。&lt;/li&gt;&lt;li&gt; MetaServer：Katalyst Agent 的元数据管理组件。对于内存 QoS 管理，它提供 Pod 和容器的元数据、缓存指标并提供动态配置功能。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Malachite：&lt;/strong&gt;运行在每个节点上的Metrics数据收集组件。对于内存 QoS 管理，它提供节点、NUMA 和容器级别的内存相关指标。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Katalyst Scheduler：&lt;/strong&gt;内存 QoS 管理涉及以下插件：&lt;ul&gt;&lt;li&gt;本机&lt;code&gt;TaintToleration&lt;/code&gt;插件：基于节点污点的过滤器。&lt;/li&gt;&lt;li&gt;扩展&lt;code&gt;QoSAwareTaintToleration&lt;/code&gt;插件：根据&lt;code&gt;CustomNodeResource&lt;/code&gt; CRD 中定义的污点实现调度禁止，以实现 QoS 感知。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="detailed-design"&gt;详细设计&lt;/h3&gt;&lt;h4 class="wp-block-heading" id="multi-dimensional-interference-detection"&gt;多维干涉检测&lt;/h4&gt;&lt;p&gt;Memory Advisor 定期执行干扰检测，主动感知内存压力并触发相应的缓解措施。目前支持以下维度的干扰检测：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;系统和NUMA级内存水印：将系统和NUMA级别的空闲内存水印与全局异步内存回收的阈值水印（Low Watermark）进行比较，尽可能避免触发全局直接内存回收。&lt;/li&gt;&lt;li&gt;系统层面的Kswapd内存回收率：如果全局异步内存回收率较高且持续时间较长，则表明系统内存压力较大，未来可能会触发全局直接内存回收。&lt;/li&gt;&lt;li&gt; Pod级RSS过度使用：过度使用可以充分利用节点的内存，但无法控制过度使用的内存是用于页面缓存还是用于RSS。如果某些 Pod 的 RSS 使用量远远超过其请求，可能会导致无法回收的高节点内存水印。这可能会影响其他 Pod 无法使用足够的页面缓存，从而导致性能下降，或者可能导致 OOM 事件。&lt;/li&gt;&lt;li&gt; QoS级内存资源履行情况：通过比较节点上回收内存的供应量与该节点&lt;code&gt;reclaimed_cores&lt;/code&gt; QoS级别的内存请求总量，计算出离线作业的内存资源履行情况，防止严重影响离线作业的服务质量。&lt;/li&gt;&lt;/ol&gt;&lt;h4 class="wp-block-heading" id="multi-tiered-mitigation-measures"&gt;多层次缓解措施&lt;/h4&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="Image" src="https://gokatalyst.io/blog/2024/03/22/how-katalyst-guarantees-memory-qos-for-colocated-applications/mitigations.png" title="缓解措施" /&gt;&lt;/figure&gt;&lt;p&gt;根据干扰检测反馈的不同级别的异常情况，Memory Advisor支持多层次的缓解措施。在避免干扰高优先级 Pod 的同时，它的目标是尽量减少对受害 Pod 的影响。&lt;/p&gt;&lt;h5 class="wp-block-heading" id="forbid-scheduling"&gt;禁止调度&lt;/h5&gt;&lt;p&gt;禁止调度是影响最小的缓解措施。当干扰检测发现任何级别的系统异常时，该节点将禁止调度，以防止 Pod 进一步调度，从而防止情况进一步恶化。目前，Memory Advisor 通过 Node Taint 支持所有 pod 的此功能。将来，我们将使调度程序能够了解&lt;code&gt;CustomNodeResource&lt;/code&gt; CRD 中扩展的污点，以实现对&lt;code&gt;reclaimed_cores&lt;/code&gt; pod 的细粒度调度禁止。&lt;/p&gt;&lt;h5 class="wp-block-heading" id="tune-memcg"&gt;调整内存&lt;/h5&gt;&lt;p&gt;Tune Memcg 是一种缓解措施，对受害者 pod 的影响相对较小。当干扰检测检测到的异常程度较低时，会触发Tune Memcg操作。这样会选择一些&lt;code&gt;reclaimed_cores&lt;/code&gt; pod，并为它们配置更高的内存回收触发阈值，以更早地触发内存回收，从而尽可能避免触发全局直接内存回收。 Tune Memcg 默认情况下不启用，因为它需要使用 veLinux 内核的开源 Memcg 异步内存回收功能[3]，不影响使用。&lt;/p&gt;&lt;h5 class="wp-block-heading" id="drop-cache"&gt;删除缓存&lt;/h5&gt;&lt;p&gt;删除缓存是一种缓解措施，对受害 Pod 影响中等。当干扰检测检测到的异常程度为中等时，触发丢弃缓存操作。这会选择一些缓存使用率较高的&lt;code&gt;reclaimed_cores&lt;/code&gt; pod，并强制释放其缓存，以尽可能避免触发全局直接内存回收。在Cgroups v1环境中，缓存释放是通过&lt;code&gt;memory.force_empty&lt;/code&gt;接口触发的：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;echo 0 &amp;gt; memory.force_empty&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在Cgroups v2环境中，缓存释放是通过向&lt;code&gt;memory.reclaim&lt;/code&gt;接口写入较大的值来触发的，例如：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;echo 100G &amp;gt; memory.reclaim&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;由于删除缓存是一个耗时的操作，我们实现了异步任务执行框架以避免阻塞主进程。这部分的技术细节将在以后的文章中讨论。&lt;/p&gt;&lt;h5 class="wp-block-heading" id="eviction-1"&gt;驱逐&lt;/h5&gt;&lt;p&gt;驱逐是一种对受害者 Pod 产生重大影响的措施，但它是最快、最有效的后备措施。当干扰检测检测到高度异常时，会触发系统或NUMA级别（或仅针对&lt;code&gt;reclaimed_cores&lt;/code&gt; pod）的驱逐，以有效避免触发全局直接内存回收。 Memory Advisor 支持用户为要驱逐的 pod 配置自定义排序逻辑。如果用户没有配置，则默认的排序逻辑如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;根据 pod 的 QoS 级别对 pod 进行排序，其中&lt;code&gt;reclaimed_cores&lt;/code&gt; &amp;gt; &lt;code&gt;shared_cores&lt;/code&gt; / &lt;code&gt;dedicated_cores&lt;/code&gt; 。&lt;/li&gt;&lt;li&gt;根据 pod 的优先级对 pod 进行排序，优先级较低的 pod 首先被驱逐。&lt;/li&gt;&lt;li&gt;根据 pod 的内存使用情况对 pod 进行排序，使用率较高的 pod 首先被驱逐。我们在 Katalyst 代理中抽象出了一个驱逐管理器框架。该框架将逐出策略委托给插件，并在管理器中整合逐出操作，具有以下优点：&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;插件和管理器可以通过本地函数调用或 gRPC 进行通信，从而允许灵活的插件启动和停止。&lt;/li&gt;&lt;li&gt;管理器可以轻松支持治理操作，例如过滤、速率限制、排序和驱逐审核。&lt;/li&gt;&lt;li&gt;支持管理器中插件的试运行，允许在策略生效之前对其进行彻底验证。&lt;/li&gt;&lt;/ul&gt;&lt;h4 class="wp-block-heading" id="resource-cap-for-reclaimed_cores"&gt; reclaimed_cores 的资源上限&lt;/h4&gt;&lt;p&gt;为了防止离线容器过度使用内存，影响在线容器的服务质量，我们通过资源上限来限制&lt;code&gt;reclaimed_cores&lt;/code&gt; pod的总内存使用量。具体来说，我们在 SysAdvisor 中扩展了内存保护插件。该插件定期计算&lt;code&gt;reclaimed_cores&lt;/code&gt; pod 整体可以使用的内存总量，并通过内存 QRM 插件相应写入&lt;code&gt;BestEffort&lt;/code&gt; cgroup 的&lt;code&gt;memory.limit_in_bytes&lt;/code&gt;文件。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="memory-migration"&gt;内存迁移&lt;/h4&gt;&lt;p&gt;对于Flink这样的应用来说，业务的性能与内存带宽和内存延迟密切相关，并且会消耗大量的内存。默认内存分配策略优先从本地 NUMA 节点分配内存，以实现更低的内存访问延迟。但另一方面，默认的内存分配策略可能会导致各个NUMA节点内存使用不均匀，导致某些NUMA节点在压力过大的情况下成为热点，严重影响服务性能并导致延迟问题。因此，我们使用Memory Advisor来监控每个NUMA节点的内存水印，并动态调整容器的NUMA节点绑定进行内存迁移，以防止任何NUMA节点成为热点。在生产环境中实现内存动态迁移功能的过程中，我们遇到了可能导致系统挂起的异常情况。因此，我们优化了内存迁移的方法。这个实践经验将会在后续的博客中详细阐述。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="differentiated-memcg-level-reclamation-strategy"&gt;差异化memcg级回收策略&lt;/h4&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="Image" src="https://gokatalyst.io/blog/2024/03/22/how-katalyst-guarantees-memory-qos-for-colocated-applications/memcg-memory-reclaim.png" title="Memcg 内存回收" /&gt;&lt;/figure&gt;&lt;p&gt;鉴于memcg级直接内存回收会对应用程序性能产生显着影响，字节跳动的内核团队增强了Linux内核（即veLinux），提供了memcg级异步内存回收功能，并且该功能已开源[4]。在主机托管场景中，在线应用的典型I/O活动涉及日志的读写，而离线任务的I/O活动则涉及更频繁的文件I/O操作，页面缓存对离线作业的性能影响较大。因此，通过Memory Advisor，我们支持memcg级别的差异化内存回收策略：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对于需要大量页面缓存的应用（例如离线作业），用户可以通过pod注解指定相对较低的memcg级异步内存回收阈值。这种保守的内存回收方法允许更多的页面缓存使用。&lt;/li&gt;&lt;li&gt;相反，对于需要最小化由于直接内存回收而导致的性能下降的应用程序，用户可以通过 pod 注释配置相对激进的 memcg 级别的异步回收策略。默认情况下不启用此功能，因为它需要来自 veLinux 内核的补丁。&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading" id="future-plans"&gt;未来的计划&lt;/h2&gt;&lt;p&gt;在 Katalyst 的后续版本中，我们将继续迭代 Memory Advisor，以增强其对更广泛用户场景的支持。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="decoupling-some-capabilities-from-qos"&gt;将某些功能与 QoS 解耦&lt;/h3&gt;&lt;p&gt;Memory Advisor 在托管场景中扩展了一些增强的内存管理功能，其中一些功能与 QoS 正交，即使在非托管场景中也仍然适用。因此，在后续迭代中，我们会将memcg级差异化回收策略、干扰检测、缓解等功能与QoS增强解耦。这将把它们变成适用于一般场景的细粒度内存管理能力，让非主机场景的用户也能使用它们。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="oom-priority"&gt; OOM优先级&lt;/h3&gt;&lt;p&gt;在前面提到的上下文中，Kubernetes 根据 pod 的 QoS 级别为容器配置不同的&lt;code&gt;oom_score_adj&lt;/code&gt;值。然而，最终的 OOM 分数仍然会受到其他因素（例如内存使用情况）的影响。在潮汐托管[5]场景中，离线 Pod 属于相同的 QoS 级别，可能无法保证离线 Pod 会先于在线 Pod 被 OOM 杀死。因此，需要引入Katalyst QoS增强功能：QoS优先级。 Memory Advisor 应该能够为用户空间中属于不同 QoS 优先级的容器配置相应的&lt;code&gt;oom_score_adj&lt;/code&gt;值，确保离线 pod 严格的 OOM 顺序。此外，字节跳动内核团队最近向 Linux 内核提交了一个补丁 [6]，旨在通过 BPF hooks 以编程方式定制内核的 OOM 行为。该举措旨在增强定义 OOM 策略的灵活性。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="cold-memory-offloading"&gt;冷内存卸载&lt;/h3&gt;&lt;p&gt;节点上可能存在一些不常用的内存（称为冷内存）没有释放，导致可供离线作业使用的内存有限。这种情况会阻止有效的内存过量使用，因为可分配给脱机作业的内存仍未得到充分利用。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="Image" src="https://gokatalyst.io/blog/2024/03/22/how-katalyst-guarantees-memory-qos-for-colocated-applications/tmo.png" title="冷内存卸载" /&gt;&lt;/figure&gt;&lt;p&gt;为了增加可分配的内存量，我们参考了 Meta 的透明内存卸载（TMO）论文 [7]。未来Memory Advisor将在用户空间利用基于procfs的内存压力监控框架（PSI）来检测内存压力。当内存压力较低时，会主动触发内存回收。此外，我们将利用 DAMON 子模块进行内存热度检测来收集有关内存使用模式的信息。这些信息将用于将冷内存卸载到相对便宜的存储设备或使用 zRAM 对其进行压缩，从而节省内存空间并提高内存资源利用率。该功能的技术细节将在后续博客中详细阐述。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="summary"&gt;概括&lt;/h2&gt;&lt;p&gt;在字节跳动，Katalyst 部署在超过 90 万个节点上，管理数千万个核心，并统一管理各种工作负载类型，包括微服务、搜索、广告、存储、大数据和人工智能作业。 Katalyst 将字节跳动的日常资源利用率从 20% 提高到 60%，同时确保同时满足各种工作负载类型的 QoS 要求。未来，Katalyst Memory Advisor将持续迭代优化。有关冷内存卸载和内存迁移优化等功能的进一步技术见解将在后续博客中进行解释。敬请关注！&lt;/p&gt;&lt;h2 class="wp-block-heading" id="references"&gt;参考&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;[1] Katalyst简介： &lt;a href="https://www.cncf.io/blog/2023/12/26/katalyst-a-qos-based-resource-management-system-for-workload-colocation-on-kubernetes/"&gt;https://www.cncf.io/blog/2023/12/26/katalyst-a-qos-based-resource-management-system-for-workload-colocation-on-kubernetes /&lt;/a&gt;&lt;/li&gt;&lt;li&gt; [2] Kubernetes驱逐策略： &lt;a href="https://kubernetes.io/docs/concepts/scheduling-eviction/node-pressure-eviction/"&gt;https://kubernetes.io/docs/concepts/scheduling-eviction/node-Pressure-eviction/&lt;/a&gt;&lt;/li&gt;&lt;li&gt; [3] 内存 QoS KEP： &lt;a href="https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/2570-memory-qos"&gt;https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/2570-memory-qos&lt;/a&gt;&lt;/li&gt;&lt;li&gt; [4] Memcg级异步回收：https://github.com/bytedance/kernel/commit/7d7386ec89caf078f21836c5cae33ffa886125c4&lt;/li&gt;&lt;li&gt; [5]潮汐托管： &lt;a href="https://gokatalyst.io/docs/user-guide/tidal-colocation/"&gt;https://gokatalyst.io/docs/user-guide/tidal-colocation/&lt;/a&gt;&lt;/li&gt;&lt;li&gt; [6] 用于在 OOM 事件期间选择受害者任务的 BPF 挂钩： &lt;a href="https://lore.kernel.org/lkml/20230804093804.47039-1-zhouchuyi@bytedance.com/"&gt;https://lore.kernel.org/lkml/20230804093804.47039-1-zhouchuyi@bytedance.com/&lt;/a&gt;&lt;/li&gt;&lt;li&gt; [7] TMO论文：https://www.pdl.cmu.edu/ftp/NVM/tmo_asplos22.pdf &lt;/li&gt;&lt;/ul&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Wed, 24 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/25/how-katalyst-guarantees-memory-qos-for-colocated-applications/</guid></item><item><title>回顾：KubeCon + CloudNativeCon Europe 2024</title><link>https://www.cncf.io/blog/2024/04/23/a-recap-kubecon-cloudnativecon-europe-2024/</link><description>&lt;p&gt;&lt;em&gt;社区帖子最初由 Ryan Gough 和 Majid Attar 发表在&lt;a href="https://jysk.tech/kubecon-cloudnativecon-europe-2024-694f4b95e99e"&gt;Medium&lt;/a&gt;上&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://miro.medium.com/v2/resize:fit:700/1*mIhpY9bK-ITgsmBXYdkBIg.jpeg" /&gt;&lt;/figure&gt;&lt;p id="d7d8"&gt;今年，我们（JYSK tech）前往巴黎参加 KubeCon + CloudNativeCon Europe 2024。经过三天的会谈、交流和研讨会。我们整理了一小部分观察结果，将我们带入云原生领域。 JYSK 是&lt;a href="https://www.cncf.io/enduser/" rel="noreferrer noopener" target="_blank"&gt;CNCF 最终用户&lt;/a&gt;成员，这意味着我们能够观察社区并为塑造作为我们运营基础设施核心的云原生技术做出贡献。我们的团队对 Kubernetes 生态系统的发展印象特别深刻，这反映了其成熟程度超出了单纯的容器编排。 &lt;/p&gt;&lt;blockquote class="wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p id="40ba"&gt;产品有184个， &lt;strong&gt;Kubernetes&lt;/strong&gt;只是CNCF的一小部分。 CNCF 已对超过 30 万人进行了 Kubernetes 认证培训，并且正在考虑针对“第二天”培训的投资，即不再是 Kubernetes，而是与开放遥测、安全等元素相关的工具。&lt;/p&gt;&lt;p id="7009"&gt;现在的焦点集中在参与培训的社区成员身上。社区贡献的内容是关键，应该得到认可。&lt;/p&gt; &lt;cite&gt;&lt;a href="https://www.youtube.com/watch?v=c-Ys4qR41e4&amp;amp;list=PLenh213llmcZ0LfAsKPCeKOUKoHoAkuc8&amp;amp;index=30"&gt;– theCUBE 与&lt;strong&gt;Christophe Sauthier 和 Chris Aniszczyk&lt;/strong&gt;&lt;/a&gt;&lt;/cite&gt;&lt;/blockquote&gt;&lt;p id="3a91"&gt; JYSK 与社区的互动并不仅限于使用技术，还延伸到积极参与推动创新的对话。这种协作精神真正定义了 CNCF 的精神，确保像我们这样的最终用户的需求和观点能够帮助引导云原生项目的未来方向。展望未来，我们很高兴能够实施我们学到的一些前沿实践，并将我们自己的经验回馈给 CNCF 社区。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="dad3"&gt;&lt;strong&gt;我们发现有趣的主题：&lt;/strong&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;树内云提供商消失了！&lt;/li&gt;&lt;li&gt;人工智能当然正在获得关注，但从操作的角度来看也面临着挑战。&lt;/li&gt;&lt;li&gt;对“DevOps”和平台工程思维的关注较少。现在很明显，该行业已经适应了。&lt;/li&gt;&lt;li&gt;多集群、混合拓扑。&lt;/li&gt;&lt;li&gt;炸毁东西是好事——用混沌工程正确地做到这一点甚至更好（感谢乐高）&lt;/li&gt;&lt;li&gt;令人印象深刻的社区并注重包容性。&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="0661"&gt; Kubernetes 最终删除树内云提供商&lt;/h3&gt;&lt;p id="606a"&gt;经过多年的开发和许多贡献者的协作，Kubernetes 项目最终删除了树内云提供商。这是 Kubernetes 的一个重要里程碑，因为所有组件现在完全独立于云提供商。&lt;/p&gt;&lt;p id="d082"&gt;如果您在 AWS、Azure、GCE、OpenStack 或 vSphere 上运行 Kubernetes，您可能会受到影响。&lt;strong&gt;从 Kubernetes 1.30 版本开始，只有 GCE 上的用户会受到影响&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;演讲： &lt;a href="https://www.youtube.com/watch?v=IIxQHQHOXs4"&gt;Kubernetes 最终删除树内云提供商 — Bridget Kromhout 和 Chris Privitere&lt;/a&gt;&lt;/li&gt;&lt;li&gt;链接： &lt;a href="https://github.com/kubernetes/enhancements/blob/master/keps/sig-cloud-provider/2395-removing-in-tree-cloud-providers/README.md#summary"&gt;KEP-2395：删除树内云提供商代码&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading" id="8c45"&gt;&lt;strong&gt;房间里的大象——大规模人工智能&lt;/strong&gt;&lt;/h2&gt;&lt;p id="4532"&gt;除非你在过去的一年里一直生活在岩石下，否则 ChatGPT 和其他领域的努力推动了人工智能的发展并不奇怪。 KubeCon 举办了一系列令人印象深刻的人工智能演讲；是不是太多了？在我看来，不，它只是表明人工智能正在为 IT 思维新方式铺平道路。今年，至少对我来说，有趣的是看到人们对运营状态的关注。如何合理扩展人工智能以适应需要它的工作负载。 GPU 已成为处理密集计算不可或缺的一部分。然而，在 Kubernetes 环境中集成 GPU 加速会带来资源管理和复杂配置等障碍。&lt;/p&gt;&lt;p id="8013"&gt;公司和社区正在为实现资源共享、高级调度和加速器配置等功能铺平道路。通过克服这些挑战，Kubernetes 将成为 AI/ML 工作负载的领先平台，&lt;strong&gt;类似于 Linux 在现代数据中心中的角色。&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;主题演讲： &lt;a href="https://www.youtube.com/watch?v=gn5SZWyaZ34" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;在 Kubernetes 中使用 GPU 加速 AI 工作负载 — Kevin Klues 和 Sanjay Chatterjee&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;演讲&lt;strong&gt;：&lt;/strong&gt; &lt;a href="https://www.youtube.com/watch?v=Q5a1v_ShPew&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=55" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;分布式人工智能：使用 NATS.Io 无缝连接从云端到边缘的人工智能应用&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;演讲： &lt;a href="https://www.youtube.com/watch?v=u8pCyZFDX_g&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=90" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;边缘人工智能：云原生技术如何推动下一波智能应用&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading" id="768b"&gt;&lt;strong&gt;从 DevOps 到平台工程：关键转变？&lt;/strong&gt;&lt;/h2&gt;&lt;p id="928b"&gt;最近，围绕从 DevOps 到平台工程转型的热潮是不可否认的。在海量（阅读......混乱）的讨论和数百篇讨论该&lt;em&gt;学科&lt;/em&gt;发展的文章中，有一件事&lt;em&gt;非常&lt;/em&gt;清楚：平台工程远不是一种转瞬即逝的趋势或一个晦涩的话题。它已成为当今不断发展且复杂的 IT 环境中扩展、管理和促进创新的新标准。当我们深入研究 FinOps、可持续计算和即时部署等领域时，重新思考我们的系统管理方法变得非常重要。 &lt;/p&gt;&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;blockquote class="wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p id="320f"&gt;现在，比以往任何时候&lt;strong&gt;都更需要采用平台工程作为充分利用现代技术和方法潜力的手段。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;p id="0932"&gt;在会议期间，我特别被 CERN 主办的会议所吸引，重点讨论了他们在其平台上使用 Keycloak 进行单点登录 (SSO) 的情况。他们选择 Keycloak 的理由很明确，但最突出的方面是他们的实施方法。他们成功地制定了一个解决方案，不仅为整个组织服务，而且已成为他们研究工作不可或缺的一部分。这反映了彭博社等领先实体和挪威公共部门各个团队观察到的更广泛趋势。这些团体通过进行有意义的研究来准确地确定其“客户”的需求，从而体现了平台工程的本质。这种方法对于在当今的竞争格局中建立相关性并获得吸引力至关重要&lt;/p&gt;&lt;p id="dde2"&gt;越来越明显的是，平台工程正在演变成一门独特的学科，未经仔细考虑就不应采用。&lt;/p&gt;&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p id="2522"&gt;这波变革的浪潮是强大的，但驾驭它需要清晰的愿景和深思熟虑的策略，而不是盲目跟风。&lt;/p&gt;&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;演讲： &lt;a href="https://www.youtube.com/watch?v=3WFZhETlS9s&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=18" rel="noreferrer noopener" target="_blank"&gt;挪威公共部门的平台成熟度状况 — Hans Kristian Flaatten&lt;/a&gt;&lt;/li&gt;&lt;li&gt;主题演讲： &lt;a href="https://www.youtube.com/watch?v=rHJxdheLNwY&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=7" rel="noreferrer noopener" target="_blank"&gt;平台构建模块：如何使用 CNCF 项目构建机器学习基础设施&lt;/a&gt;&lt;/li&gt;&lt;li&gt;演讲： &lt;a href="https://www.youtube.com/watch?v=rqDrrTKzNd8&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=183" rel="noreferrer noopener" target="_blank"&gt;保护粒子加速器的艰辛 — Antonio Nappi 和 Sebastian Lopienski，CERN&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading" id="6db5"&gt;&lt;strong&gt;拥抱多集群、混合环境&lt;/strong&gt;&lt;/h2&gt;&lt;p id="80de"&gt;我们拥有几个心爱的集群的日子已经一去不复返了，我们会像对待宠物一样精心管理它们。今天的现实有很大不同。我们在各种环境中运营各种集群——无论是在多个超大规模、大型和小型数据中心的私有云设置上，还是在紧凑的边缘位置。这就是&lt;em&gt;“您的 Kubernetes 节点在哪里运行？”&lt;/em&gt;这个问题的答案。在当今的科技中&lt;em&gt;，“嗯，我们是混合动力”&lt;/em&gt;正在变得直截了当——它们在价格便宜和/或距离客户最近的地方运行。&lt;/p&gt;&lt;p id="de32"&gt;这种转变意味着集群不再需要像以前那样的溺爱、个性化关注。现在的重点是浏览复杂的、有时令人困惑的多集群环境。然而，为了给这种混乱带来一些秩序，我们正在采取一些举措，例如 ClusterInventoryAPI（尽管我听说这个名字可能有争议）等旨在建立通用标准的努力。&lt;/p&gt;&lt;p id="2222"&gt; &lt;strong&gt;ClusterAPI&lt;/strong&gt;等技术正在成为无缝扩展和管理运营的主要技术。然后还有推出可投入生产的迷你集群（例如 SideroLabs 的&lt;strong&gt;Talos）&lt;/strong&gt;的奇迹。这证明了 Kubernetes 的弹性及其对快速部署的最低要求。还记得我们花几个小时设置集群，然后庆祝每次升级的时候吗？虽然怀旧很有趣，但那些日子已经过去了。&lt;/p&gt;&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p id="b07a"&gt;现在，如果升级失败，该方法非常有效：终止集群并重新开始。&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="09aa"&gt;这种演变引出了一个问题： &lt;strong&gt;“升级”的概念本身是否已经过时了？难道我们不应该推出额外的多集群设置并转移我们的工作负载吗？&lt;/strong&gt;这个问题的答案确实取决于人们所拥有的设置类型，无论哪种方式，在当今时代，这无疑是一个可行的选择。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;演讲： &lt;a href="https://www.youtube.com/watch?v=ntSGFk0290w&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=21" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;Bloomberg 的多集群工作流程编排平台之旅 — Yao Lin 和 Reinhard Tartler&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;演讲： &lt;a href="https://www.youtube.com/watch?v=qbB3TEiOb24&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=94" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;使用 Cilium 简化多集群和多云部署 – Liz Rice，Isovalent&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;演讲： &lt;a href="https://www.youtube.com/watch?v=Xt1cuHKjKg8&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=108" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;ClusterInventory 和 ClusterFeature API 简介 — Eduardo Arango Gutierrez 和 Ryan Zhang&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading" id="4032"&gt;&lt;strong&gt;混沌工程&lt;/strong&gt;&lt;/h2&gt;&lt;p id="8a78"&gt;一段时间以来，这种关系一直是我又爱又恨的关系。想要做到这一点的想法很棒，但实际上做起来可能会令人畏惧。我是一名运营人员，我喜欢能够让我的“客户”满意并且不受干扰。 &lt;/p&gt;&lt;blockquote class="wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p id="d176"&gt;乐高的人就此发表了一次非常鼓舞人心的演讲，我很高兴听到他们&lt;strong&gt;给出了正确的方法和良好的计划。这可以是一个持续的过程。从小事做起，很快就能获得收益。&lt;/strong&gt;在整个会议期间以及闲聊中，我越来越多地听到这样的说法。这即使不是一个热门话题，也绝对是我觉得有必要调查的事情。&lt;/p&gt;&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;演讲： &lt;a href="https://www.youtube.com/watch?v=SmeekXGYuFU&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=109" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;保持积木流动：乐高集团的制造平台工程方法&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading" id="4e49"&gt;&lt;strong&gt;社区和包容性&lt;/strong&gt;&lt;/h2&gt;&lt;p id="1dc2"&gt;从适合儿童的课程到听力障碍人士的突破。看到为实现这一目标付出了多少努力和努力，我印象非常深刻。这些概念让人感觉非常熟悉——是会议不可或缺的一部分。我什至尝试参加学习手语！&lt;/p&gt;&lt;p id="bf42"&gt;有些概念可以帮助新手提交代码、无代码并学习如何参与的诀窍。我本人在 KubeCon 前几个月首次提交了 Kubernetes SIG 项目，维护人员在指导完成棘手部分以确保代码与项目保持一致并正确记录方面所提供的帮助给我留下了深刻的印象。在开发方面，我不是一个“强硬的人”，我用它来自动化、工具化等——但它感觉充满力量。虽然我喜欢开发，但我会坚持我的日常工作，运维才是未来！你首先从我那里听到的。 😉&lt;/p&gt;&lt;p id="f06b"&gt;在今年的 KubeCon 上，无论我走到哪里，脸上都洋溢着笑容。脱离同事让我们能够独立探索更多曲目，并计划稍后重新组合。与志同道合的新人交往和建立联系的机会令人兴奋。然而，这一次对我来说最引人注目的是北欧社区的非凡存在。感觉就像是一次重聚；我认出了许多熟悉的面孔，相互之间的热情问候证明了当时的云原生北欧社区的成长。&lt;/p&gt;&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p id="6946"&gt;&lt;strong&gt;这次经历衷心地提醒我们，我们的社区已经变得多么紧密相连和充满活力！&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="4122"&gt;最后，在等待演讲或在咖啡桌前排队时与我交谈过的许多人都是第一次参加。他们中的许多人对 Kubernetes 或云原生领域了解不多，但非常有兴趣了解其他公司的经验，甚至我从与这些人的交谈中也学到了一些东西。我们可以从每个角落学到一些东西。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;主题演讲： &lt;a href="https://www.youtube.com/watch?v=vwZANXuYdRI" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;主题小组讨论：多样性中的统一&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading" id="a370"&gt;&lt;strong&gt;我们发现有趣的其他相关演讲：&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="cd75"&gt;&lt;strong&gt;从 CNI 零到 CNI 英雄：实践教程&lt;/strong&gt;&lt;/h3&gt;&lt;p id="f2b0"&gt;Doug 和 Tomo 的“K8s CNI 从零到英雄”演讲是一次进入容器网络接口 (CNI) 世界的旅程。从零开始，我们对 CNI 的世界有了全面的了解。&lt;/p&gt;&lt;p id="9600"&gt;演讲结束后，我们对 CNI 的内部运作有了更深入的了解，也对解决问题和向集群引入新功能有了了解。对于那些对演讲感兴趣的人，随附的 Git 存储库和演示视频提供了一个了解并深入研究 Kubernetes CNI 世界的机会。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;视频和 GIT ： &lt;a href="https://github.com/dougbtv/cni-hero-hands-on" rel="noreferrer noopener" target="_blank"&gt;https://github.com/dougbtv/cni-hero-hands-on&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;演讲&lt;/strong&gt;：&lt;a href="https://www.youtube.com/watch?v=YumoKGhuZ2o" rel="noreferrer noopener" target="_blank"&gt;教程：从 CNI 零到 CNI 英雄：使用 CNI 的 Kubernetes 网络教程&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="b4a7"&gt;&lt;strong&gt;你的镜像真的是无Distroless的吗？ — 劳伦特·戈德尔，Docker&lt;/strong&gt;&lt;/h3&gt;&lt;p id="b832"&gt; Laurent Goderre 的演讲“你的图像真的没有 Distroless 吗？”深入研究使用多阶段构建和 distroless 容器概念制作简约 Docker 镜像的复杂性。演讲强调了 Docker 中多阶段构建的重要性，强调构建时依赖项与运行时依赖项的分离。&lt;/p&gt;&lt;p id="7b51"&gt;许多应用程序需要额外的工具（例如 shell）来有效配置运行时环境。 Goderre 建议使用&lt;strong&gt;init 容器&lt;/strong&gt;来应对这一挑战。通过将配置运行时环境所需的逻辑与环境本身分离，开发人员可以创建没有 shell 或脚本功能的镜像，从而增强容器的安全性。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;谈话&lt;/strong&gt;：&lt;a href="https://www.youtube.com/watch?v=1iJTyf4O8T8" rel="noreferrer noopener" target="_blank"&gt;你的镜像真的是 Distroless 吗？ — 劳伦特·戈德尔，Docker&lt;/a&gt;&lt;/li&gt;&lt;li&gt; &lt;strong&gt;GIT&lt;/strong&gt; ： &lt;a href="https://github.com/LaurentGoderre/kubecon-cloudnative-eu-2024-distroless" rel="noreferrer noopener" target="_blank"&gt;https://github.com/LaurentGoderre/kubecon-cloudnative-eu-2024-distroless&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="c0c6"&gt;&lt;strong&gt;为什么 Kubernetes 不适合平台，以及如何让它变得更好&lt;/strong&gt;&lt;/h3&gt;&lt;p id="5513"&gt;当前的趋势是生态系统在 Kubernetes 上构建平台，从“中心集群”开始，集成 GitOps、应用程序描述和基础设施管理的各种工具。然而，随着这些平台的发展，它们很快就会遇到 Kubernetes 作为框架的固有限制。&lt;br /&gt;&lt;br /&gt;在本次演讲中，重点强调了三个关键维度，以增强 Kubernetes 的平台工程、工作空间层次结构、跨工作空间 API 导出和集群安装。&lt;/p&gt;&lt;p id="ddc0"&gt; KCP，被描述为类似 Kubernetes 的控制平面，是作为满足这些维度的解决方案而引入的。它可以管理多个独立、隔离的“集群”（称为工作区），允许 API 服务提供商提供集中管理的 API，同时确保用户在各自的工作区中轻松使用。这种方法被定位为 SaaS 服务提供商和企业 IT 部门的构建块，旨在为孤立的租户提供 Kubernetes 原生 API。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;视频： &lt;a href="https://www.youtube.com/watch?v=7op_r9R0fCo" rel="noreferrer noopener" target="_blank"&gt;https://www.youtube.com/watch?v&lt;/a&gt; =7op_r9R0fCo&lt;/li&gt;&lt;li&gt;项目： &lt;a href="https://github.com/kcp-dev/kcp" rel="noreferrer noopener" target="_blank"&gt;https://github.com/kcp-dev/kcp&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading" id="e866"&gt;需要关注的项目：&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="7f95"&gt; KCL：基于约束的记录和函数语言&lt;/h3&gt;&lt;p id="81a1"&gt;KCL 是最终用户提交数量排名前 10 的 CNCF 项目中的第二个项目，表明根据用户贡献，云原生计算基金会 (CNCF) 生态系统中最活跃的项目。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://miro.medium.com/v2/resize:fit:700/1*c8r0BYHn3OU21OmfYJLIzg.jpeg" /&gt;&lt;/figure&gt;&lt;p id="0915"&gt; KCL 是一种开源的、基于约束的记录和函数语言，可以增强复杂配置的编写，包括云原生场景的配置。凭借其先进的编程语言技术和实践，KCL 致力于促进更好的模块化、可扩展性和配置稳定性。它支持更简单的逻辑编写，并提供易于自动化的 API 以及与本土系统的集成。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;项目： &lt;a href="https://github.com/kcl-lang/kcl" rel="noreferrer noopener" target="_blank"&gt;https://github.com/kcl-lang/kcl&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="ba25"&gt;&lt;strong&gt;维特斯&lt;/strong&gt;&lt;/h3&gt;&lt;p id="1dbf"&gt;Vitess 是一个数据库集群系统，通过通用分片来水平扩展 MySQL。&lt;/p&gt;&lt;p id="2fbb"&gt;通过封装分片路由逻辑，Vitess 允许应用程序代码和数据库查询与多个分片上的数据分布无关。借助 Vitess，您甚至可以根据需求的增长来拆分和合并分片，原子切换步骤只需几秒钟。&lt;/p&gt;&lt;p id="b8de"&gt;自 2011 年以来，Vitess 一直是&lt;strong&gt;YouTube&lt;/strong&gt;数据库基础设施的核心组件，并已发展到包含数万个 MySQL 节点。 Vitess 2010 年&lt;a href="https://vitess.io/docs/overview/history/" rel="noreferrer noopener" target="_blank"&gt;出生于 YouTube&lt;/a&gt; ， &lt;a href="https://www.cncf.io/blog/2018/02/05/cncf-host-vitess/" rel="noreferrer noopener" target="_blank"&gt;2018 年 2 月&lt;/a&gt;加入 CNCF。&lt;/p&gt;&lt;p id="326c"&gt; Vitess 的一些功能包括&lt;strong&gt;在线模式更改&lt;/strong&gt;，Vitess 解决了最古老的 MySQL 模式阻塞问题之一， &lt;a href="https://vitess.io/docs/archive/13.0/user-guides/schema-changes/" rel="noreferrer noopener" target="_blank"&gt;请参阅文档&lt;/a&gt;- 其他值得注意的功能包括可扩展性、性能、连接池、可管理性等等！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;项目&lt;/strong&gt;： &lt;a href="https://vitess.io/" rel="noreferrer noopener" target="_blank"&gt;vitess.io&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;演讲&lt;/strong&gt;： &lt;a href="https://www.youtube.com/watch?v=uRB-Qni_bCM&amp;amp;list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0&amp;amp;index=40" rel="noreferrer noopener" target="_blank"&gt;Vitess：简介、新功能和 Vinted 用户故事&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="7929"&gt;集群库存 API&lt;/h3&gt;&lt;p id="0398"&gt; ClusterInventory API 为任何多集群应用程序（框架、工具集）提供可靠、一致且自动化的方法，以发现可用集群并采取相应的操作，其方式类似于微服务架构中的服务发现工作方式。通过清单，应用程序可以查询要访问的集群列表，或者监视不断流动的集群生命周期事件流，应用程序可以及时采取行动，例如自动扩展、升级、故障和连接问题。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;项目&lt;/strong&gt;： &lt;a href="https://github.com/kubernetes-sigs/cluster-inventory-api" rel="noreferrer noopener" target="_blank"&gt;https://github.com/kubernetes-sigs/cluster-inventory-api&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="628c"&gt;韩国共产党&lt;/h3&gt;&lt;p id="94a4"&gt;kcp 可以成为 SaaS 服务提供商的构建块，这些服务提供商需要大规模多租户平台，以便使用 Kubernetes 原生 API 为大量完全隔离的租户提供服务。目标是对云提供商以及在公司内部提供 API 的企业 IT 部门有用。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;项目&lt;/strong&gt;： &lt;a href="https://github.com/kcp-dev/kcp" rel="noreferrer noopener" target="_blank"&gt;https://github.com/kcp-dev/kcp&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="17b5"&gt;薄荷工具包&lt;/h3&gt;&lt;p id="7153"&gt;Mint 工具包，以前称为 DockerSlim。 &lt;strong&gt;Mint&lt;/strong&gt;允许开发人员使用&lt;code&gt;xray&lt;/code&gt; 、 &lt;code&gt;lint&lt;/code&gt; 、 &lt;code&gt;build&lt;/code&gt; 、 &lt;code&gt;debug&lt;/code&gt; 、 &lt;code&gt;run&lt;/code&gt; 、 &lt;code&gt;images&lt;/code&gt; 、 &lt;code&gt;merge&lt;/code&gt; 、 &lt;code&gt;registry&lt;/code&gt; 、 &lt;code&gt;vulnerability&lt;/code&gt; （和其他）命令检查、优化和调试他们的容器。&lt;strong&gt;它简化并改善了开发人员构建、定制和使用容器的体验&lt;/strong&gt;。&lt;strong&gt;它使您的容器更好、更小、更安全，&lt;/strong&gt;同时提供高级可见性并提高与原始容器和缩小容器一起使用的可用性。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;项目&lt;/strong&gt;： &lt;a href="https://github.com/mintoolkit/mint" rel="noreferrer noopener" target="_blank"&gt;https://github.com/mintoolkit/mint&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="6684"&gt;塔洛斯&lt;/h3&gt;&lt;p id="83ae"&gt;&lt;strong&gt;Talos&lt;/strong&gt;是一个用于运行 Kubernetes 的现代操作系统：安全、不可变且最小化。 Talos 完全开源，可用于生产，并由&lt;a href="https://www.siderolabs.com/" rel="noreferrer noopener" target="_blank"&gt;Sidero Labs&lt;/a&gt;的人员提供支持。所有系统管理均通过 API 完成 -&lt;strong&gt;没有 shell 或交互式控制台&lt;/strong&gt;。好处包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;安全性&lt;/strong&gt;：Talos 减少了您的攻击面：它是最小的、强化的且不可变的。所有 API 访问均通过相互 TLS (mTLS) 身份验证进行保护。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可预测性&lt;/strong&gt;：Talos 消除了配置漂移，通过采用不可变的基础设施理念减少未知因素，并提供原子更新。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可进化性&lt;/strong&gt;：Talos 简化了您的架构，提高了敏捷性，并始终提供当前稳定的 Kubernetes 和 Linux 版本。&lt;/li&gt;&lt;/ul&gt;&lt;p id="1fab"&gt;&lt;strong&gt;项目&lt;/strong&gt;： &lt;a href="https://github.com/siderolabs/talos" rel="noreferrer noopener" target="_blank"&gt;https://github.com/siderolabs/talos&lt;/a&gt;&lt;/p&gt;&lt;h2 class="wp-block-heading" id="7785"&gt;所有 KubeCon + CloudNativeCon 2024 演讲&lt;/h2&gt;&lt;p id="3e92"&gt;CNCF 很快就在 YouTube 上获得了几乎所有的内容，他们提供了一个包含所有内容的漂亮播放列表。 &lt;/p&gt;&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;/div&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading" id="a190"&gt;最后的评论&lt;/h2&gt;&lt;p id="6855"&gt;以上绝不是 KubeCon + CloudNativeCon 2024 的全部综述，只是我们的观点——活动中还有数百场演讲、研讨会和会议。如果您有兴趣，我强烈建议您参加。保持开放的心态，做好计划。我发现随机挑选一些演讲也很令人耳目一新，也许那些与你当前的兴趣和/或职位并不100%相关的演讲，想法可以来自任何角落！&lt;/p&gt;&lt;p id="4578"&gt;下次 KubeCon 再见，如果您不能坚持到那时，今年&lt;strong&gt;丹麦&lt;/strong&gt;总会有&lt;strong&gt;Kubernetes 社区日&lt;/strong&gt;！请继续关注或访问&lt;a href="https://kcddenmark.dk/" rel="noreferrer noopener" target="_blank"&gt;https://kcddenmark.dk/&lt;/a&gt; ！！！ &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Mon, 22 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/23/a-recap-kubecon-cloudnativecon-europe-2024/</guid></item><item><title>使用 GreptimeDB 和 Streamlit 解码您的日常打字习惯</title><link>https://www.cncf.io/blog/2024/04/23/decoding-your-daily-typing-habits-with-greptimedb-and-streamlit/</link><description>&lt;p&gt;&lt;em&gt;会员帖子最初由 Tison 发布在&lt;a href="https://medium.com/greptime/keyboard-monitoring-and-visualization-with-greptimedb-and-streamlit-489b45764cf6"&gt;Greptime 的博客&lt;/a&gt;上&lt;/em&gt;&lt;/p&gt;&lt;p id="9e63"&gt;如今，打字对于大多数人来说几乎是每天都会发生的事情。有趣的是，您的打字习惯可能与您想象的有很大不同。下面，您将找到一个仪表板，它提供了我自己的打字倾向的可视化。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://miro.medium.com/v2/resize:fit:1400/0*fLdhaOa4bajXPbDb" /&gt;&lt;/figure&gt;&lt;p id="566d"&gt;预计我总是使用&lt;code&gt;Key.space&lt;/code&gt;来确认我的输入，并使用&lt;code&gt;Key.cmd + Key.tab&lt;/code&gt;在窗口之间切换，因为我只有一台显示器。但令人惊讶的是，我输入&lt;code&gt;Key.cmd + v&lt;/code&gt;频率比输入&lt;code&gt;Key.cmd + c&lt;/code&gt;频率要高得多，而且我总是无意识地输入&lt;code&gt;Key.cmd + s&lt;/code&gt; ，尽管我的大多数编辑器现在都可以自动保存。&lt;/p&gt;&lt;p id="7529"&gt;如果您觉得有趣，本文将告诉您如何为您构建这样的仪表板。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="9b01"&gt;先决条件&lt;/h2&gt;&lt;p id="86f8"&gt;构建此仪表板所需的所有源代码都可以在 GreptimeTeam/demo-scene 存储库中找到。&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt; &lt;a href="https://www.cncf.io/blog/2024/04/23/decoding-your-daily-typing-habits-with-greptimedb-and-streamlit/demo-scene/keyboard-monitor%20at%20main%20%C2%B7%20GreptimeTeam/demo-scene"&gt;&lt;img alt="附有超链接的 Github 图片" class="wp-image-105736" height="374" src="https://www.cncf.io/wp-content/uploads/2024/04/image-17.png" width="1390" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading" id="b1a5"&gt;什么是 Streamlit？&lt;/h2&gt;&lt;p id="69b0"&gt;在本演示中，我们使用 Streamlit 来显示输入频率。&lt;/p&gt;&lt;p id="92d3"&gt; &lt;a href="https://streamlit.io/" rel="noreferrer noopener" target="_blank"&gt;Streamlit&lt;/a&gt;是一个免费的开源框架，用于快速构建和共享精美的数据科学 Web 应用程序。它是一个专门为数据工程师设计的基于Python的库。 Streamlit 可以轻松显示数据并收集建模所需的参数，使用户只需几行代码即可创建令人惊叹的应用程序。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="c8c4"&gt;什么是 GreptimeDB？&lt;/h2&gt;&lt;p id="5525"&gt;在此演示中，我们将键盘输入事件存储到 GreptimeDB 集群中。&lt;/p&gt;&lt;p id="16ef"&gt; &lt;a href="https://github.com/GreptimeTeam/greptimedb" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;GreptimeDB&lt;/strong&gt;&lt;/a&gt;是一个开源时间序列数据库，专注于效率、可扩展性和分析能力。 GreptimeDB 专为云时代的基础设施而设计，以其弹性和商品存储为用户带来好处，&lt;strong&gt;为 InfluxDB 提供快速且经济高效的替代方案&lt;/strong&gt;，并&lt;strong&gt;为 Prometheus 提供长期存储&lt;/strong&gt;。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="b8b0"&gt;准备环境&lt;/h2&gt;&lt;p id="710e"&gt;现在，克隆源代码并安装所有依赖项：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;git clone https://github.com/GreptimeTeam/demo-scene.git&lt;br /&gt; cd demo-scene/keyboard-monitor&lt;br /&gt; pip3 install -r requirements.txt&lt;/code&gt;&lt;/pre&gt;&lt;p id="03eb"&gt;您将安装 Streamlit、SQLAlchemy 以连接到 GreptimeDB，并&lt;a href="https://pynput.readthedocs.io/en/latest/" rel="noreferrer noopener" target="_blank"&gt;安装 pynput&lt;/a&gt;以监视键盘事件。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="9871"&gt;免费获取GreptimeDB集群&lt;/h2&gt;&lt;p id="5634"&gt;获得 GreptimeDB 集群的最快方法是在&lt;a href="https://console.greptime.cloud/" rel="noreferrer noopener" target="_blank"&gt;GreptimeCloud&lt;/a&gt;上启动爱好计划（完全免费，无需信用卡信息）服务。&lt;/p&gt;&lt;p id="a15f"&gt;按照说明获取新的 GreptimeDB 服务，前往其“连接”选项卡并找到正在使用的 MySQL 连接字符串。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://miro.medium.com/v2/resize:fit:1400/0*HDLQO4_uPCG3lyOg" /&gt;&lt;figcaption class="wp-element-caption"&gt;转到服务的“连接”选项卡&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="3ad5"&gt;创建一个名为&lt;code&gt;.env&lt;/code&gt;的文件，其中包含以下内容（将相应字段替换为连接字符串）：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;DATABASE_URL=mysql://[username]:[password]@[hostname]:4002/[database]&lt;/code&gt;&lt;/pre&gt;&lt;p id="be82"&gt;现在，所有设置都已完成。转到下一步以捕获您的打字行为。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="a0a1"&gt;启动键盘监视器&lt;/h2&gt;&lt;p id="65cb"&gt;运行代理脚本以监听键盘输入：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;python3 agent.py&lt;/code&gt;&lt;/pre&gt;&lt;p id="b232"&gt;您应该看到如下日志：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;2024-03-07 20:57:53,799 INFO listener_thread Listening...&lt;/code&gt;&lt;/pre&gt;&lt;p id="8463"&gt;然后，像往常一样在任何窗口中继续输入，您将发现终端运行代理脚本日志，如下所示：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;2024-03-07 20:58:01,510 INFO sender_thread sent: Key.backspace&lt;br /&gt; 2024-03-07 20:58:01,947 INFO sender_thread sent: Key.enter&lt;br /&gt; 2024-03-07 20:58:02,498 INFO sender_thread sent: Key.shift+&amp;#39;#&amp;#39;&lt;br /&gt; 2024-03-07 20:58:02,938 INFO sender_thread sent: Key.space&lt;br /&gt; 2024-03-07 20:58:03,377 INFO sender_thread sent: Key.cmd+Key.right&lt;br /&gt; 2024-03-07 20:58:04,052 INFO sender_thread sent: Key.cmd+&amp;#39;s&amp;#39;&lt;br /&gt; ...&lt;/code&gt;&lt;/pre&gt;&lt;h2 class="wp-block-heading" id="a47a"&gt;查询键盘输入统计信息&lt;/h2&gt;&lt;p id="f0fc"&gt;当您看到“sender_thread sent”日志时，这意味着 GreptimeDB 服务现在正在接收键入事件。您可以在 GreptimeCloud Web Dashboard 上查询输入统计信息： &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://miro.medium.com/v2/resize:fit:1400/0*N6hbicDZ8od_x4qm" /&gt;&lt;figcaption class="wp-element-caption"&gt;门户 → 网络仪表板&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="单击+按钮创建查询" src="https://miro.medium.com/v2/resize:fit:1400/0*AX7MZmHbyN6t1R1t" /&gt;&lt;figcaption class="wp-element-caption"&gt;单击“+”按钮创建查询&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="f298"&gt;例如，您可以使用标准 SQL 查找最常见的键：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;SELECT hits, COUNT(*) as times&lt;br /&gt; FROM keyboard_monitor&lt;br /&gt; WHERE hits NOT LIKE &amp;#39;%+%&amp;#39;&lt;br /&gt; GROUP BY hits&lt;br /&gt; ORDER BY times DESC limit 10;&lt;/code&gt;&lt;/pre&gt;&lt;p id="b235"&gt;要计算每分钟的点击量，您可以利用 GreptimeDB 强大的&lt;a href="https://docs.greptime.com/reference/sql/range" rel="noreferrer noopener" target="_blank"&gt;RANGE QUERY&lt;/a&gt; ：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;SELECT ts, COUNT(1) RANGE &amp;#39;1h&amp;#39; as times FROM keyboard_monitor ALIGN &amp;#39;1h&amp;#39; ORDER BY ts DESC LIMIT 10;&lt;/code&gt;&lt;/pre&gt;&lt;h2 class="wp-block-heading" id="0b95"&gt;使用 Streamlit 进行可视化&lt;/h2&gt;&lt;p id="28c1"&gt;将 GreptimeDB 与 Streamlit 集成非常容易，因为它可以被视为 SQL 后端，无需开发额外的集成层。因此，您可以轻松地利用 Streamlit 来可视化您的输入频率。&lt;/p&gt;&lt;p id="f6d2"&gt;运行以下脚本：streamlit run display.py&lt;/p&gt;&lt;p id="f56a"&gt;它将在浏览器中打开一个窗口 (http://localhost:8501/) 并显示数据框： &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="键盘监视器" src="https://miro.medium.com/v2/resize:fit:1400/0*t2hoX5f6TX8tSBMM" /&gt;&lt;/figure&gt;&lt;p id="0947"&gt;就这样！&lt;/p&gt;&lt;p id="ef07"&gt;总而言之，在本指南中，我们向您展示了如何创建仪表板来监控您的打字习惯。我们邀请您亲自踏上这段发现和实验之旅。您可能会发现有关您的行为的有趣见解，这是您以前从未考虑过的。此外，请随意使用 GreptimeDB 探索其他行为，并在 X (Twitter) 或我们的讨论论坛上分享您的发现和演示。&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt; &lt;a href="https://github.com/orgs/GreptimeTeam/discussions?source=post_page-----489b45764cf6--------------------------------"&gt;&lt;img alt="GreptimeDB 讨论论坛" class="wp-image-105737" height="358" src="https://www.cncf.io/wp-content/uploads/2024/04/image-18.png" width="1390" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading" id="4290"&gt;&lt;strong&gt;关于Greptime&lt;/strong&gt;&lt;/h2&gt;&lt;p id="db26"&gt;我们帮助车联网、物联网、可观测性等产生大量时序数据的行业实时高效地发现数据的隐藏价值。&lt;/p&gt;&lt;p id="1e18"&gt;从任何设备访问&lt;a href="https://www.greptime.com/resources" rel="noreferrer noopener" target="_blank"&gt;最新版本 v0.7&lt;/a&gt;即可开始并充分利用您的数据。&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;a href="https://github.com/GreptimeTeam/greptimedb" rel="noreferrer noopener" target="_blank"&gt;GreptimeDB&lt;/a&gt;用 Rust 编写，是一个分布式开源时间序列数据库，专为可扩展性、效率和强大的分析而设计。&lt;/li&gt;&lt;li&gt; &lt;a href="https://www.greptime.com/product/cloud" rel="noreferrer noopener" target="_blank"&gt;GreptimeCloud&lt;/a&gt;提供完全托管的 DBaaS，与可观测性和物联网领域完美集成。&lt;/li&gt;&lt;li&gt; &lt;a href="https://www.greptime.com/product/ai" rel="noreferrer noopener" target="_blank"&gt;GreptimeAI&lt;/a&gt;是专为 LLM 应用程序量身定制的可观察性解决方案。&lt;/li&gt;&lt;/ul&gt;&lt;p id="6ccf"&gt;如果以上任何内容引起了您的注意，请随时在&lt;a href="https://github.com/GreptimeTeam/greptimedb" rel="noreferrer noopener" target="_blank"&gt;GitHub&lt;/a&gt;上为我们加注星标或加入&lt;a href="https://www.greptime.com/slack" rel="noreferrer noopener" target="_blank"&gt;Slack&lt;/a&gt;上的 GreptimeDB 社区。此外，您还可以访问我们的&lt;a href="https://github.com/GreptimeTeam/greptimedb/contribute" rel="noreferrer noopener" target="_blank"&gt;贡献页面&lt;/a&gt;来查找一些有趣的问题。 &lt;/p&gt;&lt;p&gt;&lt;a href="https://medium.com/@tisonkun?source=post_page-----489b45764cf6--------------------------------"&gt;&lt;/a&gt;&lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Mon, 22 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/23/decoding-your-daily-typing-habits-with-greptimedb-and-streamlit/</guid></item><item><title>Cloud Custodian 完成审核以加强安全状况并实现持续评估</title><link>https://www.cncf.io/blog/2024/04/19/cloud-custodian-completes-audit-to-strengthen-security-posture-and-enable-continuous-assessment/</link><description>&lt;p&gt;&lt;em&gt;Cloud Custodian 维护人员发布的项目&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Cloud Custodian 维护人员很高兴通过 Ada Logics 成功完成安全审核。开源技术改进基金 (OSTIF) 促进了此次审计，并由云原生计算基金会 (CNCF) 慷慨资助。此次审核标志着我们在加强云托管安全状况的持续承诺方面迈出了重要一步。&lt;/p&gt;&lt;p&gt;多年来，Cloud Custodian 已成为云治理事实上的标准。该项目允许您对治理的各个方面进行编码和自动化，包括运营、成本、安全性和语言。数千个全球品牌使用 Cloud Custodian，其贡献者超过 400 名。在审核之前，Cloud Custodian 实施了强大的安全措施来保障其运营：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;静态分析：&lt;/strong&gt;使用 Semgrep 和 Bandit 工具扫描所有拉取请求，确保在开发过程的早期识别并纠正代码漏洞。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;安全工件：&lt;/strong&gt; Docker 镜像工件通过使用 Cosign 签名的源元数据进行发布，从而增强了我们发行版的完整性。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;安全发布&lt;/strong&gt;：每次发布都使用冻结的依赖关系图进行，这可以防止注入攻击并确保可重复性。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;审计的目标和过程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Ada Logics 发起的审计的主要目标是加强 Cloud Custodian 的安全框架。该过程始于开发一个全面的威胁模型，作为审计的路线图。该模型在整个审计过程中不断完善，增强了我们对潜在安全威胁的理解和响应。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;主要活动&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;威胁模型形式化：&lt;/strong&gt;建立正式的威胁模型是至关重要的第一步，它提供了识别和减轻风险的结构化方法。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;代码审计：&lt;/strong&gt;对 Cloud Custodian 代码库的审查导致了各种安全漏洞的识别和修复。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Fuzzing 集成：&lt;/strong&gt;一个重要的里程碑是将 Cloud Custodian 集成到 OSS-Fuzz 中。此举有利于持续的安全测试，从而能够持续发现和解决漏洞。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模糊测试套件开发：&lt;/strong&gt; Ada 团队专门为 Cloud Custodian 开发了一个有针对性的模糊测试套件。该套件不仅测试 Cloud Custodian 抵御攻击的能力，还为持续的安全评估建立了可持续的基础设施。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;审计增强功能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;审计后，进行了几项关键改进：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;安全修复：&lt;/strong&gt;进行了调整以纠正与临时文件和 URL 处理相关的不安全做法。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;增强测试：&lt;/strong&gt; OSS-Fuzz测试的引入进一步增强了我们的安全测试能力，确保对潜在威胁的持续警惕。&lt;/p&gt;&lt;p&gt;从这次审计中获得的见解非常宝贵，并且对增强 Cloud Custodian 的安全状况做出了重大贡献。我们仍然致力于持续改进 Cloud Custodian，确保其安全并领先于现代安全威胁。&lt;/p&gt;&lt;p&gt;我们感谢 Ada Logics 的细致工作、OSTIF 的协助以及 CNCF 的支持。这种协作努力强调了我们致力于提供满足云治理不断变化的需求的安全工具的承诺。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://cloudcustodian.io/"&gt;云托管网站&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://github.com/cloud-custodian/cloud-custodian"&gt;云托管 Github&lt;/a&gt;&lt;/p&gt;&lt;p&gt; OSTIF 博客文章： &lt;a href="http://ostif.org/cc-audit-complete/"&gt;ostif.org/cc-audit-complete/&lt;/a&gt; &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Thu, 18 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/19/cloud-custodian-completes-audit-to-strengthen-security-posture-and-enable-continuous-assessment/</guid></item><item><title>KubeCon + CloudNativeCon 2024 回顾：亮点和要点</title><link>https://www.cncf.io/blog/2024/04/19/kubecon-cloudnativecon-2024-recap-highlights-and-takeaways/</link><description>&lt;p&gt;&lt;em&gt;社区帖子最初由 Maryam Tavakkoli 发表在&lt;a href="https://medium.com/womenintechnology/kubecon-cloudnativecon-2024-recap-highlights-and-takeaways-dfe4b6dd7159"&gt;Medium&lt;/a&gt;上&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="KubeCon 巴黎" src="https://miro.medium.com/v2/resize:fit:1400/1*WntJArILgmosjRr2DB0Ghw.jpeg" /&gt;&lt;/figure&gt;&lt;p id="7525"&gt;今年，我有机会参加在巴黎举行的 KubeCon + CloudNativeCon Europe。虽然这标志着我第二次亲自参加 KubeCon，但这是我作为大使和社区成员的第一次经历（您可以在这里找到&lt;a href="https://medium.com/@maryam.tavakoli.3/a-comprehensive-report-on-my-first-in-person-attendance-at-kubecon-cloudnativecon-2023-europe-cbabee1bb313"&gt;我第一次 KubeCon 2023 经历的&lt;/a&gt;见解。）。在本文中，我旨在总结我在该活动中的经历和观察，希望为云原生技术和社区协作的动态世界提供见解。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="46e3"&gt;云原生拒绝&lt;/h2&gt;&lt;p id="03f5"&gt;无论是过去还是今年，我都没有亲自参加过&lt;a href="https://cloud-native.rejekts.io/" rel="noreferrer noopener" target="_blank"&gt;Cloud Native Rejekts&lt;/a&gt;活动。然而，通过与 KubeCon 与会者的交谈，我注意到有些人并不知道这一事件。因此，我想简单介绍一下 Cloud Native Rejekts 事件。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="拒绝事件" src="https://miro.medium.com/v2/resize:fit:1400/1*XEToPhFpVts5szKQdFKdfg.png" /&gt;&lt;figcaption class="wp-element-caption"&gt; &lt;a href="https://cloud-native.rejekts.io/" rel="noreferrer noopener" target="_blank"&gt;https://cloud-native.rejekts.io/&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="9796"&gt;正如会议网站所述：&lt;/p&gt;&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p id="4a64"&gt; Cloud Native Rejekts 是一个 B 端会议，为 KubeCon + CloudNativeCon 拒绝的许多精彩演讲提供了第二次机会。&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="af5c"&gt;这种现场会议通常在 KubeCon 主要活动前几天举行，今年于 3 月 17 日至 18 日举行。 &lt;a href="https://www.youtube.com/watch?v=qTBHjTQ4KWc&amp;amp;list=PLnfCaIV4aZe86GBQ0GWT3JA4IG6Z7gpH_" rel="noreferrer noopener" target="_blank"&gt;会议录音&lt;/a&gt;可供查看。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="d38c"&gt;欧洲贡献者峰会&lt;/h2&gt;&lt;p id="7077"&gt;3 月 19 日在巴黎与 KubeCon + CloudNativeCon 一起举行的 &lt;a href="https://www.kubernetes.dev/events/2024/kcseu/" rel="noreferrer noopener" target="_blank"&gt;贡献者峰会&lt;/a&gt;是我第一次参加该活动。如需参加，注册仅限&lt;a href="https://www.kubernetes.dev/events/2024/kcseu/faq/#why-do-i-need-to-be-a-kubernetes-org-member-to-attend-in-person" rel="noreferrer noopener" target="_blank"&gt;Kubernetes 组织&lt;/a&gt;之一的成员或赞助的与会者。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="KubeCon 巴黎" src="https://miro.medium.com/v2/resize:fit:1400/1*CA-VZ7Rb8quPbZ_jUEZ5tg.jpeg" /&gt;&lt;figcaption class="wp-element-caption"&gt; &lt;a href="https://www.flickr.com/photos/143247548@N03/albums/with/72177720315666206" rel="noreferrer noopener" target="_blank"&gt;CNCF Flickr 帐户&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="4bfc"&gt;贡献者峰会通常包括会谈、非会议会议以及 SIG 和 WG 会议。尽管我是中午抵达巴黎，但我还是按照计划享用了专属午餐并履行了峰会志愿者职责。与社区成员一起吃饭提供了一个宝贵的机会，可以与我以前只在网上认识的人建立联系，这是这一天的一个很好的开始！&lt;/p&gt;&lt;h3 class="wp-block-heading" id="0b25"&gt;志愿服务&lt;/h3&gt;&lt;p id="68d9"&gt;贡献者峰会很大程度上取决于社区内志愿者的出色努力。我对这个过程很感兴趣，决定亲自体验一下，并自愿主持两场演讲。我强烈鼓励 Kubernetes 组织的成员参加本次活动，并考虑自愿承担任何力所能及的任务，因为正是这些贡献使本次活动成为可能。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="a9b5"&gt;同期举办活动&lt;/h2&gt;&lt;p id="0a56"&gt;我在之前的文章中讨论了 KubeCon 的布局，您可以在这里找到该文章： &lt;a href="https://faun.pub/get-the-most-out-of-kubecon-cloudnativecon-eu-2024-essential-tips-for-an-exceptional-experience-bba406537774" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;充分利用 KubeCon + CloudNativeCon EU 2024：获得卓越体验的基本技巧&lt;/strong&gt;&lt;/a&gt;。如前所述，KubeCon 的第一天致力于同期举办的活动。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="欧洲ArgoCon" src="https://miro.medium.com/v2/resize:fit:1400/1*kLRylEKG8zxWbRW8jFCsIg.jpeg" /&gt;&lt;figcaption class="wp-element-caption"&gt; &lt;a href="https://www.flickr.com/photos/143247548@N03/albums/with/72177720315666206" rel="noreferrer noopener" target="_blank"&gt;CNCF Flickr 帐户&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="4194"&gt;由于贡献者峰会与同期举办的活动同时进行，我无法参加很多演讲。然而，我特别热衷于参加&lt;a href="https://colocatedeventseu2024.sched.com/overview/type/Platform+Engineering+Day?iframe=no" rel="noreferrer noopener" target="_blank"&gt;Platform Engineering Day&lt;/a&gt;和&lt;a href="https://colocatedeventseu2024.sched.com/overview/type/ArgoCon?iframe=no" rel="noreferrer noopener" target="_blank"&gt;ArgoCon&lt;/a&gt; 。我的同事和朋友的反馈凸显了这两次活动中大量引人入胜的讨论。值得庆幸的是，所有演讲都及时发表，让我和其他人能够跟上。您可以&lt;a href="https://www.youtube.com/@cncf/playlists" rel="noreferrer noopener" target="_blank"&gt;在这里&lt;/a&gt;探索它们。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="66a4"&gt;主题演讲&lt;/h2&gt;&lt;p id="5242"&gt;今年，KubeCon 似乎采取了不同的方法，每天围绕特定主题组织主题演讲和演讲。第一天完全专注于人工智能，主题演讲和大部分演讲都聚焦于人工智能相关主题。 3 月 20 日星期三，KubeCon 的讨论气氛十分活跃。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="KubeCon 欧洲" src="https://miro.medium.com/v2/resize:fit:1400/1*lc8QrDhlZGmO7nQj0EYxWA.jpeg" /&gt;&lt;figcaption class="wp-element-caption"&gt; &lt;a href="https://www.flickr.com/photos/143247548@N03/albums/with/72177720315666206" rel="noreferrer noopener" target="_blank"&gt;CNCF Flickr 帐户&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="2c38"&gt;CNCF 工作人员今年的工作非常出色，并提供了有关每天活动的详细博客文章。我强烈建议您阅读它们以获取更多见解，您可以&lt;a href="https://www.cncf.io/blog/2024/03/20/kubecon-cloudnativecon-europe-2024-day-two-how-cloud-native-is-powering-the-ai-movement-and-other-news/" rel="noreferrer noopener" target="_blank"&gt;在此处&lt;/a&gt;找到第 2 天的博客。&lt;/p&gt;&lt;p id="369e"&gt;第二天的主题是可持续发展，尽管会谈并没有像第一天的人工智能那样完全围绕这个主题。您可以&lt;a href="https://www.cncf.io/blog/2024/03/21/kubecon-cloudnativecon-europe-2024-day-three-the-power-of-sustainable-computing/" rel="noreferrer noopener" target="_blank"&gt;在此处&lt;/a&gt;找到有关第 2 天的更多信息。&lt;/p&gt;&lt;p id="8552"&gt;不幸的是，我本人未能参加第 3 天，但根据 CNCF 博客，主题是反思 Kubernetes 的过去并展望未来。这个主题很可能源于即将到来的&lt;a href="https://events.linuxfoundation.org/kuber10es-birthday-bash/" rel="noreferrer noopener" target="_blank"&gt;Kubernetes 10 周年纪念日&lt;/a&gt;，该周年纪念日定于今年 6 月 6 日举行。现在正是回顾过去十年并展望下一个十年的最佳时机。请&lt;a href="https://www.cncf.io/blog/2024/03/22/kubecon-cloudnativecon-europe-2024-day-four-how-cloud-native-is-powering-the-ai-movement-and-other-news/" rel="noreferrer noopener" target="_blank"&gt;在此处&lt;/a&gt;阅读 CNCF 博客文章。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="KubeCon 欧洲" src="https://miro.medium.com/v2/resize:fit:1400/1*Yvn_k29so0AwIldtAW0E7w.jpeg" /&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading" id="aa0f"&gt;解决方案展示&lt;/h2&gt;&lt;p id="73e5"&gt;与我之前参加过多次演讲的 KubeCon 经历相比，今年我选择将大部分时间花在解决方案展示上并与其他与会者互动 - 我一点也不后悔！&lt;/p&gt;&lt;p id="5a40"&gt;解决方案展示是来自不同公司和项目的专家聚集的中心，提供了与合适的个人联系并交流见解的绝佳机会。特别值得注意的是社区内人们的开放和乐于助人，促进了丰富的对话和新的发现。我很高兴与老朋友重新建立联系并结交新朋友，参与有趣的讨论并扩展我的知识。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="KubeCon 欧洲" src="https://miro.medium.com/v2/resize:fit:1400/1*_DZ13UZyTErcIx_Xn7SoWw.jpeg" /&gt;&lt;figcaption class="wp-element-caption"&gt; &lt;a href="https://www.flickr.com/photos/143247548@N03/albums/with/72177720315666206" rel="noreferrer noopener" target="_blank"&gt;CNCF Flickr 帐户&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="3dc2"&gt;我什至有机会见到了 ArgoCD 的工作人员，我对这个话题有一些具体的问题。他们慷慨地分享了他们的专业知识，花时间展示解决方案并与我深入讨论。&lt;/p&gt;&lt;p id="75f3"&gt;我对未来 KubeCon 与会者的建议是什么？优先参加符合您兴趣的演讲，并提供与演讲者直接接触的机会。然后，将大部分时间用于扩展你的网络、参与对话和培养新的联系。您会发现这些互动本身就是宝贵的学习经历。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="a9d1"&gt;英特尔多元化 + 公平 + 包容性午餐&lt;/h2&gt;&lt;p id="3c94"&gt;去年，我有幸参加了 KubeCon 的多元化午餐，给我留下了深刻的印象。自然，今年我毫不犹豫地再次加入了。顾名思义，该活动提供了一个亲密的环境，参与者可以参与有关多样性和包容性的讨论。与一小群人坐在一起可以促进有意义的联系并可以丰富对话。今年的会议也不例外，我非常享受在那里的时光。我们深入研究了女性在科技行业中的角色，并探讨了导致女性在这些领域代表性不足的因素。听到参与者分享不同的观点和个人故事，揭示这个问题的复杂性，真是令人着迷。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="eb65"&gt;其他相关博客文章&lt;/h2&gt;&lt;p id="835e"&gt;您可以在以下链接中了解其他人在 KubeCon EU 2024 上的体验：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;a href="https://blog.mb-consulting.dev/kubecon-rejekts-kubetrain-kcd-dd68804e9e3e" rel="noreferrer noopener" target="_blank"&gt;https://blog.mb-consulting.dev/kubecon-rejekts-kubetrain-kcd-dd68804e9e3e&lt;/a&gt;&lt;/li&gt;&lt;li&gt; &lt;a href="https://medium.com/@mabenoit/platform-engineering-kubecon-paris-2024-1da02e6247e2"&gt;https://medium.com/@mabenoit/platform-engineering-kubecon-paris-2024-1da02e6247e2&lt;/a&gt;&lt;/li&gt;&lt;li&gt; &lt;a href="https://danielbryantuk.medium.com/kubecon-eu-2024-paris-key-takeaways-ad4c1bb7fbfe"&gt;https://danielbryantuk.medium.com/kubecon-eu-2024-paris-key-takeaways-ad4c1bb7fbfe&lt;/a&gt;&lt;/li&gt;&lt;li&gt; &lt;a href="https://jysk.tech/kubecon-cloudnativecon-europe-2024-694f4b95e99e" rel="noreferrer noopener" target="_blank"&gt;https://jysk.tech/kubecon-cloudnativecon-europe-2024-694f4b95e99e&lt;/a&gt;&lt;/li&gt;&lt;li&gt; &lt;a href="https://www.salaboy.com/2024/03/25/kubecon-eu-2024/" rel="noreferrer noopener" target="_blank"&gt;https://www.salaboy.com/2024/03/25/kubecon-eu-2024/&lt;/a&gt;&lt;/li&gt;&lt;li&gt; &lt;a href="https://www.cncf.io/blog/2024/03/28/missed-kubecon-cloudnativecon-europe-2024-heres-everything-you-need-to-know/" rel="noreferrer noopener" target="_blank"&gt;https://www.cncf.io/blog/2024/03/28/missed-kubecon-cloudnativecon-europe-2024-heres-everything-you-need-to-know/&lt;/a&gt; &lt;/li&gt;&lt;/ul&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="" src="https://miro.medium.com/v2/resize:fit:1400/0*MkqJ5sIq0gIMGHHQ.png" /&gt;&lt;/figure&gt;&lt;p id="08e9"&gt;&lt;em&gt;我很想听听您对本文的想法和反馈。&lt;br /&gt;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;让我们一起继续学习、分享、共同进步！&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;&lt;br /&gt;直到下一次！&lt;/em&gt; &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Thu, 18 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/19/kubecon-cloudnativecon-2024-recap-highlights-and-takeaways/</guid></item><item><title>MTTR 不断上升的挑战——以及该怎么做</title><link>https://www.cncf.io/blog/2024/04/18/the-challenges-of-rising-mttr-and-what-to-do/</link><description>&lt;p&gt;&lt;em&gt;成员帖子，作者： &lt;a href="https://logz.io/author/jake-odonnell/" rel="noreferrer noopener" target="_blank"&gt;Jake O&amp;#39;Donnell&lt;/a&gt; ，Logz.io&lt;/em&gt;&lt;/p&gt;&lt;p&gt;数据量正在飙升。环境变得越来越复杂。应用程序和系统遇到故障的风险非常高，生产事件的平均恢复时间 (MTTR) 正朝着错误的方向发展。&lt;/p&gt;&lt;p&gt;中断不仅会危及关键基础设施，还会直接影响组织的利润。受影响服务的快速恢复变得至关重要，因为它与业务连续性和弹性直接相关。&lt;/p&gt;&lt;p&gt; MTTR 是可观察性的关键指标。它是组织在生产事故后恢复正常能力的晴雨表。事实上，解决这些问题的周转时间越快，企业的航行就越顺利。&lt;/p&gt;&lt;p&gt;从本质上讲，MTTR 不仅是可观察性有效性的关键指标，也是组织整体运营效率的关键指标。&lt;/p&gt;&lt;p&gt;尽管对可观测性解决方案的投资不断增加并且可用工具不断增加，但 MTTR 的轨迹讲述了一个发人深省的故事。对 500 多名 IT 专业人员进行的&lt;a href="https://logz.io/observability-pulse-2024/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;2024 年可观察性脉搏调查&lt;/a&gt;结果表明，他们的组织的 MTTR 正在变长。&lt;/p&gt;&lt;p&gt;这就提出了有关现有可观测系统的有效性以及复杂环境中管理操作事件所采用的策略的相关问题。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt; 2024 年 MTTR 的令人不安的趋势&lt;/h2&gt;&lt;p&gt;我们向 Pulse 受访者询问了几个有关其组织 MTTR 的问题，结果显示组织要么进展甚微，要么倒退。&lt;/p&gt;&lt;p&gt;近 23% 的受访者表示，他们在缩短 MTTR 方面取得了长足进步，另有 9% 的受访者表示，他们已大幅缩短了 MTTR。然而，近五分之一的人表示他们的 MTTR 需要改进，并且大量受访者（41%）表示他们在这一领域进展缓慢。&lt;/p&gt;&lt;p&gt;最重要的是，我们要求受访者描述他们当前生产事故期间的 MTTR。不到五分之一 (18%) 的人表示他们的时间不到一小时。 44% 的人表示需要几个小时，四分之一的人表示半天。超过十分之一的人表示需要一天多的时间才能从生产事故中恢复过来。一小部分人（2%）表示他们的 MTTR 可能是几周或更长时间。&lt;/p&gt;&lt;p&gt;尽管如此，这意味着 82% 的受访者正在处理超过一个小时的 MTTR。我们的调查结果延续了令人不安的同比趋势。 2021 年，47% 的受访者表示他们的 MTTR 超过 1 小时，2022 年这一比例为 64%，2023 年这一比例将增长至 74%。&lt;/p&gt;&lt;p&gt;这意味着，尽管人们越来越重视可观察性，并且有许多可用的工具和流程旨在帮助从生产事故中恢复，但 MTTR 正朝着错误的方向前进。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;为什么组织的 MTTR 可能会延长？&lt;/h2&gt;&lt;p&gt;组织的 MTTR 持续延长的原因可能因团队而异。然而，2024 年 Pulse 调查的其他一些统计数据提供了有关环境挑战以及这些挑战如何对 MTTR 产生影响的线索。&lt;/p&gt;&lt;p&gt;该调查的另一个主要收获是关于获得云原生环境的可观察性的主要挑战的问题。最常见的反应是团队缺乏知识（48%）。如果近一半的团队在可观察性方面存在&lt;a href="https://logz.io/blog/reduce-mttr-talent-gap-logzio-alert-recommendations/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;知识差距&lt;/a&gt;，那么不难看出这与生产事件导致的 MTTR 缓慢之间存在联系。&lt;/p&gt;&lt;p&gt;此外，42% 的受访者将总拥有成本和大数据量视为云原生可观测性挑战。环境的复杂性以及环境产生的大量数据肯定是 MTTR 缓慢的罪魁祸首。&lt;/p&gt;&lt;p&gt;在思考 MTTR 延长的原因时， &lt;a href="https://logz.io/blog/tracing-your-steps-toward-full-kubernetes-observability/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;Kubernetes&lt;/a&gt;是另一个需要考虑的领域。大约 70% 的组织表示他们已经实施了 Kubernetes、正在开始测试它或将在未来六个月内实施。对于那些运行 Kubernetes 的人来说，40% 的受访者认为监控/故障排除是在生产环境中运行 Kubernetes 的最大挑战。安全性位居第二，为 37%。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;可以采取哪些措施来减少 MTTR？&lt;/h2&gt;&lt;p&gt;降低复杂性可能是&lt;a href="https://logz.io/blog/5-tips-for-faster-troubleshooting-to-reduce-mttr/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;减少 MTTR&lt;/a&gt;的答案之一。作为该战略的一部分，团队可以考虑整合服务。近十分之三 (28%) 的 Pulse 受访者表示，他们计划转向更多可观察性和安全监控的共享模型，这一比例高于 2023 年的 15%。&lt;/p&gt;&lt;p&gt; MTTR 问题还应该激励团队考虑更聪明地工作，而不是更努力地工作。组织可以考虑围绕自动化、人工智能/机器学习和增强监控的技术选项，以实现当今许多团队需要手动操作的流程自动化。&lt;/p&gt;&lt;p&gt; &lt;a href="https://logz.io/platform/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;Logz.io 的 Open 360™ 可观测性平台&lt;/a&gt;旨在帮助组织充分发挥关键系统和应用程序的潜力并缩短 MTTR。借助&lt;a href="https://logz.io/platform/kubernetes-360/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;Kubernetes 360&lt;/a&gt;等解决方案来全面了解基础设施，并&lt;a href="https://logz.io/blog/how-to-implement-app-360/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;使用 App 360&lt;/a&gt;作为传统 APM 的经济高效替代方案，Logz.io 可以帮助&lt;a href="https://logz.io/solutions/accelerate-cloud-monitoring/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;加速您的云监控&lt;/a&gt;并获得更好的立足点以从生产事件中恢复。&lt;/p&gt;&lt;p&gt;借助 Open 360，组织可以利用这些功能来缩短 MTTR，并在出现问题时使生产环境恢复正常：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;a href="https://logz.io/blog/logzio-service-overview-simplify-observability/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;服务概述&lt;/a&gt;将基础设施和应用程序中的遥测数据和见解统一到一个界面中。&lt;/li&gt;&lt;li&gt; &lt;a href="https://logz.io/blog/service-map/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;服务地图&lt;/a&gt;可视化整个微服务架构中的数据流、依赖关系和关键性能指标，以便于调查和故障排除。服务地图会自动发现并映射服务以及它们之间的互连，从而在服务性能的背景下提供整个分布式系统的单一视图。&lt;/li&gt;&lt;li&gt;如果您在跟踪中发现 CPU 指标或延迟出现峰值，您可以通过关联您的日志、指标和跟踪，立即获得有关问题的上下文，并通过我们的&lt;a href="https://logz.io/solutions/accelerate-cloud-monitoring/#correlate?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;事件关联&lt;/a&gt;功能调查生产问题的根本原因。&lt;/li&gt;&lt;li&gt; &lt;a href="https://logz.io/blog/anomaly-detection-application-observability/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;App 360 的异常检测&lt;/a&gt;可让用户自动监控特定服务和微服务中发生的任何问题并发出警报，这些问题是他们认为直接影响业务或 SLO 相关需求的。&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt; &lt;a href="https://logz.io/blog/reduce-mttr-talent-gap-logzio-alert-recommendations/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;警报建议&lt;/a&gt;对平台用户采取的操作进行建模，然后通过监督机器学习建议后续用户在遇到类似问题时该怎么做。&lt;/li&gt;&lt;li&gt; Logz.io 的&lt;a href="https://logz.io/solutions/reduce-observability-costs/#noisy?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;数据优化中心&lt;/a&gt;功能可以轻松删除干扰数据，这些数据会掩盖快速排除故障所需的关键见解。客户可以利用 Logz.io 自助服务工具或我们支持工程师的直接支持来识别和删除噪音数据。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt; &lt;a href="https://logz.io/freetrial/?utm_medium=referral&amp;amp;utm_source=cncf" rel="noreferrer noopener" target="_blank"&gt;立即注册 Open 360 免费试用版，&lt;/a&gt;了解它如何帮助您的组织更好地应对 MTTR。 &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Wed, 17 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/18/the-challenges-of-rising-mttr-and-what-to-do/</guid></item><item><title>Triton Server 加速基于 Dragonfly 的模型分发</title><link>https://www.cncf.io/blog/2024/04/15/triton-server-accelerates-distribution-of-models-based-on-dragonfly/</link><description>&lt;p&gt;&lt;em&gt;项目帖子，作者：Yufei Chen、Miaohao 和 Min Huang，Dragonfly 项目&lt;/em&gt;&lt;/p&gt;&lt;p&gt;本文档将帮助您体验如何将 Dragonfly 与&lt;a href="https://github.com/pytorch/serve"&gt;TritonServe&lt;/a&gt;结合使用。模型下载过程中，文件大小较大，同时有多个服务在下载文件。存储的带宽将达到极限，下载速度会很慢。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://lh7-us.googleusercontent.com/R1HVNQwGrc00vK2y_E9StRHZuF2KezxRXobvDYaSPGW77IySZ1ewLg9aL2RgBjOc6dCXJ5YCPq1ULLCB2m3E3h0E1hwzz6EryTGnQ7M5Dvb3VArP5SOlcJHB_-CymQ2i4XAMJw3xO2Nse4F-inJFbw" /&gt;&lt;/figure&gt;&lt;p&gt; Dragonfly可以通过P2P技术消除存储的带宽限制，从而加速文件下载。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://lh7-us.googleusercontent.com/MgrCqgKJqLXuB9Hq053tzCulbZRBEjpTxxdRy2j3j6Z0VJf3rI7nywINB5rZUv0o2LhSNGizxs58r_-nNMVGLOLURGBfI9p0c7xtf5MHqnPnFOlh6Qzn2Za-nyceVWgJWvccXKYEoONRNT9aLwD9ag" /&gt;&lt;/figure&gt;&lt;h1 class="wp-block-heading"&gt;&lt;strong&gt;安装&lt;/strong&gt;&lt;strong&gt;​&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;通过将 Dragonfly Repository Agent 集成到 Triton 中，通过 Dragonfly 下载流量来拉取存储在 S3、OSS、GCS 和 ABS 中的模型，并在 Triton 中注册模型。 Dragonfly 存储库代理位于&lt;a href="https://github.com/dragonflyoss/dragonfly-repository-agent"&gt;Dragonfly-repository-agent&lt;/a&gt;存储库中。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;先决条件&lt;/strong&gt;&lt;/h2&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;姓名&lt;/td&gt;&lt;td&gt;版本&lt;/td&gt;&lt;td&gt;文档&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Kubernetes集群&lt;/td&gt;&lt;td&gt;1.20+&lt;/td&gt;&lt;td&gt; &lt;a href="https://kubernetes.io/"&gt;kubernetes.io&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;舵&lt;/td&gt;&lt;td&gt;3.8.0+&lt;/td&gt;&lt;td&gt;&lt;a href="https://helm.sh/"&gt;舵机sh&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;海卫一服务器&lt;/td&gt;&lt;td&gt;23.08-py3&lt;/td&gt;&lt;td&gt;&lt;a href="https://github.com/triton-inference-server/server"&gt;海卫一服务器&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;如果没有 kubernetes 集群可供测试，建议使用&lt;a href="https://kind.sigs.k8s.io/"&gt;Kind&lt;/a&gt; 。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt; &lt;strong&gt;Dragonfly Kubernetes 集群设置&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;详细安装文档请参考&lt;a href="https://d7y.io/zh/docs/getting-started/quick-start/kubernetes/"&gt;quick-start-kubernetes&lt;/a&gt; 。&lt;/p&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;准备 Kubernetes 集群&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;创建kind多节点集群配置文件kind-config.yaml，配置内容如下：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kind: Cluster&lt;br /&gt; apiVersion: kind.x-k8s.io/v1alpha4&lt;br /&gt; nodes:&lt;br /&gt;  - role: control-plane&lt;br /&gt;  - role: worker&lt;br /&gt;  - role: worker&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用配置文件创建一个多节点集群：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kind create cluster --config kind-config.yaml&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将 kubectl 的上下文切换到 kind cluster：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kubectl config use-context kind-kind&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;种类加载蜻蜓图像&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;拉蜻蜓最新图片：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;docker pull dragonflyoss/scheduler:latest&lt;br /&gt; docker pull dragonflyoss/manager:latest&lt;br /&gt; docker pull dragonflyoss/dfdaemon:latest&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;类集群加载蜻蜓最新图像：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kind load docker-image dragonflyoss/scheduler:latest&lt;br /&gt; kind load docker-image dragonflyoss/manager:latest&lt;br /&gt; kind load docker-image dragonflyoss/dfdaemon:latest&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;基于helm Charts创建Dragonfly集群&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;创建helm图表配置文件charts-config.yam并设置dfdaemon.config.agents.regx以匹配对象存储的下载路径。示例：添加 regx:.*models.* 以匹配对象存储桶模型的下载请求。配置内容如下：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;scheduler:&lt;br /&gt;  image: dragonflyoss/scheduler&lt;br /&gt;  tag: latest&lt;br /&gt;  replicas: 1&lt;br /&gt;  metrics:&lt;br /&gt;    enable: true&lt;br /&gt;  config:&lt;br /&gt;    verbose: true&lt;br /&gt;    pprofPort: 18066&lt;br /&gt;&lt;br /&gt; seedPeer:&lt;br /&gt;  image: dragonflyoss/dfdaemon&lt;br /&gt;  tag: latest&lt;br /&gt;  replicas: 1&lt;br /&gt;  metrics:&lt;br /&gt;    enable: true&lt;br /&gt;  config:&lt;br /&gt;    verbose: true&lt;br /&gt;    pprofPort: 18066&lt;br /&gt;&lt;br /&gt; dfdaemon:&lt;br /&gt;  image: dragonflyoss/dfdaemon&lt;br /&gt;  tag: latest&lt;br /&gt;  metrics:&lt;br /&gt;    enable: true&lt;br /&gt;  config:&lt;br /&gt;    verbose: true&lt;br /&gt;    pprofPort: 18066&lt;br /&gt;    proxy:&lt;br /&gt;      defaultFilter: &amp;#39;Expires&amp;amp;Signature&amp;amp;ns&amp;#39;&lt;br /&gt;      security:&lt;br /&gt;        insecure: true&lt;br /&gt;        cacert: &amp;#39;&amp;#39;&lt;br /&gt;        cert: &amp;#39;&amp;#39;&lt;br /&gt;        key: &amp;#39;&amp;#39;&lt;br /&gt;      tcpListen:&lt;br /&gt;        namespace: &amp;#39;&amp;#39;&lt;br /&gt;        port: 65001&lt;br /&gt;      registryMirror:&lt;br /&gt;        url: https://index.docker.io&lt;br /&gt;        insecure: true&lt;br /&gt;        certs: []&lt;br /&gt;        direct: false&lt;br /&gt;      proxies:&lt;br /&gt;        - regx: blobs/sha256.*&lt;br /&gt;        # Proxy all http downlowd requests of model bucket path.&lt;br /&gt;        - regx: .*models.*&lt;br /&gt;&lt;br /&gt; manager:&lt;br /&gt;  image: dragonflyoss/manager&lt;br /&gt;  tag: latest&lt;br /&gt;  replicas: 1&lt;br /&gt;  metrics:&lt;br /&gt;    enable: true&lt;br /&gt;  config:&lt;br /&gt;    verbose: true&lt;br /&gt;    pprofPort: 18066&lt;br /&gt;&lt;br /&gt; jaeger:&lt;br /&gt;  enable: true&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用配置文件创建蜻蜓集群：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;$ helm repo add dragonfly https://dragonflyoss.github.io/helm-charts/&lt;br /&gt; $ helm install --wait --create-namespace --namespace dragonfly-system dragonfly dragonfly/dragonfly -f charts-config.yaml&lt;br /&gt; LAST DEPLOYED: Wed Nov 29 21:23:48 2023&lt;br /&gt; NAMESPACE: dragonfly-system&lt;br /&gt; STATUS: deployed&lt;br /&gt; REVISION: 1&lt;br /&gt; TEST SUITE: None&lt;br /&gt; NOTES:&lt;br /&gt; 1. Get the scheduler address by running these commands:&lt;br /&gt;  export SCHEDULER_POD_NAME=$(kubectl get pods --namespace dragonfly-system -l &amp;quot;app=dragonfly,release=dragonfly,component=scheduler&amp;quot; -o jsonpath={.items[0].metadata.name})&lt;br /&gt;  export SCHEDULER_CONTAINER_PORT=$(kubectl get pod --namespace dragonfly-system $SCHEDULER_POD_NAME -o jsonpath=&amp;quot;{.spec.containers[0].ports[0].containerPort}&amp;quot;)&lt;br /&gt;  kubectl --namespace dragonfly-system port-forward $SCHEDULER_POD_NAME 8002:$SCHEDULER_CONTAINER_PORT&lt;br /&gt;  echo &amp;quot;Visit http://127.0.0.1:8002 to use your scheduler&amp;quot;&lt;br /&gt;&lt;br /&gt; 2. Get the dfdaemon port by running these commands:&lt;br /&gt;  export DFDAEMON_POD_NAME=$(kubectl get pods --namespace dragonfly-system -l &amp;quot;app=dragonfly,release=dragonfly,component=dfdaemon&amp;quot; -o jsonpath={.items[0].metadata.name})&lt;br /&gt;  export DFDAEMON_CONTAINER_PORT=$(kubectl get pod --namespace dragonfly-system $DFDAEMON_POD_NAME -o jsonpath=&amp;quot;{.spec.containers[0].ports[0].containerPort}&amp;quot;)&lt;br /&gt;  You can use $DFDAEMON_CONTAINER_PORT as a proxy port in Node.&lt;br /&gt;&lt;br /&gt; 3. Configure runtime to use dragonfly:&lt;br /&gt;  https://d7y.io/docs/getting-started/quick-start/kubernetes/&lt;br /&gt;&lt;br /&gt;&lt;br /&gt; 4. Get Jaeger query URL by running these commands:&lt;br /&gt;  export JAEGER_QUERY_PORT=$(kubectl --namespace dragonfly-system get services dragonfly-jaeger-query -o jsonpath=&amp;quot;{.spec.ports[0].port}&amp;quot;)&lt;br /&gt;  kubectl --namespace dragonfly-system port-forward service/dragonfly-jaeger-query 16686:$JAEGER_QUERY_PORT&lt;br /&gt;  echo &amp;quot;Visit http://127.0.0.1:16686/search?limit=20&amp;amp;lookback=1h&amp;amp;maxDuration&amp;amp;minDuration&amp;amp;service=dragonfly to query download events&amp;quot;&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;检查蜻蜓是否部署成功：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;$ kubectl get pods -n dragonfly-system&lt;br /&gt; NAME                                 READY   STATUS    RESTARTS       AGE&lt;br /&gt; dragonfly-dfdaemon-8qcpd             1/1     Running   4 (118s ago)   2m45s&lt;br /&gt; dragonfly-dfdaemon-qhkn8             1/1     Running   4 (108s ago)   2m45s&lt;br /&gt; dragonfly-jaeger-6c44dc44b9-dfjfv    1/1     Running   0              2m45s&lt;br /&gt; dragonfly-manager-549cd546b9-ps5tf   1/1     Running   0              2m45s&lt;br /&gt; dragonfly-mysql-0                    1/1     Running   0              2m45s&lt;br /&gt; dragonfly-redis-master-0             1/1     Running   0              2m45s&lt;br /&gt; dragonfly-redis-replicas-0           1/1     Running   0              2m45s&lt;br /&gt; dragonfly-redis-replicas-1           1/1     Running   0              2m7s&lt;br /&gt; dragonfly-redis-replicas-2           1/1     Running   0              101s&lt;br /&gt; dragonfly-scheduler-0                1/1     Running   0              2m45s&lt;br /&gt; dragonfly-seed-peer-0                1/1     Running   1 (52s ago)    2m45s&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;暴露Proxy服务端口&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;创建 dfstore.yaml 配置文件以公开 Dragonfly Peer 的 HTTP 代理侦听的端口。默认端口为 65001，将 targetPort 设置为 65001。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kind: Service&lt;br /&gt; apiVersion: v1&lt;br /&gt; metadata:&lt;br /&gt;  name: dfstore&lt;br /&gt; spec:&lt;br /&gt;  selector:&lt;br /&gt;    app: dragonfly&lt;br /&gt;    component: dfdaemon&lt;br /&gt;    release: dragonfly&lt;br /&gt;&lt;br /&gt;  ports:&lt;br /&gt;    - protocol: TCP&lt;br /&gt;      port: 65001&lt;br /&gt;      targetPort: 65001&lt;br /&gt;&lt;br /&gt;  type: NodePort&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;创建服务：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kubectl --namespace dragonfly-system apply -f dfstore.yaml&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将请求转发到 Dragonfly Peer 的 HTTP 代理：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kubectl --namespace dragonfly-system port-forward service/dfstore 65001:65001&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;安装 Dragonfly 存储库代理&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;设置 Dragonfly 存储库代理配置&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;创建dragonfly_config.json配置文件，配置如下：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;{&lt;br /&gt;  &amp;quot;proxy&amp;quot;: &amp;quot;http://127.0.0.1:65001&amp;quot;,&lt;br /&gt; &amp;quot;header&amp;quot;: {&lt;br /&gt; },&lt;br /&gt; &amp;quot;filter&amp;quot;: [&lt;br /&gt;  &amp;quot;X-Amz-Algorithm&amp;quot;,&lt;br /&gt;  &amp;quot;X-Amz-Credential&amp;amp;X-Amz-Date&amp;quot;,&lt;br /&gt;  &amp;quot;X-Amz-Expires&amp;quot;,&lt;br /&gt;  &amp;quot;X-Amz-SignedHeaders&amp;quot;,&lt;br /&gt;  &amp;quot;X-Amz-Signature&amp;quot;&lt;br /&gt; ]&lt;br /&gt; }&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&lt;li&gt; proxy：Dragonfly Peer 的 HTTP 代理的地址。&lt;/li&gt;&lt;li&gt; header：为请求添加请求头。&lt;/li&gt;&lt;li&gt;过滤器：用于生成唯一的任务并过滤URL中不必要的查询参数。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在配置的过滤器中，使用不同的对象存储时设置不同的值：&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;类型&lt;/td&gt;&lt;td&gt;价值&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;开放源码软件&lt;/td&gt;&lt;td&gt;[“过期”，“签名”，“ns”]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; S3&lt;/td&gt;&lt;td&gt; [“X-Amz-算法”、“X-Amz-凭证”、“X-Amz-日期”、“X-Amz-过期”、“X-Amz-SignedHeaders”、“X-Amz-签名”]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; OBS&lt;/td&gt;&lt;td&gt; [“X-Amz-算法”、“X-Amz-凭证”、“X-Amz-日期”、“X-Obs-日期”、“X-Amz-过期”、“X-Amz-SignedHeaders”、“ X-Amz-签名”]&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;设置模型存储库配置&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;创建cloud_credential.json云存储凭证，配置如下：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;{&lt;br /&gt;  &amp;quot;gs&amp;quot;: {&lt;br /&gt;    &amp;quot;&amp;quot;: &amp;quot;PATH_TO_GOOGLE_APPLICATION_CREDENTIALS&amp;quot;,&lt;br /&gt;    &amp;quot;gs://gcs-bucket-002&amp;quot;: &amp;quot;PATH_TO_GOOGLE_APPLICATION_CREDENTIALS_2&amp;quot;&lt;br /&gt;  },&lt;br /&gt;  &amp;quot;s3&amp;quot;: {&lt;br /&gt;    &amp;quot;&amp;quot;: {&lt;br /&gt;      &amp;quot;secret_key&amp;quot;: &amp;quot;AWS_SECRET_ACCESS_KEY&amp;quot;,&lt;br /&gt;      &amp;quot;key_id&amp;quot;: &amp;quot;AWS_ACCESS_KEY_ID&amp;quot;,&lt;br /&gt;      &amp;quot;region&amp;quot;: &amp;quot;AWS_DEFAULT_REGION&amp;quot;,&lt;br /&gt;      &amp;quot;session_token&amp;quot;: &amp;quot;&amp;quot;,&lt;br /&gt;      &amp;quot;profile&amp;quot;: &amp;quot;&amp;quot;&lt;br /&gt;    },&lt;br /&gt;    &amp;quot;s3://s3-bucket-002&amp;quot;: {&lt;br /&gt;      &amp;quot;secret_key&amp;quot;: &amp;quot;AWS_SECRET_ACCESS_KEY_2&amp;quot;,&lt;br /&gt;      &amp;quot;key_id&amp;quot;: &amp;quot;AWS_ACCESS_KEY_ID_2&amp;quot;,&lt;br /&gt;      &amp;quot;region&amp;quot;: &amp;quot;AWS_DEFAULT_REGION_2&amp;quot;,&lt;br /&gt;      &amp;quot;session_token&amp;quot;: &amp;quot;AWS_SESSION_TOKEN_2&amp;quot;,&lt;br /&gt;      &amp;quot;profile&amp;quot;: &amp;quot;AWS_PROFILE_2&amp;quot;&lt;br /&gt;    }&lt;br /&gt;  },&lt;br /&gt;  &amp;quot;as&amp;quot;: {&lt;br /&gt;    &amp;quot;&amp;quot;: {&lt;br /&gt;      &amp;quot;account_str&amp;quot;: &amp;quot;AZURE_STORAGE_ACCOUNT&amp;quot;,&lt;br /&gt;      &amp;quot;account_key&amp;quot;: &amp;quot;AZURE_STORAGE_KEY&amp;quot;&lt;br /&gt;    },&lt;br /&gt;    &amp;quot;as://Account-002/Container&amp;quot;: {&lt;br /&gt;      &amp;quot;account_str&amp;quot;: &amp;quot;&amp;quot;,&lt;br /&gt;      &amp;quot;account_key&amp;quot;: &amp;quot;&amp;quot;&lt;br /&gt;    }&lt;br /&gt;  }&lt;br /&gt; }&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;为了通过 Dragonfly 拉取模型，需要在模型配置文件 config.pbtxt 文件中添加以下代码：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;model_repository_agents&lt;br /&gt; {&lt;br /&gt;  agents [&lt;br /&gt;    {&lt;br /&gt;      name: &amp;quot;dragonfly&amp;quot;,&lt;br /&gt;    }&lt;br /&gt;  ]&lt;br /&gt; }&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; &lt;a href="https://github.com/dragonflyoss/dragonfly-repository-agent/tree/main/examples/model_repository/densenet_onnx"&gt;ensenet_onnx 示例&lt;/a&gt;包含修改后的配置和模型文件。修改config.pbtxt如：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;name: &amp;quot;densenet_onnx&amp;quot;&lt;br /&gt; platform: &amp;quot;onnxruntime_onnx&amp;quot;&lt;br /&gt; max_batch_size : 0&lt;br /&gt; input [&lt;br /&gt;  {&lt;br /&gt;    name: &amp;quot;data_0&amp;quot;&lt;br /&gt;    data_type: TYPE_FP32&lt;br /&gt;    format: FORMAT_NCHW&lt;br /&gt;    dims: [ 3, 224, 224 ]&lt;br /&gt;    reshape { shape: [ 1, 3, 224, 224 ] }&lt;br /&gt;  }&lt;br /&gt; ]&lt;br /&gt; output [&lt;br /&gt;  {&lt;br /&gt;    name: &amp;quot;fc6_1&amp;quot;&lt;br /&gt;    data_type: TYPE_FP32&lt;br /&gt;    dims: [ 1000 ]&lt;br /&gt;    reshape { shape: [ 1, 1000, 1, 1 ] }&lt;br /&gt;    label_filename: &amp;quot;densenet_labels.txt&amp;quot;&lt;br /&gt;  }&lt;br /&gt; ]&lt;br /&gt; model_repository_agents&lt;br /&gt; {&lt;br /&gt;  agents [&lt;br /&gt;    {&lt;br /&gt;      name: &amp;quot;dragonfly&amp;quot;,&lt;br /&gt;    }&lt;br /&gt;  ]&lt;br /&gt; }&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 class="wp-block-heading"&gt; &lt;strong&gt;Triton Server 集成 Dragonfly Repository Agent 插件&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;使用 Docker 安装 Triton 服务器&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;拉取 Dragonflyoss/dragonfly-repository-agent 镜像，该镜像是 Triton Server 中集成的 Dragonfly Repository Agent 插件，请参阅&lt;a href="https://github.com/dragonflyoss/dragonfly-repository-agent/blob/main/Dockerfile"&gt;Dockerfile&lt;/a&gt; 。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;docker pull dragonflyoss/dragonfly-repository-agent:latest&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行容器并挂载配置目录：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;docker run --network host --rm \&lt;br /&gt;  -v ${path-to-config-dir}:/home/triton/ \&lt;br /&gt;  dragonflyoss/dragonfly-repository-agent:latest tritonserver \&lt;br /&gt;  --model-repository=${model-repository-path}&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&lt;li&gt; path-to-config-dir：dragonfly_config.json&amp;amp;cloud_credential.json的文件路径。&lt;/li&gt;&lt;li&gt; model-repository-path：远程模型存储库的路径。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;正确的输出如下：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;=============================&lt;br /&gt; == Triton Inference Server ==&lt;br /&gt; =============================&lt;br /&gt; successfully loaded &amp;#39;densenet_onnx&amp;#39;&lt;br /&gt; I1130 09:43:22.595672 1 server.cc:604]&lt;br /&gt; +------------------+------------------------------------------------------------------------+&lt;br /&gt; | Repository Agent | Path                                                                   |&lt;br /&gt; +------------------+------------------------------------------------------------------------+&lt;br /&gt; | dragonfly        | /opt/tritonserver/repoagents/dragonfly/libtritonrepoagent_dragonfly.so |&lt;br /&gt; +------------------+------------------------------------------------------------------------+&lt;br /&gt;&lt;br /&gt; I1130 09:43:22.596011 1 server.cc:631]&lt;br /&gt; +-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt; | Backend     | Path                                                            | Config                                                                                                                                                        |&lt;br /&gt; +-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt; | pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {}                                                                                                                                                            |&lt;br /&gt; | onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {&amp;quot;cmdline&amp;quot;:{&amp;quot;auto-complete-config&amp;quot;:&amp;quot;true&amp;quot;,&amp;quot;backend-directory&amp;quot;:&amp;quot;/opt/tritonserver/backends&amp;quot;,&amp;quot;min-compute-capability&amp;quot;:&amp;quot;6.000000&amp;quot;,&amp;quot;default-max-batch-size&amp;quot;:&amp;quot;4&amp;quot;}} |&lt;br /&gt; +-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt;&lt;br /&gt; I1130 09:43:22.596112 1 server.cc:674]&lt;br /&gt; +---------------+---------+--------+&lt;br /&gt; | Model         | Version | Status |&lt;br /&gt; +---------------+---------+--------+&lt;br /&gt; | densenet_onnx | 1       | READY  |&lt;br /&gt; +---------------+---------+--------+&lt;br /&gt;&lt;br /&gt; I1130 09:43:22.598318 1 metrics.cc:703] Collecting CPU metrics&lt;br /&gt; I1130 09:43:22.599373 1 tritonserver.cc:2435]&lt;br /&gt; +----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt; | Option                           | Value                                                                                                                                                                                                           |&lt;br /&gt; +----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt; | server_id                        | triton                                                                                                                                                                                                          |&lt;br /&gt; | server_version                   | 2.37.0                                                                                                                                                                                                          |&lt;br /&gt; | server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data parameters statistics trace logging |&lt;br /&gt; | model_repository_path[0]         | s3://192.168.36.128:9000/models                                                                                                                                                                                 |&lt;br /&gt; | model_control_mode               | MODE_NONE                                                                                                                                                                                                       |&lt;br /&gt; | strict_model_config              | 0                                                                                                                                                                                                               |&lt;br /&gt; | rate_limit                       | OFF                                                                                                                                                                                                             |&lt;br /&gt; | pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                                       |&lt;br /&gt; | min_supported_compute_capability | 6.0                                                                                                                                                                                                             |&lt;br /&gt; | strict_readiness                 | 1                                                                                                                                                                                                               |&lt;br /&gt; | exit_timeout                     | 30                                                                                                                                                                                                              |&lt;br /&gt; | cache_enabled                    | 0                                                                                                                                                                                                               |&lt;br /&gt; +----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt;&lt;br /&gt; I1130 09:43:22.610334 1 grpc_server.cc:2451] Started GRPCInferenceService at 0.0.0.0:8001&lt;br /&gt; I1130 09:43:22.612623 1 http_server.cc:3558] Started HTTPService at 0.0.0.0:8000&lt;br /&gt; I1130 09:43:22.695843 1 http_server.cc:187] Started Metrics Service at 0.0.0.0:8002&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;执行以下命令查看 Dragonfly 日志：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kubectl exec -it -n dragonfly-system dragonfly-dfdaemon-&amp;lt;id&amp;gt; -- tail -f /var/log/dragonfly/daemon/core.log&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;检查通过Dragonfly下载是否成功：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;{&lt;br /&gt; &amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:&amp;quot;2024-02-02 05:28:02.631&amp;quot;,&lt;br /&gt; &amp;quot;caller&amp;quot;:&amp;quot;peer/peertask_conductor.go:1349&amp;quot;,&lt;br /&gt; &amp;quot;msg&amp;quot;:&amp;quot;peer task done, cost: 352ms&amp;quot;,&lt;br /&gt; &amp;quot;peer&amp;quot;:&amp;quot;10.244.2.3-1-4398a429-d780-423a-a630-57d765f1ccfc&amp;quot;,&lt;br /&gt; &amp;quot;task&amp;quot;:&amp;quot;974aaf56d4877cc65888a4736340fb1d8fecc93eadf7507f531f9fae650f1b4d&amp;quot;,&lt;br /&gt; &amp;quot;component&amp;quot;:&amp;quot;PeerTask&amp;quot;,&lt;br /&gt; &amp;quot;trace&amp;quot;:&amp;quot;4cca9ce80dbf5a445d321cec593aee65&amp;quot;&lt;br /&gt; }&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;核实&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;调用推理API：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;docker run -it --rm --net=host nvcr.io/nvidia/tritonserver:23.08-py3-sdk /workspace/install/bin/image_client -m densenet_onnx -c 3 -s INCEPTION /workspace/images/mug.jpg&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;检查响应是否成功：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;Request 01&lt;br /&gt; Image &amp;#39;/workspace/images/mug.jpg&amp;#39;:&lt;br /&gt;    15.349563 (504) = COFFEE MUG&lt;br /&gt;    13.227461 (968) = CUP&lt;br /&gt;    10.424893 (505) = COFFEEPOT&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;性能测试&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;测试集成Dragonfly P2P后通过Triton API下载单机模型的性能。由于机器本身网络环境的影响，实际下载时间并不重要，但不同场景下下载速度的比例更有意义： &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://lh7-us.googleusercontent.com/wFGp6qxEQvNWh5ZADtHZaZzASh6Cnf_vYoHTWF7rvyyVHV6aSzr3mtYe_bLJdrN9EXSgYmyXbusCYwqVKiUmayWnx8LCI4IuVXUme958nfjx6IJwpkFvtoVZy82P8Drf_BB_5wMdGOvw7qfaWx5_YA" /&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt; Triton API：使用对象存储提供的签名URL直接下载模型。&lt;/li&gt;&lt;li&gt; Triton API 和 Dragonfly 冷启动：使用 Triton Serve API 通过 Dragonfly P2P 网络下载模型，无缓存命中。&lt;/li&gt;&lt;li&gt;命中远程对等点：使用 Triton Serve API 通过 Dragonfly P2P 网络下载模型并命中远程对等点缓存。&lt;/li&gt;&lt;li&gt;命中本地对等点：使用 Triton Serve API 通过 Dragonfly P2P 网络下载模型并命中本地对等点缓存。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;测试结果显示 Triton 和 Dragonfly 集成。可以有效减少文件下载时间。注意，本次测试是单机测试，这意味着在缓存命中的情况下，性能限制在磁盘上。如果Dragonfly部署在多台机器上进行P2P下载，模型下载速度会更快。&lt;/p&gt;&lt;h1 class="wp-block-heading"&gt;&lt;strong&gt;相关链接&lt;/strong&gt;&lt;/h1&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;蜻蜓社区&lt;/strong&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;网站： &lt;a href="https://d7y.io/"&gt;https://d7y.io/&lt;/a&gt;&lt;/li&gt;&lt;li&gt; Github 仓库： &lt;a href="https://github.com/dragonflyoss/Dragonfly2"&gt;https://github.com/dragonflyoss/Dragonfly2&lt;/a&gt;&lt;/li&gt;&lt;li&gt; Dragonfly 存储库代理 Github 存储库： &lt;a href="https://github.com/dragonflyoss/dragonfly-repository-agent"&gt;https://github.com/dragonflyoss/dragonfly-repository-agent&lt;/a&gt;&lt;/li&gt;&lt;li&gt; Slack 频道： &lt;a href="https://slack.cncf.io/"&gt;CNCF Slack&lt;/a&gt;上的&lt;a href="https://cloud-native.slack.com/messages/dragonfly/"&gt;#dragonfly&lt;/a&gt;&lt;/li&gt;&lt;li&gt;讨论组： &lt;a href="mailto:dragonfly-discuss@googlegroups.com"&gt;dragonfly-discuss@googlegroups.com&lt;/a&gt;&lt;/li&gt;&lt;li&gt;推特： &lt;a href="https://twitter.com/dragonfly_oss"&gt;@dragonfly_oss&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading"&gt; &lt;strong&gt;NVIDIA Triton 推理服务器&lt;/strong&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;网站： &lt;a href="https://developer.nvidia.com/triton-inference-server"&gt;https://developer.nvidia.com/triton-inference-server&lt;/a&gt;&lt;/li&gt;&lt;li&gt; Github 存储库： &lt;a href="https://github.com/triton-inference-server/server"&gt;https://github.com/triton-inference-server/server&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;二维码&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Dragonfly Github仓库： &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="二维码" src="https://lh7-us.googleusercontent.com/dHuRcLXUyidFEw_iLig1WmDHNOtGGUEwVObfDjbupoVCKV1tvZ7bLv38018mFX0umVHxqRyZEGe0jBPcjJS9wEBJjQbxAlB0DAiZQs1EL27DrgdyAnhjQLsfNVR8wFavNJgNtyz6xOPqJ8_md8rF3A" /&gt;&lt;/figure&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Sun, 14 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/15/triton-server-accelerates-distribution-of-models-based-on-dragonfly/</guid></item></channel></rss>