<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>CNCF - 博客</title><link>https://www.cncf.io/blog/</link><description>CNCF - 博客 - RSSHub 用爱制作(https://github.com/DIYgod/RSSHub)</description><lastBuildDate>Wed, 17 Apr 2024 06:00:33 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Triton Server 加速基于 Dragonfly 的模型分发</title><link>https://www.cncf.io/blog/2024/04/15/triton-server-accelerates-distribution-of-models-based-on-dragonfly/</link><description>&lt;p&gt;&lt;em&gt;项目帖子，作者：Yufei Chen、Miaohao 和 Min Huang，Dragonfly 项目&lt;/em&gt;&lt;/p&gt;&lt;p&gt;本文档将帮助您体验如何将 Dragonfly 与&lt;a href="https://github.com/pytorch/serve"&gt;TritonServe&lt;/a&gt;结合使用。模型下载过程中，文件大小较大，同时有多个服务在下载文件。存储的带宽将达到极限，下载速度会很慢。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://lh7-us.googleusercontent.com/R1HVNQwGrc00vK2y_E9StRHZuF2KezxRXobvDYaSPGW77IySZ1ewLg9aL2RgBjOc6dCXJ5YCPq1ULLCB2m3E3h0E1hwzz6EryTGnQ7M5Dvb3VArP5SOlcJHB_-CymQ2i4XAMJw3xO2Nse4F-inJFbw" /&gt;&lt;/figure&gt;&lt;p&gt; Dragonfly可以通过P2P技术消除存储的带宽限制，从而加速文件下载。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://lh7-us.googleusercontent.com/MgrCqgKJqLXuB9Hq053tzCulbZRBEjpTxxdRy2j3j6Z0VJf3rI7nywINB5rZUv0o2LhSNGizxs58r_-nNMVGLOLURGBfI9p0c7xtf5MHqnPnFOlh6Qzn2Za-nyceVWgJWvccXKYEoONRNT9aLwD9ag" /&gt;&lt;/figure&gt;&lt;h1 class="wp-block-heading"&gt;&lt;strong&gt;安装&lt;/strong&gt;&lt;strong&gt;​&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;通过将 Dragonfly Repository Agent 集成到 Triton 中，通过 Dragonfly 下载流量来拉取存储在 S3、OSS、GCS 和 ABS 中的模型，并在 Triton 中注册模型。 Dragonfly 存储库代理位于&lt;a href="https://github.com/dragonflyoss/dragonfly-repository-agent"&gt;Dragonfly-repository-agent&lt;/a&gt;存储库中。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;先决条件&lt;/strong&gt;&lt;/h2&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;姓名&lt;/td&gt;&lt;td&gt;版本&lt;/td&gt;&lt;td&gt;文档&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Kubernetes集群&lt;/td&gt;&lt;td&gt;1.20+&lt;/td&gt;&lt;td&gt; &lt;a href="https://kubernetes.io/"&gt;kubernetes.io&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;舵&lt;/td&gt;&lt;td&gt;3.8.0+&lt;/td&gt;&lt;td&gt;&lt;a href="https://helm.sh/"&gt;舵机sh&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;海卫一服务器&lt;/td&gt;&lt;td&gt;23.08-py3&lt;/td&gt;&lt;td&gt;&lt;a href="https://github.com/triton-inference-server/server"&gt;海卫一服务器&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;如果没有 kubernetes 集群可供测试，建议使用&lt;a href="https://kind.sigs.k8s.io/"&gt;Kind&lt;/a&gt; 。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt; &lt;strong&gt;Dragonfly Kubernetes 集群设置&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;详细安装文档请参考&lt;a href="https://d7y.io/zh/docs/getting-started/quick-start/kubernetes/"&gt;quick-start-kubernetes&lt;/a&gt; 。&lt;/p&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;准备 Kubernetes 集群&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;创建kind多节点集群配置文件kind-config.yaml，配置内容如下：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kind: Cluster&lt;br /&gt; apiVersion: kind.x-k8s.io/v1alpha4&lt;br /&gt; nodes:&lt;br /&gt;  - role: control-plane&lt;br /&gt;  - role: worker&lt;br /&gt;  - role: worker&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用配置文件创建一个多节点集群：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kind create cluster --config kind-config.yaml&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将 kubectl 的上下文切换到 kind cluster：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kubectl config use-context kind-kind&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;种类加载蜻蜓图像&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;拉蜻蜓最新图片：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;docker pull dragonflyoss/scheduler:latest&lt;br /&gt; docker pull dragonflyoss/manager:latest&lt;br /&gt; docker pull dragonflyoss/dfdaemon:latest&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;类集群加载蜻蜓最新图像：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kind load docker-image dragonflyoss/scheduler:latest&lt;br /&gt; kind load docker-image dragonflyoss/manager:latest&lt;br /&gt; kind load docker-image dragonflyoss/dfdaemon:latest&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;基于helm Charts创建Dragonfly集群&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;创建helm图表配置文件charts-config.yam并设置dfdaemon.config.agents.regx以匹配对象存储的下载路径。示例：添加 regx:.*models.* 以匹配对象存储桶模型的下载请求。配置内容如下：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;scheduler:&lt;br /&gt;  image: dragonflyoss/scheduler&lt;br /&gt;  tag: latest&lt;br /&gt;  replicas: 1&lt;br /&gt;  metrics:&lt;br /&gt;    enable: true&lt;br /&gt;  config:&lt;br /&gt;    verbose: true&lt;br /&gt;    pprofPort: 18066&lt;br /&gt;&lt;br /&gt; seedPeer:&lt;br /&gt;  image: dragonflyoss/dfdaemon&lt;br /&gt;  tag: latest&lt;br /&gt;  replicas: 1&lt;br /&gt;  metrics:&lt;br /&gt;    enable: true&lt;br /&gt;  config:&lt;br /&gt;    verbose: true&lt;br /&gt;    pprofPort: 18066&lt;br /&gt;&lt;br /&gt; dfdaemon:&lt;br /&gt;  image: dragonflyoss/dfdaemon&lt;br /&gt;  tag: latest&lt;br /&gt;  metrics:&lt;br /&gt;    enable: true&lt;br /&gt;  config:&lt;br /&gt;    verbose: true&lt;br /&gt;    pprofPort: 18066&lt;br /&gt;    proxy:&lt;br /&gt;      defaultFilter: &amp;#39;Expires&amp;amp;Signature&amp;amp;ns&amp;#39;&lt;br /&gt;      security:&lt;br /&gt;        insecure: true&lt;br /&gt;        cacert: &amp;#39;&amp;#39;&lt;br /&gt;        cert: &amp;#39;&amp;#39;&lt;br /&gt;        key: &amp;#39;&amp;#39;&lt;br /&gt;      tcpListen:&lt;br /&gt;        namespace: &amp;#39;&amp;#39;&lt;br /&gt;        port: 65001&lt;br /&gt;      registryMirror:&lt;br /&gt;        url: https://index.docker.io&lt;br /&gt;        insecure: true&lt;br /&gt;        certs: []&lt;br /&gt;        direct: false&lt;br /&gt;      proxies:&lt;br /&gt;        - regx: blobs/sha256.*&lt;br /&gt;        # Proxy all http downlowd requests of model bucket path.&lt;br /&gt;        - regx: .*models.*&lt;br /&gt;&lt;br /&gt; manager:&lt;br /&gt;  image: dragonflyoss/manager&lt;br /&gt;  tag: latest&lt;br /&gt;  replicas: 1&lt;br /&gt;  metrics:&lt;br /&gt;    enable: true&lt;br /&gt;  config:&lt;br /&gt;    verbose: true&lt;br /&gt;    pprofPort: 18066&lt;br /&gt;&lt;br /&gt; jaeger:&lt;br /&gt;  enable: true&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用配置文件创建蜻蜓集群：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;$ helm repo add dragonfly https://dragonflyoss.github.io/helm-charts/&lt;br /&gt; $ helm install --wait --create-namespace --namespace dragonfly-system dragonfly dragonfly/dragonfly -f charts-config.yaml&lt;br /&gt; LAST DEPLOYED: Wed Nov 29 21:23:48 2023&lt;br /&gt; NAMESPACE: dragonfly-system&lt;br /&gt; STATUS: deployed&lt;br /&gt; REVISION: 1&lt;br /&gt; TEST SUITE: None&lt;br /&gt; NOTES:&lt;br /&gt; 1. Get the scheduler address by running these commands:&lt;br /&gt;  export SCHEDULER_POD_NAME=$(kubectl get pods --namespace dragonfly-system -l &amp;quot;app=dragonfly,release=dragonfly,component=scheduler&amp;quot; -o jsonpath={.items[0].metadata.name})&lt;br /&gt;  export SCHEDULER_CONTAINER_PORT=$(kubectl get pod --namespace dragonfly-system $SCHEDULER_POD_NAME -o jsonpath=&amp;quot;{.spec.containers[0].ports[0].containerPort}&amp;quot;)&lt;br /&gt;  kubectl --namespace dragonfly-system port-forward $SCHEDULER_POD_NAME 8002:$SCHEDULER_CONTAINER_PORT&lt;br /&gt;  echo &amp;quot;Visit http://127.0.0.1:8002 to use your scheduler&amp;quot;&lt;br /&gt;&lt;br /&gt; 2. Get the dfdaemon port by running these commands:&lt;br /&gt;  export DFDAEMON_POD_NAME=$(kubectl get pods --namespace dragonfly-system -l &amp;quot;app=dragonfly,release=dragonfly,component=dfdaemon&amp;quot; -o jsonpath={.items[0].metadata.name})&lt;br /&gt;  export DFDAEMON_CONTAINER_PORT=$(kubectl get pod --namespace dragonfly-system $DFDAEMON_POD_NAME -o jsonpath=&amp;quot;{.spec.containers[0].ports[0].containerPort}&amp;quot;)&lt;br /&gt;  You can use $DFDAEMON_CONTAINER_PORT as a proxy port in Node.&lt;br /&gt;&lt;br /&gt; 3. Configure runtime to use dragonfly:&lt;br /&gt;  https://d7y.io/docs/getting-started/quick-start/kubernetes/&lt;br /&gt;&lt;br /&gt;&lt;br /&gt; 4. Get Jaeger query URL by running these commands:&lt;br /&gt;  export JAEGER_QUERY_PORT=$(kubectl --namespace dragonfly-system get services dragonfly-jaeger-query -o jsonpath=&amp;quot;{.spec.ports[0].port}&amp;quot;)&lt;br /&gt;  kubectl --namespace dragonfly-system port-forward service/dragonfly-jaeger-query 16686:$JAEGER_QUERY_PORT&lt;br /&gt;  echo &amp;quot;Visit http://127.0.0.1:16686/search?limit=20&amp;amp;lookback=1h&amp;amp;maxDuration&amp;amp;minDuration&amp;amp;service=dragonfly to query download events&amp;quot;&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;检查蜻蜓是否部署成功：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;$ kubectl get pods -n dragonfly-system&lt;br /&gt; NAME                                 READY   STATUS    RESTARTS       AGE&lt;br /&gt; dragonfly-dfdaemon-8qcpd             1/1     Running   4 (118s ago)   2m45s&lt;br /&gt; dragonfly-dfdaemon-qhkn8             1/1     Running   4 (108s ago)   2m45s&lt;br /&gt; dragonfly-jaeger-6c44dc44b9-dfjfv    1/1     Running   0              2m45s&lt;br /&gt; dragonfly-manager-549cd546b9-ps5tf   1/1     Running   0              2m45s&lt;br /&gt; dragonfly-mysql-0                    1/1     Running   0              2m45s&lt;br /&gt; dragonfly-redis-master-0             1/1     Running   0              2m45s&lt;br /&gt; dragonfly-redis-replicas-0           1/1     Running   0              2m45s&lt;br /&gt; dragonfly-redis-replicas-1           1/1     Running   0              2m7s&lt;br /&gt; dragonfly-redis-replicas-2           1/1     Running   0              101s&lt;br /&gt; dragonfly-scheduler-0                1/1     Running   0              2m45s&lt;br /&gt; dragonfly-seed-peer-0                1/1     Running   1 (52s ago)    2m45s&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;暴露Proxy服务端口&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;创建 dfstore.yaml 配置文件以公开 Dragonfly Peer 的 HTTP 代理侦听的端口。默认端口为 65001，将 targetPort 设置为 65001。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kind: Service&lt;br /&gt; apiVersion: v1&lt;br /&gt; metadata:&lt;br /&gt;  name: dfstore&lt;br /&gt; spec:&lt;br /&gt;  selector:&lt;br /&gt;    app: dragonfly&lt;br /&gt;    component: dfdaemon&lt;br /&gt;    release: dragonfly&lt;br /&gt;&lt;br /&gt;  ports:&lt;br /&gt;    - protocol: TCP&lt;br /&gt;      port: 65001&lt;br /&gt;      targetPort: 65001&lt;br /&gt;&lt;br /&gt;  type: NodePort&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;创建服务：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kubectl --namespace dragonfly-system apply -f dfstore.yaml&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将请求转发到 Dragonfly Peer 的 HTTP 代理：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kubectl --namespace dragonfly-system port-forward service/dfstore 65001:65001&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;安装 Dragonfly 存储库代理&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;设置 Dragonfly 存储库代理配置&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;创建dragonfly_config.json配置文件，配置如下：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;{&lt;br /&gt;  &amp;quot;proxy&amp;quot;: &amp;quot;http://127.0.0.1:65001&amp;quot;,&lt;br /&gt; &amp;quot;header&amp;quot;: {&lt;br /&gt; },&lt;br /&gt; &amp;quot;filter&amp;quot;: [&lt;br /&gt;  &amp;quot;X-Amz-Algorithm&amp;quot;,&lt;br /&gt;  &amp;quot;X-Amz-Credential&amp;amp;X-Amz-Date&amp;quot;,&lt;br /&gt;  &amp;quot;X-Amz-Expires&amp;quot;,&lt;br /&gt;  &amp;quot;X-Amz-SignedHeaders&amp;quot;,&lt;br /&gt;  &amp;quot;X-Amz-Signature&amp;quot;&lt;br /&gt; ]&lt;br /&gt; }&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&lt;li&gt; proxy：Dragonfly Peer 的 HTTP 代理的地址。&lt;/li&gt;&lt;li&gt; header：为请求添加请求头。&lt;/li&gt;&lt;li&gt;过滤器：用于生成唯一的任务并过滤URL中不必要的查询参数。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在配置的过滤器中，使用不同的对象存储时设置不同的值：&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;类型&lt;/td&gt;&lt;td&gt;价值&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;开放源码软件&lt;/td&gt;&lt;td&gt;[“过期”，“签名”，“ns”]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; S3&lt;/td&gt;&lt;td&gt; [“X-Amz-算法”、“X-Amz-凭证”、“X-Amz-日期”、“X-Amz-过期”、“X-Amz-SignedHeaders”、“X-Amz-签名”]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; OBS&lt;/td&gt;&lt;td&gt; [“X-Amz-算法”、“X-Amz-凭证”、“X-Amz-日期”、“X-Obs-日期”、“X-Amz-过期”、“X-Amz-SignedHeaders”、“ X-Amz-签名”]&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;设置模型存储库配置&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;创建cloud_credential.json云存储凭证，配置如下：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;{&lt;br /&gt;  &amp;quot;gs&amp;quot;: {&lt;br /&gt;    &amp;quot;&amp;quot;: &amp;quot;PATH_TO_GOOGLE_APPLICATION_CREDENTIALS&amp;quot;,&lt;br /&gt;    &amp;quot;gs://gcs-bucket-002&amp;quot;: &amp;quot;PATH_TO_GOOGLE_APPLICATION_CREDENTIALS_2&amp;quot;&lt;br /&gt;  },&lt;br /&gt;  &amp;quot;s3&amp;quot;: {&lt;br /&gt;    &amp;quot;&amp;quot;: {&lt;br /&gt;      &amp;quot;secret_key&amp;quot;: &amp;quot;AWS_SECRET_ACCESS_KEY&amp;quot;,&lt;br /&gt;      &amp;quot;key_id&amp;quot;: &amp;quot;AWS_ACCESS_KEY_ID&amp;quot;,&lt;br /&gt;      &amp;quot;region&amp;quot;: &amp;quot;AWS_DEFAULT_REGION&amp;quot;,&lt;br /&gt;      &amp;quot;session_token&amp;quot;: &amp;quot;&amp;quot;,&lt;br /&gt;      &amp;quot;profile&amp;quot;: &amp;quot;&amp;quot;&lt;br /&gt;    },&lt;br /&gt;    &amp;quot;s3://s3-bucket-002&amp;quot;: {&lt;br /&gt;      &amp;quot;secret_key&amp;quot;: &amp;quot;AWS_SECRET_ACCESS_KEY_2&amp;quot;,&lt;br /&gt;      &amp;quot;key_id&amp;quot;: &amp;quot;AWS_ACCESS_KEY_ID_2&amp;quot;,&lt;br /&gt;      &amp;quot;region&amp;quot;: &amp;quot;AWS_DEFAULT_REGION_2&amp;quot;,&lt;br /&gt;      &amp;quot;session_token&amp;quot;: &amp;quot;AWS_SESSION_TOKEN_2&amp;quot;,&lt;br /&gt;      &amp;quot;profile&amp;quot;: &amp;quot;AWS_PROFILE_2&amp;quot;&lt;br /&gt;    }&lt;br /&gt;  },&lt;br /&gt;  &amp;quot;as&amp;quot;: {&lt;br /&gt;    &amp;quot;&amp;quot;: {&lt;br /&gt;      &amp;quot;account_str&amp;quot;: &amp;quot;AZURE_STORAGE_ACCOUNT&amp;quot;,&lt;br /&gt;      &amp;quot;account_key&amp;quot;: &amp;quot;AZURE_STORAGE_KEY&amp;quot;&lt;br /&gt;    },&lt;br /&gt;    &amp;quot;as://Account-002/Container&amp;quot;: {&lt;br /&gt;      &amp;quot;account_str&amp;quot;: &amp;quot;&amp;quot;,&lt;br /&gt;      &amp;quot;account_key&amp;quot;: &amp;quot;&amp;quot;&lt;br /&gt;    }&lt;br /&gt;  }&lt;br /&gt; }&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;为了通过 Dragonfly 拉取模型，需要在模型配置文件 config.pbtxt 文件中添加以下代码：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;model_repository_agents&lt;br /&gt; {&lt;br /&gt;  agents [&lt;br /&gt;    {&lt;br /&gt;      name: &amp;quot;dragonfly&amp;quot;,&lt;br /&gt;    }&lt;br /&gt;  ]&lt;br /&gt; }&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; &lt;a href="https://github.com/dragonflyoss/dragonfly-repository-agent/tree/main/examples/model_repository/densenet_onnx"&gt;ensenet_onnx 示例&lt;/a&gt;包含修改后的配置和模型文件。修改config.pbtxt如：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;name: &amp;quot;densenet_onnx&amp;quot;&lt;br /&gt; platform: &amp;quot;onnxruntime_onnx&amp;quot;&lt;br /&gt; max_batch_size : 0&lt;br /&gt; input [&lt;br /&gt;  {&lt;br /&gt;    name: &amp;quot;data_0&amp;quot;&lt;br /&gt;    data_type: TYPE_FP32&lt;br /&gt;    format: FORMAT_NCHW&lt;br /&gt;    dims: [ 3, 224, 224 ]&lt;br /&gt;    reshape { shape: [ 1, 3, 224, 224 ] }&lt;br /&gt;  }&lt;br /&gt; ]&lt;br /&gt; output [&lt;br /&gt;  {&lt;br /&gt;    name: &amp;quot;fc6_1&amp;quot;&lt;br /&gt;    data_type: TYPE_FP32&lt;br /&gt;    dims: [ 1000 ]&lt;br /&gt;    reshape { shape: [ 1, 1000, 1, 1 ] }&lt;br /&gt;    label_filename: &amp;quot;densenet_labels.txt&amp;quot;&lt;br /&gt;  }&lt;br /&gt; ]&lt;br /&gt; model_repository_agents&lt;br /&gt; {&lt;br /&gt;  agents [&lt;br /&gt;    {&lt;br /&gt;      name: &amp;quot;dragonfly&amp;quot;,&lt;br /&gt;    }&lt;br /&gt;  ]&lt;br /&gt; }&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 class="wp-block-heading"&gt; &lt;strong&gt;Triton Server 集成 Dragonfly Repository Agent 插件&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;使用 Docker 安装 Triton 服务器&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;拉取 Dragonflyoss/dragonfly-repository-agent 镜像，该镜像是 Triton Server 中集成的 Dragonfly Repository Agent 插件，请参阅&lt;a href="https://github.com/dragonflyoss/dragonfly-repository-agent/blob/main/Dockerfile"&gt;Dockerfile&lt;/a&gt; 。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;docker pull dragonflyoss/dragonfly-repository-agent:latest&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行容器并挂载配置目录：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;docker run --network host --rm \&lt;br /&gt;  -v ${path-to-config-dir}:/home/triton/ \&lt;br /&gt;  dragonflyoss/dragonfly-repository-agent:latest tritonserver \&lt;br /&gt;  --model-repository=${model-repository-path}&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&lt;li&gt; path-to-config-dir：dragonfly_config.json&amp;amp;cloud_credential.json的文件路径。&lt;/li&gt;&lt;li&gt; model-repository-path：远程模型存储库的路径。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;正确的输出如下：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;=============================&lt;br /&gt; == Triton Inference Server ==&lt;br /&gt; =============================&lt;br /&gt; successfully loaded &amp;#39;densenet_onnx&amp;#39;&lt;br /&gt; I1130 09:43:22.595672 1 server.cc:604]&lt;br /&gt; +------------------+------------------------------------------------------------------------+&lt;br /&gt; | Repository Agent | Path                                                                   |&lt;br /&gt; +------------------+------------------------------------------------------------------------+&lt;br /&gt; | dragonfly        | /opt/tritonserver/repoagents/dragonfly/libtritonrepoagent_dragonfly.so |&lt;br /&gt; +------------------+------------------------------------------------------------------------+&lt;br /&gt;&lt;br /&gt; I1130 09:43:22.596011 1 server.cc:631]&lt;br /&gt; +-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt; | Backend     | Path                                                            | Config                                                                                                                                                        |&lt;br /&gt; +-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt; | pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {}                                                                                                                                                            |&lt;br /&gt; | onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {&amp;quot;cmdline&amp;quot;:{&amp;quot;auto-complete-config&amp;quot;:&amp;quot;true&amp;quot;,&amp;quot;backend-directory&amp;quot;:&amp;quot;/opt/tritonserver/backends&amp;quot;,&amp;quot;min-compute-capability&amp;quot;:&amp;quot;6.000000&amp;quot;,&amp;quot;default-max-batch-size&amp;quot;:&amp;quot;4&amp;quot;}} |&lt;br /&gt; +-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt;&lt;br /&gt; I1130 09:43:22.596112 1 server.cc:674]&lt;br /&gt; +---------------+---------+--------+&lt;br /&gt; | Model         | Version | Status |&lt;br /&gt; +---------------+---------+--------+&lt;br /&gt; | densenet_onnx | 1       | READY  |&lt;br /&gt; +---------------+---------+--------+&lt;br /&gt;&lt;br /&gt; I1130 09:43:22.598318 1 metrics.cc:703] Collecting CPU metrics&lt;br /&gt; I1130 09:43:22.599373 1 tritonserver.cc:2435]&lt;br /&gt; +----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt; | Option                           | Value                                                                                                                                                                                                           |&lt;br /&gt; +----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt; | server_id                        | triton                                                                                                                                                                                                          |&lt;br /&gt; | server_version                   | 2.37.0                                                                                                                                                                                                          |&lt;br /&gt; | server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data parameters statistics trace logging |&lt;br /&gt; | model_repository_path[0]         | s3://192.168.36.128:9000/models                                                                                                                                                                                 |&lt;br /&gt; | model_control_mode               | MODE_NONE                                                                                                                                                                                                       |&lt;br /&gt; | strict_model_config              | 0                                                                                                                                                                                                               |&lt;br /&gt; | rate_limit                       | OFF                                                                                                                                                                                                             |&lt;br /&gt; | pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                                       |&lt;br /&gt; | min_supported_compute_capability | 6.0                                                                                                                                                                                                             |&lt;br /&gt; | strict_readiness                 | 1                                                                                                                                                                                                               |&lt;br /&gt; | exit_timeout                     | 30                                                                                                                                                                                                              |&lt;br /&gt; | cache_enabled                    | 0                                                                                                                                                                                                               |&lt;br /&gt; +----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+&lt;br /&gt;&lt;br /&gt; I1130 09:43:22.610334 1 grpc_server.cc:2451] Started GRPCInferenceService at 0.0.0.0:8001&lt;br /&gt; I1130 09:43:22.612623 1 http_server.cc:3558] Started HTTPService at 0.0.0.0:8000&lt;br /&gt; I1130 09:43:22.695843 1 http_server.cc:187] Started Metrics Service at 0.0.0.0:8002&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;执行以下命令查看 Dragonfly 日志：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;kubectl exec -it -n dragonfly-system dragonfly-dfdaemon-&amp;lt;id&amp;gt; -- tail -f /var/log/dragonfly/daemon/core.log&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;检查通过Dragonfly下载是否成功：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;{&lt;br /&gt; &amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:&amp;quot;2024-02-02 05:28:02.631&amp;quot;,&lt;br /&gt; &amp;quot;caller&amp;quot;:&amp;quot;peer/peertask_conductor.go:1349&amp;quot;,&lt;br /&gt; &amp;quot;msg&amp;quot;:&amp;quot;peer task done, cost: 352ms&amp;quot;,&lt;br /&gt; &amp;quot;peer&amp;quot;:&amp;quot;10.244.2.3-1-4398a429-d780-423a-a630-57d765f1ccfc&amp;quot;,&lt;br /&gt; &amp;quot;task&amp;quot;:&amp;quot;974aaf56d4877cc65888a4736340fb1d8fecc93eadf7507f531f9fae650f1b4d&amp;quot;,&lt;br /&gt; &amp;quot;component&amp;quot;:&amp;quot;PeerTask&amp;quot;,&lt;br /&gt; &amp;quot;trace&amp;quot;:&amp;quot;4cca9ce80dbf5a445d321cec593aee65&amp;quot;&lt;br /&gt; }&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;核实&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;调用推理API：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;docker run -it --rm --net=host nvcr.io/nvidia/tritonserver:23.08-py3-sdk /workspace/install/bin/image_client -m densenet_onnx -c 3 -s INCEPTION /workspace/images/mug.jpg&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;检查响应是否成功：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;Request 01&lt;br /&gt; Image &amp;#39;/workspace/images/mug.jpg&amp;#39;:&lt;br /&gt;    15.349563 (504) = COFFEE MUG&lt;br /&gt;    13.227461 (968) = CUP&lt;br /&gt;    10.424893 (505) = COFFEEPOT&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;性能测试&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;测试集成Dragonfly P2P后通过Triton API下载单机模型的性能。由于机器本身网络环境的影响，实际下载时间并不重要，但不同场景下下载速度的比例更有意义： &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="图像" src="https://lh7-us.googleusercontent.com/wFGp6qxEQvNWh5ZADtHZaZzASh6Cnf_vYoHTWF7rvyyVHV6aSzr3mtYe_bLJdrN9EXSgYmyXbusCYwqVKiUmayWnx8LCI4IuVXUme958nfjx6IJwpkFvtoVZy82P8Drf_BB_5wMdGOvw7qfaWx5_YA" /&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt; Triton API：使用对象存储提供的签名URL直接下载模型。&lt;/li&gt;&lt;li&gt; Triton API 和 Dragonfly 冷启动：使用 Triton Serve API 通过 Dragonfly P2P 网络下载模型，并且没有缓存命中。&lt;/li&gt;&lt;li&gt;命中远程对等点：使用 Triton Serve API 通过 Dragonfly P2P 网络下载模型并命中远程对等点缓存。&lt;/li&gt;&lt;li&gt;命中本地对等点：使用 Triton Serve API 通过 Dragonfly P2P 网络下载模型并命中本地对等点缓存。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;测试结果显示 Triton 和 Dragonfly 集成。可以有效减少文件下载时间。注意，本次测试是单机测试，这意味着在缓存命中的情况下，性能限制在磁盘上。如果Dragonfly部署在多台机器上进行P2P下载，模型下载速度会更快。&lt;/p&gt;&lt;h1 class="wp-block-heading"&gt;&lt;strong&gt;相关链接&lt;/strong&gt;&lt;/h1&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;蜻蜓社区&lt;/strong&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;网站： &lt;a href="https://d7y.io/"&gt;https://d7y.io/&lt;/a&gt;&lt;/li&gt;&lt;li&gt; Github 仓库： &lt;a href="https://github.com/dragonflyoss/Dragonfly2"&gt;https://github.com/dragonflyoss/Dragonfly2&lt;/a&gt;&lt;/li&gt;&lt;li&gt; Dragonfly 存储库代理 Github 存储库： &lt;a href="https://github.com/dragonflyoss/dragonfly-repository-agent"&gt;https://github.com/dragonflyoss/dragonfly-repository-agent&lt;/a&gt;&lt;/li&gt;&lt;li&gt; Slack 频道： &lt;a href="https://slack.cncf.io/"&gt;CNCF Slack&lt;/a&gt;上的&lt;a href="https://cloud-native.slack.com/messages/dragonfly/"&gt;#dragonfly&lt;/a&gt;&lt;/li&gt;&lt;li&gt;讨论组： &lt;a href="mailto:dragonfly-discuss@googlegroups.com"&gt;dragonfly-discuss@googlegroups.com&lt;/a&gt;&lt;/li&gt;&lt;li&gt;推特： &lt;a href="https://twitter.com/dragonfly_oss"&gt;@dragonfly_oss&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading"&gt; &lt;strong&gt;NVIDIA Triton 推理服务器&lt;/strong&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;网站： &lt;a href="https://developer.nvidia.com/triton-inference-server"&gt;https://developer.nvidia.com/triton-inference-server&lt;/a&gt;&lt;/li&gt;&lt;li&gt; Github 存储库： &lt;a href="https://github.com/triton-inference-server/server"&gt;https://github.com/triton-inference-server/server&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;二维码&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Dragonfly Github仓库： &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="二维码" src="https://lh7-us.googleusercontent.com/dHuRcLXUyidFEw_iLig1WmDHNOtGGUEwVObfDjbupoVCKV1tvZ7bLv38018mFX0umVHxqRyZEGe0jBPcjJS9wEBJjQbxAlB0DAiZQs1EL27DrgdyAnhjQLsfNVR8wFavNJgNtyz6xOPqJ8_md8rF3A" /&gt;&lt;/figure&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Sun, 14 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/15/triton-server-accelerates-distribution-of-models-based-on-dragonfly/</guid></item><item><title>使用开源本地法学硕士简化日志</title><link>https://www.cncf.io/blog/2024/04/12/streamlining-logs-with-open-source-local-llms/</link><description>&lt;p&gt;&lt;em&gt;Anup Ghatage 的社区帖子&lt;/em&gt;&lt;/p&gt;&lt;p&gt;日志消息对于调试和监视应用程序至关重要，但它们通常过于冗长和混乱，导致难以快速识别和理解关键信息。随着时间的推移，在具有多个贡献者的大型代码库中尤其如此，由于员工流失和短暂的开源贡献，导致日志行格式、长度和语言不一致。&lt;/p&gt;&lt;p&gt;大多数组织都“对人工智能感到好奇”，希望利用人工智能来解决一些现有的工作流程和问题，但都面临着共同的难题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;训练和托管自定义大型语言模型的成本极其昂贵。&lt;/li&gt;&lt;li&gt;从法学硕士获得确定性、结构化的输出具有挑战性，因为这些输出本质上是概率性的且冗长的。&lt;/li&gt;&lt;li&gt;最后，所有企业&lt;strong&gt;都不&lt;/strong&gt;希望将其专有数据和代码暴露给外部法学硕士提供商。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br /&gt;仅这些原因就足以让大多数企业“静观其变”。确实，人工智能的所有事物都在以惊人的速度发展，而且肯定会变得更好，但今天的客户要求企业提供同样的好处来提高他们的生产力。这使得等待变得更加不稳定，因为公司将失去在新技术周期开始时获取大部分价值的机会。&lt;br /&gt;&lt;/p&gt;&lt;p&gt;在这篇文章中，我们将探讨如何使用开源的 Apache 2.0 许可的本地 LLM 来解决简化日志行的任务。通过减少日志行的冗长性，同时保留上下文和细节，我们不仅可以提高和维护其可读性，而且可以在使用 Splunk 等日志管理工具时实现成本节省。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;那么我们如何开始呢？&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;在企业级工作时，必须谨慎使用第三方软件，主要是因为许可限制。最流行的开源许可证之一是&lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;Apache 2.0 许可证&lt;/a&gt;。该许可证非常宽松，允许该软件不受限制地用于商业用途。其他许可证（例如&lt;a href="https://opensource.org/license/mit"&gt;MIT 许可证）&lt;/a&gt;也是宽松的，允许免费商业使用。所以现在我们知道，无论我们使用什么工具和模型，我们都必须确保它们是 Apache 2.0 或 MIT 许可的。&lt;br /&gt;&lt;br /&gt;仍然存在的另一个问题是，如果我们没有任何 GPU，如何使用它们（或对它们进行推理）。这里的答案是量化。&lt;/p&gt;&lt;p&gt;大型语言模型 (LLM) 是非常强大的工具，但它们的计算需求通常限制它们只能在云环境中使用强大的 GPU。这对于许多用户来说可能是一个障碍，尤其是那些无法使用昂贵的硬件或没有管理硬件的专业知识的用户。&lt;/p&gt;&lt;p&gt;这就是量化的用武之地。这是一种通过降低权重精度来优化 LLM 局部推理的技术。传统上，这些权重存储为高精度浮点数。量化将它们转换为较低精度的格式，例如我们示例中的 8 位整数。这显着减少了模型的大小和内存占用。&lt;/p&gt;&lt;p&gt;好处？通过使用 8 位量化，我们可以在标准服务器 CPU 上运行 LLM。这为更广泛的采用打开了大门，特别是对于企业而言。量化提供：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;经济高效的解决方案：&lt;/strong&gt;大多数企业已经拥有现成的服务器 CPU。这消除了对昂贵 GPU 集群的需求，从而降低了硬件成本。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可访问性：&lt;/strong&gt;在 CPU 上本地运行 LLM 不需要管理 GPU 的专业知识，这使得它们对于组织内的各个团队来说更加用户友好。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;隐私和安全：&lt;/strong&gt;本地推理将数据保留在本地，可能解决基于云的解决方案可能出现的隐私和安全问题。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;从本质上讲，量化充当了一座桥梁，即使那些没有顶级硬件的人也可以直接在自己的机器上利用法学硕士的强大功能。&lt;/p&gt;&lt;p&gt;然而，在这种情况下，需要在性能和速度之间进行权衡。较低的量化（例如 4 位或 2 位）会使模型文件非常小，但输出的质量也会降低。因此，在本地托管这些数据时，使用 8 位量化为我们提供了相对较慢但相对更准确的选择。&lt;/p&gt;&lt;p&gt;有几种不同的量化格式： &lt;a href="https://arxiv.org/html/2401.00503v1"&gt;viz&lt;/a&gt; 、 &lt;a href="https://medium.com/@bnjmn_marie/gguf-quantization-for-fast-and-memory-efficient-inference-on-your-cpu-d10fbe58fbca"&gt;GGUF&lt;/a&gt; 、 &lt;a href="https://github.com/mit-han-lab/llm-awq"&gt;AWQ&lt;/a&gt;和&lt;a href="https://arxiv.org/abs/2210.17323"&gt;GPTQ&lt;/a&gt; 。&lt;br /&gt;出于本文的目的，我们将使用 GGUF 模型，因为它们周围有最活跃的社区。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我在哪里可以获得这些模型？我如何接待他们？我如何查询它们？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt; &lt;a href="https://huggingface.co/"&gt;HuggingFace&lt;/a&gt;是互联网上最流行的机器学习模型和数据集存储库之一。许多公司和用户都在那里上传他们的模型和实验，任何人都可以使用。 HuggingFace 上的每个模型都附带一张“模型卡”——类似于如何使用模型、其提示格式、许可要求和限制的说明。&lt;br /&gt;&lt;br /&gt;在查看模型时，我们必须寻找提供 Apache 2.0 或 MIT 许可证的 GGUF 量化。即使这样，也请务必阅读细则。最流行的开源 LLM 之一是 Mistral-7b v0.2。该模型及其权重是在 Apache 2.0 许可证下发布的。&lt;br /&gt;我们将在我们的示例用例中使用它。让我们转到 HuggingFace 页面，了解&lt;a href="https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF"&gt;该模型的 GGUF 量化&lt;/a&gt;并尝试理解它。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;许可&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;量化必须自动遵循原始模型的许可要求。在我们的例子中， &lt;a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2"&gt;Mistral-ai 的模型具有 Apache 2.0 许可证&lt;/a&gt;，该许可证也可以在量化模型页面的顶部看到。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;提示模板&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&amp;lt;s&amp;gt;[INST] {提示} [/INST]&lt;/p&gt;&lt;p&gt;提示模板是模型期望获得输入的方式。这是因为该模型可能是使用这些特殊字符和标记进行训练的。在这种情况下，我们必须将查询打包以代替模板中的“{prompt}”，如上所示。举例来说，如果我们问“为什么海是蓝色的？”我们想要发送的实际指令是：&lt;br /&gt;&lt;br /&gt; &amp;lt;s&amp;gt;[INST] 海水为什么是蓝色的？ [/插入]&lt;br /&gt;&lt;br /&gt;可以通过多种方式在本地托管这些模型，但今天我们将讨论两个最简单的选项。&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;Llama.cpp&lt;/a&gt; （&lt;a href="https://github.com/ggerganov/llama.cpp/tree/master/examples/server"&gt;服务器示例&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href="https://ollama.com/"&gt;奥拉马&lt;/a&gt;（ &lt;a href="https://github.com/ollama/ollama/blob/main/docs/api.md"&gt;API 参考&lt;/a&gt;）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这两个项目都是免费的、开源的并获得麻省理工学院的许可。您可以从上面提到的链接中了解如何构建和运行它们。&lt;/p&gt;&lt;p&gt;一旦启动并运行，它们都提供符合 OpenAI 的 API 访问。我们可以通过标准 REST API 调用查询它们的端点。&lt;/p&gt;&lt;p&gt;总之，到目前为止，我们已经获得了商业上可行的开源 LLM 模型文件以及托管和查询它们的方法 - 全部在本地，无需 GPU 并且免费。现在让我们进入本文开头的用例。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;通过简洁的日志降低 Splunk 成本&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;像 Splunk 这样的日志管理平台的运营成本可能很高，其成本通常与摄取和存储的日志数据量相关。通过使用 LLM 缩小日志行，我们可以显着减少需要处理和保留的数据量，从而节省成本。&lt;/p&gt;&lt;p&gt;更短、更简洁的日志行不仅消耗更少的存储空间，而且需要更少的传输带宽，并减少 Splunk 索引器和搜索头上的计算负载。这可以降低基础设施要求并减少运营费用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;利用 llama.cpp 进行本地 LLM 推理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了在我们本地的 LLM 上运行推理，我们将使用 llama.cpp。但是，我们希望将 llama.cpp 服务器端点视为“推理和智能”端点，而不是标准 REST 端点。以这种方式使用它将使我们能够围绕它构建应用程序。&lt;/p&gt;&lt;p&gt;&lt;br /&gt;首先，让我们使用下载的模型启动 llama.cpp 服务器。&lt;br /&gt;&lt;br /&gt; ./server -m /Users/aghatage/mistral-7b-instruct-v0.2.Q8_0.gguf -c 2048&lt;/p&gt;&lt;p&gt;上述命令使用 Mistral-7b v0.2 8 位量化模型启动服务器。我们现在可以对&lt;a href="http://localhost:8000/"&gt;http://localhost:8000/&lt;/a&gt;上托管的端点进行 REST API 调用。我们将利用 http://localhost:8000/completion 端点。大多数企业可以在自己的环境中甚至在开发人员笔记本电脑上安全地托管此类服务器。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Log Line 收缩过程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;正如之前所讨论的，如果我们想使用 LLM 作为情报端点，我们必须使用它的语言，我们将必须编写一些脚本来手动提供我们希望 LLM 处理的确切信息。&lt;/p&gt;&lt;p&gt; 1. **日志行提取**：我们将首先使用 Python 脚本从代码库中提取所有单行日志行。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;import os import re def find_log_lines(codebase_path): # Regex to match a log line, modified to be case-insensitive log_line_pattern = re.compile(r&amp;#39;\b(log\.\w+)\(.*?\);&amp;#39;, re.IGNORECASE) for root, dirs, files in os.walk(codebase_path): for file in files: if file.endswith(&amp;quot;.java&amp;quot;): file_path = os.path.join(root, file) with open(file_path, &amp;#39;r&amp;#39;) as f: lines = f.readlines() for i, line in enumerate(lines): if log_line_pattern.search(line): print(f&amp;quot;{file_path} : {i+1} : {line.strip()}&amp;quot;) # Replace &amp;#39;/path/to/java/codebase&amp;#39; with the actual path to your Java codebase codebase_path = &amp;#39;/path/to/java/codebase&amp;#39; find_log_lines(codebase_path)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上面的脚本按以下格式打印所有日志行：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;&amp;lt;file path&amp;gt; : &amp;lt;line number&amp;gt; : &amp;lt;actual log line&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; 2. **及时准备**：对于每个日志行，我们将查询本地 LLM 以尝试使其“更短”。每个 REST 调用都需要一个提示，其中包括日志行本身以及在保留关键详细信息的同时减少其冗长性的请求。这里的提示还用一个例子进行了解释，又名&lt;em&gt;1 shot Learning&lt;/em&gt; 。举例说明法学硕士的期望内容以及输出应该如何。每次调用时，提示的 CODE_LINE 部分都会替换为新的日志行。最后，我们通过重申结构来确保输出应该是 JSON。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;base_prompt = &amp;quot;&amp;quot;&amp;quot;&amp;lt;s&amp;gt; [INST] Here is an example of shortening a log line input: log.error(&amp;quot;Encountered error at writing records&amp;quot;, t); output: { &amp;quot;fixed&amp;quot; : &amp;quot;log.error(&amp;quot;Write error&amp;quot;, t);&amp;quot; } Now reword the following log line to be shorter if possible: ``` CODE_LINE ``` Please rewrite the log line to be shorter, do not add anything else. Make sure response is in JSON format like this: ``` { &amp;quot;fixed&amp;quot; : &amp;quot;&amp;lt;actual shortened log line&amp;gt;&amp;quot; } ```[/INST] &amp;quot;&amp;quot;&amp;quot;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; 3. **通过 llama.cpp 进行推理**：我们会将这些提示发送到运行我们的量化 LLM 模型的本地 llama.cpp 服务器。为了限制输出格式，我们将使用 llama.cpp 的 JSON 限制语法功能，确保模型的响应采用 JSON 结构。&lt;/p&gt;&lt;p&gt;我们将使用的语法的“GBNF”形式是 llama.cpp 附带的标准 JSON 语法。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;root ::= object value ::= object | array | string | number | (&amp;quot;true&amp;quot; | &amp;quot;false&amp;quot; | &amp;quot;null&amp;quot;) ws object ::= &amp;quot;{&amp;quot; ws ( string &amp;quot;:&amp;quot; ws value (&amp;quot;,&amp;quot; ws string &amp;quot;:&amp;quot; ws value)* )? &amp;quot;}&amp;quot; ws array ::= &amp;quot;[&amp;quot; ws ( value (&amp;quot;,&amp;quot; ws value)* )? &amp;quot;]&amp;quot; ws string ::= &amp;quot;\&amp;quot;&amp;quot; ( [^&amp;quot;\\\x7F\x00-\x1F] | &amp;quot;\\&amp;quot; ([&amp;quot;\\/bfnrt] | &amp;quot;u&amp;quot; [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F]) # escapes )* &amp;quot;\&amp;quot;&amp;quot; ws number ::= (&amp;quot;-&amp;quot;? ([0-9] | [1-9] [0-9]*)) (&amp;quot;.&amp;quot; [0-9]+)? ([eE] [-+]? [0-9]+)? ws # Optional space: by convention, applied in this grammar after literal chars when allowed ws ::= ([ \t\n] ws)?&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;最后，当将提示发送到 llama.cpp 服务器时，我们还必须包含语法作为推理的指示，以便按照我们最初提示的那样仅生成 JSON。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;def get_log_fix_response(code_line): final_prompt = base_prompt.replace(&amp;quot;CODE_LINE&amp;quot;, code_line) data = {&amp;quot;prompt&amp;quot;: final_prompt, &amp;quot;n_predict&amp;quot;: -1, &amp;quot;grammar&amp;quot;: list_grammar} try: response = requests.post(url, headers=headers, json=data) response.raise_for_status() json_input = json.loads(response.json().get(&amp;quot;content&amp;quot;)) content = json_input[&amp;quot;fixed&amp;quot;] return content except requests.RequestException as e: print(f&amp;quot;Error making HTTP request: {e}&amp;quot;) return None&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;最后，我们现在可以使用 LLM 的 JSON 响应来重写源文件中的原始日志行，有效地缩小它们，同时保留关键信息。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;优点和缺点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;使用本地法学硕士来缩小日志行数有几个优点：&lt;/p&gt;&lt;p&gt; – **提高可读性**：通过减少日志行的冗长性，我们可以使它们更易于阅读和理解，从而促进更有效的调试和监控。&lt;/p&gt;&lt;p&gt; – **成本节省**：较短的日志行意味着 Splunk 等日志管理平台的存储、带宽和计算要求减少，从而显着节省成本。&lt;/p&gt;&lt;p&gt; – **本地化处理**：使用本地法学硕士，所有处理都在本地进行，无需将敏感数据发送到外部服务。&lt;/p&gt;&lt;p&gt; – **成本效益**：通过利用开源工具并在 CPU 上运行，这种方法比使用基于云的 LLM 服务更具成本效益。&lt;/p&gt;&lt;p&gt;然而，也有一些潜在的缺点需要考虑：&lt;/p&gt;&lt;p&gt; – **模型质量**：虽然开源法学硕士的能力很强，但其性能可能无法与专有的最先进模型相媲美。&lt;/p&gt;&lt;p&gt; – **维护**：随着法学硕士模型和框架的发展，维护和更新本地设置可能需要持续的努力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结一下……&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过结合开源本地法学硕士、量化技术和 llama.cpp/ollama 等工具，我们可以开发满足企业级需求的经济高效的解决方案。&lt;br /&gt;对于此示例，除了提高日志可读性和效率之外，这种方法还可以在使用 Splunk 等日志管理平台时节省大量成本。虽然需要考虑权衡，但潜在的好处使其成为寻求优化日志基础设施和降低运营费用的组织的一个令人信服的选择。这篇文章还为希望将大型语言模型融入现有工作流程的组织提供了一个具有成本效益且低风险的蓝图。&lt;/p&gt;&lt;p&gt; &lt;em&gt;Anup 在大型企业构建数据基础设施方面拥有超过 10 年的经验。他的专长是数据库内部结构、数据存储和生成人工智能。&lt;/em&gt; &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Thu, 11 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/12/streamlining-logs-with-open-source-local-llms/</guid></item><item><title>绘制新领域：OpenTelemetry 拥抱分析</title><link>https://www.cncf.io/blog/2024/04/11/charting-new-territory-opentelemetry-embraces-profiling/</link><description>&lt;p&gt;&lt;em&gt;大使帖子最初由 Dotan Horovits 在&lt;a href="https://logz.io/blog/opentelemetry-embraces-profiling/"&gt;Logz.io 博客&lt;/a&gt;上发布&lt;/em&gt;&lt;/p&gt;&lt;p&gt;一段时间以来，连续分析的主题一直是可观察性世界中持续讨论的话题。我早在 2021 年就说过， &lt;a href="https://logz.io/blog/continuous-profiling-new-observability-signal-in-opentelemetry/?utm_medium=referral&amp;amp;utm_source=cncf"&gt;剖析将成为可观测性领域的下一个主要遥测信号&lt;/a&gt;，事实上，从那时起，人们对剖析的兴趣与日俱增。&lt;/p&gt;&lt;p&gt;初创公司和大型可观测性供应商已经进入这个领域。最近的一个重要步骤是&lt;a href="https://logz.io/learn/opentelemetry-guide/?utm_medium=referral&amp;amp;utm_source=cncf"&gt;OpenTelemetry 项目&lt;/a&gt;决定向其核心信号添加配置文件，并为此正式制定开放统一规范。&lt;/p&gt;&lt;p&gt;我主持了 OpenObservability Talks 的特别小组式一集，以研究分析的状态以及 OpenTelemetry 在这方面的工作。我的嘉宾都是为此主题成立的 OpenTelemetry 特别兴趣小组 (SIG) 的成员 Felix Geisendörfer 和 Ryan Perry。 &lt;/p&gt;&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;/div&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading" id="the-rise-of-continuous-profiling"&gt;连续分析的兴起&lt;/h2&gt;&lt;p&gt;我首先反思了人们对持续分析日益增长的兴趣，初创公司和主要供应商都关注这个领域。 Ryan 分享了他的创业历程，从认识到持续分析尚未开发的潜力，到创立 Pyrscope，再到后来加入 Grafana Labs。在这个繁忙的市场中，这个故事与英特尔收购 Granulate、Elastic 收购 Optimyze 等公司一起发生。&lt;/p&gt;&lt;p&gt;历史上与性能和成本分析相关的分析，现已发展到涵盖更广泛的用例，包括信号相关性、事件响应和资源消耗分析。&lt;/p&gt;&lt;p&gt; Ryan 强调了向连续分析的转变，与日志、指标和跟踪的轨迹并行。当与其他信号相关时，分析数据可以更深入地了解应用程序行为，从而促进根本原因分析和性能优化。用例涵盖从识别 CPU 峰值和内存问题到了解互斥争用、网络抖动和 goroutine 行为。 eBPF 技术在该领域也获得了很大的关注。&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt; &lt;a href="https://www.linkedin.com/embed/feed/update/urn:li:share:7170847249416052736"&gt;&lt;img alt="Dotan 的 Linkedin 帖子" class="wp-image-105643" height="1168" src="https://www.cncf.io/wp-content/uploads/2024/04/Screenshot-2024-04-15-at-09.48.27.png" style="width: 488px; height: auto;" width="1104" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading" id="runtime-and-ebpf-full-host-approaches-to-profiling"&gt;运行时和 eBPF 全主机分析方法&lt;/h2&gt;&lt;p&gt;Felix 深入研究了不同分析方法的细微差别，将运行时分析器与完整主机分析器进行了对比。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;运行时分析器&lt;/strong&gt;基于带有 SDK 的编程语言特定&lt;a href="https://logz.io/blog/where-are-apps-traces-instrumentation/?utm_medium=referral&amp;amp;utm_source=cncf"&gt;检测&lt;/a&gt;，因此提供有关 CPU、内存分配、堆、锁争用、与各个跨度的关联以及针对特定编程语言定制的类似功能的深度数据。然而，这些可能需要用户进行一些手动仪器工作才能充分发挥潜力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;全主机分析器&lt;/strong&gt;基于&lt;a href="https://logz.io/blog/ebpf-auto-instrumentation-pixie-kubernetes-observability/?utm_medium=referral&amp;amp;utm_source=cncf"&gt;eBPF 自动检测&lt;/a&gt;，因此它们提供整个系统的全面可见性，同时减少用户端的检测工作。然而，符号管理和运行时兼容性等挑战凸显了 eBPF 方法的复杂性。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="turning-profiling-data-into-observability-insights"&gt;将分析数据转化为可观察性见解&lt;/h2&gt;&lt;p&gt;讨论扩展到探索传统火焰图之外的新颖可视化技术。时间线视图描述了程序中各个线程或 goroutine 随时间的活动，提供了对资源利用率和线程交互的精细洞察。 Felix 描述了粒度调查流程的类型：“如果它在 CPU 上，它会在那里执行多长时间，如果它不在 CPU 上，它会等待什么？它在等待计时器吗？是在等待网络吗？它是否在等待被阻塞的互斥锁？”这还可以扩展到调查这些 goroutine 之间的连接以及它们如何通信。&lt;/p&gt;&lt;p&gt;我们还讨论了将分析数据转换为指标的潜力，因为某些事情只能通过分析来真正衡量。一个很好的例子是测量 Go 上垃圾收集器完成的工作量。虽然 Go 运行时没有有关垃圾收集器（或其他）goroutine 的操作系统调度的信息，但可以通过分析轻松获得此时间。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="opentelemetry-adds-support-for-continuous-profiling"&gt; OpenTelemetry 添加了对连续分析的支持&lt;/h2&gt;&lt;p&gt;随着 OpenTelemetry 的第一个章程在 2022 年底接近全面上市，社区开始探索路线图，并将持续分析确定为日志、指标和跟踪之外的下一个信号。这是 Sean Marciniak（又名 MovieStoreGuy）在 2020 年提出的一项早期&lt;a href="https://github.com/open-telemetry/oteps/issues/139"&gt;提案&lt;/a&gt;的延续。&lt;/p&gt;&lt;p&gt;然后以 OpenTelemetry 增强提案 (OTEP) 的形式正式化，并随后形成 SIG 配置文件，致力于如何在 OpenTelemetry 中实施连续分析。&lt;/p&gt;&lt;p&gt;一开始存在一些基本问题，即如何在 OpenTelemetry 中实施连续分析。它应该搭载现有的日志或其他信号模型，还是应该从头开始构建一个全新的模型？ &lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="Dotan 的 linkedin 帖子" class="wp-image-105644" height="960" src="https://www.cncf.io/wp-content/uploads/2024/04/image-16.png" style="width: 581px; height: auto;" width="1044" /&gt;&lt;/figure&gt;&lt;p&gt; SIG 需要在特定于领域的分析约定和特定于框架的 OpenTelemetry 约定之间取得平衡。他们需要弄清楚数据模型和规范是否应该从&lt;a href="https://profilerpedia.markhansen.co.nz/"&gt;现有的许多分析格式&lt;/a&gt;之一或新的格式中派生出来。&lt;/p&gt;&lt;p&gt;正如 Felix 解释的那样，“我们需要一种格式来完全指定火焰图中需要包含的所有内容，而 pprof 确实是我们可以基于的唯一选择。 JFR 是一种很棒的格式，但 JFR 不是标准化格式。它基本上没有文档记录，仅存在于 Java 平台的运行时内部。”&lt;/p&gt;&lt;p&gt;另一方面，SIG 必须解决如何以符合现有 OpenTelemetry 信号所采用的现有方法的方式进行分析。在考虑到所需的性能目标的情况下实现这种平衡是一项艰巨的任务。&lt;/p&gt;&lt;p&gt;最后，决定采用扩展&lt;strong&gt;pprof&lt;/strong&gt;规范的数据模型，该小组称之为“pprof 扩展”。 &lt;a href="https://github.com/google/pprof"&gt;pprof&lt;/a&gt;是 Google 推出的一款开源工具，用于可视化和分析分析数据。 SIG 的选择并不完全与 pprof 一致，而是对其进行了扩展。&lt;/p&gt;&lt;p&gt;实际上，这是一个分叉，在我看来这并不理想。我希望我们能够看到 Google 加入这一计划，捐赠 pprof 并将其纳入 OpenTelemetry，以造福于这两个项目的开源生态系统。&lt;/p&gt;&lt;p&gt;然后，当配置文件数据到达&lt;a href="https://logz.io/learn/opentelemetry-guide/#collector?utm_medium=referral&amp;amp;utm_source=cncf"&gt;OpenTelemetry Collector&lt;/a&gt;时，它会以类似于其他信号的统一方式被摄取和处理。这意味着数据被解构为收集器的 pdata 内部数据格式。然后，接收器之后的处理器可以对数据做一些有趣的事情。&lt;/p&gt;&lt;p&gt;重大消息是 OTEP 已合并， &lt;a href="https://www.cncf.io/blog/2024/03/19/opentelemetry-announces-support-for-profiling/"&gt;&lt;strong&gt;OpenTelemetry 现在正式支持连续分析&lt;/strong&gt;&lt;/a&gt;，尽管仍处于实验阶段。为实现这一重要里程碑的 SIG 成员和所有贡献者鼓掌。&lt;/p&gt;&lt;p&gt;想了解更多吗？查看 OpenObservability Talks 剧集： &lt;em&gt;&lt;a href="https://podcasters.spotify.com/pod/show/openobservability/episodes/Charting-New-Territory-OpenTelemetry-Embraces-Profiling---OpenObservability-Talks-S4E10-e2gtttb"&gt;绘制新领域：OpenTelemetry 拥抱分析&lt;/a&gt;。&lt;/em&gt; &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Wed, 10 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/11/charting-new-territory-opentelemetry-embraces-profiling/</guid></item><item><title>什么是代码基础设施？</title><link>https://www.cncf.io/blog/2024/04/10/what-is-infrastructure-from-code/</link><description>&lt;p&gt;&lt;em&gt;会员帖子最初由 Lauren Rother 发布在&lt;a href="https://blog.appcd.com/what-is-infrastructure-from-code"&gt;AppCD 的博客&lt;/a&gt;上&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="装饰形象" class="wp-image-105575" height="630" src="https://www.cncf.io/wp-content/uploads/2024/04/image-7.png" width="1260" /&gt;&lt;/figure&gt;&lt;p&gt;也许您听说过&lt;a href="https://en.wikipedia.org/wiki/Infrastructure_as_code"&gt;基础设施即代码&lt;/a&gt;(IaC)，这是通过版本控制的、机器可读的定义文件（或配置）来管理和配置计算机数据中心资源（主要但不完全在云中）的过程，而不是而不是通过源头的手动硬件配置或 Web 控制台。但什么是代码基础设施 (IfC)？在这篇文章中，我们将讨论 IfC 的含义、它的不同实现如何工作以及它与 IaC 有何不同。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;什么是代码基础设施？&lt;/h2&gt;&lt;p&gt;来自代码的基础设施是一种思考和使用基础设施配置的新方式，它将应用程序代码置于一切的核心。您无需根据您（或您的公司）对如何最好地构建基础架构的想法从头开始创建基础架构配置，而是根据应用程序代码的特定版本生成应用程序所需的基础架构。&lt;/p&gt;&lt;p&gt; IfC 的优点是使基础架构适应应用程序不断变化的需求，而不是让您的应用程序适应您的基础架构，然后尝试像软件一样对待基础架构。 “代码基础架构”方法显着改善了开发人员体验，有助于简化流程并加速交付，而无需任何人学习全新的专业知识领域。根据您选择的 IfC 方法，您还可以使用 IfC 来应用必要的体系结构和安全标准，同时保留版本控制的优势。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;从代码到基础设施的不同方法&lt;/h2&gt;&lt;p&gt;来自代码的基础设施出现的时间并不长，因此一直在发现和开发实现它的新方法。目前IfC的使用方式主要有四种：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;基于SDK的解决方案&lt;/li&gt;&lt;li&gt;基于代码注释的解决方案&lt;/li&gt;&lt;li&gt;新的编程语言&lt;/li&gt;&lt;li&gt;静态扫码&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;a href="https://www.infoq.com/news/2023/02/infrastructure-code-cloud-manage/"&gt;InfoQ&lt;/a&gt;对前三种方法有一个很好、快速的概述，值得一看。基本思想是，目前，您可以尝试以考虑 IfC（SDK 和编程语言）的方式构建应用程序，也可以使用现有代码来提出 IfC（代码注释和代码扫描）。&lt;/p&gt;&lt;p&gt;哪种方法最适合您将取决于您团队的时间限制、经验、兴趣以及公司和应用程序的需求。每个都有自己的优点和缺点，SDK 和编程语言方法确保从构建应用程序的一开始就集成 IfC，并且代码注释和代码扫描方法从代码构建适合应用程序的基础设施，而无需切换语言或工具。也许 IaC 对于您的整个组织来说工作得很好，并且您认为不需要 IfC。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt; IaC 与 IfC&lt;/h2&gt;&lt;p&gt; IaC 真正诞生是在 2010 年代。使用 IaC 的方法有很多，从 Helm 到 Terraform，再到 CloudFormation 等等。为了帮助用户，许多提供相关 IaC 解决方案的工具如雨后春笋般涌现，例如 Spacelift、Rancher、Pulumi 和 AWS CDK。&lt;/p&gt;&lt;p&gt;随着时间的推移以及行业的发展和变化，IaC 方法的&lt;a href="https://appcd.com/blog/7-challenges-infrastructure-as-code"&gt;缺点&lt;/a&gt;开始显现出来，并且出现了如何更好地合并应用程序代码和基础设施代码的问题。 IfC 是一个开始受到关注的答案。但他们如何比较呢？&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;基础设施&lt;strong&gt;即&lt;/strong&gt;代码&lt;/td&gt;&lt;td&gt;&lt;strong&gt;来自&lt;/strong&gt;代码的基础设施&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;将基础设施需求和实践放在首位。&lt;/td&gt;&lt;td&gt;将&lt;strong&gt;应用程序的基础设施需求放在首位。&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;创建一个基础设施的真实来源，理想情况下是 VCS 配置，但如果有人偏离该配置，可能会有点难以确定。&lt;/td&gt;&lt;td&gt;它的&lt;strong&gt;真实来源是应用程序版本&lt;/strong&gt;，因此 VCS 是内置的。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;实施架构和安全最佳实践。&lt;/td&gt;&lt;td&gt;根据应用程序需求进行扩展，确保基础设施具有最小特权和合理规模。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;随着时间的推移，管理和更新可能会变得困难。&lt;/td&gt;&lt;td&gt;每个应用程序的基础设施可能遵循相同的标准，但对于该应用程序来说是唯一的。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;往往是一刀切的。&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading"&gt;与 IfC 和 appCD 一起走向未来&lt;/h2&gt;&lt;p&gt;如果您有兴趣尝试“代码基础架构”方法，appCD 可以通过静态代码扫描以最新、最省力的方式提供 IfC，从而减少干预并加快交付速度。通过将 appCD 连接到您项目的存储库、静态扫描您的代码、检查建议的基础设施的可视化效果，然后生成用于部署的 IaC 文件来&lt;a href="https://www.appcd.com/get-started"&gt;尝试我们&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;有疑问、想法，或者只是想告诉我们我们有多酷？给我们发送&lt;a href="mailto:feedback@appcd.com"&gt;电子邮件&lt;/a&gt;或通过社交媒体与我们联系： &lt;a href="https://www.linkedin.com/company/appcd"&gt;LinkedIn&lt;/a&gt;或&lt;a href="https://twitter.com/appcd_io"&gt;X。&lt;/a&gt; &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Tue, 09 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/10/what-is-infrastructure-from-code/</guid></item><item><title>K8s 基准报告：组织是否满足 NSA 强化检查？</title><link>https://www.cncf.io/blog/2024/04/09/k8s-benchmark-report-are-organizations-meeting-nsa-hardening-checks/</link><description>&lt;p&gt;&lt;em&gt;会员帖子最初由 Joe Pelletier 在&lt;a href="https://www.fairwinds.com/blog/k8s-benchmark-report-nsa-hardening-checks"&gt;Fairwinds 博客&lt;/a&gt;上发布&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.nsa.gov/"&gt;国家安全局&lt;/a&gt;(NSA) 和&lt;a href="https://www.cisa.gov/"&gt;网络安全和基础设施安全局&lt;/a&gt;(CISA) 继续更新其 Kubernetes 强化指南，提出建议以帮助组织确保&lt;a href="https://media.defense.gov/2022/Aug/29/2003066362/-1/-1/0/CTR_KUBERNETES_HARDENING_GUIDANCE_1.2_20220829.PDF"&gt;强化 Kubernetes 集群&lt;/a&gt;。这种强大的深度防御方法可帮助组织确保当攻击者破坏集群时，影响范围尽可能小。在较高层面上，该指南对强化 Kubernetes 提出了以下建议：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href="https://www.fairwinds.com/blog/validating-container-security"&gt;扫描容器镜像&lt;/a&gt;和 Pod 是否存在漏洞和错误配置。&lt;/li&gt;&lt;li&gt;以尽可能最低的&lt;a href="https://www.fairwinds.com/blog/fairwinds-insights-basics-tutorial-check-kubernetes-configuration-for-privilege-escalation"&gt;权限&lt;/a&gt;运行容器和 Pod。&lt;/li&gt;&lt;li&gt;使用技术控制来实施最低级别的安全。&lt;/li&gt;&lt;li&gt;使用网络隔离和强化来最大程度地减少因妥协造成的损害。&lt;/li&gt;&lt;li&gt;尽可能使用防火墙限制网络连接，并使用加密来保护机密性。&lt;/li&gt;&lt;li&gt;使用强大的&lt;a href="https://rbac-manager.docs.fairwinds.com/"&gt;身份验证和授权&lt;/a&gt;来限制用户和管理员访问并最大限度地减少攻击面。&lt;/li&gt;&lt;li&gt;审核日志，以便管理员可以监控活动并获取潜在恶意活动的警报。&lt;/li&gt;&lt;li&gt;创建一个安全策略，要求定期审查所有 Kubernetes 设置并使用漏洞扫描。&lt;/li&gt;&lt;/ol&gt;&lt;h2 class="wp-block-heading"&gt;组织是否正在应用 NSA 强化检查？&lt;/h2&gt;&lt;p&gt; Fairwinds Insights 支持 NSA 的多项建议，添加了多项额外检查以帮助组织遵守 NSA 指南。今年的&lt;a href="https://www.fairwinds.com/blog/2024-kubernetes-benchmark-report-kubernetes-workload-analysis"&gt;Kubernetes 基准报告&lt;/a&gt;分析了来自超过 330,000 个工作负载的数据，使用来自数百个组织的数据来评估与&lt;a href="https://www.fairwinds.com/blog/kubernetes-benchmark-report-managing-k8s-workload-costs-2024"&gt;成本效率&lt;/a&gt;、&lt;a href="https://www.fairwinds.com/blog/2024-k8s-benchmark-report-workload-reliability"&gt;可靠性&lt;/a&gt;和&lt;a href="https://www.fairwinds.com/blog/k8s-benchmark-report-kubernetes-workloads-secure"&gt;安全性&lt;/a&gt;相关的最佳实践的一致性。最新报告还包括专门研究与 NSA 强化检查的一致性的部分。&lt;/p&gt;&lt;h3 class="wp-block-heading"&gt; Linux加固&lt;/h3&gt;&lt;p&gt;通常，工作负载拥有的权限比运行其应用程序所需的权限要多。调整容器的权限可以帮助您最大程度地降低容器泄露的速度和影响。 Fairwinds 检查工作负载是否使用 AppArmor、SELinux、Linux 功能或 seccomp 配置文件来授予工作负载运行所需的最低权限。最小化工作负载的权限还可以最大程度地减少攻击者访问其他工作负载或集群的能力。&lt;/p&gt;&lt;p&gt;在 2024 年基准中，分析显示 33% 的组织有超过 50% 的工作负载允许过多的权限。 12% 的组织仅 91-100% 的工作负载受到影响，其余分布在两者之间。这表明组织在实施 Linux 强化方面还有改进的空间。他们必须花一些时间来识别这些特权过高的工作负载，以使此更改符合 NSA 指南。 &lt;a href="https://polaris.docs.fairwinds.com/"&gt;Polaris&lt;/a&gt;是 Kubernetes 的开源策略引擎，可以帮助您识别此问题，以便您可以修复它。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="NSA 强化检查" src="https://www.fairwinds.com/hs-fs/hubfs/NSAhardeningchecks.png?width=600&amp;amp;height=234&amp;amp;name=NSAhardeningchecks.png" /&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading"&gt;缺少网络策略&lt;/h3&gt;&lt;p&gt;Kubernetes 中的&lt;a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/"&gt;网络策略&lt;/a&gt;控制与其他 Pod、IP 地址或命名空间的流量。您可以将 Kubernetes NetworkPolicies 用于集群中的各个应用程序，以指定 Pod 如何通过网络与其他网络实体进行通信。如果 Pod 没有限制其出口和入口流量的 NetworkPolicy，则它可能允许访问外部资源或来自您不希望允许的其他 Pod 的访问。&lt;/p&gt;&lt;p&gt; Kubernetes 基准测试显示，37% 的组织制定了网络策略来保护工作负载免受不需要的流量的影响。不幸的是，分析还表明，58% 的组织在其 51% 或更多的工作负载上缺少网络策略。设置网络策略是保护容器安全的关键步骤，因此令人惊讶的是，如此多的组织没有实施这种强化措施。 Polaris 还包括一些策略，可帮助识别缺少网络策略的工作负载，以便您解决这些问题。 &lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="缺少网络策略" src="https://www.fairwinds.com/hs-fs/hubfs/MissingNetworkPolicy.png?width=600&amp;amp;height=178&amp;amp;name=MissingNetworkPolicy.png" /&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading"&gt; NSA 强化指南合规性&lt;/h2&gt;&lt;p&gt;随着业界提供关于强化 Kubernetes 环境抵御恶意攻击的更多反馈以及威胁形势的发展，NSA 和 CISA 将继续更新 Kubernetes 强化指南。 Kubernetes和云原生生态系统也在快速发展，带来了新的解决方案和新的挑战。跟上这些变化是很困难的，特别是在复杂的环境中。&lt;/p&gt;&lt;p&gt;恶意行为者随时准备利用泄露的 kubeconfig、泄露的云凭证、供应链漏洞、暴露的仪表板或已知的安全漏洞。所有这些攻击途径都可能允许攻击者在您的集群中执行自己的代码、升级权限、掩盖他们的踪迹并建立持久的立足点。这使得恶意行为者可以窃取机密和敏感数据，消耗您的计算资源以谋取私利，或者以其他方式使您的业务面临风险。如果没有解决方案来帮助您识别权限过多或缺少网络策略的工作负载，则很难找到并修复这些问题以最大程度地减少攻击的潜在影响。&lt;/p&gt;&lt;p&gt; Polaris 和&lt;a href="https://www.fairwinds.com/insights"&gt;Fairwinds Insights&lt;/a&gt;是两种解决方案，可以帮助组织跟踪强化 Kubernetes 集群的建议并评估是否存在需要解决的差距。随着团队在更多环境中部署更多集群，能够持续大规模评估安全性并与 NSA 指导保持一致非常重要。 &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Mon, 08 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/09/k8s-benchmark-report-are-organizations-meeting-nsa-hardening-checks/</guid></item><item><title>开放策略代理(OPA)在电信领域的适用性</title><link>https://www.cncf.io/blog/2024/04/08/applicability-of-open-policy-agent-opa-in-telecom-domain/</link><description>&lt;p&gt;&lt;em&gt;成员帖子，作者：Infosys Limited 高级技术架构师&lt;a href="https://www.linkedin.com/in/rakesh-girija-ramesan-nair-0462a1aa/"&gt;Rakesh Girija Ramesan Nair&lt;/a&gt;和技术架构师&lt;a href="https://www.linkedin.com/in/sherni-liz-samuel-74ba8a78/"&gt;Sherni Liz Samuel&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;抽象的：&lt;/h2&gt;&lt;p&gt;&lt;em&gt;本博客介绍了电信领域与政策相关的关键焦点领域和挑战，以及如何通过开放策略代理 (OPA) 解决这些问题，开放策略代理 (OPA) 是云原生计算基金会 (CNCF) 领域的一个毕业项目。此外，它还展示了如何通过 OPA 解决类似问题的实际示例以及在执行相同操作时的关键观察结果。&lt;/em&gt;&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;介绍&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;数字化转型一直是电信公司的重点关注领域，这推动了每个通信服务提供商 (CSP) 实现基础设施、运营和服务现代化，以满足多供应商和异构网络技术生态系统不断变化的需求。这一数字化转型之旅的基本方面之一是转向云原生。开始这一旅程的原始设备制造商 (OEM)、电信公司和服务提供商强调了需要通过协作活动来解决的许多挑战和实际问题。&lt;/p&gt;&lt;p&gt; CNCF 及其相关项目在汇集电信行业的主要参与者并支持构建云原生生态系统方面发挥着关键作用。 CSP 正在转向云原生架构，而 OEM 的期望是提供符合云原生原则的解决方案。从基础设施的角度来看，Kubernetes 的核心是运行所有网络工作负载和应用程序的事实上的运行时环境。&lt;/p&gt;&lt;p&gt;在这一全面转型之旅中，存在多个需要执行政策和法规的接触点。该策略是调出电信领域的关键接触点，并利用 CNCF 项目开放策略代理来加速实施过程，从而缩短上市时间。&lt;/p&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;电信领域的政策驱动领域&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;本节着眼于政策和规则在电信领域发挥重要作用的关键领域&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;安全&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;正如上一节中提到的，随着网络走向数字化和云原生化，安全性变得至关重要。安全性分布在基础设施、集群、开发和工作负载的所有层面。互联网安全中心、国家标准与技术研究院等不同行业论坛已经发布了清单、指南和对策，用于在电信堆栈中安全配置和实施云原生原则。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;编排&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;部署工作负载（网络功能、应用程序等）涉及多个系统，例如域管理器、元素管理系统和域编排系统。同样，实现端到端客户服务或任何 B2B 服务都涉及跨网络域和多供应商设备/功能驱动配置。策略驱动的编排是跨各个层实现完全按需/动态编排的关键。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;数据&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;全球各地的电信公司正在采用新技术来帮助其转型。人工智能 (AI) 尤其被用来改善服务、提升客户体验并创造更多收入。为了在这个数据驱动的世界中脱颖而出，电信提供商正在尝试利用数据分析并创建跨域和设备收集各种数据（结构化、半结构化、非结构化等）的数据存储。实现更好的分析见解和提高生产力（自我修复）等预期结果的主要挑战是数据质量。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;一体化&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在任何重大转型计划中，跨各种系统的集成的简化是基础。电信管理论坛 (TMForum)、欧洲电信标准协会 (ETSI) 等标准行业机构正在尽最大努力标准化网络环境中的各种接口。目的是避免任何供应商锁定并以标准化方式公开/使用数据。网络即服务 (NaaS) 正在蓬勃发展，为网络提供所需的敏捷性，以释放更多收入流和用例。验证任何集成中涉及的合同协议是一个非常重要的问题。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;引入开放策略代理（OPA）&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;开放策略代理 (OPA) 是一种开源通用策略引擎，有助于跨整个技术堆栈的各个部分编写、管理和执行策略。 OPA 提供了一种称为 Rego 的高级声明性语言，它定义了管理系统/应用程序的规则。&lt;/p&gt;&lt;p&gt; OPA 的主要特点如下： –&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多功能性&lt;/strong&gt;： – OPA 可以被视为一种策略即代码工具，它提供了跨多个应用程序/云网络等强制执行策略的灵活性。它可以用于从简单的数据验证/API 授权，甚至基于升级的云原生部署政策。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可重用性&lt;/strong&gt;： – 在 OPA 中定义一次的通用策略可以在多个平台上重复使用和执行，从而减少重复。除此之外，当平台或基础设施扩展时，这还可以节省开发时间、减少错误并简化策略维护。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;高性能策略决策&lt;/strong&gt;： – OPA 能够在某些用例中并行化策略评估，从而在处理庞大且复杂的数据集和策略时优化性能。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;简化的策略管理&lt;/strong&gt;： – OPA 将策略逻辑与应用程序代码解耦，从而使管理策略变得更容易、更高效。通过使用 OPA 作为核心来定义和维护整个基础设施和技术堆栈的策略，可以实现统一的策略管理。&lt;/p&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;在电信领域利用 OPA 的实例&lt;/strong&gt;&lt;/h3&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;网络的提取、验证和转换框架：&lt;/strong&gt; –&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;连续数据的质量可以释放数据存储的价值，进而有助于最大限度地利用网络数据。它使电信公司能够运行高级分析，提供实时见解和机器学习驱动的预测。&lt;/p&gt;&lt;p&gt;下图是我们为 OPA 推动的网络数据存储设置的提取验证和转换框架 (EVTF)。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="该图显示了 OPA 推动的网络数据存储的提取验证和转换框架 (EVTF)。" class="wp-image-105582" height="868" src="https://www.cncf.io/wp-content/uploads/2024/04/image-10.png" width="1600" /&gt;&lt;/figure&gt;&lt;p&gt;该框架的整体流程为：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;数据收集层使用各种协议（例如简单网络管理协议-SNMP、gRPC网络管理接口-GNMI等）跨域（例如网络管理系统、网元管理系统、实际设备等）连接到各种网络数据源，并收集不同的网络数据。数据（例如库存、拓扑、警报、遥测）然后被推送到消息总线以供使用。&lt;/li&gt;&lt;/ol&gt;&lt;ol start="2"&gt;&lt;li&gt;然后，数据被使用并通过根据设备类型、域和供应商配置的各个验证阶段。提取验证和转换框架 (EVTF) 利用 OPA 来执行 Rego 中定义的策略。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;可以使用 OPA 定义的一些验证规则包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;数据类型检查：&lt;/strong&gt;确保数据符合预期类型（例如，端口号的整数、IP 地址的字符串）。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;完整性检查：&lt;/strong&gt;确保数据没有缺失值或缺失数据记录。 &lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;范围检查：&lt;/strong&gt;验证特定范围内的数据（例如，有效的 IP 地址范围）。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;自定义验证规则：&lt;/strong&gt;使用 Rego 函数实现更复杂的验证逻辑。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;处理所有特定电信用例/场景的抽象层被开发为自定义微服务。它充当任何协调器系统与 OPA 交互的外观。作为该服务的一部分，创建了带有驱动网络设备模型验证和转换的 Swagger 文档的定制 API。下面提供了一个示例验证 REST API 端点，它采用 4 个参数作为输入。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;域&lt;/strong&gt;：标识数据源自的特定网络区域&lt;/li&gt;&lt;li&gt;&lt;strong&gt;设备类型&lt;/strong&gt;：指定生成数据的设备类型（例如路由器、交换机、防火墙）。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;供应商&lt;/strong&gt;：提供有关原始设备制造商的信息&lt;/li&gt;&lt;li&gt;&lt;strong&gt;输入消息&lt;/strong&gt;：这是要验证的实际数据有效负载。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;每个验证规则都是在 OPA 中利用提供的开箱即用 API 进行配置的。用于执行数据类型验证的 Rego 策略示例如下所示： – &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="代码示例" class="wp-image-105584" height="393" src="https://www.cncf.io/wp-content/uploads/2024/04/image-11.png" width="617" /&gt;&lt;/figure&gt;&lt;p&gt;在此示例中，datatype_string_check Rego 规则检查输入值是否符合约定的数据类型。 Rego 策略用于生成结果并为错误场景配置自定义消息。 Rego 提供导入外部数据文件的灵活性。外部文件中的可配置数据在上述 Rego 策略中引用并使用，例如 data.deviceheaders。&lt;/p&gt;&lt;p&gt;该框架的关键思想是采用与 OPA 相一致的低代码方法，使领域中小企业更容易以最小的技术依赖性配置所需的规则。&lt;/p&gt;&lt;ol start="3"&gt;&lt;li&gt;验证成功后，数据将保存到原始存储中。无效数据会通知各自的源系统，并隔离在错误存储中以供参考。&lt;/li&gt;&lt;li&gt;转换脚本从原始存储中提取经过验证/数据质量检查的数据。&lt;/li&gt;&lt;li&gt;在转换组件中，再次使用具有底层 OPA 的 EVTF 来定义将原始数据转换为通用建模格式所需的各种转换规则。以下是定义的一些转换规则： –&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;数据映射&lt;/strong&gt;：将特定于网络的数据格式转换为符合任何行业标准的通用数据模型。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;字段重命名：&lt;/strong&gt;重命名字段以与通用模型保持一致。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;数据丰富：&lt;/strong&gt;根据预定义的规则或外部来源添加附加信息。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里也遵循步骤 2 中详述的类似方法，展示了基于 OPA 的 EVTF 的灵活性。单一解决方案可解决两个不同领域的问题。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="代码示例" class="wp-image-105585" height="405" src="https://www.cncf.io/wp-content/uploads/2024/04/image-12.png" width="399" /&gt;&lt;/figure&gt;&lt;p&gt;例如，上面的 Rego 策略显示了基于源和目标的简单转换映射逻辑。在上面的示例中，设备类型是源，要映射的数据模型类型是目标。实际映射在外部 data.json 文件下配置并导入到 Rego 策略中。&lt;/p&gt;&lt;ol start="6"&gt;&lt;li&gt;转换后的数据与通用数据模型保持一致，并被推送到转换后的存储中。&lt;/li&gt;&lt;li&gt;数据服务层从转换后的存储中提取转换后的数据，并将其作为符合各种用例的产品模型提供给不同的消费者。&lt;/li&gt;&lt;/ol&gt;&lt;ol start="2"&gt;&lt;li&gt;&lt;strong&gt;网络关联和编排策略引擎&lt;/strong&gt;： –&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;网络保障对于电信公司确保最终客户的网络可用性至关重要。编排可帮助电信公司缩短上市时间，轻松推出新产品。保证和编排齐头并进以实现自治网络。&lt;/p&gt;&lt;p&gt;下图显示了运营人工智能 (AIOPS) 平台如何与利用 OPA 驱动的关联和编排策略引擎 (COPE) 的各种网络域编排器和系统集成。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="该图显示了运营人工智能 (AIOPS) 平台如何与利用 OPA 驱动的关联和编排策略引擎 (COPE) 的各种网络域编排器和系统集成" class="wp-image-105586" height="632" src="https://www.cncf.io/wp-content/uploads/2024/04/image-13.png" width="1600" /&gt;&lt;/figure&gt;&lt;p&gt; AIOPS 平台利用其 AI/ML 功能发现网络异常和模式。这些由操作员管理员审核，以添加、修改和批准将它们存储为关联策略。然后，这些策略会更新为 COPE，在运行时用于主动解决网络问题。&lt;/p&gt;&lt;p&gt;由 OPA 驱动的关联与编排策略引擎 (COPE) 具有自定义服务，可充当任何接口应用程序的中介。所有网络级别的复杂性都在此微服务中处理，而引擎仍然是 OPA。&lt;/p&gt;&lt;p&gt;用于配置基于利用率和相关性策略的示例 Rego 策略如下所示： –&lt;/p&gt;&lt;p&gt;配置网络利用率带宽超出定义阈值时的操作。可以定义Rego策略，指定判断网络输入输出流量是否大于阈值的条件。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="代码示例" class="wp-image-105587" height="285" src="https://www.cncf.io/wp-content/uploads/2024/04/image-14.png" width="870" /&gt;&lt;/figure&gt;&lt;p&gt;在上面的例子中，我们有两个函数input_utilization和output_utilization。阈值可以通过 Spark Streaming 动态计算并配置。自定义微服务层利用此信息来丰富数据并根据定义的 Rego 策略验证数据。&lt;/p&gt;&lt;p&gt;关联警报模式的 OPA 策略示例如下所示： – &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="代码示例" class="wp-image-105588" height="387" src="https://www.cncf.io/wp-content/uploads/2024/04/image-15.png" width="507" /&gt;&lt;/figure&gt;&lt;p&gt;在上面的示例中，Rego 策略检查输入警报数组并使用预配置的警报模式数组验证警报集。警报模式通过 AI/ML 识别或根据经验进行配置，以实现主动保证。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;推理&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;OPA 为执行基于规则和策略的检查提供了急需的灵活性。正如上面示例中所解释的，OPA 具有许多开箱即用 (OTB) 功能，并且通过一些小的自定义，可以应用于涵盖电信堆栈的长度和广度的多个用例。 OPA 充当任何规则或策略驱动的解决方案的支柱。&lt;/p&gt;&lt;p&gt; OTB&lt;/p&gt;&lt;ul&gt;&lt;li&gt; OPA 通过 CRUD 操作公开 REST API 端点。&lt;/li&gt;&lt;li&gt; OPA Rego 策略是用自然语言编写的，因此与 Drools 等其他规则引擎相比，可以非常快速地掌握。任何未来的增强或实施都不需要特定的技能。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;定制&lt;/p&gt;&lt;ul&gt;&lt;li&gt;配置驱动的解决方案方法可以通过 OPA 来实现，并进行一些小的增强。它有助于避免任何 IT/人员依赖性，从而实现自助服务并缩短响应时间。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt; Rego Playground 等工具可帮助我们随时随地开发和测试 Rego 策略。除此之外，我们还有一个广泛活跃的 OPA 社区，使其易于使用。&lt;/p&gt;&lt;p&gt; OPA在电信领域有着广泛的适用性。使用 OPA 探索、应用和转变您的网络格局。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;参考&lt;/strong&gt;&lt;/h2&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;官方 OPA 文档&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;a href="https://www.openpolicyagent.org/docs/latest/policy-language/"&gt;https://www.openpolicyagent.org/docs/latest/policy-language/&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;雷戈游乐场&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;a href="https://play.openpolicyagent.org/"&gt;https://play.openpolicyagent.org/&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;strong&gt;Github 社区讨论&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;a href="https://github.com/open-policy-agent/community/discussions"&gt;https://github.com/open-policy-agent/community/discussions&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;strong&gt;Github OPA 问题/功能请求&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;a href="https://github.com/open-policy-agent/opa/issues"&gt;https://github.com/open-policy-agent/opa/issues&lt;/a&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Sun, 07 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/08/applicability-of-open-policy-agent-opa-in-telecom-domain/</guid></item><item><title>会员变更源码解读</title><link>https://www.cncf.io/blog/2024/04/04/membership-change-source-code-interpretation/</link><description>&lt;p&gt;&lt;em&gt;会员帖子最初由 DatenLord 发布在&lt;a href="https://medium.com/@datenlord/membership-change-source-code-interpretation-5a5e405b120a"&gt;Medium&lt;/a&gt;上&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="DatenLord 会员变更横幅源码解读" class="wp-image-105563" height="300" src="https://www.cncf.io/wp-content/uploads/2024/04/image-1.jpeg" width="700" /&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading" id="2447"&gt;背景&lt;/h2&gt;&lt;p id="ddf6"&gt;在分布式系统应用场景中，难免会增删节点或者更换节点，最简单的解决方案就是暂时关闭集群，然后直接修改配置文件添加新的节点，完成后重启集群过程。这确实可以达到我们的目的，但是它的问题也非常明显。变更期间集群不可用，这对于需要高可用性的系统来说是无法接受的。手动过程可能会导致其他错误，例如可能会降低系统的稳定性。因此，如何高效、安全地改变集群成员成为分布式系统开发的关键问题。对于Xline来说，不仅需要处理常规的变更过程，还需要将其与Curp协议集成，以确保引入集群成员资格变更不会导致前端协议出现错误。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="be0f"&gt;会员动态变更的问题及解决方案&lt;/h2&gt;&lt;p id="75e7"&gt;由于Xline使用Raft作为后端协议，因此为Xline添加动态更改成员的能力需要解决Raft协议本身遇到的问题。 Raft 协议成功运行的一个关键前提是在任何给定时间只能有一个领导者。在不施加任何限制的情况下，直接向集群添加节点可能会破坏这个前提，如下图所示： &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示服务器 1 到服务器 5 上 C 旧和 C 新随时间变化的比较的图表" class="wp-image-105564" height="467" src="https://www.cncf.io/wp-content/uploads/2024/04/image-5.png" width="700" /&gt;&lt;/figure&gt;&lt;p id="66b8"&gt;由于网络延迟等原因，无法保证每个节点同时从C_old切换到C_new，可能的结果如下图所示。&lt;/p&gt;&lt;p id="3403"&gt;假设此时Server 1和Server 5同时开始选举，Server 1获得了Server 2的选票，满足C_old中的法定人数，成为Leader。 Server 5收到Server 3和Server 4的投票，满足C_new中的法定人数要求，成为Leader，然后同时有两个Leader，这就产生了一致性问题。&lt;/p&gt;&lt;p id="7c22"&gt;为了解决这个问题，Raft的作者提供了两种解决方案。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;共同共识&lt;/li&gt;&lt;li&gt;单步会员变更&lt;/li&gt;&lt;/ol&gt;&lt;h2 class="wp-block-heading" id="6e4e"&gt;共同共识&lt;/h2&gt;&lt;p id="cea5"&gt;联合共识本质上是在成员变更过程中添加一个中间状态。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示 C 旧和 C 新随时间变化的比较的图表" class="wp-image-105566" height="240" src="https://www.cncf.io/wp-content/uploads/2024/04/image-6.jpg" width="700" /&gt;&lt;/figure&gt;&lt;p id="f8ff"&gt;当 Leader 收到成员资格变更请求时，它会创建一个 C_(old, new) 配置并通过 AppendEntries 与 Follower 同步。接收到C_(old,new)的节点会同时使用这两种配置来做出决策，即选举等操作需要C_old和C_new都一致才能成功。 C_(old, new)提交后，Leader创建C_new配置并与Follower同步。&lt;/p&gt;&lt;p id="4484"&gt;在这种场景下，集群成员中间状态变化有以下几种可能：&lt;/p&gt;&lt;ol&gt;&lt;li&gt; C_(old, new)被创建然后提交，此阶段集群中可能存在C_old、C_(old, new)两种配置，此阶段任何节点想要成为Leader都需要C_old配置达成一致到它，所以不会有两个领导者。&lt;/li&gt;&lt;li&gt; C_old,new提交之后，C_new创建之前，这个阶段可能同时存在C_old,C_(old,new)两种配置，但只有使用C_(old,new)的节点才能成为Leader，因为大多数节点此阶段集群中的节点已经配置了 C_old，剩余尚未切换的节点不足以选举新的 Leader。&lt;/li&gt;&lt;li&gt; C_new 创建并提交。该阶段可能同时存在C_old、C_(old, new)、C_new 三种配置，其中C_old配置无法选举出Leader，原因如前所述.C_(old, new)而 C_new 需要 C_new 同意才能选举 Leader，这种情况下不会有两个 Leader。&lt;/li&gt;&lt;li&gt; C_new提交后，C_new独立做出决定，不会出现两个领导者。&lt;/li&gt;&lt;/ol&gt;&lt;h2 class="wp-block-heading" id="34fc"&gt;单步节点变更&lt;/h2&gt;&lt;p id="59e1"&gt;除了联合共识之外，还有另一种安全地进行集群成员身份更改的方法，那就是单步节点更改。这种方法每次只增减一个节点，这种情况下，大部分新旧配置一定会有重叠的节点，而重叠的节点只能投票给一个节点，这就保证了不会有两个Leader同一时间。复杂的变更行为需要转化为多个单步节点变更才能完成。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="加入共识架构" class="wp-image-105567" height="281" src="https://www.cncf.io/wp-content/uploads/2024/04/image-6-1.jpg" width="700" /&gt;&lt;/figure&gt;&lt;p id="6139"&gt;该方案没有中间状态，只需一步操作即可完成更改。逻辑比联合共识更加简洁，没有那么多复杂的中间状态，实现会简单一点，当然它的功能没有联合共识那么强大。&lt;/p&gt;&lt;p id="391e"&gt; Xline目前的做法是单步成员变更，未来我们将增加对联合共识的支持。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="17ab"&gt; Curp协议集成&lt;/h2&gt;&lt;p id="8fe0"&gt;Membership变更的主要过程可以通过后端Raft来完成，但是这个过程可能会打乱前端Curp协议的流程。正常处理时，Curp客户端会向集群中的所有节点广播Propose请求，并根据成功的Propose数量是否大于当前集群成员的superquorum数量以及是否成功来判断本次Propose是否在curp中提交。成员在创建客户端时确定，但随着成员资格的变化而变化。在成员资格变更之前，所有成员都是在创建客户端时确定的，但是引入成员资格变更之后，需要有一种机制来确保当客户端在使用旧配置时，也能检测到服务器使用的新配置并使用新的配置重试当前请求，否则可能会导致Curp协议无法正常工作。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示 Curp 协议集成的图表" class="wp-image-105570" height="568" src="https://www.cncf.io/wp-content/uploads/2024/04/image-6-2.jpg" width="700" /&gt;&lt;/figure&gt;&lt;p id="698c"&gt;如图所示，假设Client向三节点集群广播一个Propose，那么Client收到三个（3节点的superquorum）成功响应，则认为该Propose已在Curp中提交。在此提议过程中，集群成员资格发生变化，Server4 加入集群。但节点 4 的 superquorum 为 4，这意味着 3 节点集群中 curp 刚刚提交的请求在成员资格变更后不再满足 Curp 的提交条件，可能会导致该请求丢失已退还给客户。&lt;/p&gt;&lt;p id="a0bc"&gt;为了解决这个问题，我们为外部客户端发送的请求引入了一个新字段&lt;code&gt;cluster_version&lt;/code&gt; ，它表示集群当前使用的配置版本，并且每次执行成员资格更改时都会进行修改。这样Server就可以通过该字段来判断发送请求的客户端是否使用了正确的配置，而使用错误的配置则直接拒绝该请求。 Client 检测到&lt;code&gt;cluster_version&lt;/code&gt;不一致后，会主动从 Server 上拉取当前配置，并以新配置发起新一轮请求。在上面的例子中，当Propose和membership变更同时发生时，Server1、2、3中的节点之一必须使用新的配置，这样该节点就会拒绝使用另一个&lt;code&gt;cluster_version&lt;/code&gt;的Propose。当Client检测到新的配置后&lt;code&gt;cluster_version&lt;/code&gt; ，它将从集群中重新拉取当前成员配置，并使用新配置重试整个请求。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="1c69"&gt;源码解读&lt;/h2&gt;&lt;h2 class="wp-block-heading" id="0acd"&gt;领导者发起成员变更&lt;/h2&gt;&lt;p id="00d0"&gt;发起成员资格变更的第一步是向 Leader 发送&lt;code&gt;ProposeConfChangeRequest&lt;/code&gt; ，其中包含本次提案中要变更的节点信息以及其他一些辅助字段。&lt;/p&gt;&lt;p id="0aa4"&gt;当Server收到请求时，首先检查请求的&lt;code&gt;cluster_version&lt;/code&gt;是否与集群当前的&lt;code&gt;cluster_version&lt;/code&gt;匹配，不匹配的请求会被拒绝，然后再进入Server的处理逻辑：&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class="language-cpp" lang="cpp"&gt;/// Handle `propose_conf_change` request pub(super) fn handle_propose_conf_change( &amp;amp;self, propose_id: ProposeId, conf_changes: Vec&amp;lt;ConfChange&amp;gt;, ) -&amp;gt; Result&amp;lt;(), CurpError&amp;gt; { // ... self.check_new_config(&amp;amp;conf_changes)?; let entry = log_w.push(st_r.term, propose_id, conf_changes.clone())?; debug!(&amp;quot;{} gets new log[{}]&amp;quot;, self.id(), entry.index); let (addrs, name, is_learner) = self.apply_conf_change(conf_changes); self.ctx .last_conf_change_idx .store(entry.index, Ordering::Release); let _ig = log_w.fallback_contexts.insert( entry.index, FallbackContext::new(Arc::clone(&amp;amp;entry), addrs, name, is_learner), ); // ... }&lt;/code&gt;&lt;/pre&gt;&lt;p id="2d03"&gt; Leader节点在处理时会通过&lt;code&gt;check_new_config&lt;/code&gt;方法检查本次conf变更的有效性，提前拒绝无法处理的变更，比如插入已经存在的节点或者删除不存在的节点。一旦检查通过，它就会经历与常规请求相同的过程，通过共识同步到所有 Follower。除了同一过程的这一部分之外，conf 更改还需要一些特殊处理，在将新配置插入日志后立即应用新配置，并记录用于回滚配置的上下文。这和Raft论文中提到的一样，节点拥有日志后，不需要等待它提交，它会立即生效。在Raft中，未提交的日志是可以被覆盖的，因此需要记录上下文，如果日志被覆盖，则可以利用这个上下文来回滚更改。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="f17d"&gt;关注者处理成员变更&lt;/h2&gt;&lt;p id="9721"&gt;对于Follower节点来说，成员变更的主要逻辑发生在&lt;code&gt;handle_append_entries&lt;/code&gt;中，用于处理Leader发送的日志，包括conf的变更。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class="language-cpp" lang="cpp"&gt;pub(super) fn handle_append_entries( &amp;amp;self, term: u64, leader_id: ServerId, prev_log_index: LogIndex, prev_log_term: u64, entries: Vec&amp;lt;LogEntry&amp;lt;C&amp;gt;&amp;gt;, leader_commit: LogIndex, ) -&amp;gt; Result&amp;lt;u64, (u64, LogIndex)&amp;gt; { // ... // append log entries let mut log_w = self.log.write(); let (cc_entries, fallback_indexes) = log_w .try_append_entries(entries, prev_log_index, prev_log_term) .map_err(|_ig| (term, log_w.commit_index + 1))?; // fallback overwritten conf change entries for idx in fallback_indexes.iter().sorted().rev() { let info = log_w.fallback_contexts.remove(idx).unwrap_or_else(|| { unreachable!(&amp;quot;fall_back_infos should contain the entry need to fallback&amp;quot;) }); let EntryData::ConfChange(ref conf_change) = info.origin_entry.entry_data else { unreachable!(&amp;quot;the entry in the fallback_info should be conf change entry&amp;quot;); }; let changes = conf_change.clone(); self.fallback_conf_change(changes, info.addrs, info.name, info.is_learner); } // apply conf change entries for e in cc_entries { let EntryData::ConfChange(ref cc) = e.entry_data else { unreachable!(&amp;quot;cc_entry should be conf change entry&amp;quot;); }; let (addrs, name, is_learner) = self.apply_conf_change(cc.clone()); let _ig = log_w.fallback_contexts.insert( e.index, FallbackContext::new(Arc::clone(&amp;amp;e), addrs, name, is_learner), ); } // ... }&lt;/code&gt;&lt;/pre&gt;&lt;p id="b946"&gt;常规日志的处理这里不再赘述。当Follower尝试追加来自Leader的日志时，它会确定当前节点上有哪些新的conf更改日志可用，以及哪些尚未提交的conf更改将被覆盖。然后，使用预先记录的上下文，以相反的顺序回滚被覆盖的更改并应用新的更改。应用新更改时，还应在此处记录新更改的上下文。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="2b2e"&gt;成员变更日志的提交&lt;/h2&gt;&lt;pre class="wp-block-code"&gt;&lt;code class="language-cpp" lang="cpp"&gt;async fn worker_as&amp;lt;C: Command, CE: CommandExecutor&amp;lt;C&amp;gt;, RC: RoleChange&amp;gt;( entry: Arc&amp;lt;LogEntry&amp;lt;C&amp;gt;&amp;gt;, prepare: Option&amp;lt;C::PR&amp;gt;, ce: &amp;amp;CE, curp: &amp;amp;RawCurp&amp;lt;C, RC&amp;gt;, ) -&amp;gt; bool { // ... let success = match entry.entry_data { EntryData::ConfChange(ref conf_change) =&amp;gt; { // ... let shutdown_self = change.change_type() == ConfChangeType::Remove &amp;amp;&amp;amp; change.node_id == id; // ... if shutdown_self { curp.shutdown_trigger().self_shutdown(); } true } _ =&amp;gt; // ... }; ce.trigger(entry.inflight_id(), entry.index); success }&lt;/code&gt;&lt;/pre&gt;&lt;p id="44ff"&gt;在提交conf更改后的aftersync阶段，除了一些常规操作外，我们还需要确定提交的conf更改是否删除了当前节点，如果是，我们需要在这里关闭当前节点。一般情况下，只有Leader节点会在这里执行并提交被移除节点的日志，并且在其自行关闭后，其余节点将选举出具有最新日志的Leader。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="5b6a"&gt;新节点加入集群&lt;/h2&gt;&lt;p id="886a"&gt;为了区分创建新集群运行的节点和需要加入现有集群的新启动节点，启动时需要传入一个新参数&lt;code&gt;InitialClusterState&lt;/code&gt; 。这是一个只有两个成员的枚举类型。 &lt;code&gt;InitialClusterState::New&lt;/code&gt;表示本次启动的节点是新启动的集群的成员之一； &lt;code&gt;InitialClusterState::Existing&lt;/code&gt;表示本次启动的节点是一个要添加到现有集群中的新节点。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class="language-cpp" lang="cpp"&gt;let cluster_info = match *cluster_config.initial_cluster_state() { InitialClusterState::New =&amp;gt; init_cluster_info, InitialClusterState::Existing =&amp;gt; get_cluster_info_from_remote( &amp;amp;init_cluster_info, server_addr_str, &amp;amp;name, Duration::from_secs(3), ) .await .ok_or_else(|| anyhow!(&amp;quot;Failed to get cluster info from remote&amp;quot;))?, _ =&amp;gt; unreachable!(&amp;quot;xline only supports two initial cluster states: new, existing&amp;quot;), };&lt;/code&gt;&lt;/pre&gt;&lt;p id="574e"&gt;这两种方式的本质区别在于，当创建一个新的集群时，每个节点的初始集群成员都是相同的，并且可以直接根据这个初始信息计算出全局统一的节点ID，以保证每个节点都有唯一的ID ，而在加入已有集群时，新节点无法自行计算节点ID，需要通过get_cluster_info_from_remote方法获取已有集群的信息，直接继承已有集群正在使用的ID等信息，以保证ID与集群内节点的对应关系。这样可以保证集群中ID与节点的对应关系，避免ID重复或者一个节点有多个ID。&lt;/p&gt;&lt;p id="cd9e"&gt;为了确保与etcd接口的兼容性，新节点在开始运行之前没有名称。 etcdctl根据name是否为空来判断对应节点是否已经启动。当新节点启动并运行并加入集群后，它会向 Leader 发送 Publish Rpc，以在集群中发布其名称。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="f198"&gt;节点删除&lt;/h2&gt;&lt;p id="4747"&gt;假设我们删除一个节点后没有关闭它，那么它会选择一个超时并向其余节点发送投票请求，浪费其他节点的网络和CPU资源。为了解决这个问题，我们可以想到两个办法。&lt;/p&gt;&lt;p id="6803"&gt; 1. 在应用将自行删除的新配置后，立即关闭节点。显然，这个方案一定是不可行的。因为在应用新的配置时，这条日志还没有提交，仍然有被备份的可能，如果你在这里关闭了自己，​​那么如果后面发生了配置变更，那么被移除的节点就会已经被关闭了，不能直接回复，这不是我们希望看到的结果。&lt;/p&gt;&lt;p id="32e7"&gt; 2. 节点提交删除自身日志后立即关闭节点。因为已经提交了，所以这个方法不存在上面的问题，但是如果你相应的实现的话，你会发现被移除的节点有时还是无法自动关闭。因为被删除的节点可能根本不会提交新的配置。假设我们要删除一个Follower节点，而Leader将这条删除记录添加到自己的日志中，然后立即开始使用新的日志，此时Leader不会向Follower发送任何请求，Follower也会自然无法commit记录。当然，follower 无法提交此日志并自行关闭。对于Leader来说不存在这个问题，Leader会暂时管理集群，没有自己，直到日志提交为止。&lt;/p&gt;&lt;p id="51b3"&gt;如果最直接的方法不起作用，被删除的节点应该如何自行关闭？假设我们这里不添加关闭逻辑，发生的情况是Leader将conf变更日志同步到集群，新集群的所有成员都会正常处理并提交这个日志。被删除的节点将在不知情的情况下离开集群，并且不会收到来自 Leader 的心跳。然后该节点超时并开始选举，这就是我们最终决定进行更改的地方。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class="language-cpp" lang="cpp"&gt;pub(super) fn handle_pre_vote( &amp;amp;self, term: u64, candidate_id: ServerId, last_log_index: LogIndex, last_log_term: u64, ) -&amp;gt; Result&amp;lt;(u64, Vec&amp;lt;PoolEntry&amp;lt;C&amp;gt;&amp;gt;), Option&amp;lt;u64&amp;gt;&amp;gt; { // ... let contains_candidate = self.cluster().contains(candidate_id); let remove_candidate_is_not_committed = log_r .fallback_contexts .iter() .any(|(_, ctx)| match ctx.origin_entry.entry_data { EntryData::ConfChange(ref cc) =&amp;gt; cc.iter().any(|c| { matches!(c.change_type(), ConfChangeType::Remove) &amp;amp;&amp;amp; c.node_id == candidate_id }), _ =&amp;gt; false, }); // extra check to shutdown removed node if !contains_candidate &amp;amp;&amp;amp; !remove_candidate_is_not_committed { return Err(None); } // ... }&lt;/code&gt;&lt;/pre&gt;&lt;p id="9fcb"&gt;我们在 ProVote 阶段添加了额外的检查逻辑，收到预投票的节点将检查候选人是否已被删除。假设候选者不在当前节点的配置中，并且可能的回退操作将不允许该节点重新加入集群，则意味着这是已被删除的候选者。处理请求的节点将向 Follower 发送一个带有&lt;code&gt;shutdown_candidate&lt;/code&gt;字段的特殊&lt;code&gt;VoteResponse&lt;/code&gt; 。 Candidate 收到响应并确定&lt;code&gt;shutdown_candidate&lt;/code&gt;是否为&lt;code&gt;true&lt;/code&gt; ，如果是，则开始自我关闭，如果不是，则继续选举过程。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="4d61"&gt;概括&lt;/h2&gt;&lt;p id="c8ea"&gt;在这篇文章中，我们深入探讨了分布式系统中集群成员资格变更是如何执行的，简要介绍了两种主要解决方案：联合共识和单步成员资格变更。联合共识引入了中间状态，以确保变革期间不会有两个领导者。单步集群变更牺牲了部分功能，通过逐一变更节点来简化实现逻辑。另外，我们还分析了Xline目前单步成员变更方案的源码，展示了Leader和Follower都是如何处理变更的，以及引入集群变更后需要处理哪些新的逻辑。&lt;/p&gt;&lt;p id="67ff"&gt;目前，Xline仅使用单步集群变更来处理集群成员变更，提供了基本的变更能力。未来我们将尝试支持联合共识来增强Xline的功能。&lt;/p&gt;&lt;p id="f253"&gt; Xline 的会员变更就到此为止。如果您对更多实现细节感兴趣，请参阅我们的开源存储库&lt;a href="https://github.com/xline-kv/Xline"&gt;https://github.com/xline-kv/Xline&lt;/a&gt;或在 Xline 网站上了解更多信息： &lt;a href="https://xline./"&gt;https://xline。&lt;/a&gt;云。 &lt;/p&gt;&lt;p&gt;&lt;a href="https://medium.com/@datenlord?source=post_page-----5a5e405b120a--------------------------------"&gt;&lt;/a&gt;&lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Wed, 03 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/04/membership-change-source-code-interpretation/</guid></item><item><title>2024 年 K8s 基准报告：工作负载可靠性的最新趋势</title><link>https://www.cncf.io/blog/2024/04/03/a-2024-k8s-benchmark-report-the-latest-trends-in-workload-reliability/</link><description>&lt;p&gt;&lt;em&gt;会员帖子最初由 Joe Pelletier 在&lt;a href="https://www.fairwinds.com/blog/2024-k8s-benchmark-report-workload-reliability"&gt;Fairwinds 博客&lt;/a&gt;上发布&lt;/em&gt;&lt;/p&gt;&lt;p&gt;据Gartner预测， &lt;a href="https://www.gartner.com/en/newsroom/press-releases/2023-11-29-gartner-says-cloud-will-become-a-business-necessity-by-2028"&gt;到2028年，云计算将成为保持企业竞争力&lt;/a&gt;的重要组成部分。事实上，到 2024 年，公共云服务支出预计将达到 6790 亿美元。虽然云支出很复杂，成本来自多个来源，但不可否认的是，许多组织正在将应用程序和服务转移到云中，并使用 Kubernetes 来有效管理容器并确保工作负载可靠性。&lt;/p&gt;&lt;p&gt; Fairwinds 使用来自超过 330,000 个工作负载和数百个组织的数据，创建了&lt;a href="https://www.fairwinds.com/kubernetes-config-benchmark-report"&gt;2024 年 Kubernetes 基准报告&lt;/a&gt;，该报告分析了 2024 年的趋势，并将结果与​​ 2022 年和 2023 年的基准进行比较。尽管组织已经在生产中部署 Kubernetes 工作负载，但许多组织仍然面临着与 Kubernetes 最佳实践保持一致的挑战。不幸的是，缺乏一致性可能会导致严重后果：安全风险增加、云成本失控以及应用程序和服务的&lt;a href="https://www.fairwinds.com/blog/kubernetes-best-practices-reliability"&gt;可靠性&lt;/a&gt;降低。基准分析回顾了所有这些主题，而本文重点关注与工作负载可靠性相关的六个领域，以帮助您确定做得好的领域或需要进行一些改进的领域。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;缺少活性和就绪探针&lt;/h2&gt;&lt;p&gt;&lt;a href="https://www.fairwinds.com/blog/a-guide-to-understanding-kubernetes-liveness-probes-best-practices"&gt;活性探针&lt;/a&gt;指示容器是否正在运行，这是 Kubernetes 工作负载是否按设计运行的基本指标。如果活性探测器进入失败状态，Kubernetes 会发送一个信号以自动重新启动容器。重启容器的目的是将服务恢复到可运行状态。但是，如果您无法确保 Pod 中的每个容器都有活性探测器，则无法正常运行的容器可能会无限期地运行，占用资源，并且在某些情况下会导致应用程序错误。&lt;/p&gt;&lt;p&gt;同样， &lt;a href="https://www.fairwinds.com/blog/increase-kubernetes-reliability-a-best-practices-guide-for-readiness-probes"&gt;就绪探测&lt;/a&gt;指示容器是否准备好接收流量，这也会影响应用程序的整体可靠性。容器不可避免地会发生故障并需要重新启动，而 Kubernetes 活跃度和就绪性探测在确保发生这种情况时容器可用并准备好为流量提供服务方面发挥着重要作用。根据基准，最新数据显示，69% 的组织有 11-50% 的工作负载缺少活跃度探测器。同样，我们发现 66% 的组织（其工作负载为 11-50%）缺少就绪性探测。您是否确保您的工作负载具有适当的活动性和就绪性探测器？ &lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="显示缺失活性探针图表的图表" class="wp-image-105152" height="277" src="https://www.cncf.io/wp-content/uploads/2024/04/image-4.png" style="width: 900px; height: auto;" width="718" /&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading"&gt;拉动政策并不总是&lt;/h2&gt;&lt;p&gt;在 Kubernetes 中，拉取策略是一种设置，用于确定 Kubernetes 如何以及何时为 Pod 拉取容器映像。它告诉 Kubernetes 工作节点 (kubelet) 在运行 pod 时如何处理图像下载。不幸的是，依赖缓存的 Docker 镜像可能会导致可靠性和安全性问题。默认情况下，如果镜像尚未缓存在尝试运行该镜像的节点上，Kubernetes &lt;a href="https://www.fairwinds.com/blog/kubernetes-basics-tutorial-how-to-set-image-pull-policy-to-always"&gt;会拉取该镜像&lt;/a&gt;。但是，如果您使用缓存版本，则可能会导致每个节点运行图像的多个版本。它还可能引入潜在的安全漏洞，主要是因为 Kubernetes 将使用图像的缓存版本而不验证其来源。 2024 年基准显示受影响的工作负载数量有所增加：24% 的组织超过 90% 的工作负载依赖缓存图像，这可能会严重影响应用程序的可靠性。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;部署缺少副本&lt;/h2&gt;&lt;p&gt;基准报告从 2023 年开始在分析中包含缺失的副本，因为我们发现许多工作负载未配置副本。到 2024 年，55% 的组织有超过 21% 的工作负载缺少副本。副本有助于维护容器的稳定性和可用性，因为 ReplicaSet 将替换失败的 Pod。您的工作负载中有多少百分比缺少副本？&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;缺少 CPU 限制&lt;/h2&gt;&lt;p&gt;最新的基准数据显示，越来越多的组织正在设置&lt;a href="https://training.fairwinds.com/action-item-setting-kubernetes-cpu-limits"&gt;CPU 限制&lt;/a&gt;。分析显示，22% 的组织有不到 10% 的工作负载未达到 CPU 限制。当您不指定 CPU 限制时，容器没有任何上限，这是一个问题，因为 CPU 密集型容器可能会使用节点上的所有可用 CPU，从而导致其他容器缺乏所需的资源。设置 CPU 限制有助于提高应用程序的&lt;a href="https://www.fairwinds.com/blog/kubernetes-benchmark-report-managing-k8s-workload-costs-2024"&gt;成本效率&lt;/a&gt;和可靠性，因此值得检查它们是否到位并正确设置。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt; CPU 请求丢失&lt;/h2&gt;&lt;p&gt;从新数据来看，组织似乎正在意识到确保设置&lt;a href="https://training.fairwinds.com/action-items-setting-kubernetes-cpu-requests"&gt;CPU 请求&lt;/a&gt;的价值。 2022 年，只有 50% 的组织缺少至少 10% 工作负载的请求，而到 2023 年，78% 的组织缺少至少 10% 工作负载的请求。今年，拥有 10% 工作负载的组织中，这一比例下降至 67%。 % 或更多工作负载受到缺少 CPU 请求的影响。&lt;/p&gt;&lt;p&gt;与 CPU 限制类似，如果您没有设置 CPU 请求，则单个 Pod 可能会消耗所有节点 CPU 和内存，从而导致其他 Pod 资源匮乏。当您设置资源请求时，它可以保证 pod 能够访问所需的资源。这有助于确保您的应用程序和服务具有更高的可靠性。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;工作负载可靠性仍然具有挑战性&lt;/h2&gt;&lt;p&gt;Kubernetes 在 2024 年及以后为组织带来非凡的价值，这意味着如果您想满足您的环境和业务需求，了解 Kubernetes 中可用的许多配置以及如何适当调整它们至关重要。 Kubernetes 基准报告可以帮助您了解同行在配置工作负载方面的成功和失败之处，以及他们是否始终遵循最佳实践。使用此信息可帮助您配置部署，使其尽可能安全、可靠且经济高效。&lt;/p&gt;&lt;p&gt;立即阅读&lt;a href="https://www.fairwinds.com/kubernetes-config-benchmark-report"&gt;Kubernetes 基准报告&lt;/a&gt;。 &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Tue, 02 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/03/a-2024-k8s-benchmark-report-the-latest-trends-in-workload-reliability/</guid></item><item><title>Gödel Scheduler 开源：在线和离线工作负载的统一调度程序</title><link>https://www.cncf.io/blog/2024/04/02/godel-scheduler-open-sourced-a-unified-scheduler-for-online-and-offline-workloads/</link><description>&lt;p&gt;&lt;em&gt;字节跳动的会员帖子&lt;/em&gt;&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;自 2014 年开源以来，Kubernetes 已迅速成为容器编排事实上的标准。字节跳动的基础设施团队很早就采用了 Kubernetes 来构建我们的私有云平台。多年来，字节跳动在微服务、推荐/广告/搜索服务、机器学习与大数据、存储等各业务线的快速增长，导致对计算资源的需求大幅增长。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示微服务、搜索、广告、推荐、人工智能、大数据和存储概要的表格" class="wp-image-105147" height="575" src="https://www.cncf.io/wp-content/uploads/2024/04/image.jpeg" width="1600" /&gt;&lt;/figure&gt;&lt;p&gt;最初，字节跳动使用单独的资源池来管理其在线和离线工作负载，每个资源池专用于不同的业务部门。为了适应重大节假日和重大活动期间在线业务需求的激增，基础设施团队通常需要提前规划，将线下资源重新分配到线上池，以增强处理在线活动增加的能力。虽然这一临时解决方案满足了即时需求，但池间资源借用过程被证明非常耗时、操作繁重且效率低下。此外，为在线和离线工作负载维护单独的资源池会导致大量的主机托管成本，几乎没有提高资源利用率的空间。因此，基础设施团队寻求实现一个统一的系统来调度和管理在线和离线工作负载。该举措旨在促进资源池化，提高资源利用率和弹性，优化成本和用户体验，减轻运营负担。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;统一调度实践&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Kubernetes 默认调度程序之外的增强功能：&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;自2018年广泛使用Kubernetes以来，字节跳动不断优化Kubernetes的各个组件的功能和性能。但随着2019年推荐/广告/搜索服务的容器化，原生的Kubernetes调度器无论是功能还是性能都距离满足字节跳动的业务需求越来越远。在功能上，需要更细粒度的资源调度能力和灵活的抢占策略。在性能方面，原生 Kubernetes 默认调度器在 5000 个节点的集群中只能实现每秒 10 个 Pod 左右的调度吞吐量，往往会导致业务升级遇到瓶颈，远远不能满足要求。因此，团队对 Kubernetes 默认调度器引入了多项关键优化，包括：&lt;/p&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;功能&lt;/strong&gt;：&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;扩展了调度功能以支持非本地资源，例如内存带宽和网络带宽。&lt;/li&gt;&lt;li&gt;支持微拓扑调度。&lt;/li&gt;&lt;li&gt;通过提供可插拔的抢占框架来支持扩展抢占功能，重构了抢占实现。&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;表现&lt;/strong&gt;：&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;通过重构数据结构，进一步强化快照间增量更新的理念，优化Scheduler缓存与Snapshot之间的数据同步机制。&lt;/li&gt;&lt;li&gt;对同构调度单元的调度结果进行缓存，减少冗余计算，提高效率。&lt;/li&gt;&lt;li&gt;通过重新组织抢占相关的数据结构，及时进行剪枝，减少不必要的计算，优化抢占实现。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过上述优化，我们成功增强了容器化能力，满足了字节跳动快速扩张的需求。这使得调度吞吐量显着增加了 30 倍。也就是说，在包含 10,000 个节点的集群中，我们始终实现每秒 300 个 Pod 的调度速率。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;哥德尔调度器&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;2020年，字节跳动启动了线上线下业务运营的统一调度和资源管理项目。目标是提高整体资源利用率、提高运营效率并减少维护费用。最初，该计划涉及通过单一调度系统管理在线和离线任务。然而，这种方法提出了挑战，主要是由于离线调度的复杂性，它与在线流程明显不同，尤其是对高吞吐量的需求。&lt;/p&gt;&lt;p&gt;原生的 Kubernetes 调度器主要是为 Pod 级别的调度而设计的，它对更复杂的“Job”调度语义的支持有些有限，并且在处理这些更高级别的需求时遇到了性能限制。为了有效满足这些独特的需求并更好地满足字节跳动多样化的运营需求，决定开发一个定制的内部分布式调度器。这导致了 Gödel Scheduler 的创建，专门用于与 Kubernetes 系统集成，并处理字节跳动广阔且不断发展的业务环境中苛刻且多样化的调度需求。&lt;/p&gt;&lt;p&gt; Gödel Scheduler 是一个分布式系统，旨在整合在线和离线工作负载的调度。该调度程序是 Kubernetes (K8s) 调度程序的增强版，旨在增强可扩展性并提高调度质量。善于满足字节跳动线上线下运营多样化的功能和性能需求。哥德尔调度程序的主要功能包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;乐观并发&lt;/strong&gt;：它结合了乐观并发概念，将最耗时的单元到节点匹配（过滤和评分）移至调度程序组件。这允许并发执行并提高大规模集群中的调度吞吐量。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;两层调度抽象&lt;/strong&gt;（Unit和Pod）&lt;strong&gt;和框架&lt;/strong&gt;：提供更灵活的批量调度能力，更好地支持离线操作，同时提高调度吞吐量和系统可扩展性。扩展框架更有效地处理特殊场景。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;功能丰富、性能卓越&lt;/strong&gt;：满足线上、线下（批量、流式）、训练任务等多种作业需求，实现真正的统一调度。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;与 Kubernetes 生态系统的兼容性&lt;/strong&gt;：它可以作为 K8s Scheduler 的替代方案，但由于性能和架构优化，其框架接口与 K8s Scheduler 并不完全相同。但它的扩展性不受影响，可以实现类似 Kubernetes 的调度插件。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下图是Gödel Scheduler的架构图。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="哥德尔调度器架构" class="wp-image-105148" height="566" src="https://www.cncf.io/wp-content/uploads/2024/04/image-3.png" width="1280" /&gt;&lt;/figure&gt;&lt;p&gt;如上所述，Gödel Scheduler 由三个主要组件组成：Dispatcher、Scheduler 和 Binder。其架构的关键是 Scheduler 组件，该组件通常部署在多个分片中以促进乐观并发调度。这种多分片部署提高了其效率和可扩展性。另一方面，Dispatcher 和 Binder 均部署为单个实例，这种配置适合它们在 Gödel Scheduler 系统中的特定角色和职责。&lt;/p&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;调度员&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;调度程序在管理应用程序排队、分发和节点分区方面发挥着关键作用。它由几个关键组件组成：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;排序策略管理器&lt;/strong&gt;：该模块处理应用程序的排队。目前，它实现了 FIFO 和 DRF/FairShare 排队策略，后者仍有待生产使用。未来的增强功能将引入更复杂的排队策略，包括基于优先级值的策略。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;调度策略管理器&lt;/strong&gt;：其主要功能是跨各种调度程序实例分配应用程序。目前默认采用LoadBalance策略。未来的更新旨在使此功能更加通用且基于插件。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Node Shuffler&lt;/strong&gt; ：该组件的任务是根据 Scheduler 实例的数量组织集群节点。它将每个节点分配给特定的节点分区，每个调度程序实例监督一个分区。在调度过程中，调度程序首先考虑其分区内的节点，然后再探索其他分区中的节点。这种安排是动态调整的，以响应节点可用性或调度程序计数的变化。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;分区规则&lt;/strong&gt;：目前，系统力求节点在 Scheduler 实例之间均匀分布。目前正在计划扩展这些分区策略，增强其可配置性。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Scheduler Maintenanceer&lt;/strong&gt; ：该元素负责监控 Scheduler 实例的状态。它跟踪健康状态、工作负载和每个分区内的节点计数等方面。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Reconciler&lt;/strong&gt; ：定期运行，Reconciler 监督 Pod、节点、调度程序和 SchedulingUnit 等各种元素的状态。它可以解决任何错误、差异或缺陷，确保系统完整性和性能。&lt;/li&gt;&lt;/ol&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;调度程序&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;Scheduler 在调度和抢占应用程序的决策过程中起着关键作用，尽管它本身并不执行这些决策（该任务由 Binder 处理）。它在两层框架上运行：Unit Scheduling Framework 和 Pod Scheduling Framework。整个调度过程分为三个主要阶段：节点组织、单元调度和单元抢占。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;节点组织&lt;/strong&gt;：此阶段涉及对节点进行过滤和排序，以简化调度过程并提高其质量。它由两种类型的插件组成：&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;定位插件：这些过滤器节点基于特定的应用程序信息。&lt;/li&gt;&lt;li&gt;分组插件：这些插件根据可用资源或作业级别关联性对节点进行分组。&lt;/li&gt;&lt;/ul&gt;&lt;ol start="2"&gt;&lt;li&gt;&lt;strong&gt;单元调度&lt;/strong&gt;：在此阶段，节点将根据已通过节点组织插件过滤的应用程序请求进行匹配和评分。此过程类似于 Kubernetes (K8s) 调度程序框架，包括：&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;过滤插件：这些过滤器节点基于应用程序请求的要求。&lt;/li&gt;&lt;li&gt;评分插件：这些插件将分数分配给上一步中已过滤的节点。&lt;/li&gt;&lt;/ul&gt;&lt;ol start="3"&gt;&lt;li&gt; &lt;strong&gt;Unit Preempting&lt;/strong&gt; ：如果在Unit Scheduling阶段没有找到合适的节点，Scheduler就会进入抢占阶段。在这里，它尝试通过抢占正在运行的应用程序实例来释放资源，为新的应用程序实例腾出空间。这一阶段包括：&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;受害者搜索：识别可被抢占的潜在受害者应用程序。&lt;/li&gt;&lt;li&gt;候选者排序：对节点和潜在受害者进行排序，以确定最合适的抢占选择。&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;活页夹&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;Binder 在调度过程的最后阶段起着至关重要的作用，重点是冲突检测、抢占操作以及执行应用程序与资源的绑定。它由三个主要组件组成：ConflictResolver、PreemptionOperator 和 UnitBinder。&lt;/p&gt;&lt;ol&gt;&lt;li&gt; &lt;strong&gt;ConflictResolver&lt;/strong&gt; ：该组件的任务是检测调度过程中的并发冲突。它以两种模式运行：&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;跨节点冲突解决程序：检查不同节点之间可能发生的冲突。&lt;/li&gt;&lt;li&gt;单节点冲突解决程序：识别单个节点内的冲突。&lt;br /&gt;如果检测到任何冲突，申请将立即被拒绝并重新安排。&lt;/li&gt;&lt;/ul&gt;&lt;ol start="2"&gt;&lt;li&gt; &lt;strong&gt;PreemptionOperator&lt;/strong&gt; ：在不存在冲突但需要抢占的场景下，由该算子负责。它通过删除受害者（需要终止以释放资源的应用程序或进程）来执行抢占，然后等待最终的调度。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;UnitBinder&lt;/strong&gt; ：这部分Binder负责绑定之前所需的准备工作，比如动态创建存储卷，然后进行实际的绑定操作，将应用程序链接到指定的资源。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;值得注意的是，当前版本的 Binder 集成了 PodGroup 控制器。该控制器负责管理 PodGroup 的状态和生命周期。然而，值得注意的是，在未来的版本中，我们计划从 Binder 中删除此功能，将其转换为独立的控制器。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;经验&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;在过去的两年里，Gödel Scheduler 一直是字节跳动的基石，提供了丰富的调度功能和语义。高效可靠地支撑了字节跳动多样化、复杂业务负载的运行。&lt;/p&gt;&lt;p&gt;在架构增强的基础上，字节跳动借鉴 Kubernetes 原生调度器的经验，实现了深刻的性能优化。与字节跳动内部完善的 Kubernetes 系统集成后，Gödel Scheduler 现在拥有令人印象深刻的吞吐量：单个分片中 2000+ pod/s，跨多个分片 5000+ pod/s。字节跳动不断努力扩大单集群容量，其最大的产品集群已达到超过 20,000 个节点和超过 1,000,000 个 Pod。&lt;/p&gt;&lt;p&gt;经过字节跳动内部多年的深入实践和增强，Gödel Scheduler已经达到了相对稳定的状态。 2023年，顶级云计算会议SoCC接受了我们关于Gödel Scheduler的论文，凸显了字节跳动大规模资源管理和调度的统一方法。研发团队还受邀在会议上展示了他们的工作。对于感兴趣的人，可以在 https://dl.acm.org/doi/10.1145/3620678.3624663 上获取 Gödel Scheduler 论文。&lt;/p&gt;&lt;p&gt;出于对开源社区的贡献，字节跳动团队决定开源Gödel Scheduler，提供全新的调度解决方案，通过卓越的性能和全面的调度能力，增强线上线下服务的云原生体验。&lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;未来的工作&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;展望未来，字节跳动致力于Gödel Scheduler的持续开发，重点丰富其功能并增强其可扩展性。一个重要的关注领域是优化特定挑战性场景中的调度吞吐量，例如涉及高部署率和频繁抢占的场景。通过创新的重新调度策略，字节跳动旨在解决维持调度性能和提高调度质量之间的复杂平衡。首要目标不仅是保持当前的调度吞吐量，而且还大幅提高调度质量。&lt;/p&gt;&lt;p&gt;此外，字节跳动高度重视生态系统的发展。我们将努力确保 Gödel Scheduler 与各种业务应用程序中使用的领先系统和框架的兼容性。该计划将包括与著名的大数据和机器学习框架的集成，并附有实际使用示例和全面的文档。&lt;/p&gt;&lt;p&gt;为了保持社区的参与和知情，将有条不紊地制定 Gödel Scheduler 的详细路线图，并在 Gödel Scheduler Repository 上提供。这将为感兴趣的各方提供跟踪进度、做出贡献并成为项目积极参与者的机会。&lt;/p&gt;&lt;p&gt;虽然哥德尔调度器在字节跳动内部经历了多次迭代，在各种场景下经过了严格的测试，并证明了其有效性，但字节跳动承认，在通用性和标准化方面仍然有很大的进步潜力。字节跳动热忱邀请并鼓励社区成员参与哥德尔调度器的开发，相信共同努力将带来更大的改进和创新。&lt;/p&gt;&lt;p&gt;哥德尔调度程序项目存储库： &lt;a href="https://github.com/kubewharf/godel-scheduler"&gt;https://github.com/kubewharf/godel-scheduler&lt;/a&gt; &lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Mon, 01 Apr 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/02/godel-scheduler-open-sourced-a-unified-scheduler-for-online-and-offline-workloads/</guid></item><item><title>提升系统弹性：利用 LitmusChaos 和 Backstage 集成</title><link>https://www.cncf.io/blog/2024/04/01/elevating-system-resilience-leveraging-litmuschaos-and-backstage-integration/</link><description>&lt;p&gt;&lt;em&gt;项目发布者：Namkyu Park&lt;/em&gt; ， &lt;em&gt;LitmusChaos 维护者 ( &lt;a href="https://www.linkedin.com/in/namkyupark1999/?locale=en_US"&gt;LinkedIn&lt;/a&gt; | &lt;a href="https://github.com/namkyu1999"&gt;GitHub&lt;/a&gt; )&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;这篇博文提供了使用 LitmusChaos 注入混沌并使用 Backstage 进行管理的分步说明。&lt;/em&gt; &lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;a href="https://dev.to/namkyu1999/a-beginners-guide-to-litmus-and-backstage-4p18-temp-slug-9264283?preview=1ab316fd623b5144a4102e4057db0744e32cd289a39a2ffc04e5bdaca4caf5f173faa3b2c345da6204b570a6cf4896c8000346f60706789e13f405d5#table-of-contents"&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;混沌工程、LitmusChaos 和 Backstage&lt;/li&gt;&lt;li&gt;先决条件&lt;/li&gt;&lt;li&gt;我们的演示由什么组成？&lt;/li&gt;&lt;li&gt;演示环境&lt;/li&gt;&lt;li&gt;使用 LitmusChaos 注入混沌&lt;/li&gt;&lt;li&gt;在后台管理 LitmusChaos 内容&lt;/li&gt;&lt;li&gt;概括&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading"&gt;&lt;a href="https://dev.to/namkyu1999/a-beginners-guide-to-litmus-and-backstage-4p18-temp-slug-9264283?preview=1ab316fd623b5144a4102e4057db0744e32cd289a39a2ffc04e5bdaca4caf5f173faa3b2c345da6204b570a6cf4896c8000346f60706789e13f405d5#chaos-engineering-litmuschaos-and-backstage"&gt;&lt;/a&gt;混沌工程、LitmusChaos 和 Backstage&lt;/h2&gt;&lt;p&gt;随着包括 Kubernetes 在内的云原生技术变得越来越复杂，应用程序由更多组件组成。您的系统有弹性吗？例如，如果您的一个容器由于 OOM 而宕机，它是否会自动重新创建并做好准备？&lt;a href="https://principlesofchaos.org/"&gt;混沌工程&lt;/a&gt;是一门对系统进行实验的学科，目的是建立对系统承受生产中湍流条件的能力的信心。 &lt;a href="https://docs.litmuschaos.io/docs/introduction/what-is-litmus"&gt;LitmusChaos&lt;/a&gt; （CNCF孵化项目）是一个具有跨云支持的云原生混沌工程框架。您可以使用 LitmusChaos 将混乱注入不同的基础设施层。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="金字塔图详细说明： 1．您的申请2。应用程序依赖关系3.云原生服务4。 Kubernetes 服务5。平台服务" class="wp-image-105128" height="364" src="https://www.cncf.io/wp-content/uploads/2024/04/https___dev-to-uploads.s3.amazonaws.com_uploads_articles_52ajvswmhak5nuu0oced.jpg" width="800" /&gt;&lt;/figure&gt;&lt;p&gt; &lt;a href="https://backstage.io/"&gt;Backstage&lt;/a&gt;是一个用于构建开发者门户的开放平台，是最受欢迎的 CNCF 项目之一。它允许开发人员从一个点管理云原生应用程序的众多服务和代码。&lt;/p&gt;&lt;p&gt; LitmusChaos 可以通过&lt;a href="https://github.com/litmuschaos/backstage-plugin"&gt;backstage-plugin&lt;/a&gt;与 Backstage 集成。在本教程中，我们将通过 minikube 构建本地 Kubernetes 集群并安装演示应用程序和 LitmusChaos。之后，我们将使用 LitmusChaos 进行混沌实验，并使用 Backstage 轻松查看 LitmusChaos 中的内容。 &lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;a href="https://dev.to/namkyu1999/a-beginners-guide-to-litmus-and-backstage-4p18-temp-slug-9264283?preview=1ab316fd623b5144a4102e4057db0744e32cd289a39a2ffc04e5bdaca4caf5f173faa3b2c345da6204b570a6cf4896c8000346f60706789e13f405d5#prerequisites"&gt;&lt;/a&gt;先决条件&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://docs.docker.com/engine/install/"&gt;Docker&lt;/a&gt; 、 &lt;a href="https://minikube.sigs.k8s.io/docs/start/"&gt;minikube&lt;/a&gt; （如果你使用 k8s 集群，请跳过此）&lt;/li&gt;&lt;li&gt; &lt;a href="https://docs.litmuschaos.io/docs/getting-started/installation/#prerequisites"&gt;LitmusChaos 先决条件&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://backstage.io/docs/getting-started/#prerequisites"&gt;后台先决条件&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class="wp-block-heading"&gt;&lt;a href="https://dev.to/namkyu1999/a-beginners-guide-to-litmus-and-backstage-4p18-temp-slug-9264283?preview=1ab316fd623b5144a4102e4057db0744e32cd289a39a2ffc04e5bdaca4caf5f173faa3b2c345da6204b570a6cf4896c8000346f60706789e13f405d5#what-does-our-deployment-consist-of"&gt;&lt;/a&gt;我们的部署包括什么？&lt;/h2&gt;&lt;p&gt;幸运的是，我们不必制作基于 k8s 的服务。 &lt;a href="https://github.com/GoogleCloudPlatform/microservices-demo"&gt;microservice-demo&lt;/a&gt;是我们可以使用的一个很棒的微服务。下图显示了我们将要构建的演示的架构。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="微服务demo的流程图" class="wp-image-105129" height="373" src="https://www.cncf.io/wp-content/uploads/2024/04/https___dev-to-uploads.s3.amazonaws.com_uploads_articles_3bjyi3qw7btsfwrnf0wz.jpg" width="800" /&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading"&gt;&lt;a href="https://dev.to/namkyu1999/a-beginners-guide-to-litmus-and-backstage-4p18-temp-slug-9264283?preview=1ab316fd623b5144a4102e4057db0744e32cd289a39a2ffc04e5bdaca4caf5f173faa3b2c345da6204b570a6cf4896c8000346f60706789e13f405d5#demo-environment"&gt;&lt;/a&gt;演示环境&lt;/h2&gt;&lt;p&gt;让我们安装本地 k8s 集群和演示应用程序，然后安装 LitmusChaos。 &lt;/p&gt;&lt;h3 class="wp-block-heading"&gt;&lt;a href="https://dev.to/namkyu1999/a-beginners-guide-to-litmus-and-backstage-4p18-temp-slug-9264283?preview=1ab316fd623b5144a4102e4057db0744e32cd289a39a2ffc04e5bdaca4caf5f173faa3b2c345da6204b570a6cf4896c8000346f60706789e13f405d5#minikube-local-k8s-cluster"&gt;&lt;/a&gt; minikube（本地 k8s 集群）&lt;/h3&gt;&lt;p&gt;在本教程中，我们使用本地 k8s 集群 minikube。如果您尚未安装 minikube，请按照&lt;a href="https://minikube.sigs.k8s.io/docs/start/"&gt;本指南&lt;/a&gt;进行操作。一旦&lt;code&gt;minikube start&lt;/code&gt;执行，您就可以使用&lt;code&gt;kubectl&lt;/code&gt;命令访问本地 k8s 集群。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="代码示例" class="wp-image-105130" height="59" src="https://www.cncf.io/wp-content/uploads/2024/04/https___dev-to-uploads.s3.amazonaws.com_uploads_articles_xbfz9a2p9svsl0ggifjp.png" width="582" /&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading"&gt;&lt;a href="https://dev.to/namkyu1999/a-beginners-guide-to-litmus-and-backstage-4p18-temp-slug-9264283?preview=1ab316fd623b5144a4102e4057db0744e32cd289a39a2ffc04e5bdaca4caf5f173faa3b2c345da6204b570a6cf4896c8000346f60706789e13f405d5#online-boutique-microservicesdemo"&gt;&lt;/a&gt;在线精品店（微服务演示）&lt;/h3&gt;&lt;p&gt;安装 microservices-demo 更加简单。您所要做的就是执行以下代码。这是更&lt;a href="https://github.com/GoogleCloudPlatform/microservices-demo"&gt;详细的指南&lt;/a&gt;。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;// clone the repo git clone https://github.com/GoogleCloudPlatform/microservices-demo cd microservices-demo/ // move dir cd microservices-demo/ // install using a manifest file kubectl apply -f ./release/kubernetes-manifests.yaml&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我们需要使用&lt;a href="https://minikube.sigs.k8s.io/docs/commands/service/"&gt;以下命令&lt;/a&gt;生成的 URL 来访问演示。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;minikube service frontend-external --url&lt;/code&gt; &lt;/pre&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="代码示例" class="wp-image-105131" height="119" src="https://www.cncf.io/wp-content/uploads/2024/04/https___dev-to-uploads.s3.amazonaws.com_uploads_articles_79baavrjibu24mrevztq.png" width="800" /&gt;&lt;/figure&gt;&lt;p&gt;现在我们可以通过&lt;code&gt;http://&amp;lt;&amp;lt;generated_url&amp;gt;&amp;gt;&lt;/code&gt; .GIF 访问该服务&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="网上精品店网上订单屏幕记录" class="wp-image-105132" height="251" src="https://www.cncf.io/wp-content/uploads/2024/04/image.gif" width="480" /&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading"&gt;&lt;a href="https://dev.to/namkyu1999/a-beginners-guide-to-litmus-and-backstage-4p18-temp-slug-9264283?preview=1ab316fd623b5144a4102e4057db0744e32cd289a39a2ffc04e5bdaca4caf5f173faa3b2c345da6204b570a6cf4896c8000346f60706789e13f405d5#litmuschaos"&gt;&lt;/a&gt;石蕊混沌&lt;/h3&gt;&lt;p&gt;让我们打开一个新 shell 并安装 LitmusChaos。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;// Add LitmusChaos Helm repo helm repo add litmuschaos https://litmuschaos.github.io/litmus-helm/ // Create the namespace kubectl create ns litmus // Install the chart helm install chaos litmuschaos/litmus --namespace=litmus --set portal.frontend.service.type=NodePort&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;和以前一样，我们需要创建一个 URL 来访问 litmuschaos（混沌中心）的前端。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;minikube service chaos-litmus-frontend-service -n litmus --url&lt;/code&gt; &lt;/pre&gt;&lt;p&gt;&lt;a href="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fc34o9u39m7578cs25qmw.png"&gt;&lt;/a&gt;&lt;br /&gt;以&lt;code&gt;admin / litmus&lt;/code&gt;身份登录&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Litmus 登录页面的屏幕截图" class="wp-image-105133" height="435" src="https://www.cncf.io/wp-content/uploads/2024/04/https___dev-to-uploads.s3.amazonaws.com_uploads_articles_ghkkwhwz31qhqzxetpg1.png" width="800" /&gt;&lt;/figure&gt;&lt;p&gt;第一次登录 LitmusChaos 时，您会看到一个弹出窗口，要求您启用这样的混沌基础设施&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示 Litmus 上弹出窗口“启用混沌基础设施来运行您的第一个混沌实验”的屏幕截图" class="wp-image-105134" height="389" src="https://www.cncf.io/wp-content/uploads/2024/04/https___dev-to-uploads.s3.amazonaws.com_uploads_articles_apjyjjf9w24q4336izxy.png" width="800" /&gt;&lt;/figure&gt;&lt;p&gt;完成创建环境的所有步骤后，您将看到混沌基础设施已连接，如下所示。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示 Litmus 上的 [minikube] Chaos 基础设施的屏幕截图" class="wp-image-105135" height="287" src="https://www.cncf.io/wp-content/uploads/2024/04/https___dev-to-uploads.s3.amazonaws.com_uploads_articles_d2l0mup1w0h0sm48w3tu.png" width="800" /&gt;&lt;/figure&gt;&lt;p&gt;如果您对 LitmusChaos 的架构感到好奇，请查看&lt;a href="https://docs.litmuschaos.io/docs/architecture/architecture-summary"&gt;此文档&lt;/a&gt;。 &lt;/p&gt;&lt;h2 class="wp-block-heading"&gt;&lt;a href="https://dev.to/namkyu1999/a-beginners-guide-to-litmus-and-backstage-4p18-temp-slug-9264283?preview=1ab316fd623b5144a4102e4057db0744e32cd289a39a2ffc04e5bdaca4caf5f173faa3b2c345da6204b570a6cf4896c8000346f60706789e13f405d5#injecting-chaos-using-litmuschaos"&gt;&lt;/a&gt;使用 LitmusChaos 注入混沌&lt;/h2&gt;&lt;p&gt;我们已经完成了执行混沌工程的所有准备工作。我们来讨论一个场景。假设您是一家在线精品服务的经理，您想要运行一个实验，看看当您删除其 pod 时， &lt;code&gt;cartservice&lt;/code&gt;组件是否会恢复。要检查 pod 是否存在，请使用以下命令。 &lt;code&gt;kubectl get pods -n default | grep cartservice | grep Running | wc -l&lt;/code&gt; 。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="代码示例" class="wp-image-105136" height="51" src="https://www.cncf.io/wp-content/uploads/2024/04/https___dev-to-uploads.s3.amazonaws.com_uploads_articles_467s6egncebaudn78bf2.png" width="800" /&gt;&lt;/figure&gt;&lt;p&gt; LitmusChaos 支持各种类型的探针。&lt;a href="https://docs.litmuschaos.io/docs/concepts/probes"&gt;在这里&lt;/a&gt;了解有关探针的更多信息，这里有一个很棒的&lt;a href="https://youtu.be/_nvpNdvqfvk?feature=shared"&gt;教程视频&lt;/a&gt;。 &lt;/p&gt;&lt;h3 class="wp-block-heading"&gt;&lt;a href="https://dev.to/namkyu1999/a-beginners-guide-to-litmus-and-backstage-4p18-temp-slug-9264283?preview=1ab316fd623b5144a4102e4057db0744e32cd289a39a2ffc04e5bdaca4caf5f173faa3b2c345da6204b570a6cf4896c8000346f60706789e13f405d5#setup-probe"&gt;&lt;/a&gt;设置探针&lt;/h3&gt;&lt;p&gt;您可以在&lt;code&gt;Resilience Probes&lt;/code&gt;选项卡中创建新探针。在本教程中，我们将创建一个&lt;code&gt;Command Probe&lt;/code&gt; 。输入如下所示的值。&lt;/p&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;// Command kubectl get pods -n default | grep cartservice | grep Running | wc -l // Type Int // Comparison Criteria &amp;gt; // Value 0&lt;/code&gt; &lt;/pre&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示 Litmus 上的 Resilience Probe 的屏幕记录" class="wp-image-104897" height="250" src="https://www.cncf.io/wp-content/uploads/2024/04/giphy.gif" width="480" /&gt;&lt;/figure&gt;&lt;p&gt;另一件事，因为&lt;code&gt;cartservice&lt;/code&gt;部署没有标签，我们添加了如下标签&lt;/p&gt;&lt;pre class="wp-block-code"&gt;&lt;code class=""&gt;kubectl label deployment cartservice app=cartservice&lt;/code&gt; &lt;/pre&gt;&lt;h3 class="wp-block-heading"&gt;&lt;a href="https://dev.to/namkyu1999/a-beginners-guide-to-litmus-and-backstage-4p18-temp-slug-9264283?preview=1ab316fd623b5144a4102e4057db0744e32cd289a39a2ffc04e5bdaca4caf5f173faa3b2c345da6204b570a6cf4896c8000346f60706789e13f405d5#lets-inject-chaos"&gt;&lt;/a&gt;让我们注入混乱&lt;/h3&gt;&lt;p&gt;我们所要做的就是创建一个混沌实验。正如我们之前讨论的，我们删除&lt;code&gt;cartservice&lt;/code&gt; pod 并检查该 pod 是否重新生成。下面是&lt;a href="https://docs.litmuschaos.io/docs/user-guides/schedule-experiment"&gt;详细教程&lt;/a&gt;和 gif。我只想指出一些重要的特征。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示注入混沌教程的屏幕录制" class="wp-image-105145" height="251" src="https://www.cncf.io/wp-content/uploads/2024/04/image-1.gif" width="480" /&gt;&lt;/figure&gt;&lt;p&gt;首先，我们在本次实验中选择了&lt;code&gt;pod-delete&lt;/code&gt;混沌故障。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示 Litmus 上的混沌故障的屏幕截图" class="wp-image-105137" height="250" src="https://www.cncf.io/wp-content/uploads/2024/04/https___dev-to-uploads.s3.amazonaws.com_uploads_articles_29y2k3dvffis209pewul.png" width="800" /&gt;&lt;/figure&gt;&lt;p&gt;其次，我们提供有关目标应用程序的信息，如下所示。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示 Litmus 上目标应用程序的屏幕截图" class="wp-image-105138" height="364" src="https://www.cncf.io/wp-content/uploads/2024/04/image-1-1.png" width="1360" /&gt;&lt;/figure&gt;&lt;p&gt;最后，我们使用之前制作的探针。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示 Litmus 上的探针的屏幕截图" class="wp-image-105139" height="302" src="https://www.cncf.io/wp-content/uploads/2024/04/image-2-1.png" width="1364" /&gt;&lt;/figure&gt;&lt;p&gt;当您设置并运行混沌实验时，混沌会被注入到目标应用程序中，并且探测器会检查应用程序是否具有弹性。如果是，那么您现在已经掌握了混沌工程。恭喜你🎉 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示 Litmus 上的混沌实验的屏幕截图" class="wp-image-105140" height="281" src="https://www.cncf.io/wp-content/uploads/2024/04/https___dev-to-uploads.s3.amazonaws.com_uploads_articles_sk3ne4rdxjeejtt68mni.png" width="800" /&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading"&gt;&lt;a href="https://dev.to/namkyu1999/a-beginners-guide-to-litmus-and-backstage-4p18-temp-slug-9264283?preview=1ab316fd623b5144a4102e4057db0744e32cd289a39a2ffc04e5bdaca4caf5f173faa3b2c345da6204b570a6cf4896c8000346f60706789e13f405d5#manage-litmuschaos-stuff-in-backstage"&gt;&lt;/a&gt;在后台管理 LitmusChaos 内容&lt;/h2&gt;&lt;p&gt;您可以按照本&lt;a href="https://backstage.io/docs/getting-started/#create-your-backstage-app"&gt;入门指南&lt;/a&gt;开始构建 Backstage 应用程序并使用yarn dev 运行它。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示后台仪表板的屏幕截图" class="wp-image-105141" height="436" src="https://www.cncf.io/wp-content/uploads/2024/04/https___dev-to-uploads.s3.amazonaws.com_uploads_articles_o481g3qmrhlxjycy8pr5.png" width="800" /&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading"&gt;&lt;a href="https://dev.to/namkyu1999/a-beginners-guide-to-litmus-and-backstage-4p18-temp-slug-9264283?preview=1ab316fd623b5144a4102e4057db0744e32cd289a39a2ffc04e5bdaca4caf5f173faa3b2c345da6204b570a6cf4896c8000346f60706789e13f405d5#litmuschaos-plugin-for-backstage"&gt;&lt;/a&gt;用于 Backstage 的 LitmusChaos 插件&lt;/h3&gt;&lt;p&gt;让我们向 Backstage 添加一个 LitmusChaos 插件&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示为 Backstage 添加 LitmusChaos 插件的屏幕录制" class="wp-image-104901" height="229" src="https://www.cncf.io/wp-content/uploads/2024/04/giphy-2.gif" width="480" /&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;在&lt;code&gt;./packages/app&lt;/code&gt;项目中添加插件。&lt;/li&gt;&lt;/ul&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;yarn add backstage-plugin-litmus&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&lt;li&gt;通过 LitmusChaos UI 获取 LitmusChaos API 令牌&lt;ol&gt;&lt;li&gt;单击侧栏中的“设置”。&lt;/li&gt;&lt;li&gt;单击“API 令牌”部分中的“+ 新令牌”按钮。 &lt;img alt="创建令牌" height="408" src="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fl04ndjz91tjklz4lqieg.png" width="800" /&gt;&lt;/li&gt;&lt;li&gt;输入您的信息并点击“确认”。&lt;/li&gt;&lt;li&gt;获取“VALUE”列中的令牌。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;在&lt;code&gt;app-config.yaml&lt;/code&gt;文件根目录中，添加 litmus 代理和信息，如下所示&lt;/li&gt;&lt;/ul&gt;&lt;pre class="wp-block-code"&gt;&lt;code class=""&gt; proxy: &amp;#39;/litmus&amp;#39;: target: &amp;#39;your-own-litmus-ui-url&amp;#39; changeOrigin: true headers: Authorization: &amp;#39;Bearer ${LITMUS_AUTH_TOKEN}&amp;#39; litmus: baseUrl: &amp;#39;your-own-litmus-ui-url&amp;#39; apiToken: ${LITMUS_AUTH_TOKEN}&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&lt;li&gt;将您的身份验证密钥添加到环境变量中&lt;/li&gt;&lt;/ul&gt;&lt;pre class="wp-block-code"&gt;&lt;code class=""&gt; export LITMUS_AUTH_TOKEN=&amp;quot;your-own-token&amp;quot;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&lt;li&gt;要获取项目 ID，请直接从门户 URL 中的“/project/”之后复制它&lt;img alt="项目ID" height="334" src="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fzdv8f1hkyyl4gt7fgrh4.png" width="800" /&gt;&lt;/li&gt;&lt;li&gt;将新组件附加到&lt;code&gt;./examples/entities.yaml&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre class="wp-block-code"&gt; &lt;code class=""&gt;# ... --- apiVersion: backstage.io/v1alpha1 kind: Component metadata: name: backstage-litmus-demo description: An example of a Backstage application. ## append here annotations: litmuschaos.io/project-id: your-own-project-id ## spec: type: service owner: john@example.com lifecycle: experimental&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&lt;li&gt;要启用前端，我们需要编辑&lt;code&gt;./packages/app/src/components/catalog/EntityPage.tsx&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre class="wp-block-code"&gt;&lt;code class=""&gt; // packages/app/src/components/catalog/EntityPage.tsx import { isLitmusAvailable, EntityLitmusCard, EntityLitmusContent } from &amp;#39;backstage-plugin-litmus&amp;#39; // ... const overviewContent = ( &amp;lt;Grid container spacing={6} alignItems=&amp;quot;stretch&amp;quot;&amp;gt; // ... &amp;lt;EntitySwitch&amp;gt; &amp;lt;EntitySwitch.Case if={isLitmusAvailable}&amp;gt; &amp;lt;Grid item md={4} xs={12}&amp;gt; &amp;lt;EntityLitmusCard /&amp;gt; &amp;lt;/Grid&amp;gt; &amp;lt;/EntitySwitch.Case&amp;gt; &amp;lt;/EntitySwitch&amp;gt; // ... &amp;lt;/Grid&amp;gt; ) // ... const serviceEntityPage = ( &amp;lt;EntityLayout&amp;gt; // ... &amp;lt;EntityLayout.Route path=&amp;quot;/litmus&amp;quot; title=&amp;quot;Litmus&amp;quot;&amp;gt; &amp;lt;EntityLitmusContent /&amp;gt; &amp;lt;/EntityLayout.Route&amp;gt; // ... &amp;lt;/EntityLayout&amp;gt; )&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;再次&lt;code&gt;yarn dev&lt;/code&gt; ，现在您可以在一个地方（后台）管理有关 LitmusChaos 的所有内容。&lt;a href="https://docs.litmuschaos.io/docs/integrations/backstage#entitylitmuscard"&gt;概述选项卡&lt;/a&gt;提供了 LitmusChaos 中一些重要指标的概览视图。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示后台概览的屏幕截图" class="wp-image-105142" height="393" src="https://www.cncf.io/wp-content/uploads/2024/04/https___dev-to-uploads.s3.amazonaws.com_uploads_articles_6uywsu7of0wo5xjmlro7.png" width="800" /&gt;&lt;/figure&gt;&lt;p&gt;在&lt;a href="https://docs.litmuschaos.io/docs/integrations/backstage#entitylitmuscontent"&gt;LitmusChaos 选项卡&lt;/a&gt;中，您可以在一个页面上查看有关 LitmusChaos 的所有信息，包括混沌实验、混沌基础设施等。 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示后台 Litmus 概览的屏幕截图" class="wp-image-105143" height="393" src="https://www.cncf.io/wp-content/uploads/2024/04/https___dev-to-uploads.s3.amazonaws.com_uploads_articles_b43x6wx3cwhf1mbvpc3d.png" width="800" /&gt;&lt;/figure&gt;&lt;p&gt;我想强调的是，我们可以重新运行现有的混沌实验。我们所要做的就是点击“运行实验”按钮🚀 &lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="显示后台“实验”选项卡的屏幕截图" class="wp-image-105144" height="259" src="https://www.cncf.io/wp-content/uploads/2024/04/https___dev-to-uploads.s3.amazonaws.com_uploads_articles_qjwwemtiu98uyhsevg37.png" width="800" /&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading"&gt;&lt;a href="https://dev.to/namkyu1999/a-beginners-guide-to-litmus-and-backstage-4p18-temp-slug-9264283?preview=1ab316fd623b5144a4102e4057db0744e32cd289a39a2ffc04e5bdaca4caf5f173faa3b2c345da6204b570a6cf4896c8000346f60706789e13f405d5#summary"&gt;&lt;/a&gt;概括&lt;/h2&gt;&lt;p&gt;在本教程中，我们探索了如何利用 LitmusChaos 和 Backstage 集成将混乱注入 Kubernetes 环境并对其进行有效管理。&lt;/p&gt;&lt;p&gt; LitmusChaos 和 Backstage 的集成提供了一个统一的平台来管理混沌工程的各个方面，从注入混沌到监控影响和分析结果。&lt;/p&gt;&lt;p&gt;如果您对 LitmusChaos 感兴趣，请加入社区！您可以加入&lt;a href="https://github.com/litmuschaos/litmus"&gt;GitHub&lt;/a&gt;和&lt;a href="https://kubernetes.slack.com/?redir=%2Farchives%2FCNXNB0ZTN"&gt;Slack&lt;/a&gt;上的 LitmusChaos 社区。&lt;/p&gt;&lt;p&gt;感谢您的阅读🙏&lt;/p&gt;&lt;p&gt;南久公园&lt;br /&gt;LitmusChaos 的维护者&lt;br /&gt;&lt;a href="https://www.linkedin.com/in/namkyupark1999/?locale=en_US"&gt;领英&lt;/a&gt;| &lt;a href="https://github.com/namkyu1999"&gt;GitHub&lt;/a&gt; &lt;/p&gt;&lt;p&gt;&lt;a href="https://dev.to/t/chaosengineering"&gt;&lt;/a&gt;&lt;/p&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;&lt;div class="wp-block-spacer is-style-80-120" style="height: 80px;"&gt;&lt;/div&gt;</description><pubDate>Sun, 31 Mar 2024 16:00:00 GMT</pubDate><guid isPermaLink="true">https://www.cncf.io/blog/2024/04/01/elevating-system-resilience-leveraging-litmuschaos-and-backstage-integration/</guid></item></channel></rss>