<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>优步工程博客</title><link>https://www.uber.com/blog/engineering</link><description>Uber 工程背后的技术 - 由 RSSHub 用爱制作(https://github.com/DIYgod/RSSHub)</description><lastBuildDate>Fri, 29 Mar 2024 17:15:45 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>扩展 Uber 的 AI/ML 基础设施</title><link>https://www.uber.com/blog/scaling-ai-ml-infrastructure-at-uber/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;&lt;strong&gt;介绍&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;自 2016 年我们首次开始为司机-乘客匹配和定价团队使用复杂的基于规则的机器学习模型以来，机器学习 (ML) 正在庆祝其在 Uber 的第八个年头。从那时起，我们取得了重大进展，转向采用深度学习学习模型是当今大多数关键业务应用程序的核心，同时积极探索生成式人工智能模型提供的可能性。随着 AI/ML 模型的复杂性和规模不断激增，对高效基础设施来有效支持这些模型的需求不断增长。在过去的几年里，我们战略性地实施了一系列以 CPU 和 GPU 为中心的基础设施解决方案，以动态扩展我们的系统并满足不断变化的 ML 用例环境。这一演变涉及定制硬件 SKU、软件库增强、各种分布式训练框架的集成以及对我们的端到端 Michaelangelo 平台的持续改进。这些迭代改进是由我们一路走来的经验教训以及对行业趋势和 Uber 发展轨迹的不断调整推动的，所有这些都是为了满足我们的合作伙伴和客户不断变化的需求。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-goal-and-key-metrics"&gt;&lt;strong&gt;目标和关键指标&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;当我们开始从内部部署向云基础设施的过渡（我们于 2023 年 2 月&lt;a href="https://www.wsj.com/articles/uber-signs-cloud-deals-with-google-and-oracle-b45a9372" rel="noreferrer noopener" target="_blank"&gt;宣布）&lt;/a&gt;时，我们跨团队的硬件/软件协同设计和协作是由以下具体目标驱动的：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;最大限度地利用现有基础设施&lt;/li&gt;&lt;li&gt;为新兴工作负载建立新系统，例如生成式人工智能&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为了实现这些目标，我们概述了指导我们进步的独特关键结果和指标。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可行性和可靠性：&lt;/strong&gt;机器学习用户期望在预期的时间范围内（根据复杂性，可以是几周或几个月）成功地融合他们的训练任务，并且不会出现错误。例如，训练 Falcon 180B™ 等更大、更复杂的模型可能需要数月时间，而较长的训练持续时间会增加出现可靠性问题的可能性。因此，我们的目标是为所有培训依赖项实现 99% 的正常运行时间 SLA，以确保一致且可靠的结果。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;效率：&lt;/strong&gt;我们对效率的关注涉及对不同 GPU 配置进行彻底的基准测试，并评估针对特定工作负载定制的本地和云 SKU 的性价比。我们使用模型触发器利用率 (MFU) 等指标来衡量训练效率，以保证最佳的 GPU 利用率。我们的目标是防止 GPU 闲置，通过反应式扩展在服务非高峰时段机会性地使用训练作业，并保持高利用率以最大限度地提高资源效率。我们希望做到这一点的同时也保持不同用户之间资源共享的公平性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;开发人员速度：&lt;/strong&gt;该指标通过我们的工程师在特定时间范围内可以进行的实验数量来量化。我们优先考虑成熟的生态系统来提高开发人员的速度，确保我们的团队高效工作以提供最佳解决方案。这种方法不仅简化了我们最先进的模型的生产过程，而且还减少了这一过渡所需的时间。&lt;/p&gt;&lt;p&gt;接下来是我们为使本地和云基础设施中的培训和服务部署高效且可扩展而采取的各种举措的结果摘要： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-optimizing-existing-on-prem-infrastructure"&gt;&lt;strong&gt;优化现有的本地基础设施&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-federation-of-batch-jobs"&gt;&lt;br /&gt;批处理作业联合会：&lt;/h3&gt;&lt;p&gt;我们的 GPU 资产分布在各个可用区和区域的多个&lt;a href="https://kubernetes.io/" rel="noreferrer noopener" target="_blank"&gt;Kubernetes&lt;/a&gt; ™ 集群中。这种分布主要是由于 GPU 可用性和单个 Kubernetes 集群内的节点数量限制。这种安排带来了两个主要挑战：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;向机器学习工程师展示基础设施的具体细节。&lt;/li&gt;&lt;li&gt;由于静态分配，跨集群的资源利用率不一致。虽然我们在每个集群内都有有效的资源共享系统，但我们缺乏集群间调度的能力。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为了解决这些问题，我们为批量工作负载创建了一个统一的联合层，包括&lt;a href="https://www.ray.io/" rel="noreferrer noopener" target="_blank"&gt;Ray&lt;/a&gt; ™ 和 Apache &lt;a href="https://spark.apache.org/" rel="noreferrer noopener" target="_blank"&gt;Spark&lt;/a&gt; ™，称为&lt;strong&gt;Michelangelo Job Controller&lt;/strong&gt; 。该组件充当所有工作负载调度的集中式接口，隐藏底层 Kubernetes 集群，并根据各种策略（负载感知、bin-pack）分配工作负载，包括计算和数据关联性考虑因素。我们计划在后续的博客文章中分享更多相关技术细节。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/BQBvxC9TSCSgAj8ZlAAL8Dkydbx3B__KT9nHfrs7eUfLEU6CVUiGo4uG6QUmWkJ0piVRdwkjSioJ-Q80JmKI7pFzlHOEssw3DTZlou544_4uJkyYHdbC55OkKSQfq7ZyL9x8yN8iuZ6a8Hv5RMg0-xk" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：用于 ML 工作负载分配的统一联合层。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-network-upgrade-for-llm-training-efficiency"&gt;网络升级提升LLM培训效率&lt;/h3&gt;&lt;p&gt;当扩展基础设施以适应生成式 AI 应用程序并提高分布式训练的效率，同时微调开源 LLM 时，重要的是要重点关注跨纵向扩展和横向扩展配置的网络带宽扩展。这就需要实现关键功能，例如 GPU 之间的全网状&lt;a href="https://www.nvidia.com/en-us/design-visualization/nvlink-bridges/" rel="noreferrer noopener" target="_blank"&gt;NVlink&lt;/a&gt; ™ 连接、网络链路速度升级、熟练的拥塞控制管理、QoS 控制以及专用机架和网络拓扑的建立以及其他基本功能。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1083848" height="593" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Fig2_network_upgrade-1024x593.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图2：通过网络链路容量升级提高训练效率。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们总结了大型语言模型 (LLM) 案例研究的结果，强调增强的网络带宽和拥塞控制机制对培训效果和性价比效率的巨大影响。我们的观察表明，与现有的网络互连相比，采用更高的网络带宽和更好的拥塞控制机制时，训练速度提高了近两倍，并且训练持续时间大幅缩短。在多节点训练期间，跨节点复制数据会增加本地内存需求并增加 IO 工作负载。我们的分析建议将每个 GPU 服务器上的网络链路容量增加 4 倍（25GB/s 至 100GB/s），从而可能使可用训练容量增加一倍。在构建这些服务的同时，我们还需要通过适当的隔离和 QoS 控制来确保大型训练运行生成的“大象流”不会对其他高优先级服务产生负面影响。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-memory-upgrade-to-improve-gpu-allocation-rates"&gt;&lt;br /&gt;内存升级以提高 GPU 分配率&lt;/h3&gt;&lt;p&gt;较新的 AI/ML 工作负载要求每个 GPU 工作线程使用比我们设计的更多的系统内存。固有的物理限制，例如每台服务器上的内存通道数量有限，以及 NPI（新产品推出）期间部署的 DIMM 容量限制了我们扩展 GPU 分配的能力。为了提高 GPU 分配率，我们已开始努力将这些服务器上的内存量增加一倍（每个 DIMM 通道 16GB 至 32GB）。此外，我们还在构建一个框架，以便在旧机架退役时重新利用和重复使用 DIMM。这种优化使我们能够最大限度地利用现有的机器学习基础设施，并充分利用我们当前的资源。我们将在下一篇文章中详细介绍通过这一举措所实现的效率提升。与此同时，我们已开始努力帮助调整培训工作的资源需求。正如其他人[&lt;a href="https://tianyin.github.io/pub/amp.pdf" rel="noreferrer noopener" target="_blank"&gt;参考文献&lt;/a&gt;]所证明的那样，手动请求最佳资源是一个难题，而自动化将有助于提高分配效率。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-building-new-infrastructure"&gt;&lt;strong&gt;建设新型基础设施&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-price-performance-evaluations-across-various-cloud-skus"&gt;&lt;br /&gt;各种云 SKU 的性价比评估&lt;/h3&gt;&lt;p&gt;2022 年底，当我们踏上向云过渡的旅程时，我们评估了不同云提供商提供的各种 CPU 和 GPU 模型。我们的目标是使用既定基准（从基于树的深度学习到大型语言模型）以及专有数据集和 Uber 模型（例如 deepETA 和 deepCVR）来比较它们的性价比。这些针对培训和服务目的进行的评估使我们能够选择针对特定工作负载进行优化的最合适的 SKU，同时考虑可行性、成本、吞吐量和延迟等因素。整个 2023 年，我们广泛测试了 17 种不同的 GPU 和 CPU SKU，采用了各种库和优化器，包括 Nvidia 的&lt;a href="https://github.com/NVIDIA/TensorRT" rel="noreferrer noopener" target="_blank"&gt;TensorRT&lt;/a&gt; ™(TRT) 和 TRT-LLM 优化。例如，如图 4 和图 5 所示，我们发现虽然 A10 GPU 可能无法为训练任务提供最具成本效益的吞吐量，但事实证明它们是我们服务用例的最佳选择，在提供最佳吞吐量的同时保持可接受的吞吐量。使用 TRT 的 SLA。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/6lE7W5fYhVSHGudF-A9Fu6wzvEQo4-S7ZjnN8dSgy3HcTmC4pqn-RT9VvBF0kTwZYY3rCz6OU4BVQfZ5erhWA2UMlK-7VbUYQkqKF6SUb58hKjHdzbzH7GK6Do40TLNw7bg0GTxgQYgzQDDV-jbkXxg" title="图表" /&gt;&lt;figcaption class="wp-element-caption"&gt;图3：深度学习训练和服务性能价格评估。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/jnlRbG2pls4P0xjxD9Pvv7fx4BW5_ZWXtSYLQLXfN317i1lPtxJPOxT6xbzNT8OIHEtAXarcDNNFeC-YRUAI0zh4t1sTBuPUfYeppJPdIwMpPDDJ7E8ddXBnNqde1rCZZVxCJiCIbpQ1qWd4oIGWyhk" title="图表" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：使用和不使用 TensorRT 优化的深度学习服务延迟。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; Uber 的众多生成式 AI 应用程序需要使用 Nvidia 最新的 H100 GPU 来满足其严格的延迟要求。这一要求源于 H100 GPU 的功能，与上一代 A100 GPU 相比，它包括高达 4 倍 TFlops 和双倍的内存带宽。在试验 Meta™ &lt;a href="https://llama.meta.com/" rel="noreferrer noopener" target="_blank"&gt;Llama2&lt;/a&gt; ™ 模型系列（涉及各种批量大小、量化和模型参数）时，我们评估了各种开源和闭源框架，以进一步优化 LLM 服务性能。在图 6 和图 7 中，我们提出了一个具体案例，其中我们采用两个指标：每个令牌延迟（毫秒/令牌）和令牌/秒/gpu，来评估和比较两个表现最好的框架（TRT）的模型性能。 -LLM 和当前保密的框架），保持所有其他参数不变并使用 FP16 量化。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/qs9gWGpDUlhVZrug3qN88E-xDt8PKhA0Rd-R_WL8ECGq-DG50lJ7rz1nT37PxgIRyM0k2ypyN2Aq4v_FTnve8_tq9ayMOkm4cRd0UoTzSYbalhD2CDKQINp5F8uxVVDS8Y1ol-1MeKZK3pGzcSfd4dw" title="图表" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：按框架划分的 LLM 服务延迟比较 (H100)。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/rhL0z9GvoYxR0yiwFONGfGaHXsFNo_kORbuXeb9b2c8M0NEe_jJCbeEDThJUVHc05NeSt84xDjN7m5Skd2SvbzfHTUyz-MaaEhAffQoBtuKe3k7RZPVDQFDk7ZsgMYyFXfwCX-wL2dldeo2tHYzce-A" title="图表" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：使用相同延迟预算和所需 GPU 最少数量 (H100) 的框架的 LLM 服务吞吐量比较。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;这些实验结果清楚地表明，与 TRT-LLM 相比，框架 B 的延迟增加了两倍，吞吐量提高了六倍。它进一步强调了硬件/软件协同设计的重要性，并且为了充分利用硬件功能，必须在整个堆栈中拥有正确的解决方案。 &lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-llm-training-efficiency-improvements-with-memory-offload"&gt;&lt;br /&gt;通过内存卸载提高 LLM 培训效率&lt;/h3&gt;&lt;p&gt;在本节中，我们概述了有关大型语言模型的优化器状态、参数和梯度从 GPU 内存到 CPU 内存或 NVMe 设备的放置的设计和实验框架。我们的目标是评估这种卸载对 GPU 可扩展性、训练效率和一系列系统指标的影响。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1083850" height="637" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Fig6_memory_offload_design_space-1024x637.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：内存卸载实验的设计框架。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们的实验结果表明，我们训练先前因 GPU 内存有限而阻碍的扩展模型的能力已得到显着增强。将内存从 GPU 内存卸载到系统内存甚至 NVMe 设备，通过在相同数量的 GPU 上使用更大的批量大小，有助于提高训练效率。这一转变使 MFU（模型触发器利用率）提高了 2 倍，同时 GPU 使用率降低了 34%。然而，值得注意的是，这种改进伴随着网络吞吐量的相应减少。有关此主题的详细开放计算机项目 ( &lt;a href="https://www.opencompute.org/" rel="noreferrer noopener" target="_blank"&gt;OCP&lt;/a&gt; ) 会议演讲可&lt;a href="https://www.youtube.com/watch?v=Ju0r8yU1_Lw" rel="noreferrer noopener" target="_blank"&gt;在此处&lt;/a&gt;找到。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/L8HJjzd4fJLc0rv2q8ArOqvVbN-mlHlKwGTqoYg6dPciNtvU6kjAn3NK3eVfjp1WdeqLgJu2zIhmRNxeM5vkX3E47bIRNezH-X9ytjOWzh7lRI0V9OFtZMzOtUbaZXJjf6HsXy4oznVON7V6JTQt7zc" title="图表" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：实施 Deepspeed 内存卸载优化的训练效率。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;最后，我们想向您提供三个关键见解。在快速应用和模型发展（从 XGboost 到深度学习推荐模型和大型语言模型）中设计单一的 AI/ML 系统面临着相当大的挑战。例如，虽然法学硕士需要高 TFlops，但深度学习模型可能会遇到内存限制。为了提高这些系统的成本效益，必须根据给定 SLA 内的服务成本和单位成本性能等效率指标探索工作负载优化的解决方案。最大限度地提高基础设施效率需要跨系统所有层的协作硬件和软件设计方法。在此背景下，我们在这篇文章中展示了各种示例，说明如何有效利用现有基础设施，同时构建新功能以有效扩展基础设施。最后，我们发出促进行业合作伙伴关系的邀请，敦促参与开源优化以提高效率，并就有效扩展基础设施交换想法和经验，以满足人工智能领域不断变化的需求。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="h-acknowledgments"&gt;&lt;strong&gt;致谢&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;非常感谢 UBER AI 基础设施、OCI、GCP 和 Nvidia 团队成员在上述工作中的合作。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Apache®、Apache Kafka、Kafka、Apache Spark、Spark 和星形徽标是 Apache Software Foundation 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Kubernetes® 及其徽标是 Linux Foundation® 在美国和其他国家/地区的注册商标。使用这些标记并不暗示 Linux 基金会的认可。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Falcon 180B® 及其徽标是 Technology Innovation Institute™ 在美国和其他国家/地区的注册商标。使用这些标志并不暗示技术创新学院的认可。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; LLaMA 2® 及其徽标是 Meta® 在美国和其他国家/地区的注册商标。使用这些标记并不暗示 Meta 的认可。&lt;/p&gt;</description><pubDate>Thu, 28 Mar 2024 07:28:34 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/scaling-ai-ml-infrastructure-at-uber/</guid></item><item><title>模型卓越分数：大规模提高机器学习系统质量的框架</title><link>https://www.uber.com/blog/enhancing-the-quality-of-machine-learning-systems-at-scale/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;机器学习 (ML) 是 Uber 运营战略不可或缺的一部分，影响着一系列关键业务决策。这包括预测乘客需求、识别欺诈活动、增强 Uber Eats 优食的食物发现和推荐，以及改进预计到达时间 (ETA)。尽管机器学习在各个组织中越来越普遍并产生越来越大的影响，但评估模型“质量”仍然是一个多方面的挑战。在线和离线模型评估之间存在显着区别。许多团队主要关注离线评估，偶尔会通过短期在线分析来补充。然而，随着模型在生产环境中变得更加集成和自动化，持续监控和测量常常被忽视。&lt;/p&gt;&lt;p&gt;通常，团队专注于 AUC 和 RMSE 等性能指标，而忽略其他重要因素，例如训练数据的及时性、模型再现性和自动再训练。缺乏全面的质量评估导致机器学习工程师和数据科学家对模型生命周期不同阶段的各种质量维度的了解有限。此外，这种差距阻碍了组织领导者就机器学习项目的质量和影响做出充分知情的决策。&lt;/p&gt;&lt;p&gt;为了弥补这一差距，我们建议为模型生命周期的每个阶段定义不同的维度，包括原型设计、训练、部署和预测（见图 1）。通过整合服务水平协议 (SLA) 概念，我们的目标是建立衡量和确保 ML 模型质量的标准。此外，我们正在开发一个统一的系统来跟踪和可视化模型的合规性和质量，从而为整个组织的机器学习计划提供更清晰、更全面的视图。请注意，模型卓越得分 (MES) 涵盖了 Uber 整体机器学习治理不可或缺的某些技术方面。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/isX-qlXXKvyRNL8ZrqG7ecOuLg3MzE-EeDYMT1JdrdIESlDE_PMXJcc7hHT0c4496eN18aSxij2pX5zVCRTGiovjtyGurwVEV9w1jaX-YUq2hj1huPJQM39GmLqyOlzl-HPxfhC8YP5Lp2KTLhlunbw" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：典型 ML 系统中的 ML 质量维度示例（黄色）。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-model-excellence-scores-mes"&gt;模型卓越分数 (MES)&lt;/h2&gt;&lt;p&gt;生产就绪的机器学习系统的开发和维护非常复杂，涉及模型生命周期的多个阶段和复杂的支持基础设施。通常，ML 模型会经历特征工程、训练、评估和服务等阶段。维持这一点的基础设施包括数据管道、特征存储、模型注册表、分布式训练框架、模型部署、预测服务等。&lt;/p&gt;&lt;p&gt;为了对这些阶段的模型质量进行全面评估，我们创建并引入了模型卓越评分 (MES) 框架。 MES 旨在衡量、监控和强化 ML 生命周期每个阶段的质量。该框架符合站点可靠性工程师 (SRE) 和 DevOps 专业人员常用的原则和术语，特别是那些用于管理生产环境中的微服务可靠性的原则和术语。&lt;/p&gt;&lt;p&gt; MES 围绕与服务级别目标 (SLO) 相关的三个基本概念：指标、目标和协议。指标是反映机器学习系统质量某些方面的精确定量度量。目标为这些指标设定了目标范围，而协议则在 ML 用例级别组合所有指标，根据指标结果指示总体通过/失败状态。&lt;/p&gt;&lt;p&gt; MES中的每个指标都有明确的定义，并为其指标值设定了目标范围，并指定了值更新的频率。如果某个指标在给定时间范围内未达到其目标，则将其标记为失败。封装了这些指标的协议代表了服务的承诺水平并提供了对其绩效的深入了解。图 2 说明了协议、指标和目标之间的相互关系，以及它们与特定用例和模型的关系。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/bvZ0Oj6F3DG-ZDLprNYgODtxB444TWmjTAEMqNlVxgeozimoLuFjXa6m6LVCKCAE7CrTaDD6t2SgvAUUPUmEQaYMe8bbfDOtMgsn10i2W1A3AtQemO7gpOORuYiFTPkjMhIst_8t9RtlITBHxK-dWWw" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：协议、指标、目标、用例和模型之间的关系。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;不同的指标可能需要不同的解决时间框架和不同的缓解策略。有些可能需要立即关注更高优先级的处理，特别是在未达到性能基准时。&lt;/p&gt;&lt;p&gt;同样重要的是要注意，与建模相关的角色和职责在组织之间可能存在很大差异。在某些情况下，单个团队可以处理整个流程，而在其他情况下，职责可能分布在多个团队或部门中。&lt;/p&gt;&lt;p&gt;在 Uber，每个模型的职责都分配给指定的主要团队。如协议中所述，该团队会收到与其模型相关的任何差异或问题的警报。团队可以根据 ML 用例的重要性和紧迫性灵活地定制这些警报。值得注意的是，一种模型的质量可以直接或间接影响另一种模型。例如，一个模型的输出可以作为另一个模型的输入或触发进一步的模型评估。为了解决这种相互关联性，我们实施了一个通知系统，通知服务和模型所有者相关 ML 模型中的任何质量违规情况。&lt;/p&gt;&lt;p&gt;图 3 描述了模型卓越评分 (MES) 框架与 Uber 其他 ML 系统之间的交互。MES 框架及其指标、目标和协议建立在几个关键原则之上：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;自动可测量性&lt;/strong&gt;：MES 中的每个指标均采用可量化和自动化的指标设计，确保仪器仪表的基础设施稳健。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可操作性&lt;/strong&gt;：指标不仅是可衡量的，而且是可操作的。这意味着用户或平台可以采取明确的步骤来随着时间的推移根据其设定的目标改进这些指标。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可聚合性&lt;/strong&gt;：每个指标的指标都可以聚合。这对于有效的报告和监控至关重要，可以根据组织的目标和关键结果 (OKR) 以及关键绩效指标 (KPI) 统一汇总指标。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;再现性&lt;/strong&gt;：每个指标的指标都是幂等的，这意味着它们的测量在回填时保持一致。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;责任&lt;/strong&gt;：每份协议都附有明确的所有权。指定所有者负责定义目标并确保实现这些目标。 &lt;/li&gt;&lt;/ul&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/QJtG_get-AGg37qbai6tkDE1-x9IXbOt28Xsk4tFbSBV6mGfC5jt0aOXtPOEAQpP3RIK8JiQuc2-B-HTUquxWMh0LAqWelYAIesr2YJ2z1cT9-UyyaAOaD_GHGt8iN2BY8Vj2IHOhECetrh84AZU9Tg" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：MES 框架与各种 ML 系统之间交互的高级视图。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们重点关注表1中相关文献中未广泛涵盖的一些指标。MES能够衡量公平性和隐私性等方面，这些主题不在本次讨论的范围之内。我们在下表中概述了每个指标如何遵循这些设计原则，提供了可衡量指标的示例、可操作的改进步骤以及用于确保指标在不同用例中可聚合和一致的标准化方案。这些指标要么标准化为 [0,1] 范围，要么转换为百分比，要么在各种应用程序中保持一致的范围。&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;指标&lt;/th&gt;&lt;th&gt;描述&lt;/th&gt;&lt;th&gt;可能采取的行动&lt;/th&gt;&lt;th&gt;指标标准化&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;数据质量&lt;/td&gt;&lt;td&gt;衡量用于训练模型的输入数据集的质量。这是以下的堆肥分数：&lt;br /&gt; – 特征为空&lt;br /&gt;– 跨区域一致性&lt;br /&gt;– 丢失分区&lt;br /&gt;– 重复&lt;/td&gt;&lt;td&gt;– 回填丢失的分区&lt;br /&gt;– 跨区域和实例同步数据分区&lt;br /&gt;– 删除数据中的重复行&lt;/td&gt;&lt;td&gt;综合得分中的每个组成部分均按百分比标准化&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;数据集新鲜度&lt;/td&gt;&lt;td&gt;测量用于训练模型的输入数据集的新鲜度&lt;/td&gt;&lt;td&gt;– 使用新的输入数据集重新训练&lt;br /&gt;– 如果更新的数据可用，则回填输入数据集&lt;/td&gt;&lt;td&gt;规模一致&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;特征和概念漂移&lt;/td&gt;&lt;td&gt;生产模型的目标和协变量分布以及两者之间的关系随时间的变化&lt;/td&gt;&lt;td&gt;– 应用加权训练或使用新数据重新训练模型&lt;br /&gt;– 验证上游功能ETL管道的正确性&lt;/td&gt;&lt;td&gt;使用归一化距离度量和重要性权重归一化为 [0,1]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;模型可解释性&lt;/td&gt;&lt;td&gt;衡量模型生成的每个预测的稳健特征解释的存在性和置信度&lt;/td&gt;&lt;td&gt;– 启用解释&lt;/td&gt;&lt;td&gt;标准化为 [0,1]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;预测精度&lt;/td&gt;&lt;td&gt;模型对生产流量的预测准确性（例如，AUC、归一化 RMSE）&lt;/td&gt;&lt;td&gt; – 更新训练数据集以解决训练-服务偏差&lt;br /&gt;– 检查功能或概念漂移&lt;/td&gt;&lt;td&gt;通过标准化精度指标标准化为 [0,1]&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class="wp-element-caption"&gt;表：指标样本。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-results"&gt;结果&lt;/h2&gt;&lt;p&gt;Uber 实施 MES 框架显着提高了组织内机器学习质量的可见性。这种透明度的提高有助于培育优先考虑质量的文化，从而影响业务决策和工程策略。随着时间的推移，我们在各个方面观察到在遵守 SLA 方面取得了重大进展。值得注意的是，我们模型的整体预测性能显着提高了 60%。&lt;/p&gt;&lt;p&gt;此外，从 MES 指标中收集的见解对于确定平台增强领域至关重要。这些见解带来的一个关键发展是引入了用于超参数调整的高级平台工具。这项创新可以自动定期重新调整所有模型，简化优化过程并确保一致的模型性能。这些改进凸显了 MES 框架在推动运营效率和技术进步方面的切实好处&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-lessons-learned"&gt;得到教训&lt;/h2&gt;&lt;p&gt;在 Uber 所有机器学习团队实施和监控关键指标的过程中，我们收集了一些重要的见解。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;激励机器学习从业者：&lt;/strong&gt;既定的框架可以对影响和针对质量改进的努力进行切实的衡量。通过采用标准且透明的报告系统，我们创建了一个环境，让机器学习从业者能够积极提高质量，因为他们知道他们的努力在整个组织中是可见的并得到认可的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;协调和行政支持：&lt;/strong&gt;最初，质量措施可能被视为额外的负担，除非它们从一开始就无缝地融入到日常实践中。实施质量跟踪框架可以揭示现有差距，需要在教育和意识方面付出额外努力来解决这些问题。与执行领导层保持一致至关重要，使团队能够优先考虑以质量为中心的任务。这种一致性逐渐导致全面转向更加积极主动、以质量为中心的文化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;平衡标准化与定制：&lt;/strong&gt;在设计框架时，我们的目标是实现一定程度的标准化，以便随着时间的推移进行一致的跟踪和明智的决策。然而，考虑到 Uber 的机器学习应用多种多样，允许对特定指标进行定制以准确反映每个用例的细微差别也至关重要。例如，在 ETA 预测模型中，我们采用平均平均误差作为比 RMSE 更符合上下文的指标。该框架适应了此类定制，同时保持了报告的标准化方法以确保一致性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;确定增量改进的优先级：&lt;/strong&gt;跨各种用例管理框架给确定优先级带来了重大挑战。我们开发了一个简单的优先级矩阵来确定哪些领域需要立即关注。认识到少数模型对影响的贡献最大，我们的重点是首先提高高影响力用例的质量。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;自动化的作用：&lt;/strong&gt;维持机器学习质量需要大量资源，而手动管理生产中的模型可能会分散创新的精力。事实证明，生产生命周期自动化，包括使用新数据重新训练、重新验证和重新部署模型，是非常有价值的。这种自动化不仅增强了模型的新鲜度（如模型平均寿命的缩短所示），还使团队能够更多地关注创新，而不是维护。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;我们开发了一个全面的框架，概述了高质量机器学习 (ML) 模型在其生命周期不同阶段的关键维度。该框架受到服务级别协议 (SLA) 原则的启发，旨在监控和确保 ML 模型的质量。重要的是，它的结构可以容纳额外的质量维度，适应新兴的用例和该领域不断发展的最佳实践。&lt;/p&gt;&lt;p&gt;我们的讨论还包括该框架在组织各个层面生成富有洞察力的质量报告的应用。这些报告会定期审查，促进问责制并为战略规划提供宝贵的见解。至关重要的是，通过将机器学习质量嵌入到相关软件系统的整体服务质量中，我们促进了共享责任模型。应用科学家、机器学习工程师和系统工程师现在共同拥有机器学习质量。这种协作方法极大地弥合了这些职能之间的差距，在组织内培育了积极主动、注重质量的文化。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-acknowledgments"&gt;致谢&lt;/h3&gt;&lt;p&gt;如果没有 Uber 工程师和应用科学家团队的帮助，我们不可能完成本文中概述的技术工作。我们还要感谢各位技术项目经理（Gaurav Khillon、Nayan Jain 和 Ian Kelley），感谢他们在促进 Uber 不同组织采用和合规 MES 框架方面发挥的关键作用。&lt;/p&gt;</description><pubDate>Thu, 21 Mar 2024 05:30:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/enhancing-the-quality-of-machine-learning-systems-at-scale/</guid></item><item><title>平衡 Uber DataLake 中的 HDFS 数据节点</title><link>https://www.uber.com/blog/balancing-hdfs-datanodes-in-the-uber-datalake/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;&lt;strong&gt;介绍&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;Apache Hadoop &lt;sup&gt;Ⓡ&lt;/sup&gt;分布式文件系统 (HDFS) 是一种分布式文件系统，旨在以可靠且容错的方式跨多台计算机存储大型文件。它是 Apache Hadoop 框架的一部分，也是 Uber 数据堆栈的主要组件之一。&lt;/p&gt;&lt;p&gt; Uber 拥有世界上最大的 HDFS 部署之一，在数十个集群中拥有 EB 级的数据。不断扩展我们的数据基础设施并在效率、服务可靠性和高性能之间取得平衡非常重要，但也具有挑战性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/VaaufGJF2NoMmsAXqw0SjcSbkWbdPFm1-Kr_ZYFuHKKoFGozTrx0QEhYCk2vu7lAd8vai59XYBhIssXwY0LfI5kWh7AQGTKKYTM34rWx8Re1V8U7gEI0Z0O_vLgXLXT8af8frAQNJJQ_95n95isTgWw" /&gt;&lt;/figure&gt;&lt;p&gt;图 1：Uber 的 HDFS 基础设施。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-overview"&gt;&lt;strong&gt;概述&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;HDFS 平衡器是通过在集群中均匀地重新分配数据来保持 DataNode 健康的关键组件。随着我们的 HDFS 集群的节点停用越来越频繁，HDFS 平衡器必须更有效地平衡数据，以防止 DataNode 倾斜。节点退役需求来自区域退役、安全补丁自动集群更新以及DataNode托管等项目。&lt;/p&gt;&lt;p&gt;然而，HDFS开源自带的平衡器并没有开箱即用地满足这个要求。我们已经看到一个 DataNode 出现偏差的问题（即，与同一集群中的其他节点相比，存储更多数据），这会产生多种副作用：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;导致包含过多数据的主机上的高 I/O 带宽&lt;/li&gt;&lt;li&gt;高利用率的节点有更高的速度缓慢的可能性，节点故障、数据丢失的风险更高&lt;/li&gt;&lt;li&gt;集群中活跃且健康的节点较少，无法为客户提供写入流量&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面是一个数据不平衡的例子：在我们最大的集群中，数千个节点的磁盘利用率接近95%，该集群由数千个DataNode组成，容量为数百PB，而平衡吞吐量无法有效地将数据移动到其他新添加的DataNode。这种不平衡的数据分布是由热分层和EC转换[1]产生的突发写入流量、安全补丁的区域分解/集群周转导致的密集节点退役造成的。由于写入可靠性是第一要务，因此所有 DataNode 都通过可用的容量加权算法来服务写入流量。随着写入流量的增加，数据偏差也更大。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1082498" height="212" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Figure-2-Argon-cluster-original-1024x212.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：我们最大的集群之一由大约数千个 DataNode 组成，容量为数百 PB，但 DataNode 出现了偏差。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;因此，我们需要优化HDFS平衡器，以增加从高使用率DataNode到另一个低使用率DataNode的数据平衡。&lt;/p&gt;&lt;p&gt;考虑到 Uber 的数据存储规模，单个集群中会有超过 20 PB 的数据不平衡节点，集群数量为 7-8 个。为了解决 Uber DataLake 中平衡 HDFS DataNode 的问题，我们设计了一种新算法来增加 DataNode 之间形成的对的数量，这将在平衡数据的同时增加并行块移动。此外，我们还根据利用率对数据节点进行排序，以便优化形成的数据节点对，并且不会发生递归平衡。&lt;/p&gt;&lt;p&gt;该算法将继续增加用于平衡的吞吐量，即每秒从较高占用的数据节点移动到考虑平衡的较低占用的数据节点的数据大小。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-architecture-amp-design"&gt;&lt;strong&gt;架构设计&lt;/strong&gt;&lt;/h2&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/aypCjNKWlTTa6yQzeGj53GgpowcKkI2Sowy6KlqoObWeWb2sGt7QrR7AS5AEk8kjzHKseHi4zEbcG_HW31QNaglL96kh-0RzVIhXk8qVLmLMJbr5Qr_yULMeF-HVYBCBwknrf3UCeY1RRaNRv8vyLIk" style="width: 701px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：HDFS 平衡器架构。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;ol&gt;&lt;li&gt;初始化和设置：&lt;ol&gt;&lt;li&gt; HDFS 平衡器作为 Hadoop 集群中的服务在主机上运行。&lt;/li&gt;&lt;li&gt;要启动平衡过程，集群中需要存在具有平衡器角色的节点。没有两个平衡器可以同时运行。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;请求集群信息：&lt;ol&gt;&lt;li&gt;平衡器首先联系NameNode以请求有关集群内数据分布的信息。它向NameNode发送请求以获取有关数据块在DataNode上的分布的详细信息。&lt;/li&gt;&lt;li&gt; NameNode 以 DataNode 列表和它们包含的块以及它们的存储容量和其他相关信息进行响应。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;区块选择和规划：&lt;ol&gt;&lt;li&gt;根据从NameNode收到的信息，平衡器算法选择需要移动的块以实现更平衡的分布。&lt;/li&gt;&lt;li&gt;平衡器在规划块移动时会考虑 DataNode 利用率、机架信息、线程和存储容量等因素。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;数据移动的协调：&lt;ol&gt;&lt;li&gt;在确定要移动哪些块后，平衡器会协调 DataNode 之间的实际数据移动。&lt;/li&gt;&lt;li&gt;它与 NameNode 就借助心跳移动的块进行通信。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;块迁移：&lt;ol&gt;&lt;li&gt;平衡器通过直接与源和目标 DataNode 通信来启动块迁移。&lt;/li&gt;&lt;li&gt;它指示源DataNode将选定的块传输到目标DataNode，直接移动数据块。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;监控进度：&lt;ol&gt;&lt;li&gt;在整个数据移动过程中，平衡器持续监控进度。它跟踪已成功传输的块数量，并确保数据移动按照计划进行。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;完成和报告：&lt;ol&gt;&lt;li&gt;平衡操作完成后，平衡器会在日志中并通过指标报告已传输的数据和剩余待传输的数据。&lt;/li&gt;&lt;li&gt;它还可以提供有关平衡过程的统计数据和指标，包括移动的块数量和所花费的时间。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;终止：&lt;ol&gt;&lt;li&gt;在主机中，平衡器作为服务运行。因此，在集群达到平衡之前，它不会停止移动数据。 &lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-initial-optimizations"&gt;&lt;strong&gt;初始优化&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;br /&gt;由于我们的目标是提高吞吐量，以更快的速度平衡 DataNode，因此我们使用现有的 DataNode 属性优化了 HDFS 平衡器，以提高吞吐量。&lt;br /&gt;尽管我们将平衡器的速度提高到了 3 倍，但吞吐量仍然不够。我们有太多高度占用的节点，并且在现有算法中将数据传输到的 DataNode 对的数量会明显减少。此外，我们无法通过平衡器线程提高每个节点的吞吐量，因为增加它会增加节点的速度并影响读/写流量。因此，我们需要增加 DataNode 对的数量，这最终会导致平衡吞吐量的增加。&lt;br /&gt;&lt;br /&gt;我们使用的 DataNode 和 Balancer 配置如下所述。根据您的情况，您的工作负载的配置可能会有所不同。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;DataNode配置属性：&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-table has-small-font-size"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;财产&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;默认&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;快速模式&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;dfs.DataNode.balance.max.concurrent.moves&lt;/td&gt;&lt;td&gt; 5&lt;/td&gt;&lt;td&gt; 250&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; dfs.DataNode.balance.bandwidthPerSec&lt;/td&gt;&lt;td&gt; 1048576（1MB）&lt;/td&gt;&lt;td&gt; 1073741824（1GB）&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;平衡器配置属性：&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-table has-small-font-size"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;财产&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;默认&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;快速模式&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;dfs.DataNode.balance.max.concurrent.moves&lt;/td&gt;&lt;td&gt; 5&lt;/td&gt;&lt;td&gt; 250&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; dfs.balancer.moverThreads&lt;/td&gt;&lt;td&gt; 1000&lt;/td&gt;&lt;td&gt; 2000年&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;dfs.balancer.最大移动尺寸&lt;/td&gt;&lt;td&gt;10737418240（10GB）&lt;/td&gt;&lt;td&gt; 107374182400（100GB）&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; dfs.balancer.getBlocks.最小块大小&lt;/td&gt;&lt;td&gt;10485760 (10MB)&lt;/td&gt;&lt;td&gt; 104857600 (100MB) &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-algorithm-optimizations"&gt;&lt;strong&gt;算法优化&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-increasing-datanode-pairs-for-high-throughput"&gt;增加 DataNode 对以实现高吞吐量&lt;/h3&gt;&lt;p&gt;更多的 DataNode 对意味着我们可以有更多的并发块传输，因此一个关键的改进是构造更多的对。由于现有算法，高度倾斜的集群形成的数据节点对较少。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1082506" height="549" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Figure-4-Balancer-Original-Algo-1024x549.jpeg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：现有算法。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;在 HDFS Balancer 的现有算法中，高于集群平均利用率的 DataNode（即高于平均利用率和过度利用率的节点）的数量比低于平均利用率和利用率不足的节点要高得多。因此，我们面临着节点稀缺的问题，无法从高利用率的 DataNode 上移动数据，这导致高利用率的 DataNode 无法快速停机。&lt;br /&gt;&lt;/p&gt;&lt;p&gt;在上图中，有 8 个 DataNode 高于平均利用率，4 个 DataNode 低于平均利用率，这将导致 4 个可以移动数据的目标。&lt;br /&gt;目的是修改 HDFS 算法，为 DataNode 形成更多对，从而从高使用率的 DataNode 中获得更多吞吐量，从而实现均匀利用率以及通过更大的 DataNode 覆盖范围快速降低使用率。&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们的想法是使用基于百分位数的算法来创建更多 DataNode 对。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/HlfZlWPK_wVdej0xQY_1gYkFAWt7JpDbSyPnbE4eLyQaV9-jk_XFbgFszAVnxWfTzTvMg_6MhjL3lsrAImSeStQrrcXNiIdM_W2zNWEHJlWnCsxhme1CD07Ju4Q8QoPHgBzqg-GDgSmcBSu7A8yh9RQ" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：新算法。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;在新算法中，我们根据百分位创建了调整后的平均值，这将增加数据可以移动到的节点数量。高于平均水平/过度利用的 DataNode 将尝试接近整体集群利用率，而未充分利用/低于平均利用的节点将尝试接近调整后的百分位数平均值。通过基于百分位数的算法，我们的目标是使调整后的平均值接近整体集群利用率。&lt;/p&gt;&lt;p&gt;我们将使用基于百分位数的算法来增加 DataNode 对。在高度倾斜的集群中，百分位数相当高。以上图为例，我们将百分位数设为 P60，调整后的平均值现在为 86.7%。在这种情况下，过度利用/高于平均利用的节点的数量减少，而利用不足/低于平均利用的节点的数量增加。&lt;/p&gt;&lt;p&gt;现在，将有 5 个过度利用且高于平均利用率的节点和 7 个利用率不足且低于平均水平的节点，这将导致 4 对最多形成 7 对。&lt;/p&gt;&lt;p&gt;我们有一个新的 Hadoop 配置属性&lt;em&gt;dfs.balancer.separate-percentile&lt;/em&gt; ， &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/ouUojzw_My_1YuqQvm4oGFoXtN03qy9mBcdjsfcPCHi7thgD_wkYfo3lkzZN6AzFvG2rs2qDHuftg2D3D8vpFw03dk94_r_UhuSUvSfkUr7w2YGuCOP1tNO3QDEE9RV8LwCkjScxreh3_YXyC0vPkPc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：用于定义百分位的新 Hadoop 配置。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;默认为 0.5，表示第 50 个百分位数。如果我们使用 -dynamicBalancer 部署平衡器命令，则该百分位算法将生效，并且调整后的平均值将以更高的吞吐量出现。&lt;/p&gt;&lt;p&gt;我们还可以使用这个阈值来动态平衡。例如，如果 DataNodes 超过 90%，我们将积极平衡它们（即提高速度）。因此，我们将平衡前 20% 的 DataNode，这将导致将 moverThreads 集中在利用率最高的前 20% 的源上，并且数据将从利用率高的 DataNode 移动得更快，并更快地降低使用率。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1082510" height="417" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Figure-7-Aggressive-balancer-code-1024x417.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：用于定义积极平衡的新 Hadoop 配置。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-moving-data-to-lower-occupied-datanodes"&gt;将数据移动到占用率较低的 DataNode&lt;/h3&gt;&lt;p&gt;由于自动化（即自动将DataNode中的数据移至其他DataNode进行维护），导致大型集群中的DataNode频繁退役，退役节点的数据被转移到其他节点，导致节点占用率增加。那些节点。出现的新节点慢慢平衡，因为它们没有被赋予优先级。&lt;br /&gt;另外，例如，如果平均利用率为 83%，阈值为 3%，则 90% 的 DataNode 将其部分数据移动到 79% 的节点，该节点变为 81%。现在，如果新客户端在 81% 时转储数据，则变为 87%，这可能需要进一步平衡该节点，从而分配调度程序和移动程序线程。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/lAap83ZaUUmXXZdZ45R2B9TuHzz3O8zzrYpaZpti5Srpdxga1oV2Ay6yBqrlLqRRfVYe5r0jiEYlyQe8EBhD_W9T5Z_QsbkvToqR1-VPXv-9grrMlFCNb61rpOZtsv4jG1EX4Q3loB-vg-C0236qxdc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：旧算法 – 形成对。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/xoqmBEJU1prJmh7xmVNllTySnh2KfypKUZXcfY2Kp4qG3XMWEVnNMkpOQjm9EwfarrVBwn4IlD5gnaScUKbt7jRDQnBziP4EcDQTxEErbfKzT-5xu7nzj8EpOjDxKS1aFImRaPN_U5Iz2EEKSpjJp8Q" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：旧算法 – 新的过度使用的节点出现。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/qmXk_2q380kv8Nmo5YBY-jL_T6o88ZDB9sZ_M2RG8FCQ_Cs8vCKV5YiP11ahdV98lhsqvkhhb1yxJwVHySa__dVbeW0EtUlS96qwxHwl0eGYnVAnc6kf7vnx-KZCXEtKxG0muax_12jqY5aYP0cZtgE" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 10：新算法 - 首选优化。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们的增强功能是通过按升序对未充分利用的节点或低于平均水平的节点进行排序来优先排序较小占用的DataNode，以首先平衡过度利用的节点中的数据，然后按降序排序高于平均水平的节点，以便平衡时，中间的节点不会进入图片，以防止递归平衡。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-better-observability"&gt;&lt;strong&gt;更好的可观察性&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;我们没有关于同一节点组、同一机架和任何其他机架之间过度利用和未充分利用、过度利用和低于平均利用率以及未充分利用和高于平均利用率之间形成的 DataNode 对的度量以及其他相关度量。因此，我们无法校准这些对之间的流量分配。为了找出可以在哪里增加 DataNode 对以提高吞吐量，我们创建了一个新的仪表板。&lt;/p&gt;&lt;p&gt;最后，我们添加了 10 多个指标来跟踪算法更改的性能，这将有助于我们更多地校准平衡器的自定义算法。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/qymsO6tHpnV1x5Re2lVFYtX5UqTArgNP0PT7JTLi2aua8DL9-GTRTMbFQZ7fF-WccCBJvmv5zXP72Akx1ejdFgBH2YdtFa_4tgz1CHFWyonX74vzT8OpAjRaGqDTUdNFWPAYgnGiJXaq7bg_7UtwbEw" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 11：我们的指标仪表板快照。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-results"&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;通过平衡算法的优化，我们将吞吐量提高了 5 倍以上，没有任何 DataNode 的利用率高于 90%，并且总体上降低了 DataNode 的使用率。此外，现在不需要部署仅使用某些硬编码节点来平衡数据的手动平衡器，因为我们在算法中的优化已经解决了这一问题。&lt;/p&gt;&lt;p&gt;作为我们新算法的一部分 -&lt;/p&gt;&lt;ul&gt;&lt;li&gt;吞吐量增加——我们将吞吐量增加了 5 倍以上。&lt;/li&gt;&lt;li&gt;降低高使用率的数据节点——我们将利用率高于 90% 的数据节点降低到 0。&lt;/li&gt;&lt;li&gt;数据节点的利用率相同——减少数据节点的总体使用量并使它们的容量相同。对于我们最大的集群，所有 DataNode 的利用率都低于 85%。&lt;/li&gt;&lt;li&gt;更好地管理容量——HDFS 集群的集群利用率从 65-66% 增加到 85% 左右，但我们遇到了容量瓶颈。尽管集群利用率比以往任何时候都高，但我们现在没有高度占用的数据节点。 &lt;/li&gt;&lt;/ul&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/xLa6b1OocD2j8moRGaxLJL_qbjP_xD412Zib_vZv3uYV-tXefy1Vq8IZK4Y1k8F-B_lWdetYp4_-xunCBgCdB3Ov0hhpnuKlLVARGodpE6nUURsocv7menNOQKubFT5oiBwCM7yyYfsmw4R1P64UMZ4" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 12：由于算法更改，DataNode 处于类似水平，并且我们最大的集群的利用率低于 85%。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/eO5trlhcsa5iPseVoe0deceN0afiwUstj3oyk95aGYV4xV6vO9ap3juytv9bnLQMitL88-tnRmKblbiVzmE6Li9vmAG0aRWXQ_Y5rIzo8Z846ZFOtm6BMoaFwHcQzIw8BZVgW4n2-1OTRolCH9LSnRE" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 13：反映 DataNode 偏差减少的面板。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/uqyVOYZWIMQ33KfRVuA4LeLDiASqtaMThAef2CjJ8Qa2_mNvgi51nJcH2A1VmhML8yXyE7e_cHmD8_5-zgS2OUe6PqOaEZQBbfNYvo_npxkCxKaKisWB_ZRWyOQQiN8Ox8uomG_T6DGJjR4dRPVU7Lc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 14：平衡器算法更改之前 – 使用率高于 90% 的 Datanode 为 50.8%。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/8jioc04QB8VJcyCm7bKU-IEx6cbiTgLeBe9O0aRb9CR4nwU8o4IRzQScNFOjhSns5XDspdY-u3cK5iirYw7QH9dwrCNoFoUfstbTMRuciCWxR6CHZXFTDtT_p-wuCHVYko3wmssd4f2PJnUXPa6HbPU" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 15：平衡器算法更改后 – 使用率高于 90% 的 Datanode 低于 0。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-full is-resized"&gt;&lt;img alt="" class="wp-image-1082512" height="662" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Figure-16-Cluster-previous-capacity.png" style="width: 700px; height: auto;" width="844" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 16：我们的集群之一，集群利用率较低，约为 65%。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/FUzDUIGryAJWwVwckoZQPUKatRhcPpBWOxQrGHXh9P8-y3mOTVcgJEnJJjCHromXrwQtbz1T_7t7V7TEtQ9lNT9XI4IabGVADQ2rIzXK3FeDb4Zpd93h4i0a_3Y0oDCGRdxiNx6iGwomsnTU4tqmgBM" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 17：上述同一集群的集群利用率增加至 83% 左右。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/4xMTrAtGQ4KGaHED3rgIgLPSWn3YMy25QcXsCD4uhPn3YT8M9_PiyKp7NVwdqqJexncQPxAdWg7EFk_jIQR8nYO0hPn-IAU7QA2ho2syCDMroCNi7jSpnCDXDSuYOCQgf3EcoTwV4vT-Spp1WraoKkk" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 18：由于算法更改，吞吐量增加了 3 倍以上。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;在 HDFS 集群中，数据可能会在不同 DataNode 之间出现偏差，并可能导致节点上的 I/O 较高，从而导致速度缓慢或下降，从而导致数据丢失。新算法将有助于更快地平衡数据节点，以实现更高的效率、服务可靠性和高性能，同时防止更高的缓慢概率、更高的节点故障风险和数据丢失。&lt;/p&gt;&lt;p&gt;在 Uber 中，我们将此更改部署到多个集群以提高平衡吞吐量。我们正在为我们的优化提供一个开源补丁。 Uber HDFS 团队继续致力于解决类似的数据分布问题——考虑到我们的规模，即使是很小的改进也可以带来巨大的收益。&lt;/p&gt;&lt;p&gt; [1] Uber 将具有不同访问温度的数据保留在专用集群中，以实现更好的可靠性和成本效率。我们应用热分层将数据从热集群移动到热集群，并采用EC转换将数据移动到具有纠删码功能的集群，从而节省了50%的容量。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;“Apache®、Apache Hadoop® 和 Hadoop® 是 Apache Software Foundation 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。”&lt;/em&gt;&lt;/p&gt;</description><pubDate>Thu, 14 Mar 2024 05:30:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/balancing-hdfs-datanodes-in-the-uber-datalake/</guid></item><item><title>负载平衡：处理异构硬件</title><link>https://www.uber.com/blog/load-balancing-handling-heterogeneous-hardware/</link><description>&lt;h1 class="wp-block-heading" id="h-overview"&gt;&lt;strong&gt;概述&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;这篇博文描述了 Uber 通过更好的负载平衡来高效利用硬件的历程。这里描述的工作持续了一年多，涉及多个团队的工程师，并实现了显着的效率节省。这篇文章介绍了技术解决方案以及我们实现这些解决方案的发现过程——在很多方面，旅程比目的地更艰难。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-background"&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://www.uber.com/blog/better-load-balancing-real-time-dynamic-subsetting/" rel="noreferrer noopener" target="_blank"&gt;更好的负载平衡：实时动态子集 | Uber 博客&lt;/a&gt;是一篇相关的博客文章，早于此处描述的工作。我们不会重复背景知识——我们建议浏览一下我们的服务网格的概述。我们还将重复使用相同的字典。这篇文章重点介绍通过上述服务网格进行通信的工作负载。这涵盖了我们绝大多数的无状态工作负载。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-problem-statement"&gt;&lt;strong&gt;问题陈述&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;2020 年，我们开始致力于提高 Uber 多租户平台的整体效率。我们特别注重减少运行无状态服务所需的容量。在这篇博文中，我们将介绍各个团队做出合理决策如何导致资源使用效率低下，我们如何分析问题和不同的方法，以及如何通过改进负载分配，让团队安全地提高 CPU 利用率并降低成本。这篇文章仅关注 CPU，因为这是我们的主要限制。&lt;/p&gt;&lt;p&gt;首先，了解一些背景：在 Uber，大多数容量决策都是分散的。虽然我们的平台团队提供了推荐的目标和工具（例如自动缩放器），但采用特定目标的最终决定取决于每个产品团队/组织。预算流程的存在是为了限制无限的分配。&lt;/p&gt;&lt;p&gt;作为预算过程的一部分，我们注意到我们认为利用率水平不合理地低。然而，提高利用率的尝试引起了产品团队的担忧——他们正确地担心提高利用率会危及系统的可靠性并影响其可用性/延迟目标。&lt;/p&gt;&lt;p&gt;问题的原因被认为是网络负载平衡不理想。许多工作负载的任务的 CPU 使用率高于平均水平。这些异常值在正常操作期间工作得很好，但在故障转移期间却很困难，并且不违反 SLA 的愿望导致我们的平均利用率下降。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/VPz0oGg-6KU9AQlKl7p6jeMb71w1ExYry6MeA5yDkQD_XQb62eP9S48IH_ZfGItt4tzYYz6TlzmYYaShRNRFe2x01S75ACNiS_T-OjaLcGO6FyfmyJF21eH0ks9v1fxPzvkBA-3cl0CGBKT3bY8oP-E" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：典型的“不平衡图”。每一行代表容器的 CPU 使用率。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/gV0L88878EKTUFagchXUUUkaTB0AieIEAzm4DDNKfjaATpUjMR_0yFE8vK-OY5w37lFhRS6DIRFZxEa-LE_pGYsk2PU4wQdEOfanI9pXjzqnAClzepSHXlA78fUwifiXWWF7QWlhc4Bo9WWf4g8-yfk" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：一个不太明显的情况：容器利用率分布在一个频带内，但有些容器的利用率高于其他容器。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-asymmetry-of-impact"&gt;&lt;strong&gt;影响不对称&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;负载不平衡的一个重要方面是&lt;strong&gt;其影响的不对称性&lt;/strong&gt;。想象一下这样的场景：100 个工作负载中，有 5 个工作负载未得到充分利用。这会影响效率，但成本相对较低——我们没有尽可能高效地使用 5% 的机器。&lt;/p&gt;&lt;p&gt;如果情况反过来，同样的5个工作负载被&lt;em&gt;过度&lt;/em&gt;利用，情况会严重得多。我们可能会影响客户体验并可能影响系统的可靠性。避免这些热点的简单解决方案是降低整个集群的平均利用率。这现在将产生&lt;em&gt;更显&lt;/em&gt;着的影响： &lt;strong&gt;95% 的工作负载未得到充分利用&lt;/strong&gt;，这意味着（财务）资源的浪费更加严重。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-forest-and-the-trees"&gt;&lt;strong&gt;森林和树木&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;由于异常值很容易被发现，我们最初专注于一一修复和追踪它们，试图尽快找出根本原因并单独修复每个问题。这些单独修复的结果并不总是符合预期。我们的一些更改的影响低于预期或仅影响系统的一部分。同样，后来的其他变化也带来了意想不到的重大改进。这是由于几个独立的问题正在发挥作用。这种“问题森林”导致工作基本上是连续的——只有在更大的兄弟问题得到解决后，我们才会发现一个新的、更小的问题。&lt;/p&gt;&lt;p&gt;回想起来，“意外”部分可以通过更严格的分析来减轻——我们可以更多地了解系统并提前收集更多样本。不过，工作的顺序可能是相同的——只有通过我们学习如何理解和衡量系统的过程。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-measuring-the-impact"&gt;&lt;strong&gt;衡量影响&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;也许令人惊讶的是，直到最后，该项目最具争议的方面之一就是衡量影响。讨论涉及来自不同团队和组织的人员在不同时间加入和离开该项目。每个相关方对问题、优先级和潜在解决方案都有有价值但略有不同的观点。&lt;/p&gt;&lt;p&gt;仅仅持续衡量影响就非常复杂。显然，我们应该测量异常值 - 我们很快决定使用给定工作负载中利用率排名第 99 位的任务的 CPU 利用率。经过一番讨论，我们同意使用平均值作为基础，留下 p99/平均值作为&lt;em&gt;不平衡指标&lt;/em&gt;。&lt;/p&gt;&lt;p&gt;然而，即使这样也含糊得令人惊讶：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;工作负载在跨多个区域的多个集群中运行。 p99/平均值应该在所有实例中计算还是单独为每个集群计算？如果是针对每个集群，我们如何权衡结果？这一决定&lt;em&gt;极大地&lt;/em&gt;影响了最终的数字。&lt;/li&gt;&lt;li&gt;工作负载在多个区域中运行，但与区域不同的是，我们的区域表现出很强的隔离性——向何处发送流量不受网络控制。因此，网络团队可能关心与业务不同的指标。&lt;/li&gt;&lt;li&gt;典型的工作负载具有周期性模式——服务可能在一周中的特定一天最繁忙，而在其他时间则未得到充分利用。我们应该只测量高峰时的不平衡情况还是全天测量不平衡情况？如果处于高峰期，多长时间的时间范围应被视为高峰期？我们只关心单周峰值吗？&lt;/li&gt;&lt;li&gt;我们的工作负载通常以主动-主动模式运行，每个区域都有一些备用容量用于潜在的故障转移。在这些故障转移期间，负载不平衡最为重要——我们是否应该在那时才尝试测量它？如果是这样，我们的测量频率将会减少——通常，我们每周都会得到一个简单的样本。&lt;/li&gt;&lt;li&gt;工作负载很吵。服务推出通常会导致不平衡峰值（随着新容器的到来并预热）。某些工作负载可能会很快推出（每次增量），但每天会通过 CD 管道推出数十次。其他工作负载要慢得多，单次部署可能需要几个小时。两种类型的推出都可以与高峰时间重叠。最重要的是，还有“非典型事件”，例如临时性能下降、流量耗尽、负载测试或与事件相关的问题。&lt;/li&gt;&lt;li&gt;大多数工作负载遵循“标准”模式，但一些（更关键的）服务已被划分为具有单独路由配置的自定义分片。同样，一小部分基本工作负载还可以通过自定义对等路由进行访问。最后，另一小部分服务在专用主机上运行。这些尺寸可能会影响我们的跟踪。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;一旦我们确定了每个工作负载指标，问题就会扩展到多服务：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们如何权衡最终得分中的各个工作负载？&lt;/li&gt;&lt;li&gt;每个服务的等级（优先级）如何影响其在最终得分中的权重？&lt;/li&gt;&lt;li&gt;不同的工作负载具有不同的周期模式这一事实是否会影响分数？工作负载通常有每周和每日的峰值，但这些峰值不是同时出现的。&lt;/li&gt;&lt;li&gt;我们能否将最终指标分解为子组件来跟踪各个区域或集群的不平衡情况？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些指标必须实时用于开发和监控——在这里，我们关心尽可能高的精度，通常是亚分钟。然而，相同的指标必须在很长一段时间内（数年）可用，我们需要将数据汇总成日大小的块，同时牢记之前的所有权重考虑因素。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-actual-numbers"&gt;&lt;strong&gt;实际数字：&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;最终，我们创建了一个“持续失衡指标”。对于每个工作负载，我们计算每分钟的 p99（例如，5 个核心）和平均（例如，4 个核心）CPU 利用率。结合容器的数量，我们可以计算出“浪费的核心”。对于上面的示例，10 个容器将导致 10*4=40（核心）&lt;em&gt;使用，&lt;/em&gt; (5-4)*10=10 个核心&lt;em&gt;浪费&lt;/em&gt;，最终指标为 1+10/40=1.25。这直观地映射到人类在实时调试时可以执行的“标准”p99/平均计算 125%。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/ZyU1H3XwK_fGjpDhsyhcKROE_XnjnbhmTKc_AkW1b-yvzLpTJ4TbnDiAqQ_b5jcOhM-4RFnaqrjVTFUHfNVqCRgh_299GXdMaUQeRX5Ca8eGP8mO8WrGDaHoo77l1OL5uOJJjHnNCFIqUEh3EgnzauY" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：不平衡的理论定义。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;随着时间的推移，这实际上变成了两条曲线下的面积比：p99 和平均利用率。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/Ed94kW9bEsKmlR9f6liB9hLJFJTRA2eWNbC61KrTCvqjRR16FF_17rG_29z2qqzrzobImlGT0S-GrF0ISBBjWaXnEV2TGRwIMFr_8R3E4lM5D1exq-LUcqAw4YjIVVjoVFbRYXowXbpESs_2zLlcIUM" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：实时仪表板上的连续不平衡指示器。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;这种方法的好处是，由于浪费和利用率是按核心的绝对数量计算的，因此它允许我们以自定义的任意维度聚合它们：每个服务、每个服务每个集群、每组服务、每个集群、每个区域。同样，任何时间窗口（小时、天、周）自然有效——就像对一系列整数求和一样简单。此外，该指标自然会给予“繁忙”时段更高的权重——高峰期的不平衡比非高峰期的不平衡更为严重。缺点是难以向人类解释该指标，但我们发现“加权 p99/平均值”的近似值是可以接受的。&lt;/p&gt;&lt;p&gt;另一种计算“每周 p99 的 p99”和“每周平均值”的比率的方法更容易在单个服务的基础上进行解释，但对随机事件（耗尽、故障转移、负载测试、部署）高度敏感，这让它变得很吵。此外，跨服务加权并不那么简单。&lt;/p&gt;&lt;p&gt;上述指标可通过 Grafana 中的实时指标和 Hive 中的长期存储来获取。我们需要编写自定义管道来每天预处理指标以实现可视化。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-different-slicing"&gt;&lt;strong&gt;不同切片&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;关于测量负载不平衡的一个特殊问题值得指出：如何分割数据会极大地影响结果。人们很容易从小块（集群、区域、区域）开始，然后“平均”不平衡。遗憾的是，这在实践中行不通。例如，两个集群的（平均）p99/平均比率可能为 110%，但是当纵观整个工作负载时，不平衡可能要高得多，在我们的案例中高达 140%。同样，将两个较高不平衡性的集群组合起来可能会导致较低的不平衡性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-addressing-the-issues"&gt;&lt;strong&gt;解决问题&lt;/strong&gt;&lt;/h1&gt;&lt;h2 class="wp-block-heading" id="h-the-first-step-getting-hacky-data-first"&gt;&lt;strong&gt;第一步：首先获取（hacky）数据&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;我们首先构建 Grafana 仪表板以实现实时可观察性。这使我们能够实时单独衡量每个服务的影响，但无助于理解根本原因。虽然假设负载平衡有问题，但我们“真的”不知道。最初的问题是缺乏可观察性，我们面临两个问题。&lt;/p&gt;&lt;p&gt;首先，由于基数问题，我们的负载均衡器没有按每个后端实例发出统计信息。由于许多服务运行数千个容器和数百个程序，这会导致我们的代理中的内存使用量爆炸，并使统计数据无法查询，即使是中等规模的服务。幸运的是，那个夏天的一个实习生项目添加了在新的指标命名空间（保持现有统计数据不变）上选择性加入的统计数据（节省代理内存使用）的能力。与&lt;a href="https://chronosphere.io/learn/how-can-recording-and-roll-up-rules-help-your-metrics/" rel="noreferrer noopener" target="_blank"&gt;汇总规则&lt;/a&gt;一起，我们现在可以内省大多数服务（只要我们一次只为其中一些服务启用额外的可见性）。&lt;/p&gt;&lt;p&gt;其次，我们失去了跨计算和网络堆栈唯一识别实例的能力。当时，我们可以看到每个目标的 CPU 使用情况，但无法轻松地将其映射到容器。由于我们广泛的 IP 目标范围和动态端口使用&lt;em&gt;，主机：端口&lt;/em&gt;的可用“唯一标识符”会破坏我们的指标（同样， &lt;a href="https://chronosphere.io/learn/what-is-high-cardinality/" rel="noreferrer noopener" target="_blank"&gt;基数&lt;/a&gt;）。关于适当解决方案的讨论此前已停滞了几个季度。最终，网络堆栈实现了一个基于 IP 地址排序和发出基于整数的实例 ID 的短期解决方案。这些在部署中并不稳定，但与一些更黑客的脚本一起，使我们能够获取所需的数据。&lt;/p&gt;&lt;p&gt;这一步提供了重要的教训：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;始终首先获取数据&lt;/li&gt;&lt;li&gt;恰到好处、有针对性、孤立的黑客攻击可能非常有用&lt;/li&gt;&lt;li&gt;您不需要完美的可观察性来得出正确的结论&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-manual-analysis"&gt;&lt;strong&gt;手动分析&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;一旦我们深入了解了这个问题，我们就挑选了一些大型服务并尝试分析根本原因。令人惊讶的是，负载平衡并没有出现问题——在 1 分钟窗口（我们当时的 CPU 统计分辨率）下，RPS 分布几乎是完美的。每个容器接收的请求数量几乎相同，大多数应用程序的差异低于 0.1%。然而，在同一窗口内，CPU 利用率差异很大。&lt;/p&gt;&lt;p&gt;经过几周的调查，我们能够量化几个独立的原因：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一些重要的流量来源被迫失衡。例如，我们的许多系统都是“城市感知”的，城市总是位于单个区域。这自然会为每个地区带来不同的交通量，并且随着城市的醒来和入睡，比例不断变化。&lt;/li&gt;&lt;li&gt;服务跨集群内和跨集群的多个硬件 SKU 运行。&lt;/li&gt;&lt;li&gt;即使理论上相同的硬件也表现出显着的性能差异。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;一些不平衡被留在“未知”的桶中。事实证明，其中大部分是我们的可观察性问题。我们目前将剩余部分（小于原​​始不平衡的 20%）归因于&lt;a href="https://en.wikipedia.org/wiki/Cloud_computing_issues#Performance_interference_and_noisy_neighbors" rel="noreferrer noopener" target="_blank"&gt;嘈杂的邻居&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;下图显示了对 2020 年我们最大的服务之一的初步分析。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/IovK_kUSNl_76Da7EKegaYqylzW4OiEV2s09RUzrt8Ow18SAqVzjyVT2Wrj3HNseZCmCS_J1WN-NQ0tNJAbVO5OvknwSFOnFDpAmldb5QDSGtTrFedRGz9OBgOnX2aMe1ymxQui-d4sEXFATK81vruM" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：了解不平衡。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-forced-to-build-long-term-aggregations"&gt;&lt;strong&gt;被迫建立长期聚合&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;那时，我们想从任何容易实现的目标开始。 &lt;a href="https://www.uber.com/blog/better-load-balancing-real-time-dynamic-subsetting/" rel="noreferrer noopener" target="_blank"&gt;更好的负载平衡：实时动态子集 | Uber 博客&lt;/a&gt;为我们提供了一些可以调整的旋钮。然而，这并不容易，反而提出了一个新问题。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/AHpjR9Jv7KdKJ-xuaOkLWwL9iswUHo2Of3qYZlMnURcDdhlawPN6XfL9pf96j3rFVjclApy_BT1IOEfX1w7HHzVBiuljPda6NKXGWgzQ839BfeZw53O1AYa-hYsk0qgq-2cAIEIF5RcnyaKf5ETUuSo" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：单个服务的每周 CPU 使用率模式。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们的服务表现出每日和每周的大量周期（见上文）。最重要的是，我们经常看到由故障、部署、故障转移或临时事件引起的峰值。推出更改后，人类只能发现巨大的改进（20%+），但我们的更改太微妙了。&lt;/p&gt;&lt;p&gt;这导致了前面段落中解释的可观察性决策。我们构建了基于稳定和峰值弹性指标来聚合长期数据的管道。最重要的是，我们可以按集群、区域、区域或服务组对指标进行切片——这反过来又可以让我们调查更多“可疑”行为。&lt;/p&gt;&lt;p&gt;一些预先存在的旋钮可以让我们减少服务网格引起的负载不平衡部分，但这只是整个问题的一小部分。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-possible-solutions"&gt;&lt;strong&gt;可能的解决方案&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;显然，第一步是查看底层硬件配置和操作系统设置。一些单独的线程开始研究这些。&lt;/p&gt;&lt;p&gt;解决硬件异构性需要更复杂的过程。许多方法都是可能的，来自：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;修改&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/sec-cpu" rel="noreferrer noopener" target="_blank"&gt;CFS 参数&lt;/a&gt;，使队列中的每个主机看起来相同，尽管底层硬件不同。&lt;ul&gt;&lt;li&gt;这个选项很有吸引力，但由于对各种软件堆栈（如&lt;a href="https://pkg.go.dev/runtime#GOMAXPROCS" rel="noreferrer noopener" target="_blank"&gt;GOMAXPROCS&lt;/a&gt; ）的影响不明确，最终被驳回。回想起来，这也阻止了我们利用&lt;a href="https://www.uber.com/blog/avoiding-cpu-throttling-in-a-containerized-environment/" rel="noreferrer noopener" target="_blank"&gt;cpu 集进行配置。&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;修改主机到群集的放置以实现统一的群集。&lt;/li&gt;&lt;li&gt;修改每个服务的集群布局以保证稳定但不统一的主机选择。&lt;/li&gt;&lt;li&gt;转向云式主机管理，每个团队将选择特定类型的硬件。&lt;/li&gt;&lt;li&gt;许多可能的服务网格更改可以实现更好的&lt;em&gt;负载&lt;/em&gt;平衡。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="Screenshot of a spreadsheet, fields colored by the feasibility" src="https://lh7-us.googleusercontent.com/YC4s0sGZby4epTYOC36Um_cXU12K4MNkNHr_RSpt31Nijf4xB2IrGiPs3TJosQOVCrfsNnNov_ym5o2A9SLApgHEQl3u3Uu_JpuEHsh4w2gHuytW0lxB09_iU0oOdzf0p_6tpnAq7muT8DtwhUhcBcw" title="可能的修复（故意不可读）" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：选项矩阵（故意模糊）&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;在可能的选项中，出于多种原因选择了对服务网格进行更改。从技术上讲，我们层上的更改不需要更改数据中心的物理布局，也不需要每个服务的迁移。从战术上讲，我们还可以快速地将更改交付给大多数服务。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-changes"&gt;&lt;strong&gt;变化&lt;/strong&gt;&lt;/h1&gt;&lt;h2 class="wp-block-heading" id="h-hardware"&gt;&lt;strong&gt;硬件&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;虽然硬件 SKU 内存在根本差异，但我们发现硬件、固件和低级软件存在许多问题。它们的范围包括操作系统设置、CPU 调速器设置、固件版本、驱动程序版本、CPU 微代码版本，甚至内核版本与 Intel HWP 不兼容。造成这种情况的一个普遍根本原因是，从历史上看，一旦硬件被摄入并出现在机群中，除非出现问题，否则它就不会受到影响。但随着时间的推移，这导致了机器之间的漂移。&lt;/p&gt;&lt;p&gt; Uber 在混合云/私有设置中运行，因此我们自然也遇到了特定于云的问题。与其他公司一样，我们已经看到了多个理论上相同配置的虚拟机性能不相似的情况（ &lt;a href="https://www.reddit.com/r/aws/comments/547xbx/netflix_found_5x_performance_variation_between/" rel="noreferrer noopener" target="_blank"&gt;这&lt;/a&gt;仍然是真实的）。同样，我们也看到过在本地运行良好的工作负载在云上引发问题的情况。更糟糕的是，云意味着底层基础设施细节的可见性降低。&lt;/p&gt;&lt;p&gt;如果没有最近完成的&lt;a href="https://www.uber.com/en-IN/blog/crane-ubers-next-gen-infrastructure-stack/" rel="noreferrer noopener" target="_blank"&gt;Crane 项目&lt;/a&gt;，解决所有这些问题几乎是不可能的——我们可以在没有人工参与的情况下测量、修复和推出对数万台机器的更改。现在，所有发现的问题都会被自动检测和修复。&lt;/p&gt;&lt;p&gt;这些修复的一个明显好处是它们适用于每个工作负载，无论它如何处理或发起其工作（Kafka、Cadence、RPC、计时器、批处理作业等）。除了改善负载不平衡之外，它们还为我们提供了有效的可用容量——一些 CPU 一夜之间“变得更快”。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-observability"&gt;&lt;strong&gt;可观测性&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;可观察性是这个问题的一个有趣的部分。在项目开始之前，我们知道由于 1 分钟窗口大小，我们在样本收集方面存在限制，但我们发现了更多问题。&lt;/p&gt;&lt;p&gt;从技术上讲，这些问题是由&lt;a href="https://en.wikipedia.org/wiki/Cgroups" rel="noreferrer noopener" target="_blank"&gt;cgroups、&lt;/a&gt; &lt;a href="https://github.com/google/cadvisor" rel="noreferrer noopener" target="_blank"&gt;cexporter&lt;/a&gt; 、我们内部&lt;a href="https://prometheus.io/" rel="noreferrer noopener" target="_blank"&gt;Prometheus&lt;/a&gt;指标抓取器和&lt;a href="https://github.com/m3db/m3" rel="noreferrer noopener" target="_blank"&gt;m3&lt;/a&gt;之间的交互引起的。特别是，由于指标以不断增加的方式发出，管道中任何地方统计数据收集的任何延迟都会导致百分位数计算中出现（大的）人为峰值。我们投入了大量的工作来保留样本的时间戳以及妥善处理目标和收集器服务的重新启动。一个示例 &lt;a href="https://github.com/google/cadvisor/issues/2913" rel="noreferrer noopener" target="_blank"&gt;问题&lt;/a&gt;是有效地破坏了任何足够大的服务的数据收集。&lt;/p&gt;&lt;p&gt;可观察性问题的一个令人着迷的方面与人类互动有关，或者说人类不可信这一事实。在项目早期，我们询问服务所有者什么级别的容器利用率会导致用户影响（延迟增加）。有趣的是，几个月后，在我们推出修复程序后，当我们再次询问时，我们收到了相同的答案。这两种说法都无效，因为我们知道旧数据是错误的。最终，人类的非理性导致了净效率的胜利：服务所有者最终（有效地）更热地运行他们的服务，同时认为什么都没有改变。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-load-balancing"&gt;&lt;strong&gt;负载均衡&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;正如&lt;a href="https://www.uber.com/blog/better-load-balancing-real-time-dynamic-subsetting/" rel="noreferrer noopener" target="_blank"&gt;更好的负载平衡：实时动态子集 |&lt;/a&gt;中所述。 &lt;a href="https://www.uber.com/blog/better-load-balancing-real-time-dynamic-subsetting/" rel="noreferrer noopener" target="_blank"&gt;Uber 博客&lt;/a&gt;，我们的服务网格在两个层面上工作。最初，控制平面发送&lt;em&gt;分配&lt;/em&gt;决定应向每个目标集群发送多少流量。这里决定了集群之间的不平衡性。&lt;br /&gt;随后，数据平面遵循此分配，但随后它负责选择正确的主机 - 这里发生第二级集群内负载平衡。虽然我们考虑改变这个模型，但我们保持不变，并为每个级别推出了两种解决方案。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-inter-cluster-imbalance"&gt;&lt;strong&gt;集群间不平衡&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;在 Uber，服务在多个地区的多个区域运行。由于每个区域在不同的时间出现，因此无法保证每个区域中的主机相同 - 通常，区域越新，它们拥有的硬件就越新。区域之间的性能差异会导致CPU不平衡。&lt;/p&gt;&lt;p&gt;我们最初的方法是为每个区域设置一个静态权重；然后，权重将用于负载平衡，以便具有更快硬件的区域接受更多请求。每个区域的权重计算为该区域中部署的每个主机的标准化计算单元 (NCU) 因子的平均值。 NCU 因子根据基准分数衡量主机 CPU/核心性能，其中分数取决于每周期核心指令（每个时钟周期核心完成多少工作）和核心频率（多少个时钟周期）的乘积每秒可用）。&lt;/p&gt;&lt;p&gt;然后，我们可以使用静态区域权重作为乘数，将更多流量发送到更强大/更快的区域。&lt;/p&gt;&lt;p&gt;具有更高乘数的更快区域将按比例路由更多流量，以提高 CPU 利用率，从而缓解 CPU 不平衡。&lt;/p&gt;&lt;p&gt;例如，如果某个服务在区域 A（权重 = 1）和 B（权重 = 1.2）中部署了 10 个实例，则负载平衡将按照 B 有 12 (10 * 1.2) 个实例进行，这样 B 将收到更多请求比 A。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/L22FN7eamJeUaNg5UhAokiSDGFniHnCMQqexYTjB-BIGI_bUVBreGefBUA1dqB3iOcbUUe6rVj9noQvx3Doqxjqigl7GkEk0aEYDYIOYmAVv9crDdtH6vwqrnQSwazMEU5nwjggUTjsRrhyDKWPqNkA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：区域权重&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;这种方法的效果出人意料地好——我们能够以相对较小的努力缓解大部分不平衡问题。然而，存在一些问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;区域权重是区域中所有主机的估计值（平均 NCU 因子）。然而，服务部署在区域中最快/最慢的主机上可能会非常幸运/不幸。&lt;/li&gt;&lt;li&gt;尽管不频繁，但我们经营的区域会因开工或停工而发生变化。此外，在启动期间，我们通常会逐渐摄取硬件，这可能需要多次更新。&lt;/li&gt;&lt;li&gt;有时，我们会将新硬件引入旧区域以调整其大小或更换损坏的硬件。该硬件可以是不同类型的，因此需要调整权重。&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-dynamic-host-aware-cluster-load-balancing"&gt;&lt;strong&gt;动态主机感知集群负载平衡&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;因此，我们重新审视了这个问题，并投资了一种先进的解决方案：主机感知流量负载平衡。&lt;/p&gt;&lt;p&gt;这种方法通过查看服务实例部署到的确切主机、收集其服务器类型，然后更新每个服务的集群之间的负载平衡来解决这些缺点。这是通过让我们的发现系统了解主机（通过 IP）、其主机类型和权重的映射来实现的，这样对于部署在集群中的给定服务，发现系统可以向我们的流量控制提供额外的&lt;strong&gt;&lt;em&gt;权重&lt;/em&gt;&lt;/strong&gt;信息系统。下图显示了一个示例： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/BTH2IqexwVovC1iquHIIHhv744jyBweDXUPMKK4a5bDezGdqTbhfxk3SVVl5SZCz5bvZhFdg1td0ptbM1Hmy5SxzxxRBkDstE-jwYQzPSWQIPoukzhtztVliK1Gp6f3k6VUM6uSH5jLKGOsew_h7eH8" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：动态主机感知集群负载平衡&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;对于服务 Foo，如果我们平等对待每个实例，负载均衡比例应该为&lt;strong&gt;37.5&lt;/strong&gt; %/ &lt;strong&gt;62.5&lt;/strong&gt; %，而不是示例中所示的&lt;strong&gt;&lt;em&gt;36&lt;/em&gt;&lt;/strong&gt; %/ &lt;strong&gt;&lt;em&gt;64&lt;/em&gt;&lt;/strong&gt; %。如果主机跨越多代（我们的机群中不同主机之间的权重差异高达 2 倍），则差异可能会变得更加显着。&lt;/p&gt;&lt;p&gt;与静态权重方法相比，主机感知负载平衡动态调整每个服务的权重，以减少集群间的不平衡。由于很少引入新的主机类型，因此维护起来也更加容易。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-intra-cluster-imbalance"&gt;&lt;strong&gt;集群内不平衡&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;如前所述，集群内不平衡是主机上代理（称为 Muttley）的责任。每个代理都可以完全控制为每个请求选择正确的对等点。所有服务使用的 Muttley 原始负载平衡算法是最少挂起的，该算法会将请求发送到已知未完成请求数量最少的对等点。虽然以 1 分钟为间隔测量时，这导致了 RPS 几乎完美的平衡，但由于不同的硬件类型，它仍然导致 CPU 利用率不平衡。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-assisted-load-balancing-alb"&gt;&lt;strong&gt;辅助负载平衡 (ALB)&lt;/strong&gt; &lt;/h3&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/_CL-GbcOXQlLQSs4Aq-a2Q7NaKUOA7HjoTu_P_nt0NnJM1biDm26uHcmmuVlePy5vgZenjeQsxii3KraWa3AU6ixB51OUDJehHqHMBQaM5co9vnXPy4AokvL1plsofFDmuqISUQ2drgx9sPcZylHFiQ" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 10：辅助负载平衡简而言之。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们构建了一个系统，其中每个后端&lt;em&gt;协助&lt;/em&gt;负载均衡器选择下一个对等点。应用程序中间件层将负载元数据作为标头附加到每个响应。我们有效地建立了一个无需中央协调的协调系统。以前，每个 Muttley 只知道它造成的负载（加上它可以从延迟推断出的一些信息），现在，它动态地了解每个后端的总状态。这种状态不仅受到后端本身的影响（例如，在较慢的硬件上运行），而且还受到其他 Muttley 做出的决策的影响。例如，如果（随机）将后端选择到太多子集中，则系统会动态调整。这让我们稍后可以减少 ALB 上服务的子集大小。&lt;/p&gt;&lt;p&gt;虽然&lt;a href="https://sre.google/sre-book/load-balancing-datacenter/#weighted-round-robin-eKspTGCm" rel="noreferrer noopener" target="_blank"&gt;Google SRE 书中&lt;/a&gt;的简短提及部分启发了这种方法，但我们做出了一些不同的选择。这两项更改彼此相关，并试图简化该方法。我们打算稍后开始、评估并转向更复杂的解决方案 - 幸运的是，我们不必这样做。在实施后期，我们发现了一篇&lt;a href="https://netflixtechblog.com/netflix-edge-load-balancing-695308b5548c" rel="noreferrer noopener" target="_blank"&gt;Netflix 博客文章&lt;/a&gt;，并且我们独立得出了类似的结论。&lt;/p&gt;&lt;p&gt;首先，作为负载元数据，我们使用正在处理的并发请求数，以整数形式报告（q=1、q=2、..、q=100 等）。我们也考虑了报告利用率，但这并不是立即显而易见的（报告的利用率是否应该基于&lt;a href="https://man7.org/linux/man-pages/man2/getrusage.2.html" rel="noreferrer noopener" target="_blank"&gt;getrusage&lt;/a&gt;还是&lt;a href="https://en.wikipedia.org/wiki/Cgroups" rel="noreferrer noopener" target="_blank"&gt;cgroups）。&lt;/a&gt; Cgroup 更为自然，因为服务所有者使用它来跟踪他们的目标。尽管如此，它们还是带来了更多挑战——我们的基础团队担心每个 docker 容器独立抓取 cgroup 的成本，以及如果 cgroup 布局发生变化（包括在 cgroupsv2 迁移期间）可能发生的紧密耦合。我们可以通过与收集统计数据的主机恶魔集成来解决这个问题，但我们希望避免添加新的运行时依赖项。最后，仅使用逻辑整数就足够了（进行一些调整，如下所述）。此外，它允许在不更改负载均衡器代码的情况下覆盖每个服务 - 虽然绝大多数应用程序使用标准负载指示器，但一些（异步）应用程序覆盖它以更好地反映其负载。&lt;/p&gt;&lt;p&gt;第二个出发点是&lt;a href="https://www.eecs.harvard.edu/~michaelm/postscripts/handbook2001.pdf" rel="noreferrer noopener" target="_blank"&gt;两个随机选择的力量，&lt;/a&gt;而不是加权循环赛。由于我们只有一个整数作为负载指示器，所以 pick-2 实现看起来更简单、更安全。与上面类似，这工作得很好，我们不需要改变它。事实证明，这种方法对我们整个应用程序范围内的故障非常宽容。除了典型的崩溃循环或 OOMing 应用程序之外，我们还遇到过中间件的错误/错误实现未导致事件的情况。我们推测，由于加权循环法更加精确和“严格”，因此在某些情况下它可能会表现“更好”，但可能会导致&lt;a href="https://en.wikipedia.org/wiki/Thundering_herd_problem" rel="noreferrer noopener" target="_blank"&gt;类似雷群&lt;/a&gt;的情况。&lt;/p&gt;&lt;p&gt;在实现方面，每个 Muttley 使用&lt;a href="https://en.wikipedia.org/wiki/Moving_average#Modified_moving_average" rel="noreferrer noopener" target="_blank"&gt;修改后的移动平均值&lt;/a&gt;来保持每个对等点的分数超过 25 个之前的请求——这个值在我们的测试中效果最好。为了在 RPS 较低的情况下获得有意义的数字，我们将每个报告的负载增加了 1000。&lt;/p&gt;&lt;p&gt; pick-2 负载均衡器的一个有趣问题是“负载最多”的对等点&lt;em&gt;永远不会&lt;/em&gt;被选择。而且因为我们被动地发现对等点负载，所以我们也会刷新其状态，从而使其有效地未被使用，直到另一个对等点变得更慢。我们最初通过实施“失败者惩罚”来缓解这一问题，每当一个节点失去选择时，其“负载值”就会在内部减少——因此，如果有足够的损失，该节点将再次被选择。事实证明，这对于大调用者实例计数低 RPS 的场景效果不佳，有时需要几分钟才能重新选择对等点。最终，我们将其更改为时间衰减，其中同行的分数根据上次选择时间而降低。我们目前使用 5 秒的半衰期来进行分数衰减。&lt;/p&gt;&lt;p&gt;我们还实现了一项内部称为“吞吐量奖励”的功能。这源于经验观察，即较新的硬件可以更好地处理并发请求。我们注意到，当在不同硬件上的两个对等点之间进行负载平衡并且两个对等点报告相同的“负载值”时，我们如预期的那样，向速度更快的对等点发送更多请求。但是，较快对等点的 CPU 利用率（已处理=15，CPU=10%，Q=5）仍低于较慢对等点（已处理=10，CPU=12%，Q=5）。为了弥补这一点，每次对等点“完成”一个请求时，我们都会稍微减少其负载以向其推送更多请求。对等点相对于子集中其他对等点的速度越快，它收到的“吞吐量奖励”就越多。此功能使 P99 CPU 利用率降低了 2%。&lt;/p&gt;&lt;p&gt; ALB 设计文档的一个重要部分（大部分）致力于可能的替代方案。我们认真考虑过，不是将负载元数据附加到每个响应，而是使用中央组件来收集和分发数据。人们担心元数据可能会消耗大量可用带宽。我们内部有两个表面上看起来相关的系统。第一个是集中式健康检查系统，几乎实时收集车队中每个集装箱的健康状态。第二个是上一篇博文中描述的实时聚合系统。&lt;/p&gt;&lt;p&gt;&lt;br /&gt;事实证明，重用其中任何一个都是不可行的：运行状况检查系统可以轻松地从所有容器收集负载状态，但收集后，该系统被设计为很少分发运行状况更改 - 绝大多数时间，容器仍然存在健康。然而，负载平衡指标会根据设计不断变化。由于我们运行平面网格（每个容器都可以与每个容器通信），因此我们需要不断地将数百万个容器的数据分发到数十万台机器，或者构建一个新的聚合和缓存层。同样，负载报告聚合系统也不匹配——它以低几个数量级的基数对每个集群的聚合值进行操作。&lt;/p&gt;&lt;p&gt;&lt;br /&gt;最终，我们对所选择的（基于响应标头）方法感到满意。它实施起来很简单，并且使成本归因变得容易——推动更多 RPS 的服务会带来更高的带宽成本。从绝对数字来看，与每个请求附加的其他跟踪/身份验证元数据相比，额外元数据（每个请求约 8 个字节）的成本几乎是看不见的。&lt;/p&gt;&lt;p&gt;延迟是“分布式”与“集中式”负载数据收集的一个有趣的方面。从理论上讲，响应标头方法接近实时，因为负载附加到每个响应。然而，由于每个 Muttley 都需要独立发现这一点，然后对之前的响应进行平均，因此对于基于低 RPS 的场景，该发现可能需要一些时间。基于健康检查的方法需要完整的往返（通常约为 5 秒），但会立即分发到所有调用方实例。&lt;/p&gt;&lt;p&gt;&lt;br /&gt;然而，如果我们实现了它，由于上一段中列出的带宽问题，我们可能会将推送频率降低到 1 分钟左右。这可能足以修复硬件引起的偏斜，但可能没有其他问题，例如流量峰值，较慢的应用程序或故障转移。在不同情况下，两种方法的工作可能略有不同。不过，最终，我们对分布式方法很满意 - 它很容易推理，并且缺少可能失败的集中组件。&lt;/p&gt;&lt;p&gt;所选方法的一个缺点是它需要目标服务的合作。尽管需要最少的工作，但将其应用于数千个微服务将很艰巨。幸运的是，过去几年在Uber建造的大多数应用程序都使用了&lt;a href="https://github.com/yarpc/yarpc-go" rel="noreferrer noopener" target="_blank"&gt;通用框架&lt;/a&gt;，使我们能够快速插入所需的中间件。几项大型服务没有使用框架，但是同时进行的多年努力迁移了几乎所有服务。我们发现决定有利于该框架的决定，因为它具有复杂的效果 - 服务所有者还有一个理由投资移民。到我们写这篇文章时，几乎所有服务都在共同的框架上。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-static-component-alb-v1-1"&gt;&lt;strong&gt;静态组件 -  Alb V1.1&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;最初的推出不符合我们硬件引起的减少目标。主要原因是我们的硬件在大多数时间中都充分利用了不足 - 我们为区域故障转移和每周窥视提供了缓冲区。事实证明，凭借相对较低的容器利用率，旧硬件可能会爆发足够高，以使延迟差异在消耗更多的CPU时间时不可见期。尽管这意味着在压力下（当我们需要时）载荷平衡的效果要好得多，但它使产品工程师对我们的目标利用感到不舒服，但不平衡的不平衡看上去太高了。&lt;/p&gt;&lt;p&gt;我们在负载平衡中添加了第二个静态组件来解决这个问题。我们利用了一个事实，即在我们的设置中，主机的IP地址永远不会改变。由于代理自然知道目的地的IP地址，因此我们只需要将IP地址映射到相对主机性能。由于数据的静态性质，我们开始添加此信息作为构建时间配置的一部分。这种重量本身并不完美：不同的应用程序在相同的硬件类型上的性能不同。但是，结合ALB的动态部分，这效果很好 - 我们不需要添加特定于应用程序的权重。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-testing"&gt;&lt;strong&gt;测试&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;开发过程中的一个大问题是测试。虽然我们的登台环境有限，但需要使用许多参数的新解决方案：一些呼叫者或卡勒斯有三个实例，约三千个实例。一些后端的服务&amp;lt;1，有些后端&amp;gt; 1,000 rps。一些服务采用了一个同质的程序，而另一些服务的潜伏期从低毫秒到数十秒钟不等。最终，我们在生产中使用了虚拟服务，其中一组伪造的负载生成器配置为代表异构负载。在找到正确的参数并尝试推出生产服务之前，我们进行了300多个模拟。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-results"&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;我们对最终结果感到满意 - 确切的数字取决于服务和每个集群中的硬件混合物。尽管如此，平均而言，我们将P99 CPU利用率降低了12％，其中一些服务的收益超过30％。目标服务每个后端的目标服务越大 - 我们最关心的最大服务通常非常优化。同样的运气也适用于入职 - 虽然Uber拥有超过4,000个微服务，但入职前100名为我们带来了绝大部分潜在影响力。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-rollout-and-future-changes"&gt;&lt;strong&gt;推出和将来的变化&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;推广进行得很好 - 我们尚未确定材料错误。 Pick-2负载平衡和安全的后备被证明具有弹性。我们按地区划分的层面服务，试图找到代表性的服务类型。&lt;/p&gt;&lt;p&gt; Alb被推广到我们数百种最大的服务，并以最小的打ic或更改：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;em&gt;寿命长的RPC流&lt;/em&gt;。一小类服务正在将少量长寿命的RPC流与许多非常短暂的请求混合在一起。我们在那儿滚回去。&lt;/li&gt;&lt;li&gt;&lt;em&gt;缓慢启动的运行时间&lt;/em&gt;。推出大约两年后，我们对解决方案进行了调整以更好地处理缓慢启动（Java）服务。由于JIT，这些服务在启动后无法达到相同的请求率，但是记录的静态请求的热身效果不够好；我们需要以较低的速度使用真实请求来为服务加热。在这里，我们决定将每个同伴的初始“重量”播种，同时使算法的核心保持不变。我们发现这可以在各种服务中运行良好，我们很高兴这不需要任何静态窗口设置，与Envoy的&lt;a href="https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/upstream/load_balancing/slow_start" rel="noreferrer noopener" target="_blank"&gt;慢速启动模式&lt;/a&gt;不同，该算法会自动调整到一系列RPS。&lt;/li&gt;&lt;li&gt;&lt;em&gt;在启动时预取数据。&lt;/em&gt;另一个非常小的服务是在启动时预装静态数据几分钟。由于我们服务出版机制的特殊性，这些服务的实例在我们的服务发现中可见为“不健康”。旧算法强烈更喜欢健康的实例。当服务在临时超负荷后无法启动时，我们将其更改为ALB，以避免像雷声一样的情况（由于每个实例在依次变得健康时都会立即超负荷）。新算法非常喜欢健康的实例，但是在某些情况下，请求可能会发送给“不健康”节点。这对这些服务不起作用 - 虽然报告的错误&amp;lt;0.01％和0.002％，但我们正在探索与&lt;a href="https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/upstream/load_balancing/panic_threshold" rel="noreferrer noopener" target="_blank"&gt;恐慌阈值&lt;/a&gt;相似的变化，以使其完全消失。&lt;/li&gt;&lt;li&gt; &lt;em&gt;IP地址映射&lt;/em&gt;。 IP地址到服务器类型的静态映射工作2年以上，但是当我们&lt;a href="https://www.oracle.com/news/announcement/uber-selects-oracle-cloud-infrastructure-2023-02-13/" rel="noreferrer noopener" target="_blank"&gt;将工作负载移至云时，&lt;/a&gt;可能需要对其进行调整。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;有趣的是，两个服务覆盖了默认负载提供商，以根据后台作业处理来发射自定义负载指标。这证明了默认值在大多数服务方面效果很好，但是该解决方案足够灵活以支持其他用例。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-summary"&gt;&lt;strong&gt;概括&lt;/strong&gt;&lt;/h1&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/arrmQ21tVj4fLv6DVkrkdoYxp0bRT0f1Ab5Ha98zym8rjLVCbLymSXDdqyP_RJxBlIg5KE6zaAxzjYWdmgmq13h5M-GPgiEWTF5EczSNYkmFjn3sw0EiMlh97DhB32wtW0vjRSUqRGdPjC-rRQ_sebU" /&gt;&lt;figcaption class="wp-element-caption"&gt;图11：区域权重推出。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;该项目带来了非常重大的效率胜利。我们可以以较高的利用水平运行容器，而负载不平衡不再是无状态工作负载的问题。硬件配置的改进导致了减少失衡和纯计算能力的双重胜利。&lt;/p&gt;&lt;p&gt;更有趣的是，从工程博客的角度来看，该项目也导致了一些学习。&lt;/p&gt;&lt;p&gt;主要的是数据的重要性。问题是真实的，但是我们以错误的假设开始了该项目。我们不知道如何衡量它。一旦同意，我们就缺乏有效衡量它的工具，尤其是从长远来看。即使在那之后，我们也意识到我们从基础基础设施中收集样本的潜在方式也存在缺陷。同时，数据赢得了争论，帮助我们磨练问题，并将与其他团队的工作优先考虑。另一个数据课是为长期设置数据基础架构 - 在项目期间和之前也有所帮助。我们能够将现有的数据仓库用作基础，现在后来我们会定期收到有关负载不平衡的疑问。指向仪表板的链接通常回答所有问题。&lt;/p&gt;&lt;p&gt;第二堂课是在正确的位置添加解决方案，以获取我们需要的数据。建立适当的实时可观察性将花费我们数月或几个月的时间。尽管如此，我们很快就通过有针对性的黑客来得出了正确的结论，并有选择地将观察结果基于服务样本。与此相关的是愿意做很多手动咕unt的工作：为了建立理解，我们花了数周的时间盯着仪表板并在开始编码之前验证假设。后来，当实现ALB和区域/群集权重时，我们从相对较小的更改，经过验证的假设开始，然后迭代到下一个版本。&lt;/p&gt;&lt;p&gt;第三个可以说，第三个是可以信任平台的。我们打赌我们的微服务将迁移到共同的框架。同样，在实施时，我们建立了在平台上存在的多年既有投资（仪表式）工具（仪表板，调试工具，操作知识，推出政策）的基础，我们可以合理地快速，安全地进行重大变化。 。我们用平台的谷物构建，并避免了可能使该项目脱轨的重大重写。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-acknowledgments"&gt;&lt;strong&gt;致谢&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;该项目有很多人参与其中。我们感谢Avinash Palayadi，Prashant Varanasi，Zheng Shao，Hiren Panchasara和Ankit Srivastava的一般贡献。 Jeff Bean，Sahil Rihan，Vikrant Soman，Jon Nathan和Vaidas Zlotkus用于硬件帮助，Vytenis darulis可观察性修复程序，Jia Zhan和Eric Chung，用于Alb Reviews，Nisha Khater，Nisha khater，每年的lu yarpc for yarpc for yarpc for yarpc for yarpc全球。&lt;/p&gt;&lt;p class="has-small-font-size"&gt;徽标归因： &lt;a href="https://www.flickr.com/photos/141290938@N03" rel="noreferrer noopener" target="_blank"&gt;weiss_paarz_photos&lt;/a&gt;撰写的“ &lt;a href="https://www.flickr.com/photos/141290938@N03/26682754214" rel="noreferrer noopener" target="_blank"&gt;正义规模 - 法律 - 法律 - 律师和律师&lt;/a&gt;”，根据&lt;a href="https://creativecommons.org/licenses/by-sa/2.0/?ref=openverse" rel="noreferrer noopener" target="_blank"&gt;CC BY-SA 2.0&lt;/a&gt;许可。&lt;/p&gt;</description><pubDate>Thu, 07 Mar 2024 07:00:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/load-balancing-handling-heterogeneous-hardware/</guid></item><item><title>使用 Aristotle v2 进行网络 IDS 规则集管理</title><link>https://www.uber.com/blog/network-ids-ruleset-management-with-aristotle-v2/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;如果您向资深 SOC（安全运营中心）分析师询问有关网络 IDS（入侵检测系统）或 IPS（入侵防御系统）的问题，他的回答可能会包含&lt;em&gt;“警报太多”&lt;/em&gt;和&lt;em&gt;“误报”等短语。&lt;/em&gt;在 Uber，我们面临着同样的数量、准确性和可管理性挑战。每天多次解析、分析、更新、过滤并部署超过 90,000 个 IDS 规则到我们的网络传感器。创建&lt;a href="https://github.com/secureworks/aristotle/releases/tag/v2.0.0" rel="noreferrer noopener" target="_blank"&gt;Aristotle v2 的&lt;/a&gt;目的是使我们能够自动化此过程、应用基于归纳的情报提取并增强规则元数据以减少误报并帮助确保适当的 IDS 警报得到适当的关注。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-overview"&gt;概述&lt;/h2&gt;&lt;p&gt;Uber 的 IDS 规则集更新过程涉及多个步骤，如图 1 所示。整理和分发规则非常简单，并且对于所有 Suricata™ 部署都是通用的。决定要包含哪些规则以及如何修改它们是第 4 步“过滤规则集”中发生的事情，这将是本博客的重点。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/6EfyApi87FAXsUWWOQm_9Dx78vMvI3h_N7q8faeJeghq0NI_U1tlQEGEXVwcKik1oxxRBBGJbhjjQ3SEhL9Cx4hPIwFHr8yUcMaXKLVdmz4DbRINAF4LBgk92UJKZAR993YpZQ3IsPgMauY88YLib5I" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;图 1：IDS 规则集更新流程。&lt;/em&gt; &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-background"&gt;背景&lt;/h2&gt;&lt;p&gt;IDS 警报由按照规则（或“规则集”）管理的逻辑运行的 IDS 引擎生成。在基本层面上，IDS 规则可以被视为针对网络流量和连接状态的高级模式匹配。最流行的开源网络 IDS 引擎是&lt;a href="https://suricata.io/" rel="noreferrer noopener" target="_blank"&gt;Suricata&lt;/a&gt;和&lt;a href="https://snort.org/" rel="noreferrer noopener" target="_blank"&gt;Snort&lt;/a&gt; ™。本文重点介绍 Suricata，但其中的概念和实践也适用于 Snort。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-ids-rule-selection-approaches"&gt; IDS 规则选择方法&lt;/h2&gt;&lt;p&gt;选择应用于特定传感器的规则可能会对误报率、不需要的 IDS 警报和引擎性能产生重大影响。例如，保护 Linux® Web 服务器池的传感器不需要运行旨在检测针对 Windows® 文件共享的攻击的规则。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-rule-classification"&gt;规则分类&lt;/h3&gt;&lt;p&gt;从历史上看，规则集使用者在选择启用或禁用哪些规则时使用两个大“旋钮”。第一个是“classtype”，这是一个具有有限选项集的本机规则关键字，这些选项由规则集提供者定义并尝试对规则进行分类。通常，定义的类类型类别不超过几十个，常见值包括“trojan-activity”、“attempted-dos”和“bad-unknown”。第二个旋钮是规则集提供者放置规则的文件的文件名，规则集提供者通常会将规则分离到不同的文件中，名称如“sql.rules”、“scan.rules”和“trojan.rules”。&lt;/p&gt;&lt;p&gt;这些“旋钮”的一个主要问题是它们不允许一对多映射。每个仅支持单个规则的单个值。这种缺乏灵活性可能会受到限制。例如，检测最近发现的漏洞利用工具包活动的规则是否应该放入“current-events.rules”、“exploit.rules”或“web-client.rules”文件（仅举几个选项）？ “classtype”字段也存在类似的挑战，其中检测到的活动可以合法地分为多个类别。这些有限、生硬的规则分类机制过于广泛，无法支持现代部署所需的规则集微调灵活性。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-manual-review"&gt;人工审核&lt;/h3&gt;&lt;p&gt;为了针对特定环境优化规则集，必须对其进行调整。通常这会导致不平凡的、持续的、手动的工作。事实上，一些公司的日常任务是手动检查每条新规则，决定是否应将其包含在内，然后根据需要进行调整。然而，这很快就会变得繁重，并且显然无法扩展，特别是如果现有规则也必须定期重新调整的话。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-metadata"&gt;元数据&lt;/h3&gt;&lt;p&gt;存在一个由 Suricata 和 Snort 等 IDS 引擎支持的“元数据”关键字，它允许将任意键值对嵌入到每个规则中。这对于决定启用哪些规则非常有帮助，因为可以根据元数据的内容过滤规则。 Suricata 还将在 IDS 警报中包含元数据，可用于更明智的后处理、决策和关联。&lt;/p&gt;&lt;p&gt;与传统规则分类相比，元数据键值对具有明显的优势，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;一对多映射：&lt;/strong&gt;例如，“protocols”元数据键可以具有值“http”和“tcp”&lt;/li&gt;&lt;li&gt;&lt;strong&gt;任意键名称和值：&lt;/strong&gt;分类不必局限于预定义的有限选项&lt;/li&gt;&lt;/ul&gt;&lt;h4 class="wp-block-heading" id="h-a-better-way"&gt;更好的方法&lt;/h4&gt;&lt;p&gt;&lt;a href="https://better-schema.readthedocs.io/" rel="noreferrer noopener" target="_blank"&gt;BETTER&lt;/a&gt; （更好的增强型目的和分类嵌入规则）模式于 2019 年提出，用于基于键值的 IDS 规则元数据。它认识到一对多元数据映射的需求，并尝试为常用元数据带来一些结构和标准化键和（在某些情况下）值。 &lt;a href="https://www.secureworks.com/" rel="noreferrer noopener" target="_blank"&gt;Secureworks&lt;/a&gt; ® 等供应商在其 Suricata 规则集产品中完全实现了 BETTER，而&lt;a href="https://rules.emergingthreats.net/" rel="noreferrer noopener" target="_blank"&gt;Proofpoint ET Pro&lt;/a&gt; ® 等其他供应商的规则集具有部分兼容性。 BETTER 从未得到广泛的行业采用，但其主要概念仍然存在，并且使用元数据进行规则集过滤仍然是一个可靠的策略。&lt;/p&gt;&lt;p&gt;许多规则集提供商确实会填充元数据，但几乎所有规则集提供商这样做的方式都严重限制了使用元数据作为规则过滤手段的有效性。具体来说，规则集具有以下一个或多个缺点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;缺少元数据&lt;/strong&gt;：规则集中未使用适用的元数据键值对，或者选择性地而不是普遍应用元数据键值对。如果所有适用的元数据都应用于所有适用的规则，那么基于元数据过滤规则集是最有用的，而当情况并非如此时，实用性会急剧下降。例如，当还有 400 多个可以以相同方式分类的规则时，在规则集中的 20 条规则上设置元数据“攻击目标 http-server”，使得基于该键值对的过滤的值有限。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;值格式不一致&lt;/strong&gt;：例如，“cve”键值可能显示为“cve_2023_1234”、“cve_2023_1234_cve_2023_2468”、“2023_1234”、“2023-1234”等。如果没有标准化的命名法，精确过滤将变得具有挑战性。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;值格式不佳&lt;/strong&gt;：这包括在指定时间/日期字符串时不使用&lt;a href="https://www.iso.org/iso-8601-date-and-time-format.html" rel="noreferrer noopener" target="_blank"&gt;ISO 8601&lt;/a&gt;等标准日期时间格式等。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-aristotle-v1"&gt;亚里士多德 v1&lt;/h2&gt;&lt;p&gt; 2019 年， &lt;a href="https://www.secureworks.com/" rel="noreferrer noopener" target="_blank"&gt;Secureworks&lt;/a&gt;发布了&lt;a href="https://github.com/secureworks/aristotle/releases/tag/1.0.5" rel="noreferrer noopener" target="_blank"&gt;Aristotle (v1)&lt;/a&gt; ，这是一款开源 Python 工具，允许用户根据元数据键值对“过滤”（启用或禁用）规则。通过使用具体的布尔代数，可以定义“过滤字符串”来控制规则选择。这可能非常强大，但 Aristotle v1 的实用性受到所提供规则中元数据的丰富性（或者更确切地说，缺乏元数据）的限制，这些元数据由规则集供应商控制并且手动维护繁重。由于大多数规则集供应商不提供全面的元数据和/或没有具有精确编程过滤所需的精度和一致性的元数据，因此需要比 Aristotle v1 更高的东西。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-metadata-and-beyond"&gt;元数据及其他&lt;/h1&gt;&lt;h2 class="wp-block-heading" id="h-aristotle-v2"&gt;亚里士多德 v2&lt;/h2&gt;&lt;p&gt; Uber 最近对&lt;a href="https://github.com/secureworks/aristotle/" rel="noreferrer noopener" target="_blank"&gt;Aristotle&lt;/a&gt;做出了重大改进，产生了&lt;a href="https://github.com/secureworks/aristotle/releases/tag/v2.0.0" rel="noreferrer noopener" target="_blank"&gt;Aristotle v2&lt;/a&gt; 。这些更新增加了对元数据标准化、增强和操作的支持。图 2 显示了 Aristotle v2 的不同组件，我们将对此进行更详细的讨论。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/xD-k_zGYrP0E2OvjjvYtxgHwHQ7JUMBexQANRA_Eu2aYPDpoMzEIrchMQf6wgIw2xjEyog4IaHfNg6sV20TwqA3Y71iIrf_Pd8w1_vgx7AWalDiYxSbndXriycNrLGhRqS_Gr3r2kjZ46tzqJqN6zOM" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;图 2：亚里士多德 v2 组件。&lt;/em&gt; &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-filtering"&gt;过滤&lt;/h3&gt;&lt;p&gt;Aristotle v1（基本上是“过滤规则集”步骤）在支持元数据的布尔过滤方面做得很好，甚至包括为某些键指定数字关系的能力（例如，“created_at &amp;gt; 2023-01-01”）。在支持此类比较的键列表中，Aristotle v2 添加了&lt;strong&gt;risk_score&lt;/strong&gt; （稍后会详细介绍该键）。&lt;/p&gt;&lt;p&gt;此外，Aristotle v2 中还引入了基于正则表达式的过滤功能。虽然这确实会影响过滤性能，因为它将非文字元素添加到布尔表达式中，但它确实提供了强大且经常需要的功能。具体来说，正则表达式匹配可以使用“rule_regex”关键字应用于整个规则，也可以使用“msg_regex”关键字将范围限制到“msg”字段。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-normalization"&gt;正常化&lt;/h3&gt;&lt;p&gt;为了解决由于缺乏一致的元数据值格式而带来的过滤挑战，Aristotle v2 支持某些元数据键值的规范化。具体来说，支持以下标准化：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;strong&gt;CVE&lt;/strong&gt;键值标准化为格式&lt;em&gt;YYYY-&amp;lt;num&amp;gt;&lt;/em&gt; 。如果值中表示多个 CVE 并用“_”串在一起（例如“cve_2021_27561_cve_2021_27562”[&lt;em&gt;原文如此&lt;/em&gt;]），则所有已识别的 CVE 将被标准化并包含在内。&lt;/li&gt;&lt;li&gt;来自非 BETTER 模式键&lt;strong&gt;mitre_technique_id&lt;/strong&gt;和&lt;strong&gt;mitre_tropic_id&lt;/strong&gt;的值将被放入符合标准的&lt;strong&gt;mitre_attack&lt;/strong&gt;键中。&lt;/li&gt;&lt;li&gt;日期键值（由任何以“_at”或“-at”结尾的键名称确定，例如， &lt;strong&gt;created_at&lt;/strong&gt; ）将尝试标准化为 ISO 8601 格式&lt;em&gt;YYYY-MM-DD&lt;/em&gt; 。&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-enhancement"&gt;强化&lt;/h3&gt;&lt;p&gt;虽然标准化元数据是必要且有用的，但它无法解决元数据丢失的问题。然而，规则不仅仅是它的元数据，因此我们提出了这样的问题：“&lt;em&gt;我们能否从规则的本体中识别、推论、归纳或以其他方式推断细节，并用该信息增强规则元数据？&lt;/em&gt; ” 这导致了亚里士多德 v2 能够分析每个规则的本体并通过以下&lt;a href="https://aristotle-py.readthedocs.io/en/latest/usage.html#enhance" rel="noreferrer noopener" target="_blank"&gt;增强功能&lt;/a&gt;添加/更新元数据：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;流&lt;/strong&gt;键的值标准化为“to_server”或“to_client”&lt;/li&gt;&lt;li&gt;&lt;strong&gt;协议&lt;/strong&gt;键和适用值&lt;/li&gt;&lt;li&gt;&lt;strong&gt;cve&lt;/strong&gt;键和适用值。这些值基于从原始规则中提取的数据，例如“msg”字段、“reference”关键字等。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;mitre_attack&lt;/strong&gt;键和适用的值。这些值基于从规则的“参考”关键字中提取的数据&lt;/li&gt;&lt;li&gt;&lt;strong&gt;敌对&lt;/strong&gt;密钥和适用值（“dest_ip”或“src_ip”）—这些值是从“target”关键字获取的值的倒数&lt;/li&gt;&lt;li&gt;&lt;strong&gt;类类型&lt;/strong&gt;键和适用值&lt;/li&gt;&lt;li&gt;&lt;strong&gt;文件名&lt;/strong&gt;键和适用的值 - 如果规则是从文件加载的，则该值将是规则来源的文件名&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Original_disabled&lt;/strong&gt;键和布尔值在内部添加到每个规则上，用于过滤&lt;/li&gt;&lt;li&gt;&lt;strong&gt;检测方向&lt;/strong&gt;键（见下文）&lt;/li&gt;&lt;/ul&gt;&lt;h4 class="wp-block-heading" id="h-detection-direction"&gt;检测方向&lt;/h4&gt;&lt;p&gt;虽然网络 IDS 规则可以是单向的，但绝大多数规则都是针对客户端-服务器通信的一侧而编写的。此外，规则的范围通常是通过指定源和目标的 IP 地址组来确定的。 IP 地址组是用户定义的，但几乎总是包含变量“HOME_NET”和“EXTERNAL_NET”。这个想法是 HOME_NET 是用户或公司拥有的一组 IP 地址，旨在受到保护； EXTERNAL_NET 是用户网络（通常是一般互联网）“外部”的 IP 组。 EXTERNAL_NET 通常（但不一定）定义为 HOME_NET 中未指定的所有内容。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;detector_direction 元&lt;/strong&gt;数据键尝试标准化规则检测到的流量的方向性。为此，需要对规则的源部分和目标部分进行处理并缩减为“$HOME_NET”、“$EXTERNAL_NET”、“any”或“UNDETERMINED”，并用于设置&lt;strong&gt;detector_direction&lt;/strong&gt;值，如图 3 所示。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/rwHiJEqmAcq7pqON8pnrpt2Tp9XmvhGxRSe5Vcc-i1bpiIPwjm73jvH_0raA3E9dWOkzWzd4C3vlaM7oeCUvzUacl8uKFArxQSCNCb71h1-QLfNXZD736JMmp7FwkeLGdFhj5jZZajAfVmwdP0SbDoU" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;图 3：检测方向值和条件。&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;了解规则的“检测方向”对于确定其所检测内容的重要性和严重性非常重要。例如，考虑一条检测已知由感染 Mirai 恶意软件的设备生成的流量的规则。此类入站流量（来自 EXTERNAL_NET 并定向到 HOME_NET）通常可归类为扫描，并被认为只不过是互联网噪音。然而，此类出站流量（来自 HOME_NET 并定向到 EXTERNAL_NET）很好地表明您的网络上存在受感染的设备，并且它是活动僵尸网络的一部分。后一种情况比前一种情况更为严重，应按前一种情况处理。规则及其关联的 IDS 警报需要能够传达这些现实情况。准确地对规则及其 IDS 警报进行分类，以便能够以编程方式对其进行响应非常重要，而这正是后置过滤器修改发挥作用的地方。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-pfmod-post-filter-modification"&gt; PFMod（后置滤波器修改）&lt;/h3&gt;&lt;p&gt; Aristotle v2 提供了在规范化、增强和初始过滤字符串应用后进一步过滤和修改规则集的选项。这称为 PFMod（ &lt;a href="https://aristotle-py.readthedocs.io/en/latest/post_filter_mod.html" rel="noreferrer noopener" target="_blank"&gt;过滤器后修改&lt;/a&gt;），允许根据过滤器字符串识别规则，然后对这些规则采取特定的“操作”。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-pfmod-actions"&gt; PFMod 操作&lt;/h4&gt;&lt;p&gt;PFMod 操作包括添加/删除元数据、启用/禁用规则、设置优先级以及对完整规则执行基于正则表达式的“查找和替换”的功能。支持的 PFMod 操作包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;禁用&lt;/strong&gt;：禁用该规则。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;启用&lt;/strong&gt;：启用规则。请注意，要使“禁用”规则进入 PFMod 进行考虑，它们必须首先在初始过滤器字符串匹配阶段进行匹配。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;add_metadata&lt;/strong&gt; ：YAML 键值对，其中 (YAML) 值是要添加的元数据键值对，例如“协议 http”。请注意，如果已经存在使用给定键的元数据，则不会覆盖它，除非值也相同，在这种情况下，不会添加任何内容，因为它已经存在。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;add_metadata_exclusive&lt;/strong&gt; ：YAML 键值对，其中 (YAML) 值是要添加的元数据键值对（例如，“优先级高”）。如果给定的元数据键已存在，请使用新值覆盖它。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;delete_metadata&lt;/strong&gt; ：如果给出了元数据键值对（例如，“former_category 恶意软件”），则从规则中删除该键值对。如果仅给出了元数据键名称（例如“former_category”），则使用给定键删除所有元数据，无论值如何。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;regex_sub&lt;/strong&gt; ：对规则执行正则表达式查找和替换。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;set_&amp;lt;keyword&amp;gt;&lt;/strong&gt; ：将 IDS 规则字符串中的&lt;em&gt;&amp;lt;keyword&amp;gt;&lt;/em&gt;设置为给定值。如果规则不包含给定关键字，则添加它并将值设置为给定值。支持的关键字包括“priority”、“sid”、“gid”、“rev”、“msg”、“classtype”、“reference”、“target”、“threshold”和“flow”。对于整数关键字（“priority”、“rev”、“gid”和“sid”），可以通过在整数值前面添加“+”或“-”来使用相对值。例如，操作“set_priority“-1””将导致规则中现有的优先级值减1。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;set_&amp;lt;任意_整数_元数据&amp;gt;&lt;/strong&gt; ：与“add_metadata_exclusive”类似，允许设置或更改任意基于整数的元数据键值，但也支持相对值以及默认值。格式如图4所示。 &lt;/li&gt;&lt;/ul&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/cDFJsx8a4aR3fzcHxzT5t7BZxYGOGfujqynX60OfUBJAWhp_kRonpAJJymbKHMKiwUzKGqDCVOlqw5YiAe6XLh6PfDVvMeAUWV3vwCTgRpSBLFmsNjhRAw9nfA-NBrRJppAEuYIlP9T7Fq-5apCTUAg" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;图 4：用于设置任意基于整数的元数据的 PFMod 操作语法。&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;笔记：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;em&gt;&amp;lt;任意整数元数据&amp;gt;&lt;/em&gt;字符串对应于元数据键名称，并且必须至少包含一个下划线 (&amp;#39;_&amp;#39;) 字符。&lt;/li&gt;&lt;li&gt;被引用的元数据键应该具有与整数相对应的值。&lt;/li&gt;&lt;li&gt;给定 &amp;lt;value&amp;gt; 前面的“+”或“-”将导致规则中的现有元数据值分别增加或减少给定的&lt;em&gt;&amp;lt;value&amp;gt;&lt;/em&gt; 。如果元数据键不存在，则该值将设置为给定的&lt;em&gt;&amp;lt;default&amp;gt;&lt;/em&gt;值（如果提供），否则不会进行任何更改。&lt;/li&gt;&lt;li&gt;示例如图 5 所示。 &lt;/li&gt;&lt;/ul&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/8H_XGd2h-bhRh3_3TU3DOSXxru4ndUFegnldYy6niuSgJxr5fuWo721rruZzI-nUFTGNo0g9RMEwEXPthNZQxvrqa_Anwi37gcTuely-ZGlcZopCI8gu0RmZOQhsWioYFRD-BR16fG8Bonr4HgUdV_w" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;图 5：设置任意基于整数的元数据键值对的示例 PFMod 操作。&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;h4 class="wp-block-heading" id="h-pfmod-rules"&gt; PFMod 规则&lt;/h4&gt;&lt;p&gt;PFMod 条件和操作由 PFMod 规则控制（不要与 IDS“规则”混淆）。 PFMod 规则在 YAML 文件中定义，并以深度优先、线性方式处理。这意味着您可以定义广泛应用于许多（或所有）规则的操作，然后拥有更具体的 PFMod 规则，将更精确的操作应用于这些规则的子集。如图 6 所示，PFMod 规则文件可以“包含”其他 PFMod 规则文件，以便于组织。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/qYBdFR47BWVJxSUSy7f1-35up1H8fsOESih8Vy2oX_MT0mjf-dKWSyd83FEhgW-2tVZTOpZyeuaKX1zTCHarBkDhuI92DMehaMcs1gmrXy2rhsQ0V00a8HPQz3EOkEM9J_IYm4pcvklTxDtSiMiqyoQ" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;图 6：使用&lt;/em&gt;&lt;strong&gt;&lt;em&gt;include&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;加载多个 PFMod 文件的示例文件。&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;除了&lt;strong&gt;include&lt;/strong&gt;语句之外，PFMod 规则文件还可以包含多个规则。图 7 显示了更新 IDS 规则和元数据的 PFMod 规则文件示例。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/3omcuZfAMQjK8WXdHLOLj1ITew4Nu75Ha9jPFbjPZiV7aIo3jYiHTTQY0lN0txuMFxS-VCJMtnSZegFxZux-XxMphuu4gZHLjBkaAMutOjnO66o_liREiFfbWrn2mbT9bib9G-1X-Cwz8GiAOocgNy4" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：指定&lt;strong&gt;&lt;em&gt;规则&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;的 PFMod 文件示例&lt;/em&gt;&lt;em&gt;。&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;h4 class="wp-block-heading" id="h-risk-score"&gt;风险评分&lt;/h4&gt;&lt;p&gt;Uber 部署的每条 Suricata 规则都会收到一个“风险评分”。这些风险评分在规则集编译时自动生成，并由 PFMod 规则作为元数据值应用。规则元数据（包括&lt;strong&gt;risk_score&lt;/strong&gt; ）包含在Suricata 警报中，并在事件处理中发挥重要作用。稍后会详细介绍这一点。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-maintenance"&gt;维护&lt;/h3&gt;&lt;p&gt;当新规则添加到 Uber 使用的规则集中时（这种情况每天都会发生），它们会自动服从我们现有的 Aristotle v2 管道，其中包括过滤和应用重要的 PFMod 逻辑来相应地形成和分类每个规则。因此，通过使用 Aristotle v2 作为可靠的“设置后忘记它”机制，可以避免对每个新规则进行手动分析和调整。当然，偶尔会明智地重新审视规则集过滤和 PFMod 逻辑，以使规则集与当前环境和预期流量模式保持一致。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-documentation"&gt;文档&lt;/h3&gt;&lt;p&gt;有关 Aristotle v2 以及如何使用它的更多详细信息可以在 &lt;a href="https://aristotle-py.readthedocs.io/en/latest/" rel="noreferrer noopener" target="_blank"&gt;在线文档&lt;/a&gt;中找到。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-aggregation-correlation-risk-score-and-alerting"&gt;聚合、关联、风险评分和警报&lt;/h1&gt;&lt;p&gt;Uber 每天处理数十亿个事件，其中包括数十万个 IDS 警报。事件来自多种来源，包括日志文件、供应商产品、内部系统、自定义检测和 IDS 等传感技术。安全相关事件（称为“信号”）接收由单个整数表示并与信号关联的“风险评分”值。信号的风险评分值在下游聚合和相关算法中起着重要作用，这些算法最终确定一个信号或一组信号是否符合需要响应的正式元警报。换句话说，“风险评分”值量化了响应的必要性和适当水平。根据保证的级别，响应通常采取安全分析师手动调查的形式，和/或安全编排和响应 (SOAR) 管道中的一系列编程操作。&lt;/p&gt;&lt;p&gt; Uber 的信号评估、聚合和关联是一个复杂的过程（更不用说响应管道），其复杂的细节超出了本文的范围。然而，总体策略围绕着我们所说的“基于实体的警报”。对于给定的时间窗口，信号按实体（例如，IP 地址、主机、用户等）分组，并应用相关算法来确定是否应创建可操作的元警报。来自各个信号的风险评分值在此计算中发挥着重要作用，因为它们被加权并相加在一起，并最终与用于做出最终决定的阈值进行比较。信号的权重（可以被认为是向上或向下调整风险评分）基于各种标准，包括实体特征，并且通常涉及与其他数据源的相关性。例如，用户是管理员的用户实体的信号的权重高于与非管理员用户相关的信号。类似地，涉及来自已知认可的漏洞扫描器的 IP 地址实体的信号将被赋予较低的权重，而涉及已知是负责金融交易的隔离网络的一部分的 IP 地址实体的事件将被赋予较高的权重。请注意，给定足够高的风险评分和/或权重修改，单个信号足以生成元警报和响应。&lt;/p&gt;&lt;p&gt;在实践中，聚合和关联与常见实体相关的信号已被证明是识别值得响应的事件和事件组合的有效方法。借助 IDS 警报，Aristotle v2 在能够选择启用哪些规则、包含哪些元数据以及每个规则应携带哪些风险评分值方面发挥着至关重要的作用。 IDS 警报元数据，尤其是风险评分值，可以更好地管理 Suricata 警报，使分析人员不会因警报或误报而不知所措。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;通过使用 Aristotle v2 规范、增强和操作规则元数据，可以准确地描述、以编程方式理解和任意修改规则。对元数据键值对应用具体的布尔代数会产生强大的过滤功能，使我们能够管理 Suricata 规则集，以便仅在特定环境中运行适用的规则。规则根据明确的和推断的目的论动机和本体论现实自动调整。自定义元数据值（例如“risk_score”）被智能地添加到每个规则中，从而实现有效的下游关联，从而最大限度地减少误报，并使值得注意的警报得到适当的关注。其结果是一个可扩展、可控且准确的 Suricata 规则集管理和响应解决方案。&lt;/p&gt;</description><pubDate>Thu, 29 Feb 2024 07:00:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/network-ids-ruleset-management-with-aristotle-v2/</guid></item><item><title>构建可扩展的实时聊天以改善客户体验</title><link>https://www.uber.com/blog/building-scalable-real-time-chat/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;优步是一家全球性企业，拥有遍布世界各地的客户群。 Uber 的客户群分为多个用户角色，主要是乘客、司机、食客、快递员和商家。作为一家全球性企业，Uber 的客户也期望在全球范围内获得支持。我们的客户通过各种实时（聊天、电话）和非实时（应用内消息传递）渠道与我们联系，并期望迅速解决他们的问题。 Uber 客户每周都会提出数百万次支持互动（内部称为&lt;em&gt;联系人&lt;/em&gt;），我们的目标是在预定义的服务级别协议 (SLA) 内解决这些联系人问题。客户创建的联系人可以通过自动化或在客户支持代理的帮助下解决。&lt;/p&gt;&lt;p&gt;对于代理联系人来说，解决工单的成本在 Uber 如何构建其支持渠道以及确定不同实时和非实时渠道的交易量方面发挥着重要作用。聊天渠道的每次联系成本 (CPC) 和 FCR（首次联系解决率）在不同的实时渠道中最为有效，因为它们允许客服人员同时处理多个聊天联系人，同时保持比电话等渠道更低的平均成本。这个渠道对 Uber 来说是最佳选择，因为它具有良好的&lt;a href="https://www.qualtrics.com/au/experience-management/customer/what-is-csat/" rel="noreferrer noopener" target="_blank"&gt;CSAT&lt;/a&gt;分数（客户满意度评分，衡量范围为 1 到 5），同时通常会降低每次点击费用。该渠道可以实现更高的自动化率、更高的人员配备效率（因为座席可以同时处理多个聊天）和高 FCR，这些都对 Uber 有利，同时为客户提供优质支持。&lt;/p&gt;&lt;p&gt;从历史上看，从 2019 年到 2023 年初，所有联系人中的 1% 是通过实时聊天渠道提供服务的，58% 是通过应用内消息通道（非实时渠道）提供服务的，其余的则通过电话等另一个实时渠道提供服务。为了实现更高的 CSAT 和 FCR，工程团队需要扩展聊天基础设施以满足 Uber 不断增长的业务需求，并促进大量应用内消息和电话渠道联系人迁移到聊天渠道。本文将重点关注聊天直播频道。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-challenges"&gt;挑战&lt;/h2&gt;&lt;p&gt;为了扩展聊天渠道以支持路由到代理的 Uber 联系量的 40% 以上，以下是团队面临的一些主要挑战：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;将消息从后端系统传递到代理浏览器的可靠性问题&lt;ol&gt;&lt;li&gt;46% 源自尝试联系代理的客户的事件未及时传送，导致客户双方均出现延迟并浪费代理的带宽。请注意，这里的 46% 并不是指唯一联系人的数量，而是指所有聊天联系人的事件总数。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;缺失的见解&lt;ol&gt;&lt;li&gt;无法观察到跟踪聊天联系人的健康状况。&lt;/li&gt;&lt;li&gt;由于客服人员闲置了很长一段时间，但队列也不是空的，运营人员想知道他们是否人员过多，或者是否是技术问题导致数量不成比例（称为技术与人员配置问题）。 &lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-legacy-architecture-related-challenges"&gt;遗留架构相关的挑战&lt;/h2&gt;&lt;p&gt;我们的旧架构是使用&lt;a href="https://wamp-proto.org/index.html" rel="noreferrer noopener" target="_blank"&gt;WAMP 协议&lt;/a&gt;构建的，该协议主要用于消息传递和基于 WebSocket 的 PubSub，以将联系信息中继到代理的计算机。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large is-resized"&gt;&lt;img alt="" class="wp-image-1078909" height="416" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Fig1_old_arch-1-1024x416.png" style="width: 700px; height: auto;" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：描述了聊天联系人从创建到路由到前端代理的先前高级流程。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;&lt;em&gt;注意：这与涉及客户和 Uber 支持人员之间聊天消息交换的数据路径不同，后者通过 HTTP 服务器发送事件 (SSE) 实现。为此，Uber 使用 Ramen 作为内部服务，在控制和数据路径中发挥双重作用。在控制路径中，Ramen 为客户端到移动用例提供双向支持，从而实现有效的通信。同时，在数据路径中，Ramen&lt;/em&gt;&lt;em&gt;为客户端到 Web 用例&lt;/em&gt;提供&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events" rel="noreferrer noopener" target="_blank"&gt;&lt;em&gt;SSE&lt;/em&gt;&lt;/a&gt;功能。&lt;/p&gt;&lt;p&gt;&lt;em&gt;然而，数据路径中出现了一个值得注意的区别，特别是对于客户端到 Web 的用例，Ramen 的成功交付率为 94.5%。它以单向方式运行，因此需要新的控制流。这些新的控制流对于检测和管理客户端不再响应的情况至关重要，从而解决数据路径中的单向限制。在本博客中，我们将介绍新的控制流，将事件从后端传递&lt;/em&gt;到&lt;em&gt;代理的浏览器 (Web)，以使代理能够进行第一次回复。&lt;/em&gt;&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;该团队在生产中启动了 E2E 架构，并开始发现问题。不是立即，但随着流量超出了通过的少数票证，团队意识到该架构无法轻松超出其初始功能，并且生产管理也不是那么简单。下面列出了其中一些核心问题：&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-reliability"&gt;可靠性&lt;/h3&gt;&lt;p&gt;我们面临 1.5 倍扩展流量的可靠性问题，导致后端多达 46% 的事件未传送到代理的浏览器。这增加了客户与客服人员交谈的等待时间。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-scale"&gt;规模&lt;/h3&gt;&lt;p&gt;除了 &amp;gt;~10 左右的低 RPS 之外，由于高内存使用率或文件描述符泄漏，从后端传送联系人的系统性能显着恶化。由于使用旧版本 WAMP 库的限制，不支持水平可扩展性，并且升级它是一项巨大的工作。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-observability-debuggability-nbsp"&gt;可观察性/可调试性&lt;/h3&gt;&lt;p&gt;以下是与可观测性相关的主要问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;跟踪聊天联系人的运行状况很困难，即聊天联系人是否由于工程相关问题或人员配置相关问题而缺少 SLA。&lt;/li&gt;&lt;li&gt;聊天联系人未加入基于队列的架构，导致由于代理的属性匹配流，超过 8% 的聊天量未路由到任何代理。&lt;/li&gt;&lt;li&gt;使用的 WAMP 协议和库（ &lt;a href="https://github.com/crossbario/autobahn-js"&gt;eg1&lt;/a&gt; 、 &lt;a href="https://github.com/gammazero/nexus/tree/v2"&gt;eg2&lt;/a&gt; ）已被弃用，并且没有提供很多关于内部工作原理的见解，导致调试变得更加困难。此外，我们没有实施端到端的 Chat 联系人生命周期调试，并且我们无法准确检测整个平台上的 Chat SLA 缺失。&lt;/li&gt;&lt;/ol&gt;&lt;h3 class="wp-block-heading" id="h-stateful"&gt;有状态的&lt;/h3&gt;&lt;p&gt;这些服务是有状态的，使维护和重启变得复杂，从而导致消息传递时间和损失激增。添加 WebSocket 代理来执行授权，而且由于服务整体是有状态的，因此这极大地增加了延迟。当任何一方断开连接时，双套接字代理都会引起问题。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-tech-requirements"&gt;技术要求&lt;/h2&gt;&lt;p&gt;以下是技术团队正在努力实现的一些目标：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;到 2023 年底，将聊天流量从总联系量的 1% 扩大到 40%（每周 150 万票）&lt;ol&gt;&lt;li&gt;在队列上加入并扩展聊天流量以支持与队列相关的洞察&lt;/li&gt;&lt;li&gt;到 2024 年底，扩大规模以处理 Uber 总联系量的 80% 以上（每周 300 万张罚单）。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;通过代理管道（称为推送管道）的预订（在识别代理后首次尝试将客户连接到代理）成功率应 &amp;gt;= 99.5%&lt;/li&gt;&lt;li&gt;构建整个聊天流程端到端的可观察性和可调试性。&lt;/li&gt;&lt;li&gt;无状态服务，如果水平扩展或实例因任何原因发生故障，则不需要重新校准&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-solution"&gt;解决方案&lt;/h2&gt;&lt;p&gt;新架构需要简单，以提高其内部运作的透明度，并使团队能够轻松扩展。该团队决定继续使用 Push Pipeline，这将是一个简单、无冗余的 WebSocket 服务器，代理计算机将连接到该服务器并能够通过一个通用套接字通道发送和接收消息。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-high-level-architecture"&gt;高层架构&lt;/h3&gt;&lt;p&gt;目前存在的新架构如下所示： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1078914" height="517" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Fig2_new_arch-1024x517.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：描述了通过路由到前端代理创建聊天联系人的整个过程中的新高级流程。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;该架构有以下部分：&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-front-end"&gt;前端&lt;/h3&gt;&lt;p&gt;代理使用前端 UI 与客户交互。代理可以使用小部件和不同的操作来调查并为客户采取适当的操作。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-contact-reservation"&gt;联系预订&lt;/h3&gt;&lt;p&gt;路由器是在代理和联系人之间找到最合适匹配的服务。在找到最适合客服人员的联系人后，该联系人将被推送到该客服人员的保留状态。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-push-pipeline"&gt;推送管道&lt;/h3&gt;&lt;p&gt;成功预订代理联系人后，匹配的信息将发布到 Apache Kafka®。通过 GraphQL 订阅通过套接字接收此信息后，前端会加载代理的联系人以及使代理能够响应用户的所有必要的小部件和操作。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-agent-state"&gt;代理状态&lt;/h3&gt;&lt;p&gt;任何需要开始工作的代理都需要通过前端上的切换开关上线，触发时会使用相关代理的新状态更新代理状态服务。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-edge-proxy"&gt;边缘代理&lt;/h3&gt;&lt;p&gt;客户端浏览器和后端服务之间的任何连接都通过边缘代理进行，该代理作为防火墙和代理层保护 Uber 服务。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-ease-of-operations-and-better-insights"&gt;易于操作和更好的洞察力&lt;/h3&gt;&lt;p&gt;以下是要点：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在队列上加入聊天流量，订阅的代理将根据代理配置文件的并发集接收联系人。并发性定义了客服人员可以同时处理的聊天联系人的数量。&lt;/li&gt;&lt;li&gt;队列的座席人员配备本质上是决定性的，基于 SLA 的路由（根据队列 SLA 确定聊天联系人的优先级）、粘性路由（粘性重新打开与座席的联系）和优先级路由（根据队列上定义的不同规则确定优先级）等功能已成为决定性因素。默认支持。&lt;/li&gt;&lt;li&gt;通过队列加入，仪表板被重新调整/增强，以便运维团队查看聊天队列 SLA 和客服人员可用性及其实时状态，包括联系人生命周期状态、队列流入/流出、客服人员的会话计数等。 &lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-gql-subscription-service"&gt; GQL订阅服务&lt;/h2&gt;&lt;p&gt;与 GraphQL 订阅相关的主要亮点是：&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-reconnection-on-disconnection"&gt;断开连接时重新连接&lt;/h4&gt;&lt;p&gt;我们在 GraphQL 订阅套接字上启用了 ping pong，以确保在连接不可靠的情况下自动断开套接字。当套接字断开连接时，相应的代理就没有资格接收新的联系人。自动重新尝试 Web 套接字重新连接。成功重新连接后，将获取所有保留/分配的联系人，以便客服人员可以接受它们。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-push-pipeline-reliability-nbsp"&gt;推动管道可靠性&lt;/h4&gt;&lt;p&gt;对于给定座席的保留联系人，如果前端未向聊天服务发回确认，我们会尝试为另一个可用座席保留相同的联系人。我们通过 GraphQL 订阅发送心跳来检查代理浏览器的 Web 套接字和 http 协议是否正常工作，响应是通过代理浏览器的 HTTP API 调用发送的，以检查代理是否在线。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-technical-choices"&gt;技术选择&lt;/h2&gt;&lt;p&gt;下面概述了我们为提高聊天系统的可靠性和稳健性而做出的一些技术选择，同时还考虑了我们的选择对用户感知等待时间的端到端延迟影响。为此，我们需要简化该系统，同时启用选定的产品增强功能。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-using-graphql-over-websocket-with-graphql-subscriptions"&gt;通过带有 GraphQL 订阅的 websocket 使用 GraphQL&lt;/h3&gt;&lt;p&gt;前端团队广泛利用 GraphQL 在其前端服务上进行 HTTP 调用。这导致团队选择 GraphQL 订阅来将数据从服务器推送到客户端。客户端将通过订阅请求向服务器发送消息，服务器在匹配查询时将消息发送回代理计算机。以下部分介绍了有关 GraphQL 订阅的更多信息。&lt;/p&gt;&lt;p&gt; &lt;a href="https://github.com/enisdenjo/graphql-ws" rel="noreferrer noopener" target="_blank"&gt;graphql-ws&lt;/a&gt;库给了我们信心，因为它&lt;a href="https://www.npmjs.com/package/graphql-ws" rel="noreferrer noopener" target="_blank"&gt;每周的下载量为 230 万次&lt;/a&gt;， &lt;a href="https://www.apollographql.com/docs/react/data/subscriptions/#setting-up-the-transport" rel="noreferrer noopener" target="_blank"&gt;被 Apollo 推荐&lt;/a&gt;，并且有 0 个未解决的问题。它还以&lt;a href="https://github.com/enisdenjo/graphql-ws/blob/master/PROTOCOL.md" rel="noreferrer noopener" target="_blank"&gt;基于 WS 协议的标准 GraphQL&lt;/a&gt;为模型，并完全根据该协议调整其选项，使其成为此处使用的理想选择。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-stateless-services"&gt;无状态服务&lt;/h3&gt;&lt;p&gt;将创建的新服务需要无状态才能水平扩展，并且不需要时不时地重新平衡。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-websocket-without-http-fallback"&gt;没有 HTTP 回退的 Websocket&lt;/h3&gt;&lt;p&gt;由于系统需要代理计算机和代理层之间的双向通信，因此 HTTP 回退实际上不会对系统的 SLA 产生任何影响。因此，团队专注于通过以下方式提高套接字与代理连接的可用性：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;双向 ping pong 消息可防止套接字挂起&lt;/li&gt;&lt;li&gt;断开连接后回退重新连接，以防止并发重新连接导致服务不堪重负。&lt;/li&gt;&lt;li&gt;单个代理连接套接字而无需任何切换&lt;/li&gt;&lt;/ol&gt;&lt;h3 class="wp-block-heading" id="h-using-apache-kafka-as-a-message-service-on-the-backend"&gt;使用 Apache Kafka® 作为后端的消息服务&lt;/h3&gt;&lt;p&gt;联系消息在到达代理层之前已经通过 Kafka 流经各个服务。我们决定继续并扩展 Kafka 的使用，因为它可靠、快速且支持广播 (PubSub) 功能。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-testing-amp-launch"&gt;测试与发布&lt;/h1&gt;&lt;p&gt;我们进行了功能和非功能测试，以确保为客户和代理提供端到端的最佳体验。为了预测性能，在发布之前完成的一些测试是：&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-load-tests"&gt;负载测试&lt;/h3&gt;&lt;p&gt;可以从一台机器建立约 10K 的套接字连接，随着我们添加更多机器，该连接将进一步水平扩展。我们成功测试了以旧堆栈的 20 倍推送事件。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-shadow-traffic-flows"&gt;影子流量&lt;/h3&gt;&lt;p&gt;现有流量通过旧系统和新管道进行引导，以测试其每天 40,000 个联系人和 2,000 个座席的容量。此过程没有发现任何问题，数据指标显示延迟和可用性令人满意并达到所需的阈值。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-reverse-shadow-traffic-flows"&gt;反向影子流量&lt;/h3&gt;&lt;p&gt;现有流量通过新系统和旧的代理用户界面进行引导，作为关键的可靠性测试。这是新系统的首次使用，它成功地管理了流量，同时将延迟保持在定义的 SLA 范围内。&lt;/p&gt;&lt;p&gt;在我们进行过程中，我们遇到了独特的系统和代理行为问题，并进行了一些修复以提高可靠性并减少整体管道的延迟。一些主要问题是：&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-deletion-of-cookies-from-the-browser"&gt;从浏览器中删除 cookie&lt;/h3&gt;&lt;p&gt;浏览器 cookie 被清除后，会产生与身份验证和后续 API 失败相关的问题，从而阻止前端对推送的事件采取行动。在这种情况下，客服人员通常会保持在线状态，而不处理任何联系人。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-bugs-in-auto-logout-flows"&gt;自动注销流程中的错误&lt;/h3&gt;&lt;p&gt;过去，客服人员不会因故障或事件丢失等问题而注销。完成当天工作的客服人员只需关闭选项卡即可在系统中保持在线状态。由于管道试图将事件推送给这些不在线的客服人员，这导致客户等待时间增加。然后，我们开始根据最近的确认失误自动注销代理，并从整体上追踪注销的正确原因，以提高对系统的信心。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-results"&gt;结果&lt;/h2&gt;&lt;p&gt;聊天渠道已经能够扩展到 Uber 全部联系量（路由到客服人员）的&lt;strong&gt;36%&lt;/strong&gt;左右，未来几个月还会有更多渠道出现。团队似乎已经重新获得了对扩展聊天渠道以及改善整体客户体验的信任。该团队还能够大幅提高可靠性，旧堆栈中传递联系的错误率约为 46%，而新堆栈中的错误率约为 0.45%。每次交付失败后，客户的工单都会在 30 秒的延迟后退回，然后重试交付，将这一数字大规模降低 0.45% 以下对于客户和代理的整体体验而言意义重大。&lt;/p&gt;&lt;p&gt;我们在这一领域还取得了其他胜利，其中最好的也许就是简单性。新架构在系统中内置了&lt;strong&gt;更少的服务、更少的协议和更好的可观察性&lt;/strong&gt;，以便了解联系传递指标、系统内的延迟和端到端延迟。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion-and-next-steps"&gt;结论和后续步骤&lt;/h1&gt;&lt;p&gt;新的推送管道使团队能够加入其他推送用例，并通过为代理提供实时信息来采取行动，从而为改善用户体验打开了大门。一些与 Greenlight 预约和代理工作重叠相关的用例将很快转移到这个新堆栈上，作为下一阶段的一部分。&lt;/p&gt;&lt;p&gt;聊天频道的用户体验也将进一步改善，重点是增强和系统架构调整。这将基于产品扩展的经验教训以及解决客户和代理商报告的问题来完成。&lt;/p&gt;&lt;p class="has-small-font-size"&gt;&lt;em&gt;封面图片可在此链接找到：&lt;a href="https://openverse.org/image/2b3fadf3-2490-4a0c-906d-f7cf1c13a4cb?q=customer%20support"&gt;来源&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description><pubDate>Tue, 20 Feb 2024 07:00:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/building-scalable-real-time-chat/</guid></item><item><title>Uber 如何使用集成缓存从在线存储中提供每秒超过 4000 万次的读取服务</title><link>https://www.uber.com/blog/how-uber-serves-over-40-million-reads-per-second-using-an-integrated-cache/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;&lt;a href="https://eng.uber.com/schemaless-sql-database/" rel="noreferrer noopener" target="_blank"&gt;Docstore&lt;/a&gt;是 Uber 在 MySQL® 之上构建的内部分布式数据库。它存储数十 PB 的数据并每秒处理数千万个请求，是 Uber 最大的数据库引擎之一，被所有业务垂直领域的微服务所使用。自 2020 年推出以来，Docstore 用户和用例不断增长，请求量和数据占用量也在不断增长。&lt;/p&gt;&lt;p&gt;业务垂直领域和产品的需求不断增长，引入了复杂的微服务和依赖关系调用图。因此，应用程序要求数据库具有低延迟、更高的性能和可扩展性，同时产生更高的工作负载。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-challenges"&gt;挑战&lt;/h2&gt;&lt;p&gt;Uber 的大多数微服务都使用基于磁盘的存储支持的数据库来保存数据。然而，每个数据库都面临着为需要低延迟读取访问和高可扩展性的应用程序提供服务的挑战。&lt;/p&gt;&lt;p&gt;当一个用例需要比我们任何现有用户更高的读取吞吐量时，这就达到了沸点。 Docstore 可以满足他们的需求，因为它由 NVMe SSD 支持，可提供低延迟和高吞吐量。然而，在上述场景中使用 Docstore 成本高昂，并且需要许多扩展和运营挑战。&lt;/p&gt;&lt;p&gt;在深入研究挑战之前，让我们先了解一下 Docstore 的高级架构。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-docstore-architecture"&gt;文档库架构&lt;/h2&gt;&lt;p&gt;Docstore主要分为三层：无状态查询引擎层、有状态存储引擎层、控制平面。对于本博客的范围，我们将讨论其查询和存储引擎层。&lt;/p&gt;&lt;p&gt;无状态查询引擎层负责查询规划、路由、分片、模式管理、节点健康监控、请求解析、验证和AuthN/AuthZ。&lt;/p&gt;&lt;p&gt;存储引擎层负责通过 Raft 达成共识、复制、事务、并发控制和负载管理。分区通常由 NVMe SSD 支持的 MySQL 节点组成，能够处理繁重的读写工作负载。此外，数据使用 Raft 跨多个分区进行分片，其中包含一个领导者节点和两个跟随者节点，以达成共识。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/GBkXOF__0QtOHj5Bkl_OeqGLk9LRI9iDFVs6e3J_eZJBuvIPUBGBQCGzIcwJISdPj-jIDeYjjByFDh9m5OBobGXhZYkU4xEQIP7MDQf9-iPDp0p1oOOYniJuDvo7BJeMgP-oabTjG37spd5tJFw18B8" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：Docstore 架构。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;现在让我们看看当服务需要大规模低延迟读取时所面临的一些挑战：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;从磁盘检索数据的速度有一个阈值：&lt;/strong&gt;优化应用程序数据模型和查询以改善数据库延迟和性能的程度是有限的。除此之外，不可能挤出更多的性能。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;垂直扩展：&lt;/strong&gt;分配更多资源或升级到具有更高性能的更好主机有其局限性，其中数据库引擎本身成为瓶颈。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;水平扩展：&lt;/strong&gt;将分片进一步分割到更多的分区有助于在一定程度上解决挑战，但这样做在操作上是一个更加复杂和漫长的过程。我们必须确保数据的持久性和弹性，而不会造成任何停机。此外，该解决方案并不能完全帮助解决热键/分区/分片的问题。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;请求不平衡：&lt;/strong&gt;读请求的传入速率通常比写请求高几个数量级。在这种情况下，底层 MySQL 节点将难以跟上繁重的工作负载并进一步影响延迟。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;成本：&lt;/strong&gt;从长远来看，通过垂直和水平扩展来改善延迟的成本高昂。处理两个区域的 3 个有状态节点中的每一个节点的成本都会增加 6 倍。此外，扩展并不能完全解决问题。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为了克服这个问题，微服务利用缓存。在 Uber，我们提供 Redis™ 作为分布式缓存解决方案。微服务的典型设计模式是写入数据库和缓存，同时从缓存中读取数据以改善延迟。然而，这种方法存在以下挑战：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;每个团队都必须为其各自的服务配置和维护自己的 Redis 缓存&lt;/li&gt;&lt;li&gt;缓存失效逻辑在每个微服务中分散实现&lt;/li&gt;&lt;li&gt;在区域故障转移的情况下，服务要么必须维持缓存复制以保持热状态，要么在其他区域的缓存预热时遭受更高的延迟&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;各个团队必须花费大量的精力来使用数据库实现自己的自定义缓存解决方案。当务之急是找到一种更好、更高效的解决方案，不仅能以低延迟满足请求，而且易于使用并提高开发人员的工作效率。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-cachefront-nbsp"&gt;缓存前端&lt;/h2&gt;&lt;p&gt;我们决定构建一个集成的缓存解决方案 CacheFront for Docstore，并考虑到以下目标：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;最大限度地减少垂直和/或水平缩放的需要以支持低延迟读取请求&lt;/li&gt;&lt;li&gt;减少数据库引擎层的资源分配；缓存可以从相对便宜的主机上构建，因此整体成本效率得到提高&lt;/li&gt;&lt;li&gt;改善 P50 和 P99 延迟，并稳定微突发期间的读取延迟峰值&lt;/li&gt;&lt;li&gt;替换大多数由各个团队构建（或将要构建）以满足其需求的定制缓存解决方案，特别是在缓存不是团队核心业务或能力的情况下&lt;/li&gt;&lt;li&gt;通过重用现有的 Docstore 客户端来使其透明，无需任何额外的样板，以便从缓存中受益&lt;/li&gt;&lt;li&gt;提高开发人员的工作效率，并允许我们以对客户透明的方式发布新功能或替换底层缓存技术&lt;/li&gt;&lt;li&gt;将缓存解决方案与 Docstore 的底层分片方案分离，以避免因热键、分片或分区引起的问题&lt;/li&gt;&lt;li&gt;允许我们独立于存储引擎水平扩展缓存层&lt;/li&gt;&lt;li&gt;将维护和调用 Redis 的所有权从功能团队转移到 Docstore 团队&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-cachefront-design"&gt;缓存前端设计&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-docstore-query-patterns"&gt;文档库查询模式&lt;/h3&gt;&lt;p&gt;Docstore 支持通过主键或分区键进行查询的不同方式，并可以选择过滤数据。从高层次来看，它主要可以分为以下几部分：&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;按键式/过滤器&lt;/td&gt;&lt;td&gt;没有过滤器&lt;/td&gt;&lt;td&gt;按 WHERE 子句过滤&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;行数&lt;/td&gt;&lt;td&gt;读取行&lt;/td&gt;&lt;td&gt;–&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;分区&lt;/td&gt;&lt;td&gt;读分区&lt;/td&gt;&lt;td&gt;查询行&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;我们希望从最常见的查询模式开始逐步构建我们的解决方案。事实证明，超过 50% 的 Docstore 查询都是 ReadRows 请求，而且由于这也恰好是最简单的用例（没有过滤器和点读取），因此很自然地从集成开始。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-high-level-architecture"&gt;高层架构&lt;/h3&gt;&lt;p&gt;由于Docstore的查询引擎层负责为客户端提供读写服务，因此非常适合集成缓存层。它还将缓存与基于磁盘的存储分离，使我们能够独立扩展它们中的任何一个。查询引擎层实现了一个 Redis 接口，用于存储缓存数据以及使缓存条目失效的机制。高级架构如下所示： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/Rmm5BmifYPw54KnH74kaCJWK5L-FuymknafE9zQIhfeD4NpY0voHwI_3EtWXx90vPdGl63U9Ukz3ZsZQ0hwlntl55ofun8yhFL4489HMETZ2Jkkp7662u2-mIjOojJW5irCtwyb1xybqRJMlrS-2apM" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：CacheFront 设计。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; Docstore 是一个强一致性数据库。尽管集成缓存提供了更快的查询响应，但在使用缓存时，关于一致性的一些语义可能无法为每个微服务所接受。例如，缓存失效可能会失败或滞后于数据库写入。因此，我们将集成缓存作为一项可选功能。服务可以在每个数据库、每个表甚至每个请求的基础上配置缓存使用情况。&lt;/p&gt;&lt;p&gt;如果某些流需要强一致性（例如获取食客购物车中的商品），则可以绕过缓存，而其他写入吞吐量较低的流（例如获取餐厅的菜单）将从缓存中受益。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-cached-reads"&gt;缓存读取&lt;/h3&gt;&lt;p&gt;CacheFront 使用缓存预留策略来实现缓存读取：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;查询引擎层收到多一行的读取请求&lt;/li&gt;&lt;li&gt;如果启用了缓存，请尝试从 Redis 获取行；将响应流式传输给用户&lt;/li&gt;&lt;li&gt;从存储引擎检索剩余行（如果有）&lt;/li&gt;&lt;li&gt;使用剩余行异步填充 Redis&lt;/li&gt;&lt;li&gt;将剩余行流式传输给用户&lt;/li&gt;&lt;/ol&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/TZIbPhOxvXtUMaxrn0LukNpglUsFD6CWoliV6z0OhW92wZh2wrYi6XO5-fwQyEkjGztPuGhP2j-BGxDO5Rg7MJ-lURrhwN_1Cxgt-s7i5JPNUWcm_k9s7Khb8K-_AwxOvdkni_83QqGDmuq5jOOzQC4" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：CacheFront 读取路径。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-cache-invalidation"&gt;缓存失效&lt;/h2&gt;&lt;blockquote class="wp-block-quote"&gt;&lt;p&gt;&lt;em&gt;“计算机科学中只有两件难事：缓存失效和命名。”&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;cite&gt;——菲尔·卡尔顿&lt;/cite&gt;&lt;/blockquote&gt;&lt;p&gt;虽然上一节中的缓存策略看起来很简单，但为了确保缓存正常工作，必须考虑很多细节，尤其是缓存失效。如果没有任何显式缓存失效，缓存条目将在配置的 TTL（默认情况下为 5 分钟）内过期。虽然这在某些情况下可能没问题，但大多数用户希望更改的反映速度比 TTL 更快。默认的 TTL 可以降低，但这会降低我们的缓存命中率，而不会显着提高一致性保证。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-conditional-update"&gt;有条件更新&lt;/h3&gt;&lt;p&gt;Docstore 支持条件更新，可以根据过滤条件更新一行或多行。例如，更新指定地区所有连锁餐厅的假期安排。由于给定过滤器的结果可能会发生变化，因此我们的缓存层无法确定哪些行将受到条件更新的影响，直到数据库引擎中更新了实际行。因此，我们无法在无状态查询引擎层的写入路径中使缓存行无效并填充以进行条件更新。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-leveraging-change-data-capture-for-cache-invalidation-nbsp"&gt;利用变更数据捕获来使缓存失效&lt;/h3&gt;&lt;p&gt;为了解决这个问题，我们利用了 Docstore 的变更数据捕获和流服务 Flux。 Flux 跟踪存储引擎层中每个集群的&lt;a href="https://dev.mysql.com/doc/internals/en/binary-log-overview.html" rel="noreferrer noopener" target="_blank"&gt;MySQL binlog&lt;/a&gt;事件，并将事件发布到消费者列表。 Flux 为 Docstore CDC（更改数据捕获）、复制、物化视图、数据湖摄取以及验证集群中节点之间的数据一致性提供支持。&lt;/p&gt;&lt;p&gt;编写了一个新的消费者，它订阅数据事件并使 Redis 中的新行无效或更新。现在，使用此失效策略，条件更新将导致受影响的行发生数据库更改事件，这些事件将用于使缓存中的行失效或填充。因此，我们能够在数据库更改后的几秒钟内（而不是几分钟）使缓存保持一致。此外，通过使用二进制日志，我们不会冒让未提交的事务污染缓存的风险。&lt;/p&gt;&lt;p&gt;缓存失效后的最终读写路径如下所示： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/05_8F32Yokun9_DucegrI80UJbwUwj5kulbM56xBrKCaNT2-NklDzrubhI-E7kJh3CK7Y9eQ2hggkhaXmECvSn9AZZV7ARUqiejCDk9H1SDehB_tJ3zPGmgg6UsVZKEViJM51qqqhcR-bhsS4L_DNN8" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：失效的 CacheFront 读写路径。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-deduplicating-cache-writes-between-query-engine-and-flux"&gt;在查询引擎和 Flux 之间删除重复的缓存写入&lt;/h3&gt;&lt;p&gt;然而，上述缓存失效策略有一个缺陷。由于写入在读取路径和写入路径之间同时发生在缓存中，因此我们可能会无意中将过时的行写入缓存，从而覆盖从数据库检索到的最新值。为了解决这个问题，我们根据 MySQL 中行集的时间戳来删除重复写入，这实际上作为其版本。时间戳是从 Redis 中的编码行值中解析出来的（请参阅后面有关编解码器的部分）。&lt;/p&gt;&lt;p&gt; Redis 支持使用&lt;a href="https://redis.io/commands/eval/"&gt;EVAL&lt;/a&gt;命令自动执行自定义 Lua 脚本。该脚本采用与&lt;a href="https://redis.io/commands/eval/" rel="noreferrer noopener" target="_blank"&gt;MSET&lt;/a&gt;相同的参数，但是，它还执行重复数据删除逻辑，检查已写入缓存的任何行的时间戳值并确保要写入的值是较新的。通过使用 EVAL，所有这些都可以在单个请求中执行，而不需要在查询引擎层和缓存之间进行多次往返。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-stronger-consistency-guarantees-for-point-writes"&gt;更强的点写入一致性保证&lt;/h3&gt;&lt;p&gt;虽然 Flux 允许我们比仅仅依赖 Redis TTL 来使缓存条目失效更快，但它仍然为我们提供了最终一致性语义。然而，某些用例需要更强的一致性，例如读自己写，因此对于这些场景，我们向查询引擎添加了专用 API，允许用户在相应的写入完成后显式使缓存的行无效。这使我们能够为点写入提供更强的一致性保证，但不能为条件更新提供更强的一致性保证，条件更新仍然会被 Flux 失效。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-table-schemas"&gt;表模式&lt;/h3&gt;&lt;p&gt;在深入了解有关实现的更多细节之前，我们先定义一些关键术语。 Docstore 表有一个&lt;em&gt;主键&lt;/em&gt;和&lt;em&gt;分区键&lt;/em&gt;。&lt;/p&gt;&lt;p&gt;主键（通常称为&lt;em&gt;行键&lt;/em&gt;）唯一标识 Docstore 表中的行并强制执行唯一性约束。每个表都必须有一个主键，它可以由一列或多列组成。&lt;/p&gt;&lt;p&gt;分区键是整个主键的前缀，决定了该行将驻留在哪个分片中。它们并不是完全独立的——相反，分区键只是主键的一部分（或等于）。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/3Et4lJLc7ohCnbi7oWQ5MvAnNTBN9KbRZZwVaoPf16QtK3VDpvKfr39gi4I3pdx7B5FE_IHi7Iz_tU9i4lAlEi6I_P4kPvb71vGRNxjSzCVbVe5Jr92fMfpi8tqtXh0nsqStymKUr3UymWlYmx5p9Ac" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：Docstore 架构和数据建模示例。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;在上面的示例中， &lt;strong&gt;person_id&lt;/strong&gt;是&lt;strong&gt;person&lt;/strong&gt;表的主键和分区键。而对于&lt;strong&gt;订单&lt;/strong&gt;表， &lt;strong&gt;cust_id&lt;/strong&gt;是分区键， &lt;strong&gt;cust_id&lt;/strong&gt;和&lt;strong&gt;order_id&lt;/strong&gt;一起形成主键。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-redis-codec"&gt; Redis 编解码器&lt;/h3&gt;&lt;p&gt;由于我们主要将缓存行读取，因此我们可以使用给定的行键唯一地标识行值。由于 Redis 键和值存储为字符串，因此我们需要一个特殊的编解码器以 Redis 接受的格式对 MySQL 数据进行编码。&lt;/p&gt;&lt;p&gt;选择了以下编解码器，因为它允许不同数据库共享缓存资源，同时仍保持数据隔离。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1078207" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Screenshot-2024-02-07-at-12.36.06%E2%80%AFPM-1024x267.png" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/DYQl48pmuGDctmIRBUVlDoOQ1stF1w2I9swtVZL8SlPJZZ1jVSa7klvG_SurVWfDzwi6DE_7fwkWkWTyPqyd_8NBdd02Vv9g6j-lwp5NENw5IbSeOPeWPKCzg1WZ1uMIT6jLW7lGEmmb3WLBPE4gBLA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：CacheFront Redis 编解码器。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-features"&gt;特征&lt;/h3&gt;&lt;p&gt;完成高级设计后，我们的解决方案就可以运行了。现在是我们考虑规模和弹性的时候了：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;如何实时验证数据库和缓存的一致性&lt;/li&gt;&lt;li&gt;如何容忍可用区/区域故障&lt;/li&gt;&lt;li&gt;如何容忍 Redis 故障&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-compare-cache"&gt;比较缓存&lt;/h3&gt;&lt;p&gt;如果不可测量，所有关于提高一致性的讨论都毫无意义，因此我们添加了一种特殊模式，可以隐藏对缓存的读取请求。回读时，我们比较缓存数据和数据库数据并验证它们是否相同。任何不匹配（缓存中存在的过时行或缓存中存在的行（但数据库中不存在））都会被记录并作为指标发出。通过使用 Flux 添加缓存失效功能，缓存的一致性达到 99.99%。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/5WXplUI4vPGJbSdkMGUjTl2XRN4wM8i2X6tY_SXFf_FRDWIlNCuPaTwQ-MCN-bLSWZ8k4Gp_xPZ578KB7LV8DEKvMKa6FfCByfm1BJc8_f1KRvsKuSPTnQs3KYbyj7lt2BbU6ysXVw4auVPDfoqtB30" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：比较缓存设计。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-cache-warming"&gt;缓存预热&lt;/h3&gt;&lt;p&gt;Docstore 实例会产生两个不同的地理区域，以确保高可用性和容错能力。部署是主动-主动的，这意味着可以在任何区域发出和服务请求，并且所有写入都跨区域复制。如果一个区域发生故障转移，另一个区域必须能够满足所有请求。&lt;/p&gt;&lt;p&gt;此模型对 CacheFront 提出了挑战，因为跨区域的缓存应始终保持温暖。如果不是，区域故障转移将增加对数据库的请求数量，因为故障区域中最初服务的流量的缓存未命中。这将阻止我们缩小存储引擎并回收任何容量，因为数据库负载将与没有任何缓存的情况一样高。&lt;/p&gt;&lt;p&gt;冷缓存问题可以通过跨区域Redis复制来解决，但是它带来了一个问题。 Docstore有自己的跨区域复制机制。如果我们使用Redis跨区域复制来复制缓存内容，我们将有两个独立的复制机制，这可能会导致缓存与存储引擎的不一致。为了避免CacheFront的这种缓存不一致问题，我们通过添加新的缓存预热模式来增强Redis跨区域复制组件。&lt;/p&gt;&lt;p&gt;为了确保缓存始终处于热状态，我们跟踪 Redis 写入流并将密钥复制到远程区域。在远程区域中，读取请求不是直接更新远程缓存，而是发送到查询引擎层，查询引擎层在缓存未命中时，从数据库读取数据并写入缓存，如设计的&lt;strong&gt;缓存读取&lt;/strong&gt;部分所述。通过仅在缓存未命中时发出读取请求，我们还可以避免存储引擎不必要的过载。从查询引擎层读取行的响应流被简单地丢弃，因为我们对结果并不真正感兴趣。&lt;/p&gt;&lt;p&gt;通过复制键而不是值，我们始终确保缓存中的数据与各自区域的数据库一致，并且在两个区域的 Redis 中保留相同的缓存行工作集，同时也限制了跨区域的数量使用的带宽。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/cbUIurHsBaCU231zyyfsEcF0aiSL_Tqyy8x03_I3tp66sO1BwcnmPVykW93xFdePIt1JaT2ZZYWRO0RAznx0fogY1C5rahduCC5TvagTpWrxNgB7QfoKPAupt3Ts24S4EbxW9xoCaTkbCvjtdICNgKc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：缓存预热设计。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-negative-caching"&gt;负缓存&lt;/h3&gt;&lt;p&gt;在许多读取针对不存在的行的情况下，最好缓存负结果，而不是每次都出现缓存未命中并查询数据库。为了实现这一点，我们在 Cachefront 中内置了负缓存。与常规缓存填充策略（将从数据库返回的所有行都写入缓存）类似，我们还跟踪已查询但未从数据库读取的任何行。这些不存在的行会使用特殊标志写入缓存，在将来的读取中，如果找到该标志，我们在查询数据库时会忽略该行，并且不会将该行的任何数据返回给用户。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-sharding"&gt;分片&lt;/h3&gt;&lt;p&gt;虽然Redis并没有受到热分区问题的严重影响，但Docstore的一些大客户会产生大量的读写请求，这对于在单个Redis集群中进行缓存来说是一个挑战，通常会受到其可以拥有的最大节点数量的限制。为了缓解这个问题，我们允许单个 Docstore 实例映射到多个 Redis 集群。这还可以避免数据库完全崩溃，如果单个 Redis 集群中的多个节点发生故障并且缓存对于某些范围的键不可用，则可能会对其发出大量请求。&lt;/p&gt;&lt;p&gt;然而，即使数据跨多个 Redis 集群分片，单个 Redis 集群出现故障也可能会在数据库上产生热分片问题。为了缓解这个问题，我们决定通过分区键对Redis集群进行分片，这与Docstore中的数据库分片方案不同。现在，当单个 Redis 集群出现故障时，我们可以避免单个数据库分片过载。来自失败的 Redis 分片的所有请求将分布在所有数据库分片中，如下所示： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/_NOpBAx6pbT-B-CetPrxh1Vjvj3Ref86cqNIE4WbvS00ESPzYVwI_AFpPHKFvINL6IRTZtivXpMMF5FkTuWyuAAc6ssQxp3EqkYOKh13Ici5NTl8d5U9lU02en9uYptdB902RDmBa6YBI_CloUcHwB0" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：Redis 分片请求流。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-circuit-breakers"&gt;断路器&lt;/h3&gt;&lt;p&gt;如果 Redis 节点出现故障，我们希望能够短路对该节点的请求，以避免 Redis 获取/设置请求的不必要的延迟损失，因为我们非常有信心该请求将会失败。为了实现这一目标，我们使用滑动窗口断路器。我们统计每个时间段每个节点上的错误数量，并计算滑动窗口宽度中的错误数量。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1078102" height="365" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/figure10-sliding-window-1024x365.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 10：滑动窗口设计。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;断路器配置为短路该节点的一部分请求，与错误计数成比例。一旦达到最大允许错误计数，断路器就会跳闸，并且在滑动窗口过去之前不能向节点发出更多请求。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-adaptive-timeouts"&gt;自适应超时&lt;/h3&gt;&lt;p&gt;我们意识到有时很难为 Redis 操作设置正确的超时。超时时间太短会导致 Redis 请求过早失败，浪费 Redis 资源并给数据库引擎带来额外负载。超时太长会影响 P99.9 和 P99.99 延迟，在最坏的情况下，请求可能会耗尽查询中传递的整个超时。虽然可以通过配置任意低的默认超时来缓解这些问题，但我们可能会面临将超时设置得太低的风险，因为许多请求会绕过缓存并访问数据库，或者将超时设置得太高，这会导致我们回到最初的问题。&lt;/p&gt;&lt;p&gt;我们需要自动、动态地调整请求超时，以便对 Redis 的 P99 请求在分配的超时内成功，同时完全减少延迟的长尾。配置自适应超时意味着允许动态调整 Redis 获取/设置超时值。通过允许自适应超时，我们可以设置相当于缓存请求的 P99.99 延迟的超时，从而让 99.99% 的请求进入缓存并快速响应。剩余的 0.01% 的请求（这会花费太长时间）可以更快地取消并从数据库中提供服务。&lt;/p&gt;&lt;p&gt;启用自适应超时后，我们不再需要手动调整超时来匹配所需的 P99 延迟，而只能设置最大可接受的超时限制，超过该限制框架就不允许（因为设置了最大超时）无论如何，应客户要求）。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/BFgKW0IWMozMuBjKyv8UvqNzBesswYoRMhegElEZLSlF8aBI5WT81GdZ7gHYqRX9FalcrFtlt3_Li7sd3PbxnqV5Fj0gAsl0W4SeM7-6caHi5dZDElaOvYdMEh383DXLFnnEPxPmguu5FYVS3rNaF8A" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 11：自适应超时延迟改进。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-results"&gt;结果&lt;/h2&gt;&lt;p&gt;那么我们成功了吗？我们最初打算构建一个对用户透明的集成缓存。我们希望我们的解决方案能够帮助改善延迟、易于扩展、帮助控制存储引擎的负载和成本，同时具有良好的一致性保证。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/k8nIx9d66HktdxoS2Hl1WQHvf17lZoYz1-CBKXi9HBwVIs2JPakyPe0XZN55LnqVsDP0jJTmOWsj3iI5wiDqIfBm_ldkjXAjtBEy_ql-WeUE5l7Xs54OUEFEefGlx6P9_V3IrUZsiWlUT0HTWEE6h6A" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 12：缓存与存储引擎延迟比较。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;ol&gt;&lt;li&gt;具有集成缓存的请求延迟明显更好。 P75 延迟下降了 75%，P99.9 延迟下降了 67% 以上，同时也限制了延迟峰值，如上所示。&lt;/li&gt;&lt;/ol&gt;&lt;ol start="2"&gt;&lt;li&gt;使用 Flux 和 Compare 缓存模式进行缓存失效可以帮助我们确保良好的一致性。&lt;/li&gt;&lt;li&gt;由于它位于我们现有的 API 后面，因此对用户来说是透明的，并且可以在内部进行管理，同时仍然通过基于标头的选项为用户提供灵活性。&lt;/li&gt;&lt;li&gt;分片和缓存预热使其具有可扩展性和容错性。事实上，我们最大的初始用例之一驱动了超过 6M RPS，缓存命中率高达 99%，并且经过验证，故障转移成功，所有流量都重定向到远程区域。&lt;/li&gt;&lt;li&gt;相同的用例最初需要大约 60K CPU 内核才能直接从存储引擎提供 6M RPS 服务。借助 CacheFront，我们仅用 3K Redis 核心即可实现约 99.9% 的缓存命中率，从而使我们能够减少容量。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;如今，CacheFront 支持生产中所有 Docstore 实例每秒超过 4000 万个请求，而且这个数字还在不断增长。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/pTmRmm5OFwqZ9bmcvsp_Lskq3PTyxOP8XaRaJ-OWGrg3Vy3I4rPFX5ApmE9cOCH9kvfZZRJHfHw4r9ZM0dWj27QltRed9gQJnoPZdYhYOy-tMOec-kAhQ_452oHVYgtVqPWA66dzfu1y4ClxFraeBQM" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 13：所有实例的缓存读取总数。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们已经解决了通过 CacheFront 扩展 Docstore 上的读取工作负载的核心挑战之一。它不仅可以满足需要高吞吐量和低延迟读取的大规模用例，还可以帮助我们减轻存储引擎的负载并节省资源，提高存储的整体成本，让开发人员可以专注于构建产品而不是管理基础设施。&lt;/p&gt;&lt;p&gt;如果您喜欢与分布式系统、数据库、存储和缓存相关的挑战，请&lt;a href="https://www.uber.com/us/en/careers/list/?query=storage&amp;amp;department=Engineering" rel="noreferrer noopener" target="_blank"&gt;在此处&lt;/a&gt;探索并申请空缺职位。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Oracle、Java、MySQL 和 NetSuite 是 Oracle 和/或其附属公司的注册商标。其他名称可能是其各自所有者的商标。&lt;/em&gt;&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Redis 是 Redis Labs Ltd 的商标。其中的任何权利均归 Redis Labs Ltd 保留。此处的任何使用仅供参考，并不表明 Redis 与 Uber 之间有任何赞助、认可或从属关系。&lt;/em&gt;&lt;/p&gt;</description><pubDate>Thu, 15 Feb 2024 07:00:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/how-uber-serves-over-40-million-reads-per-second-using-an-integrated-cache/</guid></item><item><title>Jupiter：配置驱动的 Adtech 批量摄取平台</title><link>https://www.uber.com/blog/jupiter-batch-ingestion-platform/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;Uber 的使命是重新构想世界变得更美好的方式，并通过其市场在全球范围内提供盈利机会。让 Uber 品牌和市场更贴近人们的一种有效方法是投资付费营销策略。&lt;/p&gt;&lt;p&gt;要实现市场的最佳平衡，就必须持续保持供需平衡。这需要创造一个消费者负担得起的环境，同时为赚钱者保留良好的赚钱机会。实现这一目标的一种方法是不断向市场引入新用户，这是一个持续的过程，涉及在 Google、Meta、Apple 等不同的营销平台上推广 Uber 的市场产品。&lt;/p&gt;&lt;p&gt;鉴于这些是付费广告，我们的营销团队不断制定策略，以快速吸引更多用户加入该平台。因此，及时接收来自这些供应商的信号对于我们有效改进我们的方法至关重要。&lt;/p&gt;&lt;p&gt;这篇博文旨在探讨我们的传统摄取系统 MaRS（营销报告服务）遇到的限制和困难，该系统负责定期从外部广告合作伙伴收集广告信号。此外，我们将讨论如何通过技术进步来增强我们的营销业务，并通过实施我们的新系统 Jupiter 来实现可扩展性。&lt;/p&gt;&lt;p&gt;在本博客中，我们将付费营销描述为一个域，而广告技术代表同一域内的系统。这些术语在此上下文中可以互换使用。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-what-is-the-performance-marketing-user-flow"&gt;什么是效果营销用户流程？&lt;/h2&gt;&lt;p&gt;总体而言，后续序列提供了完整用户旅程的完整轮廓：从接触广告开始，导航到 Uber 平台，最后实现转化。这一行动对我们的业务很有价值，在我们的背景下，可能涉及注册 Uber、通过 Uber Eats 下单或乘车。&lt;/p&gt;&lt;p&gt;经过上述操作后，会触发后续事件：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;转化事件&lt;/strong&gt;：当用户点击广告下载 Uber 应用时，标记特定于该广告的转化。这是与下载相关的一种转化事件。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;支出事件&lt;/strong&gt;：当用户查看广告时，表示向用户展示该广告的支出。&lt;/p&gt;&lt;p&gt;来自广告合作伙伴的这些支出事件需要被摄取、处理并向下游传输。这样做是为了衡量和优化广告的效果。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large is-resized"&gt;&lt;img alt="" class="wp-image-1077751" height="1363" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Figure1-edited-1.png" style="width: 767px; height: auto;" width="1817" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：Adtech 中的用户流程。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;h5 class="wp-block-heading" id="h-sample-user-flow"&gt;&lt;strong&gt;用户流程示例&lt;/strong&gt;&lt;/h5&gt;&lt;ul&gt;&lt;li&gt;第 1 步：用户点击合作伙伴页面上的 Uber 广告&lt;/li&gt;&lt;li&gt;第 2 步：用户到达 Uber 应用程序 [转化事件]&lt;/li&gt;&lt;li&gt;第 3 步：Adtech 系统从合作伙伴 [摄取平台] 检索数据&lt;/li&gt;&lt;li&gt;步骤 4：计算性能指标 ( &lt;a href="https://www.singular.net/glossary/return-on-ad-spend-roas" rel="noreferrer noopener" target="_blank"&gt;ROAS&lt;/a&gt; )&lt;/li&gt;&lt;li&gt;第 5 步：优化引擎通过根据计算的指标调整出价算法来增强出价算法。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-why-is-timely-ingestion-critical"&gt;为什么及时摄入很重要？&lt;/h2&gt;&lt;p&gt;及时、准确地吸收这些广告信号对于 Uber 的整体绩效营销至关重要。即使外部合作伙伴的及时广告信号出现最小的延迟或不准确的处理，也会影响 Uber 在这些平台上投放广告的能力。因此，这可能会影响进入该平台的用户数量。&lt;/p&gt;&lt;p&gt;举例来说，在持续两天的中断期间，我们无法从单个合作伙伴获取数据，下游关键绩效指标 ( &lt;a href="https://en.wikipedia.org/wiki/Performance_indicator" rel="noreferrer noopener" target="_blank"&gt;KPI&lt;/a&gt; )（特别是&lt;a href="https://www.singular.net/glossary/return-on-ad-spend-roas" rel="noreferrer noopener" target="_blank"&gt;ROAS&lt;/a&gt; ）的创建被延迟。这种延迟导致我们的出价和优化系统中的机器学习算法错误地得出我们的广告表现不佳的结论，从而导致广告支出停止。&lt;/p&gt;&lt;p&gt;结果，我们吸引新用户的能力受到损害，导致供需不平衡。所有这一切都是由于一次集成中断而发生的。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-problem-statement"&gt;问题陈述&lt;/h2&gt;&lt;p&gt;由于优步在全球众多国家/地区开展业务，我们与各种本地和全球广告合作伙伴或广告商合作开展付费营销工作。这导致了不同技术成熟度的多种不同技术系统的集成，具有异构的数据模式、格式、不同的传输协议以及数据新鲜度、沿袭性和完整性方面的差异。&lt;/p&gt;&lt;p&gt;广告技术行业正在经历一场重大变革，合作伙伴、移动测量平台 (MMP) 和外部广告技术平台正在从基于用户的广告跟踪过渡到一系列以隐私为中心的替代方案。这种转变催生了一个多样化的生态系统，合作伙伴之间的标准各不相同，带来了复杂性，例如数据模式频繁且不可预测的变化，挑战了营销和广告领域的历史假设。&lt;/p&gt;&lt;p&gt;由于其快速发展、规模以及所涉及数据集的多样性，这种复杂性给摄取系统带来了复杂的挑战。&lt;/p&gt;&lt;p&gt;以下是问题类别的细分以及摄取团队之前投入的时间： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1077758" height="862" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Figure2-edited.jpeg" width="1324" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：问题类别的划分。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-reliability"&gt;可靠性&lt;/h2&gt;&lt;p&gt;从数据中可以明显看出，大部分时间都用于确保摄取系统的可靠性。造成这种情况的主要因素可分为以下几类：&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-high-latency-nbsp"&gt;高延迟&lt;/h3&gt;&lt;p&gt;确保仓库中数据的及时可用性对于减少异常平均检测时间 (MTTD) 和提高广告技术系统的整体性能至关重要。&lt;/p&gt;&lt;p&gt;由于数据不完整或数据延迟问题，营销人员很难区分季节性和实际广告效果。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-no-partial-data-availability"&gt;没有部分数据可用性&lt;/h3&gt;&lt;p&gt;由于营销数据随着时间的推移而变化（例如超过 24 小时的支出数据和超过 28 天的转化数据），向下游系统提供部分数据变得非常重要。当合作伙伴端在特定广告帐户级别出现问题时，这一点尤其重要。考虑到此类问题的发生频率，拥有此功能本来可以防止大量数据中断。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-enhancements-in-technology-stack"&gt;技术堆栈的增强&lt;/h3&gt;&lt;p&gt;遗留系统 MaRS 旨在与旧的广告格式/域紧密耦合。对 MaRS 进行微小改进通常会导致工程周期延长或导致多项技术倒退。因此，在系统中容纳新的用例会导致系统变得笨重且难以管理。&lt;/p&gt;&lt;p&gt;此外，我们过时的基于 Python® 的技术堆栈导致速度减慢。利用这种情况，我们发起了升级。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-third-party-dependencies"&gt;第三方依赖项&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-standardization"&gt;标准化&lt;/h3&gt;&lt;p&gt;在我们的全球和本地广告合作伙伴中，有些拥有用于数据共享的高级 API。然而，有些规模较小的合作伙伴由于成熟度有限，通过电子邮件和 SFTP 等更多手动方法共享数据。因此，单个系统必须能够处理来自多种来源的数据提取。&lt;/p&gt;&lt;p&gt;此外，所有合作伙伴的数据格式和服务级别协议 (SLA) 也不一致。标准化的缺乏给维护带来了挑战。因此，有必要在所有合作伙伴之间建立统一的数据标准，以便下游系统无缝消费。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-rate-limits"&gt;速率限制&lt;/h3&gt;&lt;p&gt;引入新的合作伙伴数据、为现有合作伙伴引入新数据或在数据处理层中遇到错误，都需要摄取系统导入多年的历史数据（回填）。此过程会产生严重的延迟，通常需要几天到几周的时间，而且由于合作伙伴的速率限制，它还阻碍了日常管道的正常流动。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-high-maintenance"&gt;高维护成本&lt;/h3&gt;&lt;p&gt;维持合作伙伴特定的 SDK/API 需要大量的维护费用，包括专门的人员分配，以进行频繁的更新和错误修复，这最终降低了开发人员的生产力。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-scale"&gt;规模&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-huge-lead-time-to-market"&gt;上市时间长&lt;/h3&gt;&lt;p&gt;由于大量积压，我们只能满足 P0 营销请求。积压的主要原因是，过去加入新合作伙伴需要花费数周的时间，这阻碍了我们快速实验的能力。&lt;/p&gt;&lt;p&gt;例如，对于新兴合作伙伴，如果我们想在他们的平台上投放广告，我们必须等待几个月才能有资源来完成入职流程。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-high-dependency-on-eng-nbsp"&gt;对工程的高度依赖&lt;/h3&gt;&lt;p&gt;目前，任何合作伙伴的入职都严重依赖工程资源来编写用于 API 集成、数据转换、验证和测试的样板代码。这消耗了入职流程的很大一部分。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-solution-strategies"&gt;解决策略&lt;/h2&gt;&lt;p&gt;起初，MaRS 的构建受到了有限广告支出的限制。随着优步在全球范围内的扩张，本地和全球市场对日益个性化营销的需求都在增长。这就需要一个能够快速适应和纳入特定细微差别的系统。&lt;/p&gt;&lt;p&gt;营销人员需要为我们的衡量渠道中的新合作伙伴提供更快的入职流程，以促进实验。他们还以更高的频率寻求数据以加速取得成果，从而使他们能够相应地调整营销策略。&lt;/p&gt;&lt;p&gt;因此，我们开发了一个系统，通过采用高度松散耦合的架构来解决技术堆栈中的差距并满足未来的业务需求。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-build-vs-buy"&gt;建造与购买&lt;/h3&gt;&lt;p&gt;我们对外部第三方供应商的广告信号摄取进行了评估，而不是仅仅依赖内部解决方案。这主要是为了简化维护成本。&lt;/p&gt;&lt;p&gt;此外，营销团队还制定了强有力的业务指令，要求获得更大的灵活性和对主要渠道（支出较高的顶级渠道）（如 Google、Apple 和 Meta）的控制。&lt;/p&gt;&lt;p&gt;因此，我们选择了混合架构，允许将外部供应商数据与来自合作伙伴的直接内部检索相结合。在入职期间采用哪种方法的决定将取决于集成的业务关键性。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-plug-and-play-architecture"&gt;即插即用架构&lt;/h3&gt;&lt;p&gt;我们需要为各种内部用例获取广告技术内部现有数据类别以外的数据，并且许多短间隙解决方案都是在筒仓中构建的。我们需要设想一个专门针对数据集的单一摄取系统，并且我们需要轻松且轻松地完成它。&lt;/p&gt;&lt;p&gt;我们为所有组件整合了即插即用架构，因此任何摄取都可以轻松地将其内部组件更改为其他组件。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-domain-agnostic-data-ingestion"&gt;与领域无关的数据摄取&lt;/h3&gt;&lt;p&gt;在我们追求为各种数据创建包容性摄取系统的过程中，我们需要分离特定领域的复杂性，并通过完全自助服务、基于配置的架构实现可配置性。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-reliability-0"&gt;可靠性&lt;/h3&gt;&lt;p&gt;由于与各种各样的合作伙伴打交道，我们的系统必须处理大量不成熟的数据格式、不一致的 SLA 和意外场景。这些广告信号的大小也有很大差异，在特定情况下从几 GB 到 TB。 Jupiter 经过专门设计，能够以灵活的方式熟练地管理这些不同的场景。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-architecture"&gt;建筑学&lt;/h1&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1077763" height="421" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Figure3-1-1024x421.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：Jupiter 架构。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;h3 class="wp-block-heading" id="h-multi-vendor-integration"&gt;多供应商集成&lt;/h3&gt;&lt;p&gt;我们有各种业务场景，需要将来自不同供应商的不同数据集集成到我们的平台中。这些集成需要考虑特定因素，例如数据格式、摄取频率和数据成熟度级别。&lt;/p&gt;&lt;p&gt;因此，该平台的架构旨在适应任何供应商的任何数据摄取流程，从而允许以最少的配置进行无缝更改。&lt;/p&gt;&lt;p&gt;集成新供应商涉及配置其特定的集成细节，之后平台的其余部分将与其无缝连接。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-multi-source-integrations-nbsp"&gt;多源集成&lt;/h3&gt;&lt;p&gt;鉴于我们与众多供应商的互动，我们自然会遇到需要摄取的不同数据源。为了解决这个问题，我们实现了可配置的数据源，并通过配置定义了其特定属性。与供应商一样，这些数据源可以随时切换，只需最少的配置工作。&lt;/p&gt;&lt;p&gt;目前，我们已与 Amazon Web Services、Google Drive、电子邮件、API 等源集成。添加新源涉及配置其集成细节，之后平台的其余部分将无缝适应它。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-non-transformed-data-sets"&gt;未转换的数据集&lt;/h3&gt;&lt;p&gt;为了满足我们的业务需求，我们发现有必要在更长的时间间隔内提取数据，而不受合作伙伴能力的限制。此外，我们对快速检测任何异常趋势 (MTTD) 的迫切需求促使我们实施数据复制过程，而不应用任何转换。&lt;/p&gt;&lt;p&gt;这种方法使我们能够加快任何问题的调试，并在必要时有效地回填数据。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-config-driven-transformation-layer"&gt;配置驱动转换层&lt;/h3&gt;&lt;p&gt;由于我们管理的数据模式多种多样，定制转换对于标准化至关重要。&lt;/p&gt;&lt;p&gt;样板代码的很大一部分专门用于这个特定的组件。为了实现完全自助的摄取系统，我们的目标是针对每个不同的用例配置此组件。&lt;/p&gt;&lt;p&gt;因此，我们为这个转换层开发了一个内部库。该库包含用户定义的转换，范围从行到行、列到列到聚合转换。我们在内部系统和类似用例中利用了这个库，以实现可重用性。附件是一个示例配置。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-full"&gt;&lt;img alt="" class="wp-image-1077942" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Screenshot-2024-02-05-at-1.59.18%E2%80%AFPM.png" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;h3 class="wp-block-heading" id="h-self-serve-ingestion-onboarding"&gt;&lt;br /&gt;自助摄取入门&lt;/h3&gt;&lt;p&gt;我们优化了平台摄取流程的整个入职流程，将其转变为具有基本保障措施的自助服务模式。此转换涉及实现&lt;strong&gt;基于触发器的机制&lt;/strong&gt;，该机制在所有组件之间无缝运行，从从源获取数据、启动转换、进行测试、在所有检查后验证和升级以及触发验证后程序开始。这是附加的高级流程供参考。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/50cHgz3rK-Vua-iE0-r2NLsMM-sAX6Mdt6468e_JwQwyiima0Yqo_XAR8ymryQRJdW_NicyVnJ5f9_1FUVH77rGb_Lic15xQ6rl2lQxIo2bpV4ewbmaZtFC_pZuaQSTjxdEzCeq5KePOQ__W6UVl4cY" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：流程图。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;由于这些改进，该流程的责任已转移给运营团队，从而消除了持续工程参与的必要性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-impact"&gt;影响&lt;/h2&gt;&lt;p&gt;目前，现有系统已完全淘汰并过渡到木星。下面，我们概述了这两个系统的指标：&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;公制&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;改进 ％&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;入职时间 – 新摄取&lt;/td&gt;&lt;td&gt;&amp;gt; 90%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;入职时间 – 新供应商&lt;/td&gt;&lt;td&gt;&amp;gt; 75%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;入职时间 – 新来源&lt;/td&gt;&lt;td&gt;&amp;gt; 75%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;数据摄取频率&lt;/td&gt;&lt;td&gt;&amp;gt; 75%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;数据摄取延迟&lt;/td&gt;&lt;td&gt;&amp;gt; 70% &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;我们概述了与广告技术域网络相关的困难和潜在优势，以及从中获取可靠数据和实施复杂转换以满足各种业务需求的过程。目前，我们已经退役了以前的系统，并将所有用例转移到新平台，并在可行的情况下纳入新的数据增强功能。&lt;/p&gt;&lt;p&gt;我们已经成功实现了我们的主要目标，即加快新合作伙伴的入职流程，并通过为利益相关者提供自助服务方法确保数据可靠性。然而，仍有更复杂的用例需要解决。例如，到目前为止，我们专注于下载单个报告结构并应用转换。我们的下一个挑战是下载多个结构，合并它们，并通过统一的工作流程提供单个或多个数据集。下一个重要步骤是将该平台扩展到其当前特定用例支持之外，并将其转变为多租户系统。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-acknowledgments"&gt;致谢&lt;/h2&gt;&lt;p&gt;我们对核心工程和产品团队表示特别感谢，其中包括 Prathamesh Gabale（工程经理）、Akshit Jain（软件工程师）、Sarthak Chhillar（软件工程师）、Saurav Pradhan（软件工程师）和 Piyush Choudhary（产品）经理），感谢他们在确保这一旅程成功方面发挥的关键作用。&lt;/p&gt;&lt;p&gt;我们还要感谢 Devesh Kumar、Diwakar Bhatia 和 Vijayasaradhi Uppaluri 的宝贵反馈和坚定支持。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Amazon Web Services、AWS、Powered by AWS 徽标和 S3 是 Amazon.com, Inc. 或其附属公司的商标。&lt;/em&gt;&lt;/p&gt;</description><pubDate>Tue, 06 Feb 2024 07:00:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/jupiter-batch-ingestion-platform/</guid></item><item><title>DataCentral：Uber 的大数据可观测性和退款平台</title><link>https://www.uber.com/blog/datacentral-ubers-observability-and-chargeback-platform/</link><description>&lt;p&gt;在本博客中，我们将带您了解 DataCentral，这是 Uber 自主研发的大数据可观测性、归因和治理平台。该博客对 DataCentral 的主要功能进行了高级概述。在我们了解 DataCentral 的内容和原因之前，让我们快速了解一下 Uber 的数据生态系统及其挑战。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-introduction-to-uber-s-big-data-landscape"&gt; Uber 大数据格局简介&lt;/h1&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" class="wp-image-1077460" height="533" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/01/image-4.png" width="980" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：Uber 的大数据格局。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; Uber 的数据基础设施由各种计算引擎、调度/执行解决方案和存储解决方案组成。 Apache Spark &lt;sup&gt;™&lt;/sup&gt; 、 &lt;sup&gt;Presto®&lt;/sup&gt; 、Apache Hive &lt;sup&gt;™&lt;/sup&gt; 、Neutrino、Apache &lt;sup&gt;Flink®&lt;/sup&gt;等计算引擎使 Uber 能够每天运行 PB 级的操作。此外，还有调度和执行引擎，例如 Piper（Apache Airflow &lt;sup&gt;™&lt;/sup&gt;的 Uber 分支）、Query Builder（用于执行计算 SQL 的用户平台）、Query Runner（用于执行工作负载的代理层）和 Cadence（工作流编排引擎，开源） by Uber）的存在是为了允许计算工作负载的调度和执行。最后，很大一部分存储由 HDFS、Google Cloud Storage (GCS)、AWS S3、Apache Pinot &lt;sup&gt;™&lt;/sup&gt; 、 &lt;sup&gt;ElasticSearch®&lt;/sup&gt;等支持。每个引擎支持数千个执行，这些执行由多个所有者 (uOwn) 和子所有者拥有。团队。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-challenges"&gt;挑战&lt;/h2&gt;&lt;p&gt;由于大数据环境以 PB 级运行，并且每天运行约一百万个应用程序/查询，因此必须为利益相关者提供有关正确性能和资源消耗见解的整体视图。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-stakeholder-personas"&gt;利益相关者角色&lt;/h4&gt;&lt;p&gt;Uber 大数据生态系统的利益相关者包括以下内容：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;作业所有者：&lt;/strong&gt;最终用户访问 DataCentral 来查找其作业的元数据，例如持续时间、成本、资源消耗、查询文本和日志等。这使得 DataCentral 可以作为调试失败查询和应用程序的强大平台。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;大数据团队：&lt;/strong&gt; Spark、Presto、Hive 和 Neutrino 等大数据引擎团队利用 DataCentral 平台来深入了解失败作业的数量、不良/滥用作业、主要错误原因、阻塞查询等。此外、DataCentral 帮助他们调查 SLA 违规、事件和作业失败。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;行政领导：&lt;/strong&gt; DataCentral 还通过提供组织级统计数据（例如应用程序/查询级成本）来支持业务决策。它还提供可用于预测硬件需求和产生的成本的信息。&lt;/p&gt;&lt;p&gt; Uber 大数据平台涉及的各种角色的一些典型问题： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1077555" height="776" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Figure2-1024x776.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：Uber 数据平台的用户角色。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-enter-datacentral"&gt;进入数据中心&lt;/h2&gt;&lt;p&gt;在 Uber，我们开发了 DataCentral，这是一个综合平台，可为用户提供有关大数据应用程序和查询的基本见解。 DataCentral 通过提供有关工作流程和应用程序的详细信息、提高工作效率并减少调试时间来为数据平台用户提供支持。 DataCentral为客户提供以下关键服务：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;可观察性：&lt;/strong&gt;对大数据作业的性能趋势、成本和退化信号的精细洞察。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Chargeback&lt;/strong&gt; ：大数据工具和引擎（例如 Presto、Apache Yarn &lt;sup&gt;™&lt;/sup&gt; 、HDFS、Apache &lt;sup&gt;Kafka®&lt;/sup&gt;等）的指标和资源使用情况。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;消耗减少计划&lt;/strong&gt;：为 Uber 数据生态系统的核心成本降低计划提供支持，例如减少 HDFS 增长、减少 Yarn 使用等。 &lt;/li&gt;&lt;/ol&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1077558" height="730" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Figure3-1024x730.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：数据中心和产品。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;h3 class="wp-block-heading" id="h-how-does-datacentral-help-with-observability"&gt;&lt;br /&gt; DataCentral 如何帮助实现可观察性？&lt;/h3&gt;&lt;p&gt;数据可观察性提供对计算查询和应用程序的实时洞察。由于 Uber 的数据生态系统分布在不同的组件中，因此我们必须跨 Presto、Spark、Hive 和 Neutrino 等引擎跟踪指标。聚合这些指标并将其与执行引擎联系起来也是一个挑战。我们通过以下产品来做到这一点：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;时间序列指标（又名 Clio）&lt;/strong&gt; ：Uber 运行的每个查询都会被指纹识别并与执行的历史趋势相关联（我们称之为内部解决方案 Clio）。客户可以查看成本、持续时间、效率、数据读/写、随机播放等指标的历史趋势。深入了解历史趋势可以让客户更快地检测和调试应用程序。此外，我们还提供了“配置更改标记”，可以轻松关联配置更改和历史趋势变化（请参阅图 4 中的指标趋势）。我们观察到的一项主要挑战是基础设施引入了故障。为了解决这个问题，我们在 Yarn、HDFS 和关联工具中构建了可观察性。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" class="wp-image-1077471" height="900" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/01/image-8.png" style="width: 700px; height: auto;" width="1600" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：Clio 时间序列历史趋势。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;br /&gt; &lt;strong&gt;Yarn 可观察性：&lt;/strong&gt; Yarn 资源饱和会导致作业失败和缓慢，难以调试。我们提供解决方案来在应用程序运行时实时观察和关联纱线利用率。此外，当工作受到 Yarn 影响时，我们会提供见解和建议。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1077183" height="488" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/01/Figure5-1024x488.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：应用程序级 Yarn 队列洞察。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;br /&gt;&lt;strong&gt;文件系统可观察性：&lt;/strong&gt; HDFS 缓慢和文件系统引起的延迟是导致难以检测的性能下降的另一个因素。我们对 Uber Hadoop 客户端进行了更改，添加了应用程序级粒度的 HDFS 调用计数和延迟的客户端监控。每个开发人员都可以查看其特定应用程序/查询的文件系统性能，这使得调试过程更加顺利。我们还建立了相关系统来捕获各种基础设施和引擎指标以找出根本原因问题并提出修复建议——这是另一个博客的内容。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" class="wp-image-1077468" height="830" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/01/image-6.png" width="1600" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：向用户和引擎团队展示的 HDFS 指标。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" class="wp-image-1077463" height="820" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/01/image-5.png" width="1600" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：DataCentral 上的文件系统洞察用户界面。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1077559" height="524" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Figure8-1024x524.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：文件系统性能的历史见解。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;h3 class="wp-block-heading" id="h-contactless"&gt;&lt;strong&gt;非接触式&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;任何数据平台用户的大部分时间都花在对失败的查询和应用程序进行调试/故障排除上。为了帮助他们有效地排除故障，我们开发了“非接触式：系统”，其目标如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;提高错误的可发现性&lt;/li&gt;&lt;li&gt;从正确的层面识别并揭示根本原因&lt;/li&gt;&lt;li&gt;提供用户友好的解释和建议&lt;/li&gt;&lt;li&gt;提供可操作的工作流程来解决错误&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;该服务使引擎团队能够将基于正则表达式的规则添加到系统中。规则还支持添加其他元数据，例如用户友好的解释、根本原因层、优先级等。收集应用程序的堆栈跟踪后，非接触式服务将异常跟踪与规则进行匹配，并将最相关的消息显示回给用户。&lt;/p&gt;&lt;p&gt;每当应用程序出现故障时，DataCentral 就会解析错误日志并对堆栈跟踪应用非接触式规则。然后，用户友好的建议和错误消息将显示在数据中心控制台上，使最终用户能够调试并找出故障的根本原因。此外，建议选项卡指示解决错误可以采取的最佳操作。 &lt;/p&gt;&lt;div class="wp-block-columns is-layout-flex wp-container-3 wp-block-columns-is-layout-flex"&gt;&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1077184" height="1024" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/01/Figure9A-576x1024.png" width="576" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9A：用于配置规则的用户控制台。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1077187" height="1024" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/01/Figure9B-534x1024.png" width="534" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9B：用于配置规则的用户控制台。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1077562" height="509" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Figure10-1024x509.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 10：非接触式操作。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-how-does-datacentral-help-with-cost-efficiency"&gt; DataCentral 如何帮助提高成本效率？&lt;/h2&gt;&lt;p&gt; Uber 的成本治理和降低由两个概念驱动：归因和成本效率。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-chargeback"&gt;&lt;strong&gt;退款&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;Uber 没有对团队设定硬性限制和预算，而是在多个维度上提供成本和资源使用的高度透明度，以便利益相关者在做出决策时能够获得正确的数据。资源使用情况和成本以 uOwn（Uber 的所有权平台）级别的粒度进行跟踪。此外，资源使用情况可以按照不同的粒度进行剖析，例如：用户、管道、应用程序、计划和队列级别。归因对于推动保护、识别反模式和推动关键的成本削减举措至关重要。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1077563" height="520" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Figure11-1024x520.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 11：HDFS 消耗和使用情况洞察。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;br /&gt;&lt;strong&gt;减少消耗&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一旦资源归属于正确的团队和所有者，利益相关者就会深入了解以下指标：最昂贵的管道、持续失败的工作负载、不必要的计算等。作为成本效率的一部分，我们已经开始了项目（例如 HDFSRed、YarnRed、 PrestoRed 等）做出自动化、数据驱动的决策以降低成本。 HDFSRed 项目检查 Uber 数据表的访问模式，并为所有者创建 Jira 票证，以便在数据不频繁访问时推送表删除和 TTL。 Yarn 和 Presto 减少计划同样会检查反模式和不必要的计算，并提出可操作的 Jira 票证以减少/停止未使用的计算。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1077569" height="640" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Figure12-1024x640.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 12：纱线减少 JIRA 票据示例。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-datacentral-s-scale"&gt;数据中心的规模&lt;/h2&gt;&lt;p&gt;为了为 Uber 范围内的所有应用程序提供实时元数据，DataCentral 必须匹配 Uber 各种引擎的规模。 Flink 作业与引擎级规模保持同步，将实时建模数据提取到内部存储中。通过每天 500K Presto 查询、400K Spark 应用程序/天和 2M Hive 查询/天，数据可观测性作业在读取引擎级指标时每分钟处理 2K 查询和 30K RPS。此外，HDFS 洞察每天处理超过 10B 的调用，峰值速度为 150K RPS（因为它跟踪应用程序级粒度的调用）。数据存储具有 6 个月的保留期限来处理数据增长和规模。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-architecture"&gt;建筑学&lt;/h2&gt;&lt;p&gt;提供实时见解和元数据至关重要，以便最大限度地减少调试时间并减少作业失败。 DataCentral 的架构由以下组件组成：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; Presto、Hive、Spark 和 Neutrino 等引擎实时向 Kafka 主题发出查询级元数据。 DataCentral 具有 Flink 作业，可以不断侦听这些 Kafka 主题并使用引擎发出的任何作业级元数据。&lt;/li&gt;&lt;li&gt; Flink 作业实时预处理这些数据，并跨多个源合并作业级别粒度的元数据。最后，数据存储在MySQL和Docstore（Uber的内部数据存储，提供强一致性和高水平扩展）等内部存储中。&lt;/li&gt;&lt;li&gt; DataCentral 微服务堆栈由多个 API 组成，这些 API 服务于各种用例，例如 DataCentral UI、外部团队、Hive 表上的 TTL 设置等等。 &lt;/li&gt;&lt;/ul&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1077572" height="583" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Figure13-1024x583.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 13：高级数据中心架构。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;元数据从引擎到可观测性数据存储的整个过程需要不到 500 毫秒。 DataCentral UI 提供见解和元数据，通过 MySQL 和 Docstore 数据存储提供服务。支持 API 的 UI 从不同的来源获取数据并将其加入统一的响应中，最终提供面向客户的视图。&lt;/p&gt;&lt;p&gt;进一步运行批处理工作负载以支持建模数据集，从而提供关键的成本归因数据。来自各种引擎的数据与 HiveMetastore、uOwn 和其他元数据源相结合，以提供丰富的见解，这些见解在 DataCentral UI 上提供给下游团队，并用于降低成本计划。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-datacentral-amp-uber-s-move-to-cloud"&gt; DataCentral 和 Uber 向云迁移&lt;/h2&gt;&lt;p&gt;随着 Uber 转向云，我们的首要任务仍然是为云生态系统提供成本透明度和降低成本。此外，DataCentral 还为引擎团队提供关键指标支持，以进行性能测试、基准测试以及在将工作负载迁移到云时识别降级情况。这使我们能够在将关键工作迁移到云时做出正确的决策。例如，文件系统可观察性使 Spark 等引擎团队能够观察云带来的延迟增加，并制定正确的迁移解决方案。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;DataCentral 一直是 Uber 工程师、数据分析师和平台团队的重要工具。它提供对大数据应用程序和查询的高级分析和精细洞察。 DataCentral 的使用者包括工作负责人、引擎值班人员、平台团队和执行领导层。该平台的自助服务性质使客户能够高效地调试作业、减少事件和根本原因 SLA 违规。 DataCentral 的另一个关键产品是对大数据计算和存储实体（例如 HDFS、Yarn、Kafka、Presto 等）的消费洞察。DataCentral 充当利益相关者获取平台、团队和组织洞察的单一事实来源级别的见解。此外，我们计划开源 DataCentral 工具包，以实现更广泛的采用和社区协作。&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Apache®、Apache Pinot™、Apache Flink®、Apache Kafka®、Apache Hive™、Apache Hadoop®、Apache Spark™、Apache Yarn™、Kafka®、Apache Airflow™、Flink®、Hive™、Hadoop®、Spark™、 Pinot™、Airflow™ 和 Yarn™ 是 Apache Software Foundation 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/em&gt;&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Presto 是 LF Projects, LLC 的注册商标。使用这些标志并不暗示 LF Projects, LLC 的认可。&lt;/em&gt;&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Amazon Web Services、AWS、S3、Powered by AWS 徽标是 Amazon.com, Inc. 或其附属公司的商标。&lt;/em&gt;&lt;br /&gt;&lt;em&gt;标题图片：&lt;/em&gt; &lt;a href="https://www.flickr.com/photos/126444666@N05"&gt;&lt;em&gt;jensfrickephotography&lt;/em&gt;&lt;/a&gt;的“&lt;a href="https://www.flickr.com/photos/126444666@N05/14606819370"&gt;&lt;em&gt;纽约大中央车站&lt;/em&gt;&lt;/a&gt;&lt;em&gt;”&lt;/em&gt;&lt;em&gt;已获得&lt;/em&gt;&lt;a href="https://creativecommons.org/licenses/by/2.0/?ref=openverse"&gt;&lt;em&gt;CC BY 2.0&lt;/em&gt;&lt;/a&gt;许可&lt;em&gt;。&lt;/em&gt;&lt;/p&gt;</description><pubDate>Thu, 01 Feb 2024 07:30:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/datacentral-ubers-observability-and-chargeback-platform/</guid></item><item><title>通过风险挑战阻止 Uber 欺诈者</title><link>https://www.uber.com/blog/stopping-uber-fraudsters-through-risk-challenges/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;&lt;strong&gt;介绍&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;作为一款基于市场、面向消费者的应用程序，Uber 在其平台上遇到了多种欺诈来源。在最常见的欺诈案例之一中，不良行为者使用各种方法试图绕过 Uber 乘车、Eats 订单和其他服务（例如 Uber for Business）的付款。当这种情况发生时，可能会发生交易失败，从而造成损失，从而影响优步上运营的司机和企业。&lt;/p&gt;&lt;p&gt;为了解决支付欺诈的严重财务影响，优步优先考虑风险管理。为了反映整个科技行业的风险解决方案格局，我们的工程师开发了复杂的解决方案来实现以下目标：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;检测欺诈：&lt;/strong&gt;实时欺诈检测由在 Uber 规则引擎&lt;a href="https://www.uber.com/blog/mastermind/" rel="noreferrer noopener" target="_blank"&gt;Mastermind&lt;/a&gt;上运行的业务规则系统驱动。此外，机器学习模型会生成预测分数，从而深入了解用户是欺诈者的概率。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;减少欺诈：&lt;/strong&gt; Uber 采用不同形式的欺诈缓解措施来酌情执行和解决触发的规则和阈值通过分数。这些涉及手动和自动策略，这也是风险挑战发挥作用的地方。 &lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-risk-challenges"&gt;风险挑战&lt;/h1&gt;&lt;p&gt;风险挑战是要求用户完成特定任务或流程的体验，通常是为了验证其身份或支付方式的合法性。您以前可能遇到过风险挑战，而且不仅仅是在 Uber 应用程序上。常见的一种是在进行信用卡交易时输入信用卡的CVV。&lt;/p&gt;&lt;p&gt;风险挑战的主要预期结果之一是有效抓获不良行为者。这一点是不言而喻的：与对照组相比，遇到风险挑战的群体的欺诈率应该更低。然而，防范欺诈并不像向每个人引入风险挑战那么简单。风险挑战的性质是高度个性化的。鉴于 Uber 的用户、产品和地域范围广泛，Uber 遇到的风险挑战因用户而异。 Uber将不同的风险挑战应用于用户旅程的不同阶段，世界不同地区的用户可能会遇到不同的风险挑战。让我们考虑一下 Uber 应用程序中实施的一项风险挑战：一分钱掉落验证。&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading"&gt;便士掉落验证&lt;/h1&gt;&lt;p&gt;考虑这样的场景：Uber 收到来自用户的乘车请求，该用户似乎不是应用程序上使用的借记卡或信用卡的所有者。根据该 Uber 帐户的行为和数据，该特定用户很有可能窃取了他们声称拥有并计划用于乘车的卡。&lt;/p&gt;&lt;p&gt;过去，Uber 会检测到此类极有可能是欺诈者的用户，并立即采取某些严格的措施来阻止他们继续与该应用程序进行大量互动。在所描述的场景中，乘车请求将被拒绝，并且相关的支付和/或用户在某些情况下将受到限制。&lt;/p&gt;&lt;p&gt;从表面上看，这对于避免支付欺诈似乎很有效。然而，虽然这种严格行动的策略已经到位，但很明显，它对于潜在的误报用户来说并不理想。访问受到限制的 Uber 用户需要联系客户服务来解决其状态，这通常是一个资源密集型过程。&lt;/p&gt;&lt;p&gt; Uber 应用程序中引入了 Penny drop 验证，作为一种用户友好的方法，让之前可能被限制使用该应用程序的个人有机会证明其付款方式的所有权。在此挑战中，用户被要求在给定时间范围内到期之前向 Uber 确认两笔小额随机授权保留金额。&lt;strong&gt; &lt;/strong&gt;成功完成表明用户可能是合法持卡人而不是欺诈者。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1076561" height="255" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/01/1_why_pac-1024x255.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：针对潜在风险用户的禁令操作与风险挑战&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading"&gt;技术概述&lt;/h2&gt;&lt;p&gt;实施一分钱验证挑战的目的是为使用信用卡或借记卡作为支付方式的用户提供一种有效且直观的欺诈缓解方法。我们可以总结我们如何通过以下设计原则实现这一目标，这些原则不仅适用于一分钱验证挑战，还适用于任何其他良好的风险挑战：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;最大限度地减少误报：&lt;/strong&gt;信任好的用户（而不是坏的用户）。欺诈者应该无法通过这一挑战，而善意的用户应该能够在失败时自行解决并恢复。&lt;/li&gt;&lt;/ol&gt;&lt;ol start="2"&gt;&lt;li&gt;&lt;strong&gt;创建无缝且具有同理心的用户体验，并具有适量的摩擦：&lt;/strong&gt;这是必要的，因为风险挑战的频率和程度以及用户满意度和流失率之间可能存在权衡。例如，如果用户面临一个他们认为太难或太长时间无法完成的风险挑战，他们可能会完全停止使用该应用程序。应在不影响减少欺诈的情况下避免令人沮丧的用户体验。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;以下屏幕展示了合法用户面临新的一分钱验证挑战的快乐之路。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large is-resized"&gt;&lt;img alt="" class="wp-image-1076568" height="373" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/01/2_pac_ux_screens-1024x373.png" style="width: 700px; height: auto;" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：一分钱验证风险挑战的快乐路径流程&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;如图所示，挑战被集成到移动用户体验中，其方式不应严重干扰用户的预期主要操作（在本例中为请求乘车），通过清晰的指示和简单的操作。同时，“跳过”挑战是不可能的，因为接受挑战的用户需要完成挑战。即使用户退出用户界面中发起的挑战，挑战的状态仍将处于活动状态，并且如果用户尝试恢复相关操作，系统将不断提示用户完成挑战。&lt;/p&gt;&lt;h3 class="wp-block-heading"&gt;&lt;br /&gt;触发流程&lt;/h3&gt;&lt;p&gt;如上所述，某些风险挑战是针对 Uber 应用程序上的某些用户旅程流程而设计的。可能会显示一分钱验证挑战的两个主要流程：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;当用户请求乘车或送货订单时&lt;/li&gt;&lt;li&gt;当用户添加付款方式时&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;并不是每次出现这些流时都会向每个用户提出挑战。相反，在启动这两个流程之一的情况下，将调用下游服务来获取与用户相关的功能并在&lt;a href="https://www.uber.com/blog/mastermind/" rel="noreferrer noopener" target="_blank"&gt;Mastermind&lt;/a&gt;中运行风险规则。规则结果可能表明需要进一步的风险评估，特别是验证用户是否是特定支付方式的所有者。如果发生这种情况，后端服务会向移动端发送错误代码，以便用户遇到负责发起便士掉落验证质询的移动屏幕。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1076570" height="222" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/01/3_user_action_screen-1024x222.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：风险挑战由用户操作发起，例如叫车&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;h3 class="wp-block-heading"&gt;&lt;br /&gt;用户同意&lt;/h3&gt;&lt;p&gt;在触发流程期间认为有必要进行一分钱验证质询后，将显示一个模式以允许用户选择验证其选择的卡。在某些情况下，用户可能已经同意挑战，但在成功完成挑战之前就退出了，因此他们必须重新同意。&lt;/p&gt;&lt;p&gt;如果用户选择切换到其他付款方式，则可能不会要求他们进行进一步验证。这是因为提出风险挑战的操作取决于用户的特定支付方式。通常，优步用户会在其帐户中添加不止一张卡，并且他们可能是也可能不是任意数量的卡的合法所有者。同一用户的不同付款资料可以具有不同的质询状态。&lt;/p&gt;&lt;p&gt;用户单击“验证卡”后，后端进程会检查各种条件，以确定在质询流程的其余部分中向用户显示哪个客户端屏幕。首先需要确认与所选支付方式相关的数据（例如其 UUID 和便士滴验证挑战的状态）已保存在 Uber 后端数据库&lt;a href="https://www.uber.com/blog/schemaless-sql-database/" rel="noreferrer noopener" target="_blank"&gt;Docstore&lt;/a&gt;中。如果该卡是全新的，则该卡的相关数据将首次写入Docstore。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1076572" height="429" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/01/4_user_consent_screen-1024x429.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：当用户同意风险挑战时检查挑战条件&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;h3 class="wp-block-heading"&gt;&lt;br /&gt;发送授权&lt;/h3&gt;&lt;p&gt;在提供有关风险挑战的更多信息的屏幕上，系统会提示用户发送授权保留。在电子交易和支付的整体背景下，授权持有是对一定金额资金的临时持有；它们通常用于确定用户是否有足够的资金来完成交易，从而确定 Uber 是否能够向该用户收取付款。&lt;/p&gt;&lt;p&gt;用户单击“发送授权保留”后，将使用授权保留协议向用户指定的银行帐户发放两笔小额货币。为了启动此过程，内部支付操作服务向专门的“支付授权”服务发出请求以创建两个不同的授权。这是通过提供两个随机生成的持有量以及指定的无效持续时间来完成的。&lt;/p&gt;&lt;p&gt;支付授权服务与支付网关或处理器交互，支付网关或处理器联系用户的银行或发卡机构，正式请求将指定金额的临时授权保留在用户的支付帐户上。如果指定的无效期限过去并且资金保留被释放，并且用户尚未成功验证完成挑战的金额，则用户将必须重新发送授权保留。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1076575" height="446" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/01/5_send_auths_screen-1024x446.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：授权保留必须作为便士掉落挑战的一部分发送&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;h3 class="wp-block-heading"&gt;&lt;br /&gt;金额验证&lt;/h3&gt;&lt;p&gt;为了成功完成一分钱挑战，用户需要查看他们的银行对账单，并在 Uber 应用程序中准确输入授权持有的确切金额。然后对这些输入的金额进行验证。&lt;/p&gt;&lt;p&gt;在此过程中，用户的质询状态会在 Uber 的后端数据库 Docstore 中更新。如果用户在一定次数的尝试内未能成功验证授权持有金额，则他们将挑战失败。在这种情况下，他们对 Uber 应用程序的访问将受到限制，因为我们有强烈迹象表明他们不是付款方式的所有者。相比之下，如果用户成功完成挑战，他们可以无缝地继续他们在被提出挑战之前启动的预期操作。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large is-resized"&gt;&lt;img alt="" class="wp-image-1076577" height="332" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/01/6_enter_amounts_screen-1024x332.png" style="width: 700px; height: auto;" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：必须正确验证授权保留金额才能通过便士掉落挑战&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading"&gt;结论&lt;/h1&gt;&lt;p&gt;我们不断微调一分钱验证挑战的用户体验，以有效降低风险，而又不会在用户体验中造成太多摩擦。通过对成功率和流失率等指标的分析，我们不断深入了解用户如何应对面临的挑战。&lt;/p&gt;&lt;p&gt;便士掉落验证只是 Uber 应用程序中集成的一种风险挑战。其他挑战涉及不同程度的难度。根据我们对特定用户及其意图的了解，一项挑战可能比另一项更好用。总体而言，风险挑战是我们不断努力增强 Uber 应用程序安全性和用户体验的一部分。它的实施不仅有效地防范了欺诈，而且还带来了更流畅的用户体验，从而加快了 Uber for Business 等专业产品的使用速度。&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading"&gt;致谢&lt;/h2&gt;&lt;p&gt;感谢 Spender 风险团队在我的实习期间分享了他们关于一系列与欺诈相关的有趣工程挑战的专业知识，包括风险挑战。&lt;/p&gt;&lt;p&gt;特别感谢 Diganta Sarkar、Qixiong Liu 和 Susie Peng 提供与本博客相关的见解，以及 Neel Mouleeswaran 和 You Xu 对我作为软件工程师的实习和成长的支持。&lt;/p&gt;&lt;p class="has-small-font-size"&gt;封面照片归属：图片由 Nenad Stojkovic 创建。图片许可信息： &lt;a href="https://openverse.org/image/6d3d1a77-63ba-481c-9c58-42d1c7fa9507?q=payment%20credit%20card" rel="noreferrer noopener" target="_blank"&gt;链接&lt;/a&gt;。没有进行任何更改。&lt;/p&gt;</description><pubDate>Thu, 25 Jan 2024 08:00:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/stopping-uber-fraudsters-through-risk-challenges/</guid></item></channel></rss>