<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>优步工程博客</title><link>https://www.uber.com/blog/engineering</link><description>Uber 工程背后的技术 - 由 RSSHub 用爱制作(https://github.com/DIYgod/RSSHub)</description><lastBuildDate>Tue, 14 May 2024 16:04:43 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>【DataK9: Auto-categorizing an exabyte of data at field level through AI/ML】DataK9：通过 AI/ML 在现场级别自动分类 EB 数据</title><link>https://www.uber.com/blog/auto-categorizing-data-through-ai-ml/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;数据分类——根据数据的特征和本质对数据进行分类的过程——是任何隐私或安全计划的基本支柱。细粒度数据分类的有效性对于实施隐私和安全控制（例如访问策略和加密）以及管理数据资产的生命周期（包括保留和删除）至关重要。本博客深入探讨了 Uber 通过利用各种 AI/ML 技术实现大规模数据分类的方法。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-why-auto-categorization"&gt;为什么要自动分类？&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;庞大的规模和成本&lt;/strong&gt;：许多公司管理分布在各种存储系统中的大量数据集。新数据集的定期生成进一步加剧了这一规模。我们面临的挑战的核心是在现场级别标记大量列，每个列可能需要多个标签。手动标记需要大量时间和资源。此外，需要持续投资来标记新创建的数据集。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;数据所有者的参与&lt;/strong&gt;：识别数据所有者并让其参与是一个复杂的现实。由于每个数据元素需要评估多个标签，因此辨别标签定义之间的细微差别变得复杂且耗时，从而导致错误分类。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;考虑到巨大的工程成本以及通过分散的努力进行手动分类的不切实际，我们的经验使我们优先考虑自动分类。为此，我们推出了一种名为&lt;strong&gt;DataK9&lt;/strong&gt;的新颖解决方案，这是 Uber 数据的自动分类平台。主要目标是最大限度地减少和消除用户参与，从而解决规模、成本和数据所有者参与带来的挑战。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-challenges"&gt;挑战&lt;/h2&gt;&lt;p&gt;考虑一个包含纯数字内容的单列表。仅检查数据本身无法辨别这些数字的性质，这些数字可能代表纬度、经度、汇率等。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1088500" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/05/Screenshot-2024-05-06-at-2.53.45%E2%80%AFPM-1024x290.png" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：分类中的列名称。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;但是，如果我们了解列名称（例如图 1 中的&lt;em&gt;纬度&lt;/em&gt;和&lt;em&gt;经度）&lt;/em&gt; ，它将极大地有助于准确地对这些列进行分类。&lt;/p&gt;&lt;p&gt;然而，挑战仍然存在，特别是当列名称是通用的时，如图 2 中最近添加的&lt;em&gt;“注释”&lt;/em&gt;列所示。这可能包含从余额和成本到两个位置之间的距离等信息。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1088501" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/05/Screenshot-2024-05-06-at-2.54.02%E2%80%AFPM-1024x345.png" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：通用列名称。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;此外，即使在同一类型的位置数据中，分类也可以根据精度进行细微差别。例如，纬度和经度指定为三位或更多小数位的位置可以被视为精确位置。如果与个人身份相关联，则可能会被归类为高度限制类别。&lt;/p&gt;&lt;p&gt;让我们深入研究图 3 中的另一个示例： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1088502" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/05/Screenshot-2024-05-06-at-2.54.21%E2%80%AFPM-1024x240.png" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：地址列名称。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;在缺乏明确上下文的情况下，区分&lt;em&gt;个人&lt;/em&gt;地址和&lt;em&gt;企业&lt;/em&gt;地址变得很困难，尽管两者都是地址。&lt;/p&gt;&lt;p&gt;鉴于这些复杂性，没有通用的解决方案可以解决所有分类挑战。因此，我们选择利用基于概率的方法（即人工智能/机器学习）来为此努力提供帮助。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-strategy"&gt;战略&lt;/h2&gt;&lt;p&gt;人工智能/机器学习技术的应用构成了我们自动分类计划的基石。在本节中，我们将提出总体策略，描述新框架内各个系统之间更广泛的流程和依赖关系。&lt;/p&gt;&lt;p&gt;评估新自动化流程的有效性至关重要，并且取决于一小部分（&amp;lt;1%）的标记（黄金）数据集。这些数据集是手动分类的，最好是由领域专家或所有者进行分类。然后，自动分类机制利用经过审查的训练数据来标记剩余的数据集 (&amp;gt;99%)。本质上，该解决方案采用混合方法，将手动分类与自动化相结合，封装在三个相互关联的阶段中，如下图 4 所示。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/wQRv72HPpi7ZE6eo9u0s6UjgYz7wwLExhcEkpdLdHwRZhw1xz1njMh661wIfwvhFGHOw1P9Ac4GLuXKowp-gbqa_-BaQKdwL2LOFHgxAOinjYHauzsEJ-AYPW3uvSEJuTBbsWSUB8RaFYgwTZBkyoLM" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：分类策略。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-building-baseline"&gt;建立基线&lt;/h2&gt;&lt;p&gt;我们建议将 &amp;lt;1% 的数据集（近 1,000 个）分类为由人类在隐私和领域专家的密切监督下关键且高度利用的表。这些数据集被视为“黄金”数据集，具有很高的分类准确性，并用于衡量自动化准确性。虽然“黄金”数据集的数量相对较少，但有一些显着的好处：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;模型训练&lt;/strong&gt;：训练是任何基于监督机器学习的解决方案中最关键的步骤。如果没有经过适当训练的模型，机器甚至不知道首先要理解什么。我们利用手动分类的数据作为人工智能方法的基线。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;风险缓解&lt;/strong&gt;：我们有一些关键业务数据集，我们不想因为错误标记而冒这些风险。这就是为什么我们由所有者或专家手动标记那些具有高度影响力的数据集。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;理想情况下，用于标记的数据集的选择应随机进行，以尽可能避免在标记数据集中插入统计偏差。这种统计偏差降低了离线模型性能测试的可靠性，并可能导致生产中的系统性分类错误。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-training"&gt;训练&lt;/h2&gt;&lt;p&gt;对于其余 99% 的数据集（&amp;gt;400K），我们将主要使用名为 DataK9 的新自动化系统（稍后小节将详细介绍）。首先，DataK9 针对手动分类（黄金）数据集进行训练，直到准确性达到令人满意的水平而不会过度调整。具体来说，将有两个子阶段：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们基于黄金数据集的子集迭代训练模型，然后针对其余黄金数据集（测试数据）运行该模型。我们在每次测试运行后分析标准指标（即准确度、精确度、召回率、F2 分数等）。如果指标不可接受，我们会调整模型并重新运行/重新评估它，直到获得满意的结果。&lt;/li&gt;&lt;li&gt;用于标记数据的检测规则列表由领域专家创建。定义规则后，它会不断进行测试运行和规则调整，直到达到可接受的指标值。最初的规则定义和早期的规则迭代将有更多的人为参与。我们将逐步进入规则的自动调整，使调整过程自动化，并推出规则更改，从而产生更好的预测。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-serving-in-production"&gt;服务于生产&lt;/h2&gt;&lt;p&gt;在 Datak9 展示了其令人满意的训练数据集指标（即准确率 &amp;gt;90%、F2 分数 &amp;gt;85%）后，它将准备好对其余数据集进行生产标记。不过，我们计划在大规模分类的早期阶段采取一些防御流程。它包括在数据集（暂时）自动分类后自动创建票证以进行审查（对于数据所有者或经过培训的隐私专家来说更佳）。当所有者盖章后，分类将被视为最终分类。此外，在这个过渡阶段，我们将密切监控进展情况，尤其是错误分类率。如果审稿人的反馈可以接受，我们将大规模部署数十万个数据集。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-architecture"&gt;建筑学&lt;/h1&gt;&lt;p&gt;本节介绍基于 AI 的核心平台的架构，以及 DataK9 如何在框架的不同部分和阶段采用 ML/AI 技术，如图 5 所示。本节我们重点关注标记数据集的主要用例。首先识别和收集数据集的基本特征，然后使用 ML/AI 技术确定特定标签的列权重/分数。然后，我们讨论如何将特定领域的多个信号组合成最终决策。最后，我们详细介绍了根据原始标记中所犯错误调整规则和 ML 模型的主动学习过程。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/d8h-crQtz9vDMKFyrGRuALVxL8rWsE4srz6RSopnKAU0rfOwdIrIa9X_pY-XR7a4qi6BGiKx1R7UemrVXIwahIopFhKNv6a9SwrclnWzCLVraWsriXdXEjtKz2KmJxLkxEwy_1BFkrCZMPMdvTNcEaQ" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：Data K9 架构。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-key-features-nbsp"&gt;主要特征&lt;/h2&gt;&lt;p&gt;DataK9 使用数据集的以下信息，我们可以将其用作各种 ML/AI 分类技术中的潜在特征：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;元数据&lt;/strong&gt;：它包括数据集中每个字段的名称和类型。例如，数据集“ &lt;em&gt;uber_rides&lt;/em&gt; ”可能有 100 多个字段。 DataK9 利用所有字段的名称，例如“ &lt;em&gt;request_latitude&lt;/em&gt; ”和“ &lt;em&gt;email&lt;/em&gt; ”以及相关的类型，例如&lt;em&gt;double&lt;/em&gt;和&lt;em&gt;string&lt;/em&gt; 。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;数据&lt;/strong&gt;：数据集可能包含数十亿条记录。尽管 DataK9 最终会考虑所有行的内容，但我们将从数据集每次运行/扫描的记录随机样本 (~1%) 开始。更具体地说，我们将利用单元格内容来确定列类别。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;上下文&lt;/strong&gt;：虽然每个单元格值都提供了有价值的信息，但同一记录中的其他值可能会提供额外的信号。此外，上下文（例如表和数据库名称）会呈现有关列标记的提示。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;沿袭&lt;/strong&gt;：数据沿袭是数据旅程的地图，包括其起源、创建过程等。与 DataK9 相关的数据沿袭信息有两种类型。&lt;ul&gt;&lt;li&gt;&lt;em&gt;表级沿袭&lt;/em&gt;：表沿袭将提供更高级别的信息，例如使用哪些表来创建新表。例如，表“ &lt;em&gt;uber_rides&lt;/em&gt; ”是在加入一些表（例如&lt;em&gt;drivers&lt;/em&gt;和&lt;em&gt;riders ）&lt;/em&gt;后创建的。这种类型的沿袭与派生表比原始表更相关。&lt;/li&gt;&lt;li&gt;&lt;em&gt;列级沿袭&lt;/em&gt;：此沿袭是指哪一列派生自不同表的哪一组依赖列。对于各种数据处理平台（例如 Hive™、Spark™ 等）来说，收集这些信息会更加复杂。但是，如果有可靠的列级谱系可用，DataK9 可以更好地预测标签。 &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-matching-strategy"&gt;匹配策略&lt;/h2&gt;&lt;p&gt;所提出的解决方案的本质是最终从所有数据存储中抓取数据（表或目录或文件）并定期扫描每个数据元素以获取不同标签的信号。我们在本节中讨论一些基本的匹配技术。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;个体与总体决策&lt;/strong&gt;：DataK9 在单元格级别扫描数据，并从内容和元数据中查找信号。由于有数百万个数据元素，DataK9 将检查每个元素并获取相应的指示。例如，假设单元格值为&lt;em&gt;john@gmail.com&lt;/em&gt; 。我们会将此电子邮件地址与每个标签进行匹配，并生成该值的匹配分数。然而，根据一个匹配分数做出最终决定可能会产生误导。实际上，电子邮件地址可能位于另一列（例如&lt;em&gt;Promotion_code&lt;/em&gt; ）中，这可能不会被解释为 PII 数据。此外，我们的主要目标是标记表的列，而不是单个列值。因此，我们将所有列值的这些单独分数合并为全局分数并最终做出决定。例如，如果列的 80% 的值与电子邮件匹配，我们可以安全地假设该列包含电子邮件 PII 数据并相应地对其进行标记。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;概率决策：&lt;/strong&gt; DataK9 寻找特定标签的特定匹配。然而，几乎没有找到匹配就能确保标签分配的情况。因此，我们为每项检查定义一个分数。分数越高，标签关联的可能性就越高。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;负分：&lt;/strong&gt; DataK9 允许负分来表明它不太可能是特定标签的一部分。例如，数据库名称模式“ &lt;em&gt;products&lt;/em&gt; ”下的任何数据不太可能具有任何 PII 数据。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-rule-based-ai"&gt;基于规则的人工智能&lt;/h2&gt;&lt;p&gt;当我们抓取新的数据集时，我们对样本数据应用两种人工智能方法，然后识别每个字段/列类别。我们在本节中解释&lt;em&gt;基于规则的内容&lt;/em&gt;，然后在下一节中&lt;em&gt;解释基于学习的内容&lt;/em&gt;。&lt;/p&gt;&lt;p&gt;我们将从一组手工制定的规则开始，并构建相关的规则语言和引擎。找到具有适当知识和经验（例如对数据内容、分类内部结构和工程能力的深入理解）的领域专家具有挑战性。本质上，设计规则需要考虑两个关键维度：40 多个不同的标签和基本功能。我们支持以下构建块来表达规则：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;布隆过滤器匹配&lt;/strong&gt;：我们根据特定实体的最常见数据值创建&lt;a href="https://en.wikipedia.org/wiki/Bloom_filter" rel="noreferrer noopener" target="_blank"&gt;布隆过滤器&lt;/a&gt;。然后在扫描每个列值的过程中，我们测试成员资格并决定可能的标签。例如，我们可以为 Uber 送货服务上个月使用的所有地址创建布隆过滤器。然后，在扫描过程中，我们可以测试每个数据单元格的成员资格以找到可能的匹配。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;字典匹配&lt;/strong&gt;：我们创建一个包含常用值列表的字典。在扫描过程中，K9为数据集的每个数据元素（单元格）查找字典，并根据规则定义决定匹配分数。例如，我们可以创建一个字典来包含 750 多个&lt;em&gt;机场代码&lt;/em&gt;来匹配位置信息。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;模式匹配&lt;/strong&gt;：我们定义一个正则表达式来查找与列内容或列名称的匹配。例如，我们可以使用模式&lt;em&gt;^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,} $&lt;/em&gt;匹配电子邮件地址，例如&lt;em&gt;john@gmail.com&lt;/em&gt; 。需要注意的是，在某些情况下，模式匹配可能不足以确定最终标签。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;上下文匹配&lt;/strong&gt;：列名称和值本身可能无法提供有关其内容类型的任何强烈信号。因此，我们允许寻找单元格值本身之外的上下文。我们将支持三种不同的上下文：&lt;ul&gt;&lt;li&gt;&lt;em&gt;记录级别&lt;/em&gt;：基本原理是某些数据标签可能与同一数据集中的其他数据标签一起出现。例如，假设列中有一个纬度值。在这种情况下，它被认为是非敏感位置数据，因为相同的纬度可能存在数百万个位置点。因此，我们还应该在同一条记录中查找经度。&lt;/li&gt;&lt;li&gt;&lt;em&gt;表级别&lt;/em&gt;：在某些情况下，表名称模式在确定某些实例的数据类型方面发挥着重要作用。例如，“ &lt;em&gt;virtual_machine&lt;/em&gt; ”表中的全名不敏感，而“ &lt;em&gt;rider&lt;/em&gt; ”表（保存最终用户数据）则非常敏感。&lt;/li&gt;&lt;li&gt;&lt;em&gt;数据库级别&lt;/em&gt;：某些数据库名称模式可能指示数据库可能包含的数据类型。例如，如果数据库的名称中包含“ &lt;em&gt;finance”&lt;/em&gt; ，则它可能会包含一些交易数据。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;数据类型匹配&lt;/strong&gt;：数据类型匹配包括类别的可能数据类型列表。如果任何字段不遵守标签的类型限制，K9 将跳过该标签的该列匹配。例如，个人电子邮件列的类型为&lt;em&gt;string&lt;/em&gt; ；因此，如果列的数据类型是非字符串，我们不需要检查电子邮件类别。这种类型的检查对每个文件或数据集进行一次的频率较低，因为它是在元数据级别。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-rule-language"&gt;规则语言&lt;/h3&gt;&lt;p&gt;定义规则是基于规则的人工智能的第一步，支持标准的规则定义语言或模板势在必行。本节介绍为特定标签定义规则的基本构建块。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;根据其检查的数据类型，规则中包含三个更广泛的子规则：列值匹配 ( &lt;em&gt;columnValueMatch&lt;/em&gt; )、元数据匹配 ( &lt;em&gt;columnNameMatch&lt;/em&gt; ) 和上下文匹配 ( &lt;em&gt;contextMatch&lt;/em&gt; )。&lt;/li&gt;&lt;li&gt;每个子规则都会有一个由规则管理员根据其领域专业知识指定的匹配“分数”。&lt;/li&gt;&lt;li&gt; &lt;em&gt;columnValueMatch&lt;/em&gt;规则主要检查数据集中每个数据元素的值。这些操作成本高昂且复杂，因为数据元素的数量和每个值的检查数量巨大。它需要以下过滤和检查：&lt;ol&gt;&lt;li&gt;&lt;em&gt;布隆过滤器&lt;/em&gt;部分包含查找预先计算的布隆过滤器以检查成员资格和关联分数所需的配置。我们可以将布隆过滤器存储在文件或表中。&lt;/li&gt;&lt;li&gt;&lt;em&gt;字典&lt;/em&gt;匹配从最常用值的预定义列表中查找精确匹配。该字典可以是 HDFS 文件或 Hive 表。&lt;/li&gt;&lt;li&gt; &lt;em&gt;lengthRange&lt;/em&gt;定义内容的长度。此过滤器可以轻松地从昂贵的匹配中早期排除大量值。例如，纬度值的长度可以在3到10之间。K9不应考虑位置数据的该长度范围之外的任何内容。&lt;/li&gt;&lt;li&gt; &lt;em&gt;valueRange&lt;/em&gt;指定标签的有效值范围。例如，一个人的年龄可以在 0-125 之间。如果某列包含超出此范围的数据，K9 将跳过此列进行任何“年龄”类型检查。与 lengthRange 一样，valueRange 也简化了许多复杂的匹配。&lt;/li&gt;&lt;li&gt;&lt;em&gt;模式&lt;/em&gt;匹配指定与值的典型模式匹配的正则表达式。例如，电子邮件始终遵循一种模式，我们可以使用该模式来检查列值是否可能是潜在的电子邮件。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt; &lt;em&gt;columnNameMatch&lt;/em&gt;规则表示列名模式和列类型的匹配。它还可以提及排除的列名称和类型，以帮助避免误报。&lt;/li&gt;&lt;li&gt; &lt;em&gt;ContextMatch&lt;/em&gt;规则查找超出特定列值的特定上下文。目前，DataK9 支持两种不同的上下文以及各自的匹配分数：&lt;ol&gt;&lt;li&gt; &lt;em&gt;ResourceContext&lt;/em&gt;指定是否存在我们想要获取信号的任何表或数据库名称模式。例如，如果数据库名称包含“finance”，则该数据集中很有可能包含交易数据。&lt;/li&gt;&lt;li&gt; &lt;em&gt;categoryContext&lt;/em&gt;概述了哪些其他相关类别可以提供额外的信号。例如，1 级位置数据标签必须在同一数据集中具有可识别的个人类别。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt; DataK9 在一个或多个 YAML 文件中管理规则的定义。或者，DataK9 将支持存储在数据库表中的规则。该表更适合动态更新规则或相关分数。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我们提供了一组“位置纬度”示例规则来识别图 6 中 YAML 格式的标签，这将有助于理解前面部分中描述的概念。绿色的内嵌注释包含了每个键值对的含义。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/4wEm-2So0frIQ5F3byMZNiANyt_bEf_njBgaz2TA3ckBrvkiG4Sn9YpCHNguU9mtB49UyXoU9D59hTEFzyQkjkS2trLvDVyhOmoUYZvOffEqGDmM3q0WrdRtiDzp8hpny5Rx3mMU0DYNtojTGBrjrmo" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：位置纬度分类配置。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-learning-based-ai"&gt;基于学习的人工智能&lt;/h2&gt;&lt;p&gt;分类在 AI/ML 领域得到了很好的研究。我们的分类问题非常适合多标签分类的监督学习。使用标准分类算法，我们打算使用元数据和单元格内容来预测实际标签。关键思想如图 7 所示，描述如下：&lt;/p&gt;&lt;p&gt;图 7：基于学习的人工智能&lt;/p&gt;&lt;ul&gt;&lt;li&gt;使用标记数据集来训练我们的模型。我们可以分别使用元数据和数据值来训练两个模型。&lt;/li&gt;&lt;li&gt;评估训练后的模型的典型准确度、精确度、召回率和 F2 得分指标。如果指标的值不可接受，我们会在调整参数和算法后重新训练我们的模型。否则，我们可以在生产中部署模型。如果模型评分分布一致，则可以采用阈值技术来权衡精度和召回率，并提供更好的控制。对于支持度较低的类别，可以通过额外的手动标记来改进模型。如果额外的手动标记失败，可以考虑合并类别。机器学习模型将接受完整的训练/测试实验，作为部署前的最终健全性检查。该实验还必须通过上述所有指标的既定阈值。 DataK9 检测器将根据训练模型预测列的标签。&lt;/li&gt;&lt;li&gt;机器学习算法和初始实验：大量机器学习算法以及各种输入转换和特征工程策略已经接受了测试。我们已经检查了经典的 ML 程序，例如线性支持向量机 (SVM)、K 最近邻 (KNN) 和朴素贝叶斯。到目前为止，做得最好的是线性 SVM。然而，机器学习建模仍有很艰巨的工作要做，特别是在这些低支持类别方面。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-aggregating-signals"&gt;聚合信号&lt;/h2&gt;&lt;p&gt;如上所述，DataK9 生成多个信号以及每列的相关分数值。一列可以有多个潜在标签以及通过以下方法估计的分数：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;基于规则的人工智能在为每个类别应用规则后创建标签和分数。&lt;/li&gt;&lt;li&gt;基于学习的人工智能将根据元数据和列值预测每列可能的标签对和分数。&lt;/li&gt;&lt;li&gt;谱系服务还可以为每列提供附加信号。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;收集这些信号后，DataK9 使用加权聚合方法合并每个标签、每列的所有分数。每个匹配的权重是根据经验确定的，并作为规则定义的一部分进行参数化。综合得分与预先指定的阈值进行比较后确定最终标签。该产品的后续版本可能会使用基于 ML 的集成方法。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-learning-feedback-loop"&gt;学习：反馈循环&lt;/h2&gt;&lt;p&gt;DataK9 严重依赖 ML/AI 技术，这些技术可能会在标签预测中出现潜在的错误。我们打算通过采用反馈循环来自动学习以避免类似的错误。本节简要描述我们如何将此方法融入到我们的框架中。&lt;/p&gt;&lt;p&gt;挑战的第一部分是找出错误。自动标记后，所有者或隐私专家可以使用提供的 UI 修改类别。我们将在一个中心位置跟踪所有这些修改的审计跟踪。下一步是找到可以自动调整 AI/ML 平台的典型错误模式。特别是，我们努力调整我们的规则数据库，其中我们使用了许多根据经验指定的参数。我们计划根据错误模式修改这些参数。此外，我们希望根据从错误中学习来改变不同的模型训练参数。虽然我们的最终目标是完全自动化，但我们将从人机交互开始调整规则。我们最终将走向基于我们对现实世界的理解的自动反馈循环。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-measuring-the-accuracy"&gt;测量精度&lt;/h2&gt;&lt;p&gt;在自动分类领域，准确性是至高无上的，因此，我们将精心测量和披露根据受众需求定制的各种级别的指标作为我们的首要任务。在我们报告层次结构的顶峰，我们将公布以下关键指标：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;分类的标准指标&lt;/strong&gt;：我们的自动化框架的质量对于评估和跟踪进度至关重要。然而，如果没有适当的基线，就不可能衡量自动分类的质量。因此，我们还建议所有者/专家对覆盖所有数据标签的 &amp;lt;1% 的数据集进行手动分类将提供现实的基线。在机器学习/人工智能领域，分类是经过深入研究的文献，专家们定义了一组指标来衡量分类方法的质量。我们在图 8 中用混淆矩阵展示了它们，并在下面进行了描述： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/zZ-qtmybdg0JJVBt6e6iQyOeaylKWmOz4qColn-CDR54eKCLGAemdWT5HBXZcoGJyOoO31BfRgcgeotJV1mRMDXiR26iF7_s0fmZYlXqoL3DQKxkEbgWmc1Z_vt0_mY3rA_8kgouIgfdVD9VDS9CvGI" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：准确性混淆矩阵。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;准确度&lt;/strong&gt;：分类准确度是正确预测的总数除以所有数据集上做出的预测的数量。换句话说，这表示机器为标记数据集适当标记了多少列。例如，如果我们有 100 列，K9 正确分类其中 90 列，则准确率为 90%。我们不能仅仅依赖准确性，因为包含 PII 的列只占所有列的一小部分。无法对任何内容进行分类的分类器将具有异常高的准确度，因为真阴性将超过假阴性。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;精度&lt;/strong&gt;：精度是指我们的积极预测的“正确”程度。误报越少，我们的精确度就越高。然而，它并没有讲述完整的故事。例如，如果我们进行单个预测，成功率为 100%，但未能对其他 9 个敏感列进行分类，则我们有 100% 的精确度，但准确度和召回率较低。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;召回率（敏感性）&lt;/strong&gt; ：召回率是指我们识别敏感信息的可能性。假阴性越少，我们的回忆就越好。然而，它并没有讲述完整的故事。例如，如果我们预测所有列都是敏感信息，我们将获得 100% 的召回率，但准确性和精确度较低。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;F2 分数&lt;/strong&gt;：F2 分数是一种在单个可测量指标中偏向于优化召回率而不是精确率的方法。 &lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-precision-vs-recall"&gt;准确率与召回率&lt;/h2&gt;&lt;p&gt;准确率和召回率的影响会影响两个不同的受众。例如，工程师和数据科学家可能会担心低精度指标。较高的误报会不必要地限制对非敏感数据的访问或过早删除它们。如果存在大量漏报，系统可能无法限制敏感数据并强制执行适当的保留，这可能会违反合规性合同。&lt;/p&gt;&lt;p&gt;除了上述指标之外，我们还努力衡量一些额外的指标来跟踪工程进度。这些指标衡量以下观点：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;自动化质量&lt;/strong&gt;：我们想要衡量有多少自动标签被数据所有者/管理员等人类推翻。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;规模&lt;/strong&gt;：由于我们必须标记数十万个数据集，因此我们需要测量每天可以加载多少数据集。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;重新分类&lt;/strong&gt;：何时根据架构更改或何时引入/更新新标签对任何数据集进行重新分类。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;效率&lt;/strong&gt;：该举措基于数据爬行，计算成本较高。我们将跟踪 Uber 为每个数据元素（即列或表）自动化支付的费用。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;卓越运营&lt;/strong&gt;：开发过程和初始入职结束后，我们将跟踪需要多少运营开销，例如支持、错误修复和待命。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;存储系统覆盖范围&lt;/strong&gt;：如上所述，我们有不同的存储技术和主干网；跟踪有多少存储实例参与分类工作至关重要。 &lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-production-experiences"&gt;生产经验&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-centralized-data-collection-system"&gt;集中数据采集系统&lt;/h3&gt;&lt;p&gt;Uber 在各种基础设施中采用了多种存储系统，每个系统都有自己独特的特点。有些系统遵循特定的模式，而其他系统则不然。即使在基于模式的系统中，模式结构也可能存在很大的差异。&lt;/p&gt;&lt;p&gt;为了简化这些不同系统中存储的数据的分类，我们实施了一个强大的数据收集系统。该系统对来自不同存储系统的数据进行采样，并将它们整合到一个集中式数据湖中。在这种统一方法下，采样数据通过标准化工作流程进行处理。&lt;/p&gt;&lt;p&gt;主要优点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;一致的处理：&lt;/strong&gt;通过将数据集中到公共数据湖中，我们可以促进使用标准化工作流程进行处理。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;简化管理：&lt;/strong&gt;该方法简化了分类作业的管理，提供了集中控制点。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该策略不仅解决了存储系统的不同性质带来的挑战，而且还提高了数据处理和管理的效率。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-advancements-in-accuracy"&gt;准确性的进步&lt;/h3&gt;&lt;p&gt;自首次量产以来，DataK9 在过去几年中的准确性不断提高。我们采用两个关键指标来展示 DataK9 的整体准确性，如图 9 所示： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/tU27ocyWH8-RZAuYulUXribMOk2SxfJZryHDxaqmFB1ixYI4o8NxuolUVKCe3UgHCbTBT1g0nHBbT8fstC4laCj7koByY4rbwoENpB0_z8VmzynA3sXCJygI0HoFJZA2SKvJxofEN2bjg2z2FT7UVQM" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：准确度指标&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;黄金数据集的准确性：&lt;/strong&gt;在这种方法中，我们将标记结果与经过我们内部隐私专家仔细审查的黄金数据集进行比较。该指标反映了 DataK9 相对于隐私专家制定的标准的准确性和可靠性。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;所有者审查的数据集的准确性：&lt;/strong&gt;此外，我们通过将结果与数据所有者执行的分类进行比较来评估准确性。该指标可以深入了解 DataK9 与数据负责人定义的预期分类的一致性。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些指标是强有力的指标，说明了 DataK9 对提高准确性和检查 DataK9 在满足内部隐私标准和数据所有者期望方面的有效性的持续承诺。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-success-metrics-amp-funnel-analysis"&gt;成功指标和漏斗分析&lt;/h3&gt;&lt;p&gt;在追求成功的过程中，我们实施了一套全面的指标来衡量和优化我们的自动化流程。精心设计了详细的漏斗（见下文），以方便调查和识别每个步骤的差距。这个宝贵的工具提供了一种系统方法来跟踪和监控整体分类状态，使我们能够做出明智的决策和改进。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/N0Snd-Ysm8WFVIl1YLVm_d5dDfd-9AKdbOORGr05RIowrgMxD97wBlBFVGmOBCHkHAScS_dxHlC_QF5fXBq_ZBf3Z_VkI0hS7G6gBnpgyeohouXbch4ABmujjZxLdWGx4Mp-2-3x6TZ0c1iNT9T9zYA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 10：数据集分类漏斗。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;主要优点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;精细分析：&lt;/strong&gt;漏斗使我们能够将自动化流程分解为各个步骤，从而对每个阶段的性能进行精细分析。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;差距识别：&lt;/strong&gt;通过使用漏斗，我们可以有效地识别并缩小自动化流程中的差距，从而简化我们提高效率的工作。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可追溯性：&lt;/strong&gt;漏斗作为一种可靠的跟踪机制，提供对分类状态的实时洞察，并允许我们跟踪一段时间内的进度。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这种对成功指标和漏斗分析的细致方法强化了我们对持续改进的承诺，并使我们能够主动应对自动化流程中的挑战。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;Uber 的 DataK9 项目代表了一项开创性的努力，旨在通过实施人工智能和机器学习技术来解决大规模和现场级别的数据分类挑战。认识到数据分类对于隐私和安全举措的根本作用，Uber 采取了这一举措来自动化和简化流程。&lt;/p&gt;&lt;p class="has-small-font-size"&gt;&lt;em&gt;封面图片归属：&lt;/em&gt; &lt;a href="https://commons.wikimedia.org/wiki/User:MCruz_(WMF)"&gt;&lt;em&gt;MCruz (WMF)&lt;/em&gt;&lt;/a&gt;的“&lt;a href="https://commons.wikimedia.org/w/index.php?curid=38171185"&gt;&lt;em&gt;分类系统 2&lt;/em&gt;&lt;/a&gt; &lt;em&gt;”&lt;/em&gt;已获得&lt;a href="https://creativecommons.org/licenses/by-sa/4.0/?ref=openverse"&gt;&lt;em&gt;CC BY-SA 4.0&lt;/em&gt;&lt;/a&gt;&lt;em&gt;许可&lt;/em&gt;&lt;em&gt;。&lt;/em&gt;&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Apache®、Apache Hive、Hive、Apache Spark 和 Spark 是 Apache Software Foundation 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/em&gt;&lt;/p&gt;</description><pubDate>Thu, 09 May 2024 06:56:57 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/auto-categorizing-data-through-ai-ml/</guid></item><item><title>【From Predictive to Generative – How Michelangelo Accelerates Uber’s AI Journey】从预测到生成——米开朗基罗如何加速 Uber 的人工智能之旅</title><link>https://www.uber.com/blog/from-predictive-to-generative-ai/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;在过去的几年里，机器学习 (ML) 在 Uber 所有业务线的采用和影响都在加速。如今，机器学习在 Uber 的业务中发挥着关键作用，被用来制定关键业务决策，例如预计到达时间、乘客与司机匹配、Eats homefeed 排名和欺诈检测。&lt;/p&gt;&lt;p&gt;作为 Uber 的集中式 ML 平台，自 2016 年首次推出以来， &lt;a href="https://www.uber.com/blog/michelangelo-machine-learning-platform/" rel="noreferrer noopener" target="_blank"&gt;Michelangelo&lt;/a&gt;在推动 Uber ML 发展方面发挥了重要作用。它提供了一套涵盖端到端 ML 生命周期的全面功能，使 Uber 的 ML 从业者能够开发和产品化高-大规模的高质量机器学习应用程序。目前，Michelangelo 管理着大约 400 个活跃的机器学习项目，每月有超过 2 万个模型训练作业。目前有超过 5K 个模型正在生产中，峰值时每秒可提供 1000 万次实时预测。&lt;/p&gt;&lt;p&gt;如下图 1 所示，ML 开发人员经验是一个重要的倍增器，使开发人员能够提供现实世界的业务影响。通过利用米开朗基罗，Uber 的机器学习用例已经从简单的树模型发展到高级深度学习模型，并最终发展到最新的生成式人工智能。在这篇博客中，我们介绍了 Michelangelo 在过去八年中的演变，重点关注 Uber 机器学习开发人员体验的不断增强。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/7H03P6ohPRRzlipNe07kKr3cGsFo3FYOQ1XQNZZbipKWQ5_mLrCuIaDCMtSQyrTGSJ4P-hLG7y7Z_n4C4xIA7Way05VtOWqTigGi1Haq7bBehIOMMi2d7TEW833CMJpgqqXDwBSlq2mGoq_fK8tel14" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：ML 开发人员体验是实现 ML 业务影响的倍增器。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-journey-of-ai-ml-uber"&gt; Uber 的 AI/ML 之旅&lt;/h2&gt;&lt;p&gt;目前，Uber 在 70 多个国家的 10,000 多个城市开展业务，平台每天服务 2500 万次出行，每月活跃用户达 1.37 亿。机器学习几乎已融入 Uber 日常运营的各个方面。事实上，Uber 应用程序中的每一次交互都涉及幕后的机器学习。以骑手应用程序为例：当用户尝试登录时，机器学习用于检测欺诈信号，例如可能的帐户接管。在许多司法管辖区的应用程序中，机器学习被部署来建议目的地自动完成并对搜索结果进行排名。一旦选择了目的地，机器学习就会发挥多种功能，包括预计到达时间计算、行程价格计算、考虑安全措施的乘客与司机匹配以及行程路线选择。行程完成后，机器学习有助于检测支付欺诈、预防退款，并将其范围扩展到为客户服务聊天机器人提供支持。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/p3awCLhFgkOjDsk_T8R0DomPhWJWm9vkP8ZTb2VqKOHi7UN1Ous3e_wqGnM-CBBkOVBnw-pmFRYtF6Ik6kl9e31_t9k-BM6BGs9532Hc3b5u6Bej89QBOlJedgeT23t7mm-iTmTq8RRFKhCpMbWFrYY" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：实时 ML 支撑 Rider 应用程序用户流程。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;如图 2 所示，实时 ML 为骑手应用程序中的用户流程提供动力，对于 Eats 应用程序（以及许多其他应用程序）也是如此，如下图 3 所示。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/Yw8-VN8tnl7p9vyZHpX0l4Su9yIzWGHlF2f3mrYbi569DAiz2us-0FLr5Ti7be5HDUFEpyZrNg7SXfBi8edCm3FpklgTkxpr1jMyhuIkuM-oNrfcZpMUjP1BYMTfy3rhCP6OL98YjobFh6GkWR3v0h0" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：实时机器学习支撑 Eater 应用核心用户流程。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;回顾 Uber 机器学习的演变，可分为三个不同的阶段：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;strong&gt;2016 年至 2019 年：&lt;/strong&gt;在这个初始阶段，Uber 主要将预测机器学习用于表格数据用例。 XGBoost 等算法用于 ETA 预测、风险评估和定价等关键任务。此外，Uber 在自动驾驶汽车的 3D 映射和感知等关键领域深入研究了深度学习 (DL) 领域，因此需要在 GPU 调度和分布式训练方法（如 Horovod®）方面进行大量投资。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;2019 – 2023：&lt;/strong&gt;第二阶段共同推动高影响力机器学习项目采用深度学习和协作模型开发。重点是模型迭代作为 ML monorepo 中的代码，并支持 DL 作为米开朗基罗的一等公民。在此期间，超过60%的一级模型在生产中采用了深度学习，并显着提升了模型性能。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;从 2023 年开始：&lt;/strong&gt;第三阶段代表新一波生成式 AI 的最新发展，重点是改善 Uber 的最终用户体验和内部员工生产力（在&lt;a href="https://www.uber.com/blog/the-transformative-power-of-generative-ai/" rel="noreferrer noopener" target="_blank"&gt;之前的博客&lt;/a&gt;中进行了描述）。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/QNrwoFNrmVffQxsYS6KkqfXjHLJBBT1QHK99UO3o9KmMdC2t3DP_wUNIvUoU0dK2TOI4krdwKwb_EmV71O2Lm3vqqiYjyuzEwFq6oQZBVro17q1Xr45lpIPyEtaGpgYUEcVNXA60CxYwlJ7YJwFGJ28" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：Uber 从 2016 年到 2023 年的机器学习历程。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;在这一变革之旅中，米开朗基罗在提升机器学习能力和帮助团队构建行业领先的机器学习应用程序方面发挥着关键作用。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-michelangelo-1-0-2016-2019"&gt;米开朗基罗 1.0（2016 – 2019）&lt;/h2&gt;&lt;p&gt;当 Uber 于 2015 年踏上 ML 之旅时，应用科学家使用 Jupyter Notebooks™ 来开发模型，而工程师则构建定制管道以将这些模型部署到生产中。没有适当的系统来构建可靠且可重复的管道来大规模创建和管理训练和预测工作流程，也没有简单的方法来存储或比较训练实验结果。更重要的是，没有既定的路径可以在不创建自定义服务容器的情况下将模型部署到生产中。&lt;/p&gt;&lt;p&gt; 2016 年初，Michelangelo 推出，通过端到端系统标准化 ML 工作流程，使 Uber 的 ML 开发人员能够轻松地大规模构建和部署 ML 模型。它首先解决了可扩展模型训练和部署到生产服务容器的挑战（ &lt;a href="https://www.uber.com/blog/michelangelo-machine-learning-platform/" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;）。然后，构建了一个名为 Palette 的特征存储，以更好地管理和跨团队共享特征管道。它支持批量和近实时特征计算用例。目前，Palette 拥有超过 20,000 个功能，Uber 团队可以直接利用这些功能来构建强大的 ML 模型（ &lt;a href="https://www.infoq.com/presentations/michelangelo-palette-uber/" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;发布的其他关键 Michelangelo 组件包括但不限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;图库：&lt;/strong&gt;米开朗基罗的模型和机器学习元数据注册表，为所有类型的机器学习实体提供全面的搜索 API。 （ &lt;a href="https://openproceedings.org/2020/conf/edbt/paper_217.pdf" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;）&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Manifold：&lt;/strong&gt; Uber 的 ML 模型无关的可视化调试工具。 （ &lt;a href="https://www.uber.com/blog/manifold/?uclick_id=91e0edf5-abbe-49f9-b9ee-2a7c598a6a35" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;）&lt;/li&gt;&lt;li&gt; &lt;strong&gt;PyML：&lt;/strong&gt;一个加速 Python ML 模型原型设计、验证和生产周期的框架。 （&lt;a href="https://www.uber.com/blog/michelangelo-pyml/" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;扩展米开朗基罗的模型表示以实现大规模的灵活性。 （ &lt;a href="https://www.uber.com/blog/michelangelo-machine-learning-model-representation/" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;）&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Horovod&lt;/strong&gt;用于分布式训练。 （&lt;a href="https://www.uber.com/blog/horovod/" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;） &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-michelangelo-2-0-2019-2023"&gt;米开朗基罗 2.0（2019 – 2023）&lt;/h2&gt;&lt;p&gt;米开朗基罗的最初目标是在 Uber 引导机器学习并使之民主化。到 2019 年底，Uber 的大多数业务线都已将机器学习集成到他们的产品中。随后，米开朗基罗的重点开始从“让机器学习无处不在”转向“加倍投入高影响力的机器学习项目”，以便开发人员可以提升这些项目的模型性能和质量，从而为 Uber 带来更高的商业价值。考虑到这些项目的复杂性和重要性，需要更先进的机器学习技术，特别是深度学习，并且通常需要许多不同的角色（例如数据科学家和工程师）更快地协作和迭代模型，如图 5 所示这给米开朗基罗 1.0 带来了一些挑战，如下所列。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/2F31vZ3o80U_oyCz7LSHemUXQWNzYy6xLCkn4jIALAjnj83oO6Q8uAiCDOSo3YGDzJBCUOsgI6dKigsqOWqfmKnasgL2vQ3BQP8BOEJZkJBmpj9L4zk9sIMKaYVaHDTO6J7opoEBmGhpIz6OIGvGafU" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：ML 生命周期是迭代的，并且与许多不同的角色协作。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; &lt;strong&gt;1.缺乏全面的机器学习质量定义和项目分层&lt;/strong&gt;：与具有明确定义的质量标准和最佳实践的微服务不同，当时没有一致的方法来衡量全方位的模型质量。例如，许多团队只测量 AUC 和 RMSE 等离线模型性能，而忽略了在线模型性能、训练数据的新鲜度和模型再现性等其他关键指标。这导致模型性能的可见性很低、生产中的模型过时以及数据集覆盖率较差。&lt;/p&gt;&lt;p&gt;此外，重要的是要认识到机器学习项目在业务影响方面存在很大差异。由于缺乏独特的机器学习分层系统，导致在资源分配、支持和管理中断方面采用统一的方法，而不管项目的影响如何。这导致高影响力项目投资不足或没有得到应有的优先考虑。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;2. 对深度学习模型的支持不足：&lt;/strong&gt;直到 2019 年，Uber 的机器学习用例主要使用基于树的模型，这本质上不利于采用自定义损失函数、增量训练和嵌入等先进技术。相反，Uber 拥有适合训练 DL 模型的大量数据，但基础设施和开发人员体验方面的挑战阻碍了这一方向的进展。许多团队（例如 Maps ETA 和 Rider 激励团队）必须花费数月时间来开发自己的 DL 工具包，然后才能成功训练第一个版本的 DL 模型。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;3. 对协作模型开发的支持不足&lt;/strong&gt;：早期，大多数机器学习项目都是小规模的，并且从开始到生产仅由单个开发人员编写和迭代。因此，Michelangelo 1.0 并未针对高度协作的模型开发进行优化，并且 Michelangelo 1.0 UI 和 Jupyter Notebook 中的协作很困难，并且通常通过手动复制和合并来完成，而无需版本控制或分支。此外，没有针对 UI 模型配置更改或笔记本编辑的代码审查流程，并且缺乏 ML 代码和配置的集中存储库导致它们分散在各个来源中。这些对我们的工程流程构成了重大威胁，并使跨众多机器学习项目的大规模模型探索变得困难。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;4. 碎片化的 ML 工具和开发人员体验：&lt;/strong&gt;自 2015 年以来，除了 Michelangelo 之外，Uber 的不同团队还为 ML 生命周期和用例的子集构建了许多 ML 工具，例如来自数据团队的&lt;a href="https://www.uber.com/blog/evolution-ds-workbench/" rel="noreferrer noopener" target="_blank"&gt;Data Science Workbench&lt;/a&gt; (DSW)，用于托管Jupyter Notebooks、来自 Marketplace 团队的用于 ML 工作流程编排和自动化的 ML Explorer，以及来自 Risk 团队的 uFlow/uScorer，专门用于来自其自己团队的训练和推理模型。为不同的模型类型开发 ML 模型也有不同的方法，例如，用于 SparkML 和 XGBoost 模型的 Michelangelo UI、用于 DL 模型的 Jupyter Notebook 以及用于基于 Python 的自定义模型的&lt;a href="https://www.uber.com/blog/michelangelo-pyml/" rel="noreferrer noopener" target="_blank"&gt;PyML&lt;/a&gt; 。启动一个机器学习项目通常需要在这种半隔离的工具之间不断切换，这些工具是用不同的 UI 模式和用户流程构建的，导致用户体验碎片化并降低了生产力。&lt;/p&gt;&lt;p&gt;为了应对这些挑战，米开朗基罗 2.0 将分散的 ML 平台重新架构为具有统一 UI 和 API 的单一连贯产品，用于端到端 ML 生命周期。 Michelangelo 2.0 有四个面向用户的主题：(1) 模型质量和项目分层，(2) 通过 Canvas 将模型迭代为代码，(3) DL 作为一流的平台公民，(4) 通过 MA 统一 ML 开发人员体验工作室。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-architectural-overview"&gt;架构概览&lt;/h3&gt;&lt;p&gt;米开朗基罗 2.0 以四个支柱为中心。在最底层，我们正在启用一个允许即插即用平台组件的架构。一些组件是内部构建的，其他组件可以是来自开源或第三方的最先进的商品。最重要的是迎合应用科学家和机器学习工程师的开发和生产经验。为了提高模型开发速度，我们正在简化开发体验和支持协作、可重用开发的技术。我们相信这种方法将使我们能够在平台级别跟踪和执行合规性。我们正在投资模型的安全部署和自动模型再训练等生产经验，以方便大规模维护和管理模型。最后，我们专注于模型的质量，并投资于能够在所有阶段衡量模型质量并系统地改进模型的工具。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/gRuNaUCrkkMDsG1LwyLo43lqxK0Sl_dtJXQU3o2NX2VKH1wPy9SOvlPbk91_8o6dOGEsbSQz336xH1u9Z_RVi5vfoS9A2TjQg5_T5sQ7-jCrMkfRrxL4supkxIoviPLMvO8Gs0iV0QA2O0p-rxUIk_g" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：米开朗基罗 2.0 架构的高级概念。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;以下是米开朗基罗2.0的一些架构设计原则：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;定义项目分层，并专注于高影响力的用例，以最大限度地提高 Uber 的机器学习影响力。为长尾机器学习用例提供自助服务，以便他们可以利用平台的强大功能。&lt;/li&gt;&lt;li&gt;大多数 ML 用例可以利用 Michelangelo 的核心工作流程和 UI，而 Michelangelo 还支持深度学习等高级用例所需的更多定制工作流程。&lt;/li&gt;&lt;li&gt;单片与即插即用。架构将支持不同组件的即插即用，但托管解决方案将仅支持其中的一部分以获得最佳用户体验。为高级用例带来您自己的组件。&lt;/li&gt;&lt;li&gt; API/代码驱动与 UI 驱动。遵循 API 优先原则，利用 UI 实现可视化和快速迭代。支持模型迭代作为版本控制和代码审查的代码，包括 UI 中所做的更改。&lt;/li&gt;&lt;li&gt;构建与购买决策。利用 OSS 或云或内部构建的一流产品。 OSS 解决方案可能优先于专有解决方案。请谨慎对待云解决方案的容量成本。&lt;/li&gt;&lt;li&gt;将最佳 ML 实践（例如安全模型部署、模型再训练和平台中的功能监控）编入规范。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;该系统由三个平面组成，即控制平面、离线和在线数据平面。控制平面定义面向用户的 API 并管理系统中所有实体的生命周期。离线数据平面负责大数据处理的繁重工作，例如特征计算、模型训练和评估、离线批量推理等。在线数据平面处理实时模型推理和特征服务，供其他微服务使用。&lt;/p&gt;&lt;p&gt;控制平面采用相同的&lt;a href="https://github.com/cncf/tag-app-delivery/blob/163962c4b1cd70d085107fc579e3e04c2e14d59c/operator-wg/whitepaper/Operator-WhitePaper_v1-0.md" rel="noreferrer noopener" target="_blank"&gt;Kubernetes™ Operator 设计模式，&lt;/a&gt;实现模块化和可扩展性。 Michelangelo API 还遵循相同的&lt;a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md" rel="noreferrer noopener" target="_blank"&gt;Kubernetes API 约定&lt;/a&gt;，并标准化了 ML 相关实体（如项目、Pipeline、PipelineRun、Model、Revision、InferenceServer、Deployment 等）的操作。通过利用 Kubernetes API 机制（包括 API 服务器、 &lt;a href="https://etcd.io/" rel="noreferrer noopener" target="_blank"&gt;etcd&lt;/a&gt;和控制器）管理器中，所有 Michelangelo API 都可以以一致的方式访问，从而带来更加用户友好和简化的用户体验。此外，声明式 API 模式对于 Michelangelo 支持通过 UI 和 GIT 存储库中的代码进行突变也至关重要，稍后将详细介绍。&lt;/p&gt;&lt;p&gt;离线数据平面由一组 ML 管道组成，包括训练、评分、评估等，这些管道被定义为步骤的 DAG。 ML 管道支持中间检查点并在步骤之间恢复，以避免重复执行先前的步骤。步骤在 Ray™ 或 Spark™ 等框架之上执行。在线数据平面管理 RPC 服务和流处理作业，为在线预测、在线特征访问和近实时特征计算提供服务。&lt;br /&gt;&lt;/p&gt;&lt;p&gt;图7显示了Michelangelo 2.0系统的详细设计，它降低了工程复杂性并简化了对其他基础设施组件的外部依赖。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/MqljT9LUabDAsMHNb1k6y5LqyILCQdzWU1zi1ZD_XWneCBiYqo3Wtoda2_ysExjD0prHflRC8yBVK5Cziy2VkrQHuThszXcgvWMS4CfSZDllePznu6UB_Jw_mOZE25UA4o5gPy46woAP9uSFXrJlctI" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：Michelangelo 2.0 的详细系统设计，包括离线、在线和控制平面。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-model-quality-and-project-tiering"&gt;模型质量和项目分层&lt;/h3&gt;&lt;p&gt;生产就绪的机器学习系统的开发和维护非常复杂，涉及模型生命周期的多个阶段和复杂的支持基础设施。通常，ML 模型会经历特征工程、训练、评估和服务等阶段。缺乏全面的 ML 质量测量导致 ML 开发人员对模型生命周期不同阶段的各种质量维度的了解有限。此外，这种差距阻碍了组织领导者就机器学习项目的质量和影响做出充分知情的决策。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/bIbKLbwB7em5FhgTLHym9OHRHcaORl4UASUzEquCX0O11RkyCoOCxYbiANmykUDdFUoAZGfX7EZ_kCLyeloxxy82D_gvWZX7aYpfQmVZWPb68632BR5YjLcCSSLOznLU8Yr-Ei7QbnqSuNYiuTyu33w" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：典型 ML 系统中的 ML 质量维度示例（黄色）。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;为了弥补这些差距，我们推出了模型卓越评分（MES），这是一个用于测量和监控模型生命周期每个阶段的关键维度和指标的框架，例如训练模型准确性、预测准确性、模型新鲜度和预测特征质量，确保采用全面、严格的方法大规模部署机器学习。该框架利用站点可靠性工程师 (SRE) 和 DevOps 专业人员在生产环境中管理微服务可靠性时常用的相同&lt;a href="https://en.wikipedia.org/wiki/Service-level_agreement" rel="noreferrer noopener" target="_blank"&gt;服务级别协议&lt;/a&gt;(SLA) 概念。通过与 SLA 工具集集成，MES 建立了衡量和确保 Uber ML 模型质量的标准。此外，MES 跟踪并可视化模型的合规性和质量，从而为整个组织的 ML 计划提供更清晰、更全面的视图。请参阅&lt;a href="https://www.uber.com/blog/enhancing-the-quality-of-machine-learning-systems-at-scale/" rel="noreferrer noopener" target="_blank"&gt;MES 博客&lt;/a&gt;了解更多详细信息。&lt;/p&gt;&lt;p&gt;为了区分高影响力和长尾用例，我们引入了定义明确的机器学习项目分层方案。该计划由四层组成，其中第一层是最高的。第 1 级项目由服务于核心出行和核心乘客流程中关键功能的模型组成，例如 ETA 计算、安全性和欺诈检测等。只有直接影响核心业务运营的模型才有资格获得第 1 级状态。相反，第四级项目通常包含实验性和探索性用例，直接业务影响有限。这种分层方案使我们能够就机器学习项目中断处理的资源分配、资源投资、最佳实践实施和合规性事务等方面做出明智的决策。它确保对每个项目的关注和资源投入与其相对优先级和影响相称。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-model-iterations-as-code-nbsp"&gt;将模型迭代作为代码&lt;/h3&gt;&lt;p&gt;为了提高 ML 开发人员的工作效率、促进无缝团队协作并提高 2020 年 ML 应用程序的整体质量，我们推出了 Project Canvas。该项目旨在将软件工程最佳实践应用于 ML 开发生命周期，实施版本控制，利用 Docker 容器的强大功能、集成 CI/CD 工具，并通过引入标准化 ML 应用程序框架来加快模型开发。 Canvas 的关键组件包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;strong&gt;ML 应用程序框架 (MAF)&lt;/strong&gt; ：预定义但可自定义的 ML 工作流程模板，为 ML 开发提供代码和配置驱动的方式，专为深度学习等复杂的 ML 技术量身定制。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;ML Monorepo&lt;/strong&gt; ：一个集中存储库，将所有 ML 开发事实来源存储为代码，具有强大的版本控制功能。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;ML 依赖管理&lt;/strong&gt;：使用 Bazel 和 docker 构建提供软件依赖管理。每个 ML 项目都有自己定制的 docker 镜像。除了软件依赖之外，模型训练和服务代码将被打包到一个不可变的 docker 镜像中，用于生产模型重新训练和服务。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;机器学习开发环境：&lt;/strong&gt;为机器学习开发人员提供一致的本地开发和远程生产执行环境，以便他们可以在本地测试和调试模型，然后在远程生产环境中运行模型，以实现快速模型迭代。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;ML 持续集成/持续交付&lt;/strong&gt;：针对主分支进行持续集成，并通过各种测试和验证将 ML 模型自动部署到 ML monorepo 主分支的生产环境。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;ML 工件管理：&lt;/strong&gt;为工件和沿袭跟踪提供支持。工件是 ML 对象，例如模型、数据集和评估报告及其相应的元数据。对象将存储在分布式存储中，元数据将被完全索引和搜索。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;MA Assistant (MAA)：&lt;/strong&gt;米开朗基罗的 AutoML 解决方案，用于自动模型架构搜索和特征探索/修剪。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/Teij0cWxZToDYuyzL5LIk0iUWeSr1N3cpFnCpJGVHg8M8Hj8twroleP_flTmf6kSCkgHPXcdcTBg8-wuGN2SoaA0squnLErPVSDf2xBqPV6bz9pFlvRRXQz56LOZfWrCau7nHkfqWeTCmxCoXS5eh_A" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：Canvas：简化端到端 ML 开发人员体验。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; Canvas 还通过利用 Bazel 和 docker 构建简化了 ML 依赖项管理。每个 ML 项目都会有其自定义的 docker 镜像，模型训练和服务代码将被打包到一个不可变的 docker 镜像中，用于生产模型重新训练和服务。此外，Canvas 为 ML 开发人员提供了一致的本地和远程开发环境，可以在本地测试和调试模型，然后在远程生产环境中运行模型以实现快速模型迭代。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-deep-learning-as-a-first-class-platform-citizen"&gt;深度学习作为一流平台公民&lt;/h3&gt;&lt;p&gt;采用自定义损失函数、增量训练和嵌入等先进技术带来了重大挑战。深度学习可以更灵活地应对这些挑战。此外，随着数据集变大，深度学习通常会表现出色，因为它可以利用更多数据来学习更复杂的表示。&lt;/p&gt;&lt;p&gt; 2019 年之前，Uber 的大多数 DL 模型都用于&lt;a href="https://www.uber.com/blog/machine-learning-model-life-cycle-version-control/" rel="noreferrer noopener" target="_blank"&gt;自动驾驶汽车&lt;/a&gt;（例如&lt;a href="https://proceedings.mlr.press/v87/yang18b/yang18b.pdf?uclick_id=91e0edf5-abbe-49f9-b9ee-2a7c598a6a35" rel="noreferrer noopener" target="_blank"&gt;3D 映射&lt;/a&gt;、感知）、计算机视觉（例如 &lt;a href="https://www.uber.com/blog/real-time-id-check/" rel="noreferrer noopener" target="_blank"&gt;驾驶员面部识别&lt;/a&gt;）和自然语言处理（例如&lt;a href="https://www.uber.com/en-AU/blog/cota/" rel="noreferrer noopener" target="_blank"&gt;客户痴迷&lt;/a&gt;）用例。然而，针对核心业务的深度学习模型非常少，特别是针对表格数据用例。阻碍深度学习采用的一个重要原因是米开朗基罗1.0缺乏端到端的深度学习支持。与基于树的模型不同，深度学习模型通常需要更复杂的机器学习平台支持，从特征转换和模型训练到模型服务和 GPU 资源管理。本节的其余部分将概述我们在 Michelangelo 2.0 中对深度学习支持的投资。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-feature-transformation"&gt;特征变换&lt;/h4&gt;&lt;p&gt;米开朗基罗 1.0 实现了用于特征转换的 DSL，例如在模型训练和服务路径中使用的标准化和分桶化。该转换与&lt;a href="https://www.uber.com/blog/michelangelo-machine-learning-model-representation/" rel="noreferrer noopener" target="_blank"&gt;Spark PipelineModel&lt;/a&gt;模型捆绑在一起，从而&lt;a href="https://developers.google.com/machine-learning/guides/rules-of-ml#training-serving_skew" rel="noreferrer noopener" target="_blank"&gt;消除了训练服务偏差的根源。&lt;/a&gt;然而，DSL 转换是作为 Spark 转换器实现的，无法在用于低延迟服务的 DL 模型的 GPU 上运行。在 Michelangelo 2.0 中，我们实现了一种新的 DL 原生转换解决方案，允许用户使用 Keras 或 PyTorch 运算符转换其特征，并为高级用户提供使用 Python 代码定义自定义特征转换的灵活性。与&lt;a href="https://blog.research.google/2017/02/preprocessing-for-machine-learning-with.html" rel="noreferrer noopener" target="_blank"&gt;TensorFlow 变换&lt;/a&gt;类似，变换图与 TensorFlow 或 TorchScript 中的模型推理图相结合，以在 GPU 上提供低延迟服务。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-model-training"&gt;模型训练&lt;/h4&gt;&lt;p&gt;Michelangelo 2.0 通过利用我们的分布式训练框架 Horovod，支持 TensorFlow 和 PyTorch 框架进行大规模深度学习模型训练。此外，我们还进行了以下改进，以实现更好的可扩展性、容错性和效率。&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;strong&gt;Ray 上的分布式 GPU 训练和调优。&lt;/strong&gt; （ &lt;a href="https://www.youtube.com/watch?v=gMT_ONmI9RM&amp;amp;list=PLzTswPQNepXmLUiL4F_1VHrPcCz1OeILw&amp;amp;index=47" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;）。从历史上看，Michelangelo 的模型训练是在 Spark 上运行的。然而，DL 给 Spark 带来了新的挑战，例如缺乏 GPU 执行器、mini-batch shuffle 和 all-reduce。 &lt;a href="https://horovod.readthedocs.io/en/stable/spark_include.html" rel="noreferrer noopener" target="_blank"&gt;Horovod on Spark&lt;/a&gt;使用 Spark 估计器语法封装了深度学习训练，并提供了与训练管道的轻松集成。然而，它也引入了许多操作复杂性，例如单独的集群作业、生命周期管理和故障场景。在 Michelangelo 2.0 中，我们用基于 Ray 的训练器取代了基于 Spark 的 XGBoost 和 DL 训练器，以实现更好的可扩展性和可靠性。我们还从内部超参数调整解决方案切换到 RayTune。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;具有自动缩放和容错功能的 Elastic Horovod&lt;/strong&gt; 。 （&lt;a href="https://www.uber.com/blog/horovod-ray/" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;）。 Elastic Horovod 允许分布式训练，在整个训练过程中动态扩展工作人员数量。现在，当机器来回工作时，工作人员可以在最小程度地中断的情况下继续培训。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;资源高效的增量培训&lt;/strong&gt;。深度学习的优点之一是能够使用额外的数据集增量训练模型，而无需从头开始训练。这显着提高了生产重新训练的资源效率，并增加了数据集覆盖范围以提高模型准确性。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Canvas 中的声明式深度学习训练管道&lt;/strong&gt;。深度学习模型需要自定义模型代码和损失函数等。在 Canvas 中，我们将训练管道设计为声明式和可扩展的，以便用户插入自定义模型代码，例如估计器、优化器和损失函数，如图 9 所示。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/wq4mV9-lSpxnYgUrC91PzO7JaMnSawey2wir-Ai0odqHzIaTkMA8erWscsRHZl22fpCQvzipR86Tkw_jgzFs3jokhk86Zqnc2OfeY882_3ChONlnLYAtEQpMCi8u6lMAw9PS8oOD-0WmtSsbEvs1bZA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：Canvas 中深度学习模型的示例训练管道。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-model-serving"&gt;模特服务&lt;/h4&gt;&lt;p&gt;大多数采用深度学习的 Uber 一级 ML 项目对服务延迟非常敏感，例如地图 ETA 和 Eats homefeed 排名。此外，模型服务必须支持 TensorFlow 和 PyTorch DL 框架，但要从用户那里抽象出框架级细节。从历史上看， &lt;a href="https://github.com/uber/neuropod" rel="noreferrer noopener" target="_blank"&gt;Neuropod&lt;/a&gt;一直是 Michelangelo 中默认的深度学习服务引擎。然而，它缺乏持续的社区支持，并且正在被弃用。在 Michelangelo 2.0 中，我们将&lt;a href="https://github.com/triton-inference-server/server" rel="noreferrer noopener" target="_blank"&gt;Triton&lt;/a&gt;作为下一代模型服务引擎集成到我们的在线预测服务 (OPS) 中，作为新的 Spark 变压器。 Triton 是 Nvidia 开发的开源推理服务器，支持包括 TensorFlow、PyTorch、Python 和 XGBoost 在内的多种框架，它针对 GPU 进行了高度优化，可实现低延迟服务。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-gpu-resource-management"&gt; GPU资源管理&lt;/h4&gt;&lt;p&gt;深度学习训练和服务都需要大规模的 GPU 资源。如今，Uber 在本地数据中心和 OCI 和 GCP 等云提供商中管理着 5000 多个 GPU。这些 GPU 分布在多个区域、许多专区和集群中。计算集群正在从&lt;a href="https://kccna18.sched.com/event/GrTx/peloton-a-unified-scheduler-for-web-scale-workloads-on-mesos-kubernetes-min-cai-nitin-bahadur-uber" rel="noreferrer noopener" target="_blank"&gt;Peloton / Mesos&lt;/a&gt;迁移到&lt;a href="https://kccncna19.sched.com/event/Uaad/kubernetizing-big-data-and-ml-workloads-at-uber-mayank-bansal-min-cai-uber" rel="noreferrer noopener" target="_blank"&gt;Kubernetes&lt;/a&gt; 。为了最大限度地提高资源利用率，Uber 投资于不同团队之间的弹性 CPU 和 GPU 资源共享，以便每个团队都可以机会性地使用其他团队的闲置资源。在计算集群之上，我们跨多个 Kubernetes 集群构建了一个作业联合层，以隐藏区域、区域和集群详细信息，以实现更好的作业可移植性和轻松的云迁移。作业联合层采用与 Kubernetes 运算符相同的设计模式，并在 Michelangelo 的统一 API 框架中作为作业 CRD 控制器实现，如图 7 所示。目前，作业控制器支持 Spark 和 Ray 作业。&lt;/p&gt;&lt;p&gt;凭借 Michelangelo 2.0 中对深度学习的端到端支持，Uber 在不同业务线的深度学习采用方面取得了显着改进。在过去几年中，一级项目中的深度学习采用率从几乎为零增加到 60% 以上。例如， &lt;a href="https://www.uber.com/blog/deepeta-how-uber-predicts-arrival-times/" rel="noreferrer noopener" target="_blank"&gt;DeepETA&lt;/a&gt;模型拥有超过 1 亿个参数，训练次数超过 10 亿次。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-ma-studio-one-unified-web-ui-tool-for-everything-ml-uber"&gt; MA Studio – 一个统一的 Web UI 工具，适用于所有 ML @ Uber&lt;/h3&gt;&lt;p&gt;为了解决上述机器学习开发人员体验中的挑战，开发了 Michelangelo (MA) Studio，将现有的 Michelangelo 产品和新建的平台功能统一到一个用户旅程中，通过完全重新设计的 UI 和 UX 提供无缝的用户体验。 MA Studio 提供了简化的用户流程，涵盖了 ML 旅程的每一步，从特征/数据准备、模型训练、部署，一直到生产性能监控和模型 CI/CD，全部集中在一个地方，以提高 ML 开发人员的工作效率。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/23NZpcegPdWpU-kpA3971k3KKYGxjh-AMVlljf26FeKV1eAga8tCkU3vuZCgWOwlDYwDbkWXFJ0wDX-8DDsXKBGT1-ucOZbA375Pg7aectkscLfD01kJbB0EEp5vX1LSQ4ba6NhbS_N1fpX89-Dit9Y" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 10：MA Studio 项目登陆页面涵盖端到端 ML 开发生命周期。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; MA Studio 拥有一系列额外优势：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;版本控制和代码审查&lt;/strong&gt;：所有与 ML 相关的代码和配置均受版本控制，所有更改都经过代码审查过程，包括从 UI 创建的模型。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;现代化的模型部署堆栈&lt;/strong&gt;：安全和增量的区域部署、自动回滚触发器和生产运行时验证。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;内置统一的ML可观测性工具包&lt;/strong&gt;：模型性能监控、特征监控、在线/离线特征一致性检查和MES。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;统一的 ML 实体生命周期管理&lt;/strong&gt;：用户受益于直观的 UI 和结构良好的用户流程，用于管理从模型和管道到数据集和报告的所有 ML 实体。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;增强的调试功能&lt;/strong&gt;：MA Studio 增强了调试功能并加速了 ML 管道故障的恢复。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/v2Dr41DHAjWT4JcMTHMRZ-EFv51edbx8RPw4BJ0MsqrnNAlI0lKoZJ-ZGRvUAZ5ez9VjNeKizUBwq-Hlxzp3uVs9i4NahPqDmgI9bOrJyBM_MC1NZjz7FD2Q46MJ_H32lP6VN3zqgEeeghht_r3mdrk" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 11：适用于标准和高级 ML 用例的 MA Studio 和 Canvas。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;对于 Uber 的任何机器学习需求，您只需要两个工具：Canvas 和 MA Studio。 MA Studio 的用户友好型 UI 涵盖了标准 ML 工作流程，可促进 XGB 模型训练和标准模型重新训练流程等任务，而无需编写任何代码。在处理更复杂的场景时，例如深度学习训练或定制的再训练流程，Canvas 是首选工具。无论您是通过 Canvas 还是 UI 构建管道，您都可以无缝执行和管理这些管道、部署经过训练的模型以及监控和调试模型性能 - 所有这些都可以通过 MA Studio UI 进行。值得注意的是，所有模型代码和相关配置现在都受到版本控制，任何更改都经过细致的代码审查过程，这极大地提高了 Uber 生产中的 ML 应用程序的质量。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-generative-ai-2023-now"&gt;生成式人工智能（2023 年至今）&lt;/h2&gt;&lt;p&gt;生成式人工智能的最新进展，特别是在大语言模型（LLM）领域，能够从根本上改变我们通过自然语言与机器的交互。 Uber 的多个团队正在积极研究使用法学硕士来通过助理提高内部生产力，通过自动化简化业务运营，并通过神奇的用户体验改进最终用户产品，同时解决&lt;a href="https://en.wikipedia.org/wiki/Wikipedia:Large_language_models" rel="noreferrer noopener" target="_blank"&gt;与使用法学硕士相关的问题&lt;/a&gt;。图 12 显示了 Uber 这三类生成式 AI 用例的潜在价值。 &lt;a href="https://www.uber.com/blog/the-transformative-power-of-generative-ai/" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/ymra4p74-37pbRET_WeL_zvyEI6I9LOg8RICp0dVRQYBEYEllRz9psRc7omJcLe6ohyJrEztIFvOK7egSKiev_hgSpI8L4CmZ_pntoRdOOaJT9DAAgWWOMonlGcLDZl0oC3OpEs21Te5R-hr7KLdG-I" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 12：Uber 的三类生成人工智能用例。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;为了开发生成式人工智能应用程序，团队需要通过第三方 API 访问外部法学硕士和/或内部托管的开源法学硕士。这是因为外部模型在需要常识和复杂推理的任务中具有卓越的性能，同时通过利用丰富的专有数据，我们可以微调开源模型，以在以 Uber 为中心的任务上实现高水平的准确性和性能，成本的一小部分和更低的延迟。这些经过微调的开源模型由内部托管。&lt;/p&gt;&lt;p&gt;因此，我们开发了 Gen AI Gateway，为团队提供统一的界面，以遵守安全标准和保护隐私的方式访问外部法学硕士和内部托管的法学硕士。 Gen AI 网关的一些功能包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;记录和审计：&lt;/strong&gt;确保全面的跟踪和问责。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;成本护栏和归因：&lt;/strong&gt;在归因使用情况的同时管理费用，并对过度使用发出警报。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;安全和政策护栏：&lt;/strong&gt;确保法学硕士的使用符合我们的内部准则。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;个人身份信息 (PII) 编辑：&lt;/strong&gt;对个人数据进行识别和分类，并在将输入发送到外部法学硕士之前对其进行编辑。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了加速 Uber 生成式 AI 应用程序的开发，我们对 Michelangelo 进行了扩展，以支持完整的 LLMOps 功能，例如微调数据准备、即时工程、LLM 微调和评估、LLM 部署和服务以及生产性能监控。一些关键组件包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;模型目录包含一系列预构建且随时可用的 LLM，可通过第三方 API（例如 GPT4、Google PaLM）或 Michelangelo 上内部托管的开源 LLM（例如 Llama2）访问。用户可以在目录中探索有关这些法学硕士的广泛信息并启动各种工作流程。这包括在 MA Studio 中微调模型或将模型部署到在线服务环境。该目录提供了多种预训练模型的选择，增强了平台的多功能性。&lt;/li&gt;&lt;li&gt; LLM评估框架使用户能够在不同方法（例如，内部与3P和提示与3P微调）中比较LLM，并通过提示和模型的迭代来评估改进。&lt;/li&gt;&lt;li&gt;提示工程工具包使用户可以通过完整版本控制和代码审核过程创建和测试提示，验证输出并将提示模板保存在集中式存储库中。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了实现具有成本效益的LLM微调和低延迟LLM服务，我们已经对米开朗基罗培训和服务堆栈实施了一些重要的增强：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;与拥抱的脸部集成&lt;/strong&gt;：我们利用了&lt;a href="https://huggingface.co/models" rel="noreferrer noopener" target="_blank"&gt;拥抱面枢纽&lt;/a&gt;和相关库（如&lt;a href="https://huggingface.co/docs/peft/index" rel="noreferrer noopener" target="_blank"&gt;PEFT）&lt;/a&gt;上可用的开源LLM为LLMS实施了基于射线的培训师。微调的LLM和相关的元数据存储在Uber的模型存储库中，该存储库可从模型推理基础架构访问。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;启用模型并行性&lt;/strong&gt;：米开朗基罗以前不支持训练DL模型的模型并行性。该限制将可训练模型的大小限制在可用的GPU内存中，例如，在16 GB GPU上，理论上最大值为40亿个参数。在更新的LLM培训框架中，我们集成了DeepSpeed以启用模型并行性。这一突破消除了GPU内存限制，并允许训练更大的DL模型。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;弹性GPU资源管理：&lt;/strong&gt;我们已经通过Michelangelo工作控制器在GPU上提供了射线簇。该规定使LLM模型的培训能够在本地最强大的GPU上进行培训。此外，这种集成为使用云GPU的未来扩展设定了阶段，从而增强了可扩展性和灵活性。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;利用Michelangelo提供的这些平台功能，Uber的团队热情地开发了LLM驱动的应用程序。我们期待很快分享我们在LLM的生产中的进步。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;ML已发展成为Uber关键业务领域的基本驱动力。该博客深入研究Uber的ML平台米开朗基罗的八年变革旅程，强调了ML开发人员体验的重大增强。这一旅程以三个不同的阶段展开：2016年至2019年表格数据的预测ML的基础阶段，2019年至2023年之间向深度学习的逐步转变，以及最近从2023年开始转向生成AI的企业。&lt;/p&gt;&lt;p&gt;在如此复杂的层面上构建大规模的端到端ML平台的知识经验教训，以Uber的规模支持ML用例。主要要点包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;建立一个集中的ML平台，而不是让单个产品团队建立自己的ML基础架构，可以显着提高中型或大型公司内的ML开发效率。理想的ML组织结构包括一个集中的ML平台团队，并由每个产品团队中嵌入的专门数据科学家和ML工程师进行补充。&lt;/li&gt;&lt;li&gt;以统一的方式提供基于UI的和代码/配置驱动的用户流，对于提供无缝的ML DEV体验至关重要，尤其是对于ML开发人员对Dev Tools的偏好的大型组织而言，Dev Tools的偏好在不同人群中很大变化。&lt;/li&gt;&lt;li&gt;为大多数用户提供具有预定义的工作流模板和配置的高级抽象层的策略，同时允许高级电源用户直接访问低级基础架构组件以构建自定义的管道和模板有效。&lt;/li&gt;&lt;li&gt;以模块化的方式设计平台体系结构，以便可以使用插件方法来构建每个组件，从而可以快速采用开源，第三方供应商或内部的最先进技术发展。&lt;/li&gt;&lt;li&gt;尽管深度学习证明在解决复杂的ML问题方面证明了强大的功能，但挑战在于支持大规模的DL基础架构并保持这些模型的性能。仅当其优势与特定要求保持一致时，只使用DL。 Uber的经验表明，在某些情况下，XgBoost在性能和成本方面都优于DL。&lt;/li&gt;&lt;li&gt;并非所有ML项目都是平等的。拥有明确的ML分层系统可以有效地指导资源和支持的分配。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;米开朗基罗的使命是为Uber的ML开发人员提供一流的ML功能和工具，以便他们可以大规模地迅速构建，部署和迭代高质量的ML应用程序。作为AI平台团队，我们提供了深入的ML专业知识，推动ML技术的标准化和创新，建立信任并与我们的合作伙伴团队合作，并培养一种充满活力的ML文化，以便将ML拥抱和利用到其最大的潜力。我们对这项任务的承诺坚定不移，我们对前方有前途的未来充满热情。&lt;/p&gt;&lt;p&gt;如果您有兴趣加入我们的这项激动人心的冒险，请查看我们的&lt;a href="https://www.uber.com/us/en/careers/" rel="noreferrer noopener" target="_blank"&gt;工作网站&lt;/a&gt;以获取空缺。此外，我们期待与AI/ML空间中的其他团队合作，以建立一个强大的ML社区，并共同加快AI/ML技术的进步。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Apache®，Apache Spark，Spark和Star Logo是美国和/或其他国家/地区Apache Software Foundation的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Horovod和Kubenetes是美国和/或其他国家的LinuxFoundation®的注册商标或商标。 LinuxFoundation®的认可不受这些标记的使用暗示。&lt;/p&gt;&lt;p class="has-small-font-size"&gt;雷是美国和/或其他国家/地区的Enscale，Inc的注册商标或商标。&lt;/p&gt;</description><pubDate>Thu, 02 May 2024 09:46:07 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/from-predictive-to-generative-ai/</guid></item><item><title>【DragonCrawl: Generative AI for High-Quality Mobile Testing】DragonCrawl：用于高质量移动测试的生成式 AI</title><link>https://www.uber.com/blog/generative-ai-for-high-quality-mobile-testing/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;&lt;strong&gt;介绍&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;Uber 的开发者平台团队不断开发新的创新想法，以增强开发者的体验并增强我们应用程序的质量。质量和测试齐头并进，2023 年，我们接受了一项令人兴奋的新挑战，改变我们测试移动应用程序的方式，重点是机器学习 (ML)。具体来说，我们正在训练模型来测试我们的应用程序，就像真人一样。&lt;/p&gt;&lt;p&gt;移动测试仍然是一个尚未解决的挑战，尤其是在我们的规模下，包括数千名开发人员和 3,000 多个同时进行的实验。通常会进行手动测试，但开销较高，无法针对每一个微小的代码更改进行广泛的测试。虽然测试脚本可以提供更好的可扩展性，但它们也不能免受较小更新（例如新的弹出窗口和按钮更改）引起的频繁中断的影响。所有这些更改，无论多么微小，都需要定期手动更新测试脚本。因此，从事此工作的工程师将 30-40% 的时间投入到维护上。此外，这些测试的大量维护成本极大地阻碍了它们在不同城市和语言之间的适应性和可重用性（想象一下，必须为我们所使用的 50 多种语言雇用手动测试人员或移动工程师！），这使得我们真的很难有效地扩展测试并确保 Uber 在全球范围内高质量运营。&lt;/p&gt;&lt;p&gt;为了解决这些问题，我们创建了 DragonCrawl，这是一个使用大型语言模型（LLM）以人类直觉执行移动测试的系统。它根据看到的屏幕决定采取什么操作，并独立适应用户界面的变化，就像真人一样。&lt;/p&gt;&lt;p&gt;当然，新的创新也会带来新的错误、挑战和挫折，但这是值得的。我们没有放弃为 Uber 应用带来无代码测试的使命，并于 2023 年底推出了 DragonCrawl。从那时起，我们一直在不同的城市和语言中以高稳定性测试一些最重要的流程，并且无需维护它们。在 DragonCrawl 的帮助下，在如此多的语言和城市中扩展移动测试并确保质量从人类不可能变为可能。自推出 DragonCrawl 以来的三个月内，我们阻止了十个影响客户的高优先级错误，同时节省了数千个开发人员时间并降低了测试维护成本。&lt;/p&gt;&lt;p&gt;本博客将快速介绍大型语言模型，深入探讨我们的架构、挑战和结果。最后我们将简单介绍一下 DragonCrawl 的内容。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-what-are-large-language-models"&gt;&lt;strong&gt;什么是大型语言模型？&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;大语言模型 (LLM) 是人工智能领域的变革性发展，特别是在自然语言处理 (NLP) 领域。从本质上讲，法学硕士是先进的模型，旨在以有意义且与上下文相关的方式理解、解释、生成和参与人类语言。这些模型在由各种来源的文本组成的庞大数据集上进行训练，使它们能够学习自然语言的细微差别、习语和语法。法学硕士最关键的方面之一是它们能够根据输入提示生成连贯且上下文相关的文本。此功能不仅限于简单的文本生成；它扩展到复杂的任务，如回答问题、翻译语言、总结文档，甚至创建诗歌或代码等内容。法学硕士的底层技术通常涉及神经网络架构，例如 Transformer，它们擅长处理顺序数据，并且可以捕获文本中的远程依赖关系。这使得它们对于需要理解较长文本的上下文的任务特别有效。现代大型语言模型是在多种语言上进行训练的，这意味着我们可以使用它们并在其他语言中获得合理的输出。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-did-we-choose-large-language-models-for-mobile-testing"&gt; &lt;strong&gt;为什么我们选择大型语言模型进行移动测试？&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;我们意识到我们可以将移动测试制定为语言生成问题。归根结底，移动测试是一系列步骤，可能会因应用程序、设备等的变化而遇到障碍和/或路线修正。为了成功克服这些障碍并完成测试，我们需要背景和目标，我们将这些提供给自动化系统的最简单方法是通过自然语言。我们向 DragonCrawl 提供当前屏幕的文本表示，以及我们想要执行的测试的目标，然后我们询问它应该做什么。在给定上下文的情况下，它会选择要与之交互的 UI 元素以及如何与之交互。由于这些模型已经过预先训练，并且在英语以外的语言中被证明具有弹性，因此我们可以使用其他语言的文本向 DragonCrawl 询问这些问题。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1086897" height="325" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/juan_blog-1-1024x325.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：DragonCrawl 的高级概述。龙的图像由OpenAI的DALL·E生成&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-modeling"&gt;&lt;strong&gt;造型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;MPNet，即“语言理解的掩蔽和排列预训练”，是自然语言处理中的一种先进方法，它结合了预训练语言模型中的掩蔽和排列策略。它的工作原理是屏蔽某些单词并改变输入文本中其他单词的顺序，使模型不仅能够学习屏蔽单词的预测，还能学习更广泛的上下文和语言语法。这种双任务方法使 MPNet 能够更深入地理解语言语义，超越了仅专注于掩蔽或排列的传统模型。一旦在大型数据集上进行了训练，MPNet 就可以针对各种 NLP 任务进行微调，由于其对单词级和句子级上下文的全面掌握，从而在理解和生成语言方面提供增强的性能。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/GXXjoxKzdTjJWERTI0nBZMaQVMb4hnarA5_B-c4XoK_GjBwkPn2VeKaM39v62RRcbik-3erep9vkXF8we1npSfj6PK3GxtTGhLRzbfFNtzYe6dpY_g1294hlsgzoLhtTPK1NpSQy2w3ca6BGYbPBpPw" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：DragonCrawl 模型中的 Transformer 层。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-evaluation"&gt;&lt;strong&gt;评估&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;在广阔而复杂的语言景观中，单词不仅仅是一串字母；而是一串字母。它们富含意义、上下文和微妙的细微差别，这就是嵌入发挥作用的地方。嵌入就像多维地图，其中每个单词都找到其独特的位置，不仅基于其自身的身份，还基于与其周围单词的关系。通过获得高质量的嵌入，我们确保我们的模型不会将语言视为单词的随机分类，而是将其视为连贯且相互关联的思想和含义结构。&lt;/p&gt;&lt;p&gt;我们将评估定义为检索任务，因为我们最终希望 DragonCrawl 模仿人类检索信​​息和做出决策的方式。就像我们在图书馆选择正确的书籍时付出一些努力一样，DragonCrawl 努力选择正确的行动来实现其目标。 Precision@N 指标类似于当您只能带几本书回家时找到合适的书，它向我们展示了该模型不仅能够检索，而且能够在众多可能性中找出最佳选择。通过 precision@N 测量和提高嵌入质量，我们确保 DragonCrawl 不仅能够理解语言，而且能够以近乎人类般的洞察力来理解语言。&lt;/p&gt;&lt;p&gt;为了为 DragonCrawl 选择正确的模型，我们调整并评估了多个模型。下表总结了我们的发现：&lt;br /&gt;&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;精度@1&lt;/td&gt;&lt;td&gt;精度@2&lt;/td&gt;&lt;td&gt;精度@3&lt;/td&gt;&lt;td&gt;参数&lt;/td&gt;&lt;td&gt;嵌入尺寸&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;MPNet（基础）&lt;/td&gt;&lt;td&gt; 0.9723&lt;/td&gt;&lt;td&gt; 0.9623&lt;/td&gt;&lt;td&gt; 0.9423&lt;/td&gt;&lt;td&gt; 110M&lt;/td&gt;&lt;td&gt;第768章&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;MPNet（大）&lt;/td&gt;&lt;td&gt; 0.9726&lt;/td&gt;&lt;td&gt; 0.9527&lt;/td&gt;&lt;td&gt; 0.9441&lt;/td&gt;&lt;td&gt; 340M&lt;/td&gt;&lt;td&gt;第768章&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;T5&lt;/td&gt;&lt;td&gt; 0.97&lt;/td&gt;&lt;td&gt; 0.9547&lt;/td&gt;&lt;td&gt; 0.9338&lt;/td&gt;&lt;td&gt; 11B&lt;/td&gt;&lt;td&gt; 3584&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;罗伯塔&lt;/td&gt;&lt;td&gt;0.9689&lt;/td&gt;&lt;td&gt; 0.9512&lt;/td&gt;&lt;td&gt; 0.9464&lt;/td&gt;&lt;td&gt; 82M&lt;/td&gt;&lt;td&gt;第768章&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;T5（未调）&lt;/td&gt;&lt;td&gt; 0.9231&lt;/td&gt;&lt;td&gt; 0.9213&lt;/td&gt;&lt;td&gt; 0.9213&lt;/td&gt;&lt;td&gt; 11B&lt;/td&gt;&lt;td&gt; 3584&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;br /&gt;可以看出，所有模型的嵌入质量都很高，但延迟差异很大。最快的模型是基础 MPNet，具有约 110M 参数（从技术上讲，这使其成为中小型语言模型）。此外，它的嵌入大小为 768 维，这将使其他下游系统将来使用我们的嵌入的成本更低。&lt;/p&gt;&lt;p&gt;另一方面，考虑到这些数字，人们可能会说我们甚至不需要调整，但这不是我们选择的。未调整的 T5-11b 为我们提供了良好的精度@1、2 和 3，但考虑到我们计划使用该模型的频率，以及由于 Uber 应用程序不断变化而导致的数据变化，我们很快就会遭受这些额外的影响积分不是由非我们定制的模型提供的。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-challenges"&gt;&lt;strong&gt;挑战&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;在开发过程中我们需要克服一些挑战。其中一些是 Uber 特有的，还有一些与大型语言模型的弱点有关。&lt;/p&gt;&lt;p&gt;我们在提出 DragonCrawl 的请求和完成行程流程时早期遇到的一个问题是设置 DragonCrawl 的（假）乘客和司机的 GPS 位置。 Uber 的匹配算法负责将乘客与司机联系起来，非常复杂，并且是为规模化而构建的，甚至考虑了一天中的时间、当前交通状况、未来需求等变量。但是，在使用 DragonCrawl 进行测试时，在任何给定时间，特定城市只会有 1 名乘客和 1 名司机，这不是 Uber 后端所期望的。因此，有时即使乘客和司机紧邻，也无法匹配。为了解决这个问题，我们必须调整骑手和司机的 GPS 位置，这样才能得到满意的结果。这是针对优步和/或网约车和食品配送的。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-adversarial-cases"&gt;&lt;strong&gt;对抗性案件&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;在测试 Uber 的出行流程时，在一些城市，我们看到 DragonCrawl 做了一些奇怪的事情。在一些城市，它不再要求定期出行，而是要求定期出行。最让我们困惑的是，在仔细调试我们的工件后，DragonCrawl 实际上具备做出正确选择的所有条件（即触摸“选择 UberX”），但相反，它会选择预定的行程。然后，它将通过用户界面打开日历并选择预定行程的日期和时间，这令人印象深刻，但我们离题了。&lt;/p&gt;&lt;p&gt;上面的例子称为对抗性案例。对抗性案例或对抗性样本的概念在几年前得到了普及，当时研究人员发现，在根本不应该混淆的情况下，模型有可能会被混淆。让我们看一下下面的图片。在下图中，我们展示了如果我们在熊猫图像中添加一点噪声（这会产生几乎相同的熊猫），我们会如何混淆机器学习模型，以至于它会认为它是这样的是一只长臂猿（但我们都知道熊猫看起来不像长臂猿）。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/xY5iJU7vEjDJEkoUq7KFH4QIEIm9n1ZMqAhHMeBFwh35nF-jMcz2FYbRRqvoMyWoQyQDsWbMqA7-6IlIcN-LApmJMB2W_HIuXrDCV27xpLZn6BGj3XePo29RGs1jVDXEPEwxzdByEgrbNzUlcXuZiPk" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：难以察觉的噪声如何欺骗机器学习模型的示例。这不是一个假设的例子， &lt;a href="https://www.technologyreview.com/2019/05/19/135299/how-we-might-protect-ourselves-from-malicious-ai/" rel="noreferrer noopener" target="_blank"&gt;请看一下&lt;/a&gt;。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;虽然不可能完全消除模型在对抗性案例中的弱点，但我们计划进行对抗性训练和验证以降低风险。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-steering-dragoncrawl-to-more-optimal-paths"&gt;&lt;strong&gt;引导 DragonCrawl 走向更优化的路径&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;在我们对 Uber 行程流程的离线测试中，我们看到 DragonCrawl 总是可以请求或完成行程，但有时会花费太长时间。有时，新的弹出窗口会让 DragonCrawl 添加另一位乘客/为其他人预订行程，然后会加载几个屏幕，其中包含 DragonCrawl 必须弄清楚的选项和设置。它会弄清楚它们，但由于需要几个步骤（而不仅仅是 1 或 2 个新步骤），因此需要更长的时间。由于我们的目标是在每次 Android 代码更改时运行 DragonCrawl，因此我们无法承受那些较长的路线，因此我们必须训练 Dragon 说“不”/跳过某些事情并说“是”/确认其他事情。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-hallucinations"&gt;&lt;strong&gt;幻觉&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;最后，一个经常讨论的话题是大型语言模型中的幻觉。用 Meta 副总裁兼首席人工智能科学家 Yann LeCun 的话说，大型语言模型“有时会胡言乱语”（参见&lt;a href="https://futurism.com/the-byte/yann-lecun-large-language-models-fad" rel="noreferrer noopener" target="_blank"&gt;文章&lt;/a&gt;）。事实上，我们需要注意的是，我们不能完全信任大型语言模型，或者至少不能没有护栏。在本节中，我们将讨论我们为防止幻觉伤害 DragonCrawl 而设置的护栏。&lt;/p&gt;&lt;p&gt;首先，DragonCrawl 的最大优势之一是它使用更小的模型。我们的模型大小为 110M 个参数，比流行的 GPT-3.5/4 小大约 3 个数量级。因此，这大大降低了它可以输出的答案的可变性和复杂性。换句话说，模型大小限制了模型的无意义。&lt;/p&gt;&lt;p&gt;即便如此，我们仍然收到了一些无效的输出，以下是我们处理它们的方法：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;部分无效操作：&lt;/strong&gt;模型可能会返回某些信息不正确的响应。例如，对于可滑动的 UI 元素，它可能会返回“touch”；或者它可能会输出正确的操作和正确的位置，但会混淆 UI 元素的名称（即 request_trip_button）。对于任何一种情况，由于我们可以从模拟器中读取有效的操作、正确的 UI 元素名称等，因此我们可以解决诸如前面提到的混淆。模拟器为我们提供了基本事实，我们可以使用它来根据 UI 元素的名称找到正确的操作；给定 UI 元素名称的正确位置；甚至是正确的 UI 元素名称（给定正确的位置）。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;完全无效的操作：&lt;/strong&gt;对于完全无效的操作，我们会将之前建议的操作附加到提示中，并指出它是无效的。这将导致模型建议采取不同的操作。对于无效操作持续存在的情况，我们将回溯并重试模型中的建议。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;循环/重复操作：&lt;/strong&gt;我们可能会陷入循环（即在提要中上下滚动）或重复操作（即重复等待）。我们通过跟踪特定序列中已采取的操作甚至屏幕截图来处理这种情况，因此很容易判断我们是否处于循环中。另外，由于 DragonCrawl 输出建议列表，我们可以尝试其他建议的操作。 &lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity is-style-default" /&gt;&lt;h2 class="wp-block-heading" id="h-dragoncrawl-in-action"&gt;龙爬行在行动&lt;/h2&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/Jwm8lAVWCTAaQWhF_TMwOPa1NghHQJybRrqTWTrc5_HgHErdHudy8fRP4KlCzvokvruiQvBUHMsadMaO7cwumQQwvf3jCNm18TWnAtOo6jqC9r-AcoFJAwHuUiEltRSurmepasnaGAgkYeFIcbo333o" style="width: 273px; height: auto;" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们已经看到 DragonCrawl 做了令人惊奇的事情，但在本节中，我们将讨论两个给我们留下深刻印象的场景。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-dragoncrawl-goes-online-in-australia"&gt; &lt;strong&gt;DragonCrawl在澳大利亚上线！&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt; 2023 年 10 月，我们在澳大利亚布里斯班通过 DragonCrawl 测试 Uber 的出行流程，并看到了一些意想不到的情况。 DragonCrawl 的假司机资料设置得很完美，但这一次，它在大约 5 分钟内无法上线。在那5分钟里，DragonCrawl反复按下“GO”上线按钮，直到最终上线。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1086898" height="576" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/juan_blog-4-1024x576.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图4：DragonCrawl在澳大利亚布里斯班尝试5分钟后上线。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们感到惊喜。 DragonCrawl 是如此以目标为导向，以至于它经历了不友好的用户体验来实现其目标：上网、匹配（假）骑手并进行假设的旅行。由于完成时间有限，我们知道我们必须进行调查。我们还了解到，正如下面详细讨论的那样，DragonCrawl 不会因微小或不可重现的错误而失败，例如影响我们基于脚本的 QA 的错误。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-the-ultimate-solution-turn-it-off-and-then-turn-it-back-on"&gt;&lt;strong&gt;最终解决方案：将其关闭，然后重新打开&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;那是2023年9月，我们看到龙做了如此聪明的事情，我们不知道该笑还是该鼓掌。 Dragon 正在巴黎测试 Uber 的出行流程。它选择前往巴黎机场（CDG），当它到达屏幕选择付款方式时，付款方式未加载（很可能是我们使用的帐户中出现了问题）。龙做了什么？它关闭了应用程序，打开它，然后再次请求行程。第二次没有任何问题，龙完成了去机场的目的。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1086900" height="576" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/juan_blog-5-1024x576.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：DragonCrawl 重新启动应用程序以请求行程。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;很难用言语表达看到 DragonCrawl 做这些事情我们是多么兴奋和自豪。反复按下“上线”按钮只是为了能够使用 Uber 开车，或者打开和关闭应用程序以便它能够到达它想要的位置，这使得 DragonCrawl 比我们旧的基于脚本的测试模型更能适应较小的技术问题。&lt;/p&gt;&lt;p&gt;我们观察到，再多的代码也无法与 DragonCrawl 所展示的面向目标的行为相媲美，而它所代表的开发人员生产力是令人兴奋的。可以创建符合 DragonCrawl 策略的脚本，但是需要编写多少数千（甚至数百万）行代码？在需要时更新所有这些代码的成本有多高？现在，想象一下当传统测试遇到我们刚才描述的场景时会发生什么：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;正常运行的驾驶员帐户在 5 分钟内无法上线：&lt;/strong&gt;如果测试团队没有发出警报，这将引起人们的注意。我们甚至可能认为出现了中断，这会提醒多个工程师，但实际上，这是一个暂时的问题。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;付款方式未加载：&lt;/strong&gt;票证将被归档并处于最高优先级。这将引发多次对话、检查，并且会尝试重现该问题，但这只是昙花一现。 &lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-dragoncrawl-running-on-uber-s-ci"&gt; &lt;strong&gt;DragonCrawl 运行在 Uber 的 CI 上&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;我们生产了我们的模型以及自 2023 年 10 月左右开始使用该模型的 CI 管道，并在年底取得了一些成果。截至 2024 年 1 月，DragonCrawl 每晚在 5 个不同城市执行一次核心行程流程，并且在将 Rider 和 Driver Android 应用程序发布给我们的客户之前也执行这些流程。自推出以来，我们观察到以下情况：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;高稳定性：&lt;/strong&gt; DragonCrawl 在 2023 年 11 月和 12 月执行的流程稳定性超过 99%。 Dragon 失败的罕见情况是由于我们使用的第三方系统的中断，以及由于高优先级错误导致的真正中断没有其他移动测试工具检测到。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;无需维护：&lt;/strong&gt;我们不需要手动更新和/或维护 DragonCrawl。每当应用程序发生变化时，DragonCrawl 就会弄清楚如何通过这些变化来实现其目标，这与我们的软件测试人员团队不同，他们在 2023 年花费了数百个小时维护测试用例。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;高可重用性：&lt;/strong&gt;我们对 89 个顶级城市的 DragonCrawl 进行了评估，DragonCrawl 在其中 85 个城市成功请求并完成了行程。这是 Uber 首次在全球 85 个城市成功执行像请求和完成行程这样复杂的移动测试，而无需调整代码。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;设备/操作系统弹性：&lt;/strong&gt;我们在 CI 中使用 3 种不同的 Android 设备和 3 个不同的操作系统版本测试了 Uber 的行程流程，我们甚至还改变了其他参数，例如可用磁盘、CPU 等。DragonCrawl 成功请求并完成了跨区域的行程所有这些组合都无需对我们的代码或模型进行调整，这在传统的移动测试中并不总是能得到保证。调整测试以处理不同的屏幕尺寸/分辨率和其他设备细节是传统移动测试的一个众所周知的麻烦。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-what-s-next"&gt;&lt;strong&gt;下一步是什么？&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;我们在 2023 年奠定的基础为激动人心的 2024 年及以后铺平了道路。我们对较小语言模型的投资产生了具有非常高质量嵌入的基础模型，以至于它解锁了如下所示的架构： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1086902" height="576" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/juan_blog-6-1024x576.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：未来移动测试作为由 Dragon 基础模型 (DFM) 提供支持的 RAG 应用程序&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;借助 Dragon 基础模型 (DFM)，我们可以使用小型数据集（数百或数十个数据点）和 DFM 来创建 RAG（检索增强生成）应用程序，更准确地模拟人类如何与我们的应用程序交互。那些较小的数据集（带有口头目标和偏好）会告诉 DragonCrawl 要优化什么，而这就是它所需要的。 DFM 可能是一个法学硕士，但它实际上是一个奖励模型，通过采取行动来实现其目标，正如我们所看到的，其中一些行动模仿了真人会做的事情。&lt;/p&gt;&lt;p&gt;到 2024 年，我们的一大投资领域将是构建子系统，使开发人员能够将测试构建为 RAG，并获得在许多城市、语言中完美执行的好处，并且维护成本极低（甚至为零） 。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;随着生成式人工智能在过去 4-6 个月中取得的所有进步，还有更多的事情需要评估，以改进我们的模型和应用程序的质量。我们计划评估更现代的大型语言模型，以进一步提高我们模型的质量。模型质量的每一次提高都会增加我们可以测试的组合，减少用户遇到的错误，从而提高生产力，使开发人员能够构建新的体验，并为 DragonCrawl 提供更多的测试内容。这是一个随着模型质量启动并加速的飞轮，我们将为这种加速提供动力。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/DFEnnSB2E5rc241fUWUqJVypOJkESM0sMISfkqL-Qtq3B4gP212JD-Lw9AqaP0pRkzpo_RO25TyEBxG6NuJmqy4aRCq9XQ93l7zbEBZKfUUJriwCZAo-00dz56fReF7GrGD1eijSgGiFrx8j6ARmN0o" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：模型质量的飞轮。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-acknowledgments"&gt;&lt;strong&gt;致谢&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;像 DragonCrawl 这样复杂的事情，无需我们合作伙伴团队的帮助。我们非常感谢 Uber 的 CI、Mobile Foundations、Michelangelo、Mobile Release 和 Test 帐户。我们还要感谢创建&lt;a href="https://arxiv.org/abs/2004.09297"&gt;MPNet&lt;/a&gt; （我们使用的）、T5 和其他法学硕士的热情研究人员，感谢他们对该领域的贡献，并帮助其他人推进自己的领域。我们还要感谢&lt;a href="https://www.linkedin.com/in/dan-tsui-24624b6/"&gt;Daniel Tsui&lt;/a&gt;和&lt;a href="https://www.linkedin.com/in/sowjanyapuligadda/"&gt;Sowjanya Puligadda&lt;/a&gt;的领导、建议和持续支持，最后还要感谢&lt;a href="https://www.linkedin.com/in/srabontichakraborty/"&gt;Srabonti Chakraborti&lt;/a&gt;和我们的前实习生&lt;a href="https://www.linkedin.com/in/gustavonazarioperez/"&gt;Gustavo Nazario&lt;/a&gt; ，他们帮助我们将 DragonCrawl 变成了今天的样子。&lt;/p&gt;&lt;p class="has-small-font-size"&gt;封面照片归属：该图像是使用 OpenAI 的 DALL·E 生成的。&lt;/p&gt;</description><pubDate>Tue, 23 Apr 2024 05:00:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/generative-ai-for-high-quality-mobile-testing/</guid></item><item><title>【Ensuring Precision and Integrity: A Deep Dive into Uber’s Accounting Data Testing Strategies】确保准确性和完整性：深入探讨 Uber 的会计数据测试策略</title><link>https://www.uber.com/blog/accounting-data-testing-strategies/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;优步在全球不同地区经营多种业务。财务会计服务 (FAS) 平台（ &lt;a href="https://www.uber.com/en-IN/blog/ubers-finance-computation-platform/" rel="noreferrer noopener" target="_blank"&gt;详细架构&lt;/a&gt;）负责这些全球区域的财务会计，其设计遵循以下原则：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;遵守&lt;/li&gt;&lt;li&gt;可审计性&lt;/li&gt;&lt;li&gt;准确性&lt;/li&gt;&lt;li&gt;可扩展性&lt;/li&gt;&lt;li&gt;分析&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了维护这些原则，FAS 建立了强大的测试、监控和警报流程。这包括系统配置、业务会计和外部财务报告生成。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-challenges"&gt;挑战&lt;/h2&gt;&lt;p&gt;Uber 的财务会计服务平台在互联网规模上运营——每天大约 15 亿个日记账分录 (JE)，每天通过 ETL 和数据处理处理 1.2 亿笔交易，吞吐量为每秒 2,500 次查询（平均）。标准的现成会计系统无法支持我们不断发展的平台的交易规模和范围。此外，我们还出于会计目的管理来自超过 25 种不同服务的数据。为了处理这种规模的数据，我们的工程系统被设计为在事件级别和批处理模式下处理数据。当数据流经架构中的多个组件时，需要确保所有组件的设计都遵循上述定义的原则。&lt;/p&gt;&lt;p&gt;到 2023 年，该平台处理的年度预订和结算总额约为 120 亿美元以上。其交易规模（每年约 800 亿笔金融微交易）是旅行规模的 10 倍，目前提供 99.6% 的交易，并通过自动收入计算99.99% 的完整性、准确性保证和可审核性。我们进行了 600 多项业务变更，以支持 2023 年的业务扩展。该平台处理大数据并在 Schemaless 和 Apache Hive &lt;sup&gt;TM&lt;/sup&gt;中存储 PB 级数据。&lt;/p&gt;&lt;p&gt;会计流程有多个步骤，每个步骤都需要进行验证以遵守原则。以下是执行验证的各个步骤：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;业务需求验证&lt;/li&gt;&lt;li&gt;会计入职&lt;/li&gt;&lt;li&gt;会计执行&lt;/li&gt;&lt;li&gt;报告生成&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为了坚持我们既定的原则，我们在财务会计服务的各个阶段实施制衡：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;需求签核&lt;/li&gt;&lt;li&gt;回归测试&lt;/li&gt;&lt;li&gt;集成测试&lt;/li&gt;&lt;li&gt;UAT 验证&lt;ul&gt;&lt;li&gt;账本验证&lt;/li&gt;&lt;li&gt;交易级验证&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;影子验证&lt;/li&gt;&lt;li&gt;部署&lt;ul&gt;&lt;li&gt;金丝雀&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;健康检查&lt;ul&gt;&lt;li&gt;审核员检查&lt;/li&gt;&lt;li&gt;完整性检查&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;警报/监控&lt;/li&gt;&lt;li&gt;报告生成&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-validations-life-cycle-of-accounting-processes-nbsp"&gt;会计流程的验证生命周期&lt;/h2&gt;&lt;p&gt;当数据流经金融科技系统的各个组件时，每个阶段都会进行制衡，以便系统和流程遵守原则。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-requirements-signoff"&gt;需求签核&lt;/h3&gt;&lt;p&gt;根据在不同国家/地区运营的业务模式和当地团队的期望，提供并跟踪需求。会计要求是根据&lt;a href="https://en.wikipedia.org/wiki/Generally_Accepted_Accounting_Principles_(United_States)"&gt;公认会计原则 (GAAP)&lt;/a&gt;提供的。然后将这些要求纳入我们的会计系统。 Uber 的金融科技系统拥有验证需求的内部工具，可以执行超过 15 项自动检查来验证预期输出。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-regression-testing"&gt;回归测试&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-unit-testing"&gt;单元测试&lt;/h3&gt;&lt;p&gt;Uber 金融服务中的单元测试对于确保我们应用程序的准确性、安全性和可靠性至关重要。这些测试涉及隔离小部分代码并按预期验证功能。在优步，我们努力通过严格测试每个单元的正确运行来尽早发现并纠正错误，并确保从交易处理到财务报告的整体服务平稳、安全地运行。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-regression-kaptres"&gt;回归——Kaptres&lt;/h3&gt;&lt;p&gt; Kaptre（Capt &lt;s&gt;ure&lt;/s&gt; — Re &lt;s&gt;play&lt;/s&gt; ）是一种捕获和重放测试工具，主要用于功能和回归测试目的。以下是我们的金融系统如何使用其关键组件的详细说明：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;测试用例：&lt;/strong&gt;对于任何会计变更，至少一个新的 Kaptre 测试会添加到测试套件中，以便在连续运行中测试所有用例。每个测试用例包括输入（与 UAT 使用的相同）、期望和断言。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;捕获模式：&lt;/strong&gt;添加测试时，我们在“捕获模式”下运行。此模式执行新添加的测试的记账流程，并捕获在离线模式下重新执行所需的依赖项，例如来自上游的 API 请求/响应和预期的记账日记条目 (JElines)。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重播模式：&lt;/strong&gt;后续测试运行涉及在重播模式下运行 Kaptre 回归测试套件。此模式使用最新的代码/配置版本创建新的输出，并且断言将它们与捕获的期望进行比较。如果断言失败，则会报告测试失败。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;捕获的响应的更改触发器：&lt;/strong&gt;捕获的响应会随着上游系统的更改、金融交易中新字段的添加或预期的会计更改而发生变化。验证后可以使用上述捕获模式更新这些测试。&lt;/p&gt;&lt;p&gt;这种方法确保回归测试准确反映捕获模式期间系统的行为，并随后在连续测试运行中对照预期结果进行验证。该设计可以适应上游、金融科技系统的变化和预期的会计修改，同时保持测试过程的完整性并降低测试过程中人为错误的风险。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/KFCn1YyYUZwB8_9hTsWv-M6EyBi-1rlFZuv3vnhyQmXFA2bLDQZ-7EIdWZuU_qteUyF9UBev3u0bJVNoKnQoroZrPcjFFPOcJI_RqNGDs7bIwDInlnZ3_R_CiCFKtbH0RcUwzsceuy9H4mTXpoWwY-Q" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：Kaptre（捕获重放框架的功能）。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-slate-short-lived-application-testing-environment-nbsp"&gt; SLATE（短期应用程序测试环境）&lt;/h3&gt;&lt;p&gt;在部署到生产环境之前在短期应用程序环境（又名 SLATE）中进行测试是 Uber 软件开发生命周期中的关键一步。 SLATE 测试帮助我们及早发现和解决问题，并降低将缺陷/问题引入生产环境的风险。在 SLATE 中执行各种类型的测试，包括集成、性能和安全测试。此测试的主要目的是在类似生产的环境中运行应用程序，在开发周期的早期识别和检测问题（例如运行时错误），并防止缺陷传播到更高的环境。&lt;/p&gt;&lt;p&gt;在&lt;a href="https://www.uber.com/en-IN/blog/simplifying-developer-testing-through-slate/" rel="noreferrer noopener" target="_blank"&gt;Slate Uber Eng 博客&lt;/a&gt;中查找更多详细信息。&lt;/p&gt;&lt;p&gt;总之，在短期应用程序环境中进行测试是一种最佳实践，有助于在将服务部署到生产之前提高服务的整体质量、可靠性和安全性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-integration-testing-nbsp"&gt;集成测试&lt;/h2&gt;&lt;p&gt;Uber 的财务会计服务与众多上游系统（30 多个）合作，以丰富生成会计交易所必需的行程详细信息。集成测试对于金融系统和上游组件之间的无缝通信、识别接口问题并实现早期风险缓解至关重要。&lt;/p&gt;&lt;p&gt;然而，集成测试的一个显着挑战在于确定完整性。与具有明确的代码覆盖率指标的单元测试不同，集成测试缺乏对要覆盖的场景的洞察，并且没有用于衡量集成测试覆盖率的既定指标。这种差距导致依赖团队无法自动获知正在启动的新场景，并且缺乏理解所有场景的测试覆盖率的指标。&lt;/p&gt;&lt;p&gt;为了解决这个问题，我们开发了一个内部工具，可以自动检测、通知和确认所有依赖系统的就绪情况。该工具旨在确保无缺陷启动，并提供衡量集成测试覆盖率的机制。&lt;/p&gt;&lt;p&gt;这在收入系统中变得尤为重要，该系统位于数据流的终点并与多个服务交互。在这种情况下，意外的启动可能会造成会计流程中断的风险。例如，票价发布如果缺乏适当的沟通，可能会被路由到死信队列 (DLQ)，从而由于收入系统中的入职不足而导致会计不正确。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-uat-validations"&gt; UAT 验证&lt;/h2&gt;&lt;p&gt;用户验收测试 (UAT) 是 Uber 财务系统开发中的强制性步骤，会计团队严格验证财务报告的准确性。我们通过涵盖积极和消极场景的自动化测试对聚合和交易级分类账进行全面验证，从而简化了这一流程。这确保了资产负债表、损益表和其他关键财务报表的完整性。这种细致的方法可确保更新和补丁的无缝集成，而不会破坏现有功能，并在签收前进行超过 15 项质量检查。&lt;/p&gt;&lt;p&gt;根据要求设置会计配置后，会计团队就会对其进行验证，最终得到正式签字，表明批准并证明准确性和合规性。业务规则配置更改遵循严格的协议，在合并到主系统之前需要获得主要会计利益相关者的明确授权。 Uber 利用自动化的 Buildkite 作业来确保完整性和效率，并在发现代码库差异时系统地检查必要的批准。这种自动化增强了审批流程的严格性。&lt;/p&gt;&lt;p&gt;如果更改与既定协议相矛盾或绕过强制批准，则会立即提出自动标记以进行彻底审查。这种保护措施对于维护系统的完整性和合规性至关重要。&lt;/p&gt;&lt;p&gt; Uber 的财务系统采用两种主要类型的验证来确保最大的准确性和可靠性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;示例验证&lt;/li&gt;&lt;li&gt;账本验证&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-sample-validations"&gt;示例验证&lt;/h3&gt;&lt;p&gt;对选定的一组样本订单执行验证，这些样本订单被选择来代表生产环境中的订单场景。在对金融系统进行增量改变时，这些验证通常是足够的。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large is-resized"&gt;&lt;img alt="" class="wp-image-1086095" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Screenshot-2024-04-12-at-2.17.10%E2%80%AFPM-1024x185.png" style="width: 747px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;表 1：交易级别验证/示例验证。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-ledger-validations"&gt;账本验证&lt;/h3&gt;&lt;p&gt;对于在国家或业务层面影响大量用例的变更，我们还执行账本验证以获得完整性保证。在我们在生产中实施这些变更之前，这些验证在特定时间内在总体水平上提供了额外的保证。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1086096" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Screenshot-2024-04-12-at-2.17.42%E2%80%AFPM-1024x375.png" /&gt;&lt;figcaption class="wp-element-caption"&gt;表 2：总账验证。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;这两种验证类型都是 Uber 致力于维持财务准确性和监管合规性最高标准的承诺的组成部分。他们协同工作，确保财务体系保持稳健、可靠，并反映公司的真实财务状况。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-shadow-validations"&gt;影子验证&lt;/h3&gt;&lt;p&gt;影子测试的目的是作为最终检查点，以在将构建转移到生产环境之前捕获任何潜在问题。它本质上是一种构建认证策略，有助于做出有关部署候选版本 (RC) 的明智决策。核心流程包括通过 RC 传递生产流量，并将其输出与当前生产版本的输出进行比较，以发现任何异常情况。&lt;/p&gt;&lt;p&gt;影子测试由三部分组成：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;捕获生产请求&lt;/strong&gt;：有多种策略可以实现这一目标。其中之一需要记录生产流量中的（请求、响应）对，以便与 RC 进行比较。&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;重放生产流量&lt;/strong&gt;：这些捕获的请求在 RC 上重放，并将响应与生产环境中的响应进行比较。记录任何差异以供进一步分析。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;分析差异&lt;/strong&gt;：包括对记录的差异进行彻底检查，以确定 RC 的置信水平。此步骤对于验证构建是否已准备好部署至关重要。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1086099" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Screenshot-2024-04-12-at-2.18.00%E2%80%AFPM-1024x455.png" /&gt;&lt;figcaption class="wp-element-caption"&gt;表 3：预生产环境和生产环境之间的影子验证。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-challenges-and-solutions"&gt;挑战与解决方案&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;流量和上游调用&lt;/strong&gt;：由于金融科技服务每秒处理超过 10K+ 事件，根据影子构建重放所有这些流量是不切实际的，并且可能会因大量上游调用而导致速率限制问题。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;流量采样和负载分配&lt;/strong&gt;：为了缓解这一问题，我们采用了对一小部分流量（例如 10%）进行采样并在较长时间段（例如 5 小时）内分发重放的策略。这减少了每秒的调用次数，但也限制了测试范围。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了解决这个问题，我们缓存上游调用和响应，而不是进行实时网络调用。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;缓存上游调用&lt;/strong&gt;：我们为上游（请求、响应）对实现了缓存机制，以避免重放期间的冗余调用，但代价是增加了存储费用。我们通过在旧数据被清理后保持 x 天的保留期来最大限度地减少增加的存储成本。我们总是根据最新的数据集进行回放。&lt;/li&gt;&lt;li&gt;这种方法缺乏检测由上游变化引起的实时问题的能力。为了缓解这个问题，我们正在开发一种对流量和负载分配进行采样的机制。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/laVFJXmguJ5XutZD365Hu3SdXUMpGvotZ8HUAA4_OWYtYVcItW3zl7eJoF33tD9jVk1WuvBWkDlP4rQVZnPl75wcf_6mvIqg_Rq_fBR2FJg9hrFbCT-sTPkC1nG6KyTrlSRG-acIn4mPrBWU3OrsuFM" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：采样和存储用于影子测试的事件。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-replaying-captured-requests"&gt;重放捕获的请求&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;我们开发了专门的工作流程，用于针对 RC 重放给定时间戳范围内的存储请求。记录存储的响应和 RC 响应之间的差异以供分析。&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-validating-and-analyzing-differences"&gt;验证和分析差异&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;此阶段涉及仔细检查已发现的差异。目的是区分预期差异和异常。这需要深入了解Banker系统的响应结构。&lt;/li&gt;&lt;li&gt;银行家的响应结构：银行家的输出是一系列称为“交易”的复杂数据类型，每个数据类型代表具有贷方、借方、总账帐户和业务范围等属性的多个日记帐分录。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="" class="wp-image-1086101" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Screenshot-2024-04-12-at-2.18.19%E2%80%AFPM-1024x459.png" /&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;对建设的信心是通过货币差异偏离预定阈值的程度来衡量的。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-example-scenario-and-analysis"&gt;示例场景和分析&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;事务比较：&lt;/strong&gt;比较主构建和影子构建的事务。差异记录在数据存储中。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;数据存储属性：&lt;/strong&gt;记录的数据包括事务、其源（主/影子）、重播工作流的 RunID 和时间戳。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;详细分析：&lt;/strong&gt;我们针对 LineOfBusiness 和 GlAccountNumber 等特定领域的异常情况进行分析，使用查询来识别货币差异。根据这些发现调整构建信心。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;例如，考虑 E1 是我们针对生产和发布候选者处理的事件。 TxnP 是我们从 Production 实例获得的交易，TxnS 是我们从 Release Candidate 获得的交易： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="" class="wp-image-1086104" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Screenshot-2024-04-12-at-2.18.29%E2%80%AFPM-1024x205.png" /&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; TxnP 和 TxnS 在 LineOfBusiness 中的差异。因此，我们会将它们记录到数据存储中进行分析。我们的数据存储将包含四个属性：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;交易 -&amp;gt; 交易数组。&lt;/li&gt;&lt;li&gt;源 -&amp;gt; 主要/阴影。 （即）如果交易来自生产或影子构建。&lt;/li&gt;&lt;li&gt; RunID -&amp;gt; 重播工作流的 RunID。由于我们可以使用不同的构建运行多个影子测试工作流程，因此我们应该确保仅分析特定工作流程的差异。&lt;/li&gt;&lt;li&gt;时间戳。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;重放 E1 后，我们的数据存储将包含以下两条新记录：&lt;/p&gt;&lt;ol&gt;&lt;li&gt; （TxnP、主要、运行 ID、当前时间戳）&lt;/li&gt;&lt;li&gt; （TxnS、Shadow、runID、当前时间戳）&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我们可以通过多种方式来分析这些差异。对于我们的用例，我们最感兴趣的是捕获 LineOfBusiness 和 GlAccountNumer 中的任何异常情况。因此，我们编写了查询来识别这些 LOB 和 GlAccountNumber 维度上的生产候选者和发布候选者之间的货币差异。如果贷方或借方的货币差异超过一定阈值，我们将降低构建的置信度。偏离阈值越远，构建的置信度就越低。&lt;/p&gt;&lt;p&gt;对于上面的示例，LOB 差异的影子测试报告将如下所示： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="" class="wp-image-1086105" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Screenshot-2024-04-12-at-3.07.22%E2%80%AFPM-1024x166.png" /&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;假设我们为每个业务线定义了 1,000 美元的门槛。在这种情况下，100 的差异仍然远低于阈值，因此我们构建的置信度不会受到影响。&lt;/p&gt;&lt;p&gt;通过采用这种影子测试策略，您可以确保对候选版本进行全面彻底的评估。这种有条不紊的方法不仅可以识别潜在问题，还可以提供改进未来构建所需的见解，最终有助于部署过程的稳健性和可靠性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/lWpk884yU_92bIFwEr29JfVH_HZpEPd6pXf2XMJl1hg42l9JLX39RzczjifWlo9nAjQRFFd9eu54LZgKKOvBigmIohSreFIAK_bTaHqPy_tFpgtQfVpXkS4B256K2gDy_sdQ3BSbP2DHwmAuvKEpAcY" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：影子测试工作流程。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-deployment-nbsp"&gt;部署&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-canary-testing-nbsp"&gt;金丝雀测试&lt;/h3&gt;&lt;p&gt;在 Uber 的财务会计服务中，每天都会部署构建。为了确保每个构建的成功部署并最大限度地减少性能下降、错误率增加和资源耗尽等问题的影响，合并金丝雀部署至关重要。该策略有助于控制释放，防止对整个流量产生直接影响。它可以在完成部署之前识别并解决潜在问题。&lt;/p&gt;&lt;p&gt;采用金丝雀发布方法来测试真实流量（&amp;lt;=2% 流量），影响最小。当新版本准备好部署时，金丝雀区域将作为初始部署目标。如果在此部署期间出现任何错误或问题，构建不会传播到其他生产区域，从而防止大范围中断并确保更受控的发布过程。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-deployment-monitoring-and-alerting"&gt;部署监控和警报&lt;/h3&gt;&lt;p&gt;财务会计服务平台消耗来自各种上游来源的数据。为了监控服务的运行状况，我们配置了多个指标和警报。跟踪指标并配置警报以暂停部署管道，如果我们在部署一段指定时间后收到警报，则将其回滚。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-dead-letter-queues"&gt;死信队列&lt;/h4&gt;&lt;p&gt;DLQ（死信队列）存储由于错误而未处理的事件。 DLQ 计数升高表明存在错误代码、损坏事件、上游服务问题或速率限制等问题。每个消息队列都有一个对应的DLQ，用于处理无法处理的事件。理想情况下，DLQ 必须有零个事件。我们使用基于阈值的警报来检测问题并在警报触发时调查根本原因。我们将所有错误（包括事件详细信息）记录到专用的 Apache Kafka &lt;sup&gt;Ⓡ&lt;/sup&gt;主题，并将它们提取到 Apache Hive &lt;sup&gt;TM&lt;/sup&gt;表中。我们配置了 Data Studio 仪表板来监控 Apache Hive &lt;sup&gt;TM&lt;/sup&gt;表，提供有关 DLQ 事件的影响、计数、新鲜度和趋势的见解。这种数据驱动的方法有助于快速识别问题并确定问题的优先级，以进行根本原因分析和系统改进。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-alerts-and-monitors"&gt;警报和监视器&lt;/h4&gt;&lt;p&gt;警报主要用于标记需要立即查看的紧急和关键问题。监视器是配置警报的仪表板。警报应该始终是可操作的。还建议使用相应的操作手册标记每个警报。&lt;/p&gt;&lt;p&gt;仅我们团队就配置了大约 400 多个警报，涵盖广泛的维度，包括但不限于 DLQ 计数、消息队列的消费者滞后、服务可用性等。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-completeness-checks"&gt;完整性检查&lt;/h4&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/TD2qCI_24RcKTtUAX12d2re1uJHo_00oLC6ItT3kfSvQFwEVGW4P20F71vlxJ_R4GkRxQrkNq7c9sRqGBx18KCfe_FDmGplL4j36asRsFeR8V1MaeKjFRX5zYV6Hx54BT7COj16ZgQI0AxNQh-xGfOA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：完整性检查&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;金融服务收到的所有事件都需要考虑在内。当我们的服务收到事件时，它会记录在接收记录器中。处理事件的自然结果是以下之一&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;事件已处理&lt;/strong&gt;- 记录在事实表中&lt;/li&gt;&lt;li&gt;&lt;strong&gt;过滤或忽略的事件&lt;/strong&gt;– 记录在过滤记录器中&lt;/li&gt;&lt;li&gt;&lt;strong&gt;事件处理出错&lt;/strong&gt;– 记录在错误记录器中&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了确保所有传入事件都得到考虑，我们执行完整性检查。这些检查确认接收记录器中记录的所有事件也记录在错误记录器、过滤器记录器或事实表中（指示成功处理）。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-results"&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;利用上述测试和检测策略，我们的团队在 2023 年实现了一个非凡的里程碑：将会计事件数量减少到零。这一重大成就反映了我们对财务管理准确性和效率的致力于。此外，手工日记账分录显着减少，这是会计错误减少的直接结果。这一改进不仅使每月会计账簿能够及时关闭，而且还增强了我们在会计领域管理多个项目的信心，吞吐量提高了 17%。这些进步体现了我们对会计实践卓越性和可靠性的承诺。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;总之，事实证明，Uber 财务会计服务 (FAS) 采用的全面、多方面的金融科技测试策略取得了巨大成功。通过每一步严格的验证流程（从业务需求验证到报告生成），并采用回归测试、SLATE、集成测试和影子验证等先进技术，Uber 为财务系统的可靠性和准确性设立了新标准。&lt;/p&gt;&lt;p&gt;创新的解决方案解决了处理大量交易和数据的挑战，这些解决方案不仅可以满足当前的需求，还可以扩展以适应未来的增长。细致的测试和验证方法，加上金丝雀测试和警惕的监控和警报系统等部署策略，体现了 Uber 对维持金融技术最高标准的承诺。明年，我们将在测试策略中添加更多功能，以支持不良输入的检测和自动更正，以支持无错误的自助服务之旅。&lt;/p&gt;&lt;p&gt; Uber 完善其金融科技测试策略的历程为业内其他公司树立了标杆，强调了在不断发展的金融技术领域持续创新和严格测试的重要性。&lt;/p&gt;</description><pubDate>Thu, 18 Apr 2024 05:00:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/accounting-data-testing-strategies/</guid></item><item><title>【Migrating a Trillion Entries of Uber’s Ledger Data from DynamoDB to LedgerStore】将 Uber 的一万亿条账本数据从 DynamoDB 迁移到 LedgerStore</title><link>https://www.uber.com/blog/migrating-from-dynamodb-to-ledgerstore/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;上周，我们探索了&lt;a href="https://www.uber.com/blog/how-ledgerstore-supports-trillions-of-indexes/" rel="noreferrer noopener" target="_blank"&gt;LedgerStore&lt;/a&gt; (LSG)——Uber 的仅追加、分类账式数据库。本周，我们将深入探讨如何将 Uber 的关键业务账本数据迁移到 LSG。我们将详细介绍如何在不造成中断的情况下透明地移动超过一万亿个条目（构成几 PB 的数据），并且我们将讨论在迁移过程中学到的东西。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-history"&gt;历史&lt;/h3&gt;&lt;p&gt;湾流是 Uber 的支付平台。它&lt;a href="https://www.uber.com/blog/payments-platform" rel="noreferrer noopener" target="_blank"&gt;于 2017 年推出，&lt;/a&gt;使用 DynamoDB 进行存储。以 Uber 的规模，DynamoDB 变得昂贵。因此，我们开始在 DynamoDB 中仅保留 12 周的数据（即热数据），并开始使用 Uber 的 blobstore TerraBlob 来存储较旧的数据（即冷数据）。 TerraBlob 类似于 AWS S3。&lt;/p&gt;&lt;p&gt;对于长期解决方案，我们想使用&lt;a href="https://www.uber.com/blog/dynamodb-to-docstore-migration/" rel="noreferrer noopener" target="_blank"&gt;LSG&lt;/a&gt; 。它是专门为存储支付方式数据而构建的。其主要特点是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;它是可验证的不可变的（即，您可以使用加密签名检查记录是否未被更改）&lt;/li&gt;&lt;li&gt;分层存储以管理成本（热数据保存在最适合服务请求的位置，冷数据存储在针对存储优化的位置）&lt;/li&gt;&lt;li&gt;更好的延迟以实现最终一致的二级索引&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;因此，到 2021 年，湾流将使用 DynamoDB、TerraBlob 和 LSG 的组合来存储数据。&lt;/p&gt;&lt;ul&gt;&lt;li&gt; DynamoDB 过去 12 周的数据&lt;/li&gt;&lt;li&gt;TerraBlob，Uber 的内部 Blob 存储，用于存储冷数据&lt;/li&gt;&lt;li&gt;LSG，我们在其中写入数据，并希望迁移到它&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-why-migrate"&gt;为什么要迁移？&lt;/h2&gt;&lt;p&gt;由于 LSG 的不变性，它更适合存储分类帐类型的数据。迁移到 LSG 可以显着节省经常性成本。&lt;/p&gt;&lt;p&gt;从三个存储变为单个存储将简化负责与存储交互和创建索引的湾流服务的代码和设计。这反过来又使得服务的理解和维护变得容易。&lt;/p&gt;&lt;p&gt; LSG 承诺更短的索引延迟（即写入记录和创建辅助索引之间的时间）。此外，它还会给我们带来更快的网络延迟，因为它是在 Uber 数据中心内本地运行的。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/ImSq9jhPp_-uGFsvBU0tmJA1MiY42lmKUH1fLoNJ036l2w7W9uLx89xRnBO30l7lRkHXQ0XQv_flDWeZB0pfRyYzczFfayP_Vi4j217OZt8fG5WxpM2FKdt3lB34s0emy0gp6nUKNfS2q7MR5z8ZUbc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图1：迁移前后的数据流向&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-nature-of-data-amp-associated-risk"&gt;数据的性质和相关风险&lt;/h2&gt;&lt;p&gt;我们要迁移的数据是自 2017 年以来 Uber 所有业务的所有 Uber 账本数据：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;不可变记录 – 1.2 PB 压缩大小&lt;/li&gt;&lt;li&gt;二级索引 – 0.5 PB 未压缩大小&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不可变记录不应被修改。因此，出于所有实际目的，一旦我们编写了记录，就无法更改。我们确实可以灵活地修改二级索引数据来纠正问题。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="h-checks"&gt;支票&lt;/h2&gt;&lt;p&gt;为了确保回填在各个方面都是正确且可接受的，我们需要检查我们是否可以处理当前流量以及当前未访问的数据是否正确。其标准是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;完整性：所有记录均已回填。&lt;/li&gt;&lt;li&gt;正确性：所有记录均正确。&lt;/li&gt;&lt;li&gt;负载：LSG 应能够处理当前负载。&lt;/li&gt;&lt;li&gt;延迟：LSG 的 P99 延迟在可接受的范围内。&lt;/li&gt;&lt;li&gt;滞后：二级索引是在后台创建的。我们希望确保索引创建过程的延迟在可接受的范围内。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;检查是使用&lt;em&gt;影子验证&lt;/em&gt;和&lt;em&gt;离线验证&lt;/em&gt;相结合的方式完成的。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-shadow-validation"&gt;影子验证&lt;/h3&gt;&lt;p&gt;这将我们在迁移之前返回的响应与以 LSG 作为数据源返回的响应进行了比较。这有助于我们确保当前的流量不会因数据迁移问题或代码错误而中断。根据影子验证的测量，我们希望回填的完成度和正确率至少达到 99.99%。我们还设定了 99.9999% 的上限。设置上限的原因是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在迁移历史数据时，总会存在数据损坏的问题。有时这是因为在服务的初始开发期间数据写入不正确。由于规模的原因，也可能会出现数据损坏的情况。例如，S3 提供 11 个 9 的持久性保证，那么您可以预期 1 万亿条记录中会出现 10 次损坏。&lt;/li&gt;&lt;li&gt;索引最终是一致的，这意味着一些记录会在几秒钟后出现。因此，影子验证会将它们标记为丢失。这是大规模出现的误报。&lt;/li&gt;&lt;li&gt;对于 6 个 9，您必须查看 1 亿次比较的数据才能可靠地给出结果。这意味着，如果您的影子验证每秒比较 1,000 条记录，那么您需要等待一天以上才能收集足够的数据。如果有 7 个 9，则需要等待 12 天。实际上，这将导致项目陷入停滞。&lt;/li&gt;&lt;li&gt;有了明确定义的上限，您就不必被迫查看您怀疑的每个潜在问题。假设问题的出现次数是上限的 1/10，您甚至不需要调查它。&lt;/li&gt;&lt;li&gt;如果有 6 个 9，我们最终可能会得到略多于 100 万条的损坏记录。尽管确认 6 个 9 的正确性可能会给公司带来实际成本，但该项目带来的节省超过了潜在成本。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在影子验证期间，您实质上是在 LSG 上复制生产流量。因此，通过监控 LSG，我们可以验证它是否可以处理我们的生产流量，同时满足我们的延迟和滞后要求。它让我们对为访问 LSG 数据而编写的代码充满信心。此外，它还让我们对数据的完整性和正确性有一定的信心，特别是当前正在访问的数据。我们开发了一个通用影子验证代码，可以在迁移的不同部分多次重复使用。&lt;/p&gt;&lt;p&gt;在迁移过程中，我们发现了由于不同部分存在多个错误而导致的延迟和滞后问题，并修复了这些问题。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;分区键优化以更好地分布索引数据&lt;/li&gt;&lt;li&gt;索引问题导致扫描记录而不是点查找&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不幸的是，实时影子验证无法为我们很少访问的历史数据语料库提供强有力的保证。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-offline-validation-amp-incremental-backfill"&gt;离线验证和增量回填&lt;/h3&gt;&lt;p&gt;这会将来自 LSG 的完整数据与来自 DynamoDB 的数据转储进行比较。由于各种数据问题，您必须跳过不良记录以确保您的回填能够通过。此外，回填作业本身也可能存在错误。离线验证确保数据回填正确发生并且覆盖完整数据。除了影子验证之外，还必须执行此操作，因为实时流量往往只访问最近的数据。因此，如果不经常访问的冷数据中潜伏着任何问题，影子验证将无法捕获它。&lt;/p&gt;&lt;p&gt;离线验证的关键挑战是数据大小。我们处理的最大数据大小为 70 TB 压缩数据（预计未压缩数据为 300 TB），并且我们在单个作业中比较了 7600 亿条记录。这种类型的 Apache Spark &lt;sup&gt;TM&lt;/sup&gt;作业需要数据混洗，而&lt;a href="https://www.uber.com/blog/ubers-highly-scalable-and-distributed-shuffle-as-a-service/"&gt;分布式混洗即 Spark 服务&lt;/a&gt;与动态资源分配和推测执行相结合，让我们能够在资源限制下以合理的速度准确地做到这一点。&lt;/p&gt;&lt;p&gt;离线验证发现缺失记录，其输出用于增量回填。我们在离线验证和回填之间进行迭代，以确保所有记录都已写入。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-backfill-issues"&gt;回填问题&lt;/h2&gt;&lt;p&gt;每次回填都有风险。我们使用 Uber 内部提供的 Apache Spark 进行回填。以下是我们遇到的不同问题以及我们如何处理这些问题。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-scalability"&gt;可扩展性&lt;/h3&gt;&lt;p&gt;您希望从小规模开始，逐渐扩大规模，直到达到系统的极限。如果您只是盲目地超越这一点，那么您实际上就是在对自己的系统发起 DDoS 攻击。此时，您想要找到瓶颈，解决它，然后扩大您的工作规模。大多数时候，这只是扩大下游服务的问题，有时可能会更复杂。无论哪种情况，您都不希望将回填作业扩展到超出系统瓶颈的能力。最好以小增量的方式进行扩展，并在每次扩展后密切监控。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-incremental-backfills"&gt;增量回填&lt;/h3&gt;&lt;p&gt;当您尝试在 3 个月内回填 3 年的数据时，您生成的流量将是正常流量负载的 10 倍，并且系统可能无法处理此流量。例如，当您的生产通常处理 1K/秒的速率时，您将需要 120 天以 10K/秒的速率回填 100B 记录。因此，您可以预期系统会过载。即使回填作业极有可能导致持续出现问题，您也必须将其关闭。因此，期望回填作业能够一次性从开始运行到结束是不现实的，因此您必须增量运行回填。&lt;/p&gt;&lt;p&gt;一种简单而有效的方法是将回填分成小批量，可以一点一点地完成，这样每批都可以在几分钟内完成。由于您的作业可能会在批次中间关闭，因此它必须是幂等的。每次完成一个批处理时，您都希望将统计信息（例如读取的记录、回填的记录等）转储到文件中。随着回填的继续，您可以汇总其中的数字以检查进度。&lt;/p&gt;&lt;p&gt;如果您可以删除或更新现有记录，则可以降低回填期间出现错误和代码错误的风险和成本。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-rate-control"&gt;速率控制&lt;/h3&gt;&lt;p&gt;为了安全回填，您需要确保回填作业的行为一致。因此，您的作业应该具有可以轻松调整以放大或缩小的速率控制。在 Java/Scala 中，您可以使用 Guava 的 RateLimiter。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-dynamic-rate-control"&gt;动态速率控制&lt;/h3&gt;&lt;p&gt;在某些情况下，当生产流量较少时，您可能可以加快速度。为此，您需要监视系统的当前状态并查看是否可以加快速度。我们根据&lt;a href="https://en.wikipedia.org/wiki/Additive_increase/multiplicative_decrease" rel="noreferrer noopener" target="_blank"&gt;加法增加/乘法减少&lt;/a&gt;来调整 RPS。为了安全起见，我们对交通仍然有上限。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-emergency-stop"&gt;紧急停止&lt;/h3&gt;&lt;p&gt;迁移过程需要能够在出现中断甚至怀疑过载的情况下快速停止回填。停电期间的任何回填都必须停止，这既是预防措施，也是潜在的噪音源。即使在断电后，随着系统恢复，系统也往往会承受额外的负载。能够停止回填还有助于调试与规模相关的问题。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-size-of-data-file"&gt;数据文件大小&lt;/h3&gt;&lt;p&gt;转储数据时，将文件大小保持在 1GB 左右，两侧具有 10 倍的灵活性。如果文件太大，您会遇到&lt;a href="https://kb.databricks.com/cloud/s3-part-number-limit.html" rel="noreferrer noopener" target="_blank"&gt;不同工具的 MultiPart 限制&lt;/a&gt;等问题。如果您的文件很小，则说明您的文件太多，甚至列出它们也将花费大量时间。在 shell 中运行命令时，您甚至可能开始达到 ARGMAX 限制。这变得足够重要，以确保每次您对数据执行某些操作时，它都会应用于所有文件，而不仅仅是其中的一些文件。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-fault-tolerance"&gt;容错能力&lt;/h3&gt;&lt;p&gt;所有回填作业都需要某种数据转换。当您这样做时，您不可避免地会遇到数据质量/损坏问题。您不能每次发生这种情况时都停止回填作业，因为此类不良记录往往是随机分布的。但您也不能忽略它们，因为这也可能是由于代码错误造成的。为了解决这个问题，您可以单独转储有问题的记录并监视统计数据。如果失败率很高，那么您可以手动停止回填，修复问题，然后继续。否则，让回填继续并并行查看故障。&lt;/p&gt;&lt;p&gt;记录未写入的另一个原因是 RPC 超时。你可以重试，但在某些时候，你必须放弃并继续前进，无论出于什么原因，以确保你能够取得进展。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-logging"&gt;记录&lt;/h3&gt;&lt;p&gt;在回填期间记录日志以帮助调试和监控进度是很诱人的，但这可能是不可能的，因为这会给日志基础设施带来压力。即使您可以保留日志，也会有太多的日志数据需要保留。解决方案是使用速率限制器来限制您生成的日志数量。您只需对产生大部分日志的部分进行速率限制。如果错误很少发生，您甚至可以选择记录所有错误。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/xWcB-v0gyFB4920hZx1tevZiHiSLhUKPvA7TZMvkCN6bsEmh5bZiTcZ0xYumbfjsgsG6Oz-Xnl85XeLhD4ofUc07poJ1OnsB4WlNCEyZzYmY9kuvfgCkSxzC4nSvqcBEmYQvANytw4oOyXA4wyQDias" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-mitigating-risk"&gt;降低风险&lt;/h2&gt;&lt;p&gt;除了分析来自不同验证和回填统计数据的数据外，我们对 LSG 的推出也持保守态度。我们在几周内推出了它，并得到了我们服务的主要呼叫者的值班工程师的批准。我们最初推出了回退（即，如果在 LSG 中找不到数据，我们将尝试从 DynamoDB 获取数据）。在删除回退之前，我们查看了回退日志。对于回退日志中标记为丢失的每条记录，我们检查了 LSG 以确保它并未真正丢失。即使在那之后，我们仍将 DynamoDB 数据保留了一个月，然后才停止向其中写入数据、进行最终备份并删除该表。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/P7cnF5dxZX7H5rA82nfZgC1ICBQX7Q928jAexep0GBSR39-B2kDw44hHTtEQQuBNmqw9ZeFz_KYY39uqlUBSEErrb2XWhWagcpWKrsb8tiDX_6CYfOXACQst7Wak7mIewxy4WvI3gW3Vza3altpn0Tc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：LSG 推出&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;在本文中，我们介绍了将大量业务关键型货币数据从一个数据存储迁移到另一个数据存储的过程。我们涵盖了迁移的不同方面，包括迁移标准、检查、回填问题和安全性。我们能够在两年内完成此迁移，在迁移期间或迁移后没有任何停机或中断。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-acknowledgments"&gt;致谢&lt;/h3&gt;&lt;p&gt;感谢 Amit Garg 和 Youxian Chen 帮助我们将数据从 TerraBlob 迁移到 LSG。感谢 LSG 团队的 Jaydeepkumar Chovatia、Kaushik Devarajaiah 和 Rashmi Gupta 在整个工作中对我们的支持。感谢Menghan Li 为&lt;a href="https://www.uber.com/en-EG/blog/cashless-payments-with-uber-cash/" rel="noreferrer noopener" target="_blank"&gt;Uber Cash&lt;/a&gt;的账本迁移数据。&lt;/p&gt;&lt;p class="has-small-font-size"&gt;封面照片归属： &lt;a href="https://www.flickr.com/photos/51986662@N05"&gt;USFWS Mountain Prairie&lt;/a&gt;拍摄的“&lt;a href="https://www.flickr.com/photos/51986662@N05/51912457870"&gt;休伦湿地管理区日落时的水禽迁徙&lt;/a&gt;”，标有&lt;a href="https://creativecommons.org/publicdomain/mark/1.0/?ref=openverse"&gt;公共领域标记 1.0&lt;/a&gt; 。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Amazon Web Services、AWS 和 Powered by AWS 徽标是 Amazon.com, Inc. 或其附属公司的商标。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Apache®、Apache SparkTM 和 SparkTM 是 Apache Software Foundation 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/p&gt;</description><pubDate>Thu, 11 Apr 2024 05:30:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/migrating-from-dynamodb-to-ledgerstore/</guid></item><item><title>【How LedgerStore Supports Trillions of Indexes at Uber】LedgerStore 如何支持 Uber 的数万亿个索引</title><link>https://www.uber.com/blog/how-ledgerstore-supports-trillions-of-indexes/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;Uber 将物理世界和数字世界连接起来，只需按一下按钮即可实现移动。每个季度，Uber 都会为收入者、消费者和商家进行数十亿次出行、送货和数百亿次金融交易。 LedgerStore 是 Uber 的一个不可变存储解决方案，提供可验证的数据完整性和正确性保证，以确保这些交易的数据完整性。&lt;br /&gt;&lt;br /&gt;考虑到账本是 Uber 任何财务事件或数据移动的真实来源，因此能够通过索引从各种访问模式中查找账本非常重要。这就需要&lt;strong&gt;数万亿&lt;/strong&gt;个索引来索引数千亿的账本。之前的一篇&lt;a href="https://www.uber.com/en-US/blog/dynamodb-to-docstore-migration/" rel="noreferrer noopener" target="_blank"&gt;博文&lt;/a&gt;讨论了 LedgerStore 的背景以及存储后端是如何重新架构的。本博客介绍了 LedgerStore 索引及其架构的重要性，该架构为数万亿个索引提供支持，并具有 PB 级索引存储空间。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-types-of-indexes"&gt;索引类型&lt;/h1&gt;&lt;p&gt;账本需要支持各种类型的索引。让我们探索它们以及相应的用例。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="h-strongly-consistent-indexes"&gt;索引强一致&lt;/h2&gt;&lt;p&gt;用例之一是当乘客/食客使用 Uber 时处理信用卡授权流程。在优步行程开始时，乘客/乘客的信用卡上会被冻结。该保留应转换为费用或作废，具体取决于行程是进行还是取消，如下所示。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084314" height="929" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig1-e1711742633458.png" width="1539" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：强一致性指数支持的 Uber Trip 信用卡支付流程。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;如果为保留服务的索引不是强一致的&lt;em&gt;，&lt;/em&gt;则读取时保留可能需要一段时间才能可见。这样做的结果是，可能会在用户的信用卡上重复收费，而原始保留仍保留在信用卡上。&lt;/p&gt;&lt;p&gt;现在，让我们深入研究如何构建强一致性索引，以确保一旦执行记录写入，任何后续读取都保证看到与该记录对应的索引。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-write-path"&gt;写入路径&lt;/h3&gt;&lt;p&gt;为了构建强一致性索引，我们使用两阶段提交来确保索引始终与记录强一致，如下所示。&lt;/p&gt;&lt;p&gt;插入操作从记录写入之前的索引意向写入开始。如果记录写入成功，这些意图将在记录写入操作后提交，并且这是异步完成的，以避免影响最终用户插入延迟。如果索引意图写入成功，但记录写入失败，则需要回滚索引意图，否则会导致未使用意图的累积，这将在读取时处理，如下所示。&lt;/p&gt;&lt;p&gt;需要注意的是，如果索引意图写入失败，则整个插入操作都会失败，因为我们无法保证索引与记录的一致性。因此，只有当用例强烈需要时才需要考虑强一致性索引。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084320" height="640" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig2-e1711742801993.png" width="1260" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：强一致索引的两阶段提交写入流程。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-read-path"&gt;读取路径&lt;/h3&gt;&lt;p&gt;有两种情况索引可以在插入后处于意向状态：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;索引意向提交操作在写入路径中失败或&lt;/li&gt;&lt;li&gt;如果记录写入失败&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;此类意图通过提交或删除在读取路径上进行处理。当对这些索引进行读取时，如果索引处于 Intent 状态，则会读取相应的记录。如果记录存在，则提交索引，否则回滚。这些操作异步发生，以免影响最终用户的读取延迟。一般来说，只有很小一部分索引最终处于意图状态。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084321" height="912" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig3-e1711742960693.png" width="1180" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：强一致索引的读取流程。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-eventually-consistent-indexes"&gt;最终一致的索引&lt;/h2&gt;&lt;p&gt;并非所有索引都需要强大的“读即写”保证。这种索引的一个例子是支付历史页面，其中，只要支付出现在页面上，几秒的延迟是可以接受的。&lt;/p&gt;&lt;p&gt;虽然强一致性索引提供了&lt;em&gt;读你所写的&lt;/em&gt;保证，但它们在某些情况下并不适合，因为它们会权衡以下属性来实现此保证：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;更高的写入延迟&lt;/strong&gt;&lt;br /&gt;由于索引意向写入操作和相应的记录写入必须是串行的，才能为记录提供索引的强一致性保证&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可用性较低&lt;/strong&gt;&lt;br /&gt;任何一个索引意图的写入失败都意味着整个写入应该失败，否则索引将与相应的记录不一致&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;与强一致索引相比，最终一致索引在这方面是相反的，因为它们是由与在线写入路径完全隔离的单独进程在后台构建的。因此，它们不会遭受&lt;em&gt;较高的写入延迟&lt;/em&gt;或导致 LedgerStore 服务的潜在&lt;em&gt;可用性较低&lt;/em&gt;。我们利用我们自己开发的&lt;a href="https://www.uber.com/blog/schemaless-sql-database/" rel="noreferrer noopener" target="_blank"&gt;Docstore&lt;/a&gt;数据库中名为“物化视图”的功能来生成这些索引。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084322" height="1760" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig4-e1711743013811.png" width="1820" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：最终一致索引提供的支付历史记录。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-time-range-indexes"&gt;时间范围索引&lt;/h2&gt;&lt;p&gt;账本由于其不可变的性质，会随着时间的推移而不断增长，从而增加其存储成本。因此，在 Uber，我们将时间范围内的旧账本分批卸载到更便宜的冷存储中。&lt;/p&gt;&lt;p&gt;每个账本都与一个称为业务或事件时间戳的时间戳相关联。为了将账本卸载到冷存储（也为了密封数据），我们需要一类索引来查询事件时间范围批次中的数据。该索引的不同之处在于，数据是在确定的时间范围批次中读取的，其数量级高于上述两种索引类型。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-full is-resized"&gt;&lt;img alt="" class="wp-image-1084325" height="591" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig5-e1711743069138.png" style="width: 701px; height: auto;" width="1020" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：数据分层中使用的时间范围索引。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;以下是如何在分类账上进行时间范围查询的示例：&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;从 LEDGER_TABLE 中选择 *&lt;/strong&gt; &lt;strong&gt;，其中&lt;/strong&gt;LedgerTime&lt;strong&gt;介于&lt;/strong&gt;1701252000000&lt;strong&gt;和&lt;/strong&gt;1701253800000 之间&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;分类帐&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;账本时间&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;{行程开始}&lt;/td&gt;&lt;td&gt;上午 10:01&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; {行程已完成且票价已调整}&lt;/td&gt;&lt;td&gt;上午 10:15&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; {行程后更正}&lt;/td&gt;&lt;td&gt;中午 12:01&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;有几种方法可以在分布式数据库中对此进行建模。我们将深入探讨在 Amazon DynamoDB 与 Docstore 数据库之上开发时间范围索引之间的主要区别。 DynamoDB 和 Docstore 都是分布式数据库，都提供数据建模构造作为分区和排序键。前者用于根据数据的值在分区之间均匀分布数据，后者用于控制数据的排序顺序。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-design-with-dynamodb"&gt;使用 DynamoDB 进行设计&lt;/h3&gt;&lt;p&gt;Dynamodb 提供两种管理表读/写&lt;a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html" rel="noreferrer noopener" target="_blank"&gt;容量&lt;/a&gt;的方法。我们使用预配置模式，因为流量不会太&lt;a href="https://docs.aws.amazon.com/wellarchitected/latest/serverless-applications-lens/capacity.html" rel="noreferrer noopener" target="_blank"&gt;突发，&lt;/a&gt;不需要按需模式。预配模式配置了&lt;a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html" rel="noreferrer noopener" target="_blank"&gt;自动缩放功能&lt;/a&gt;，可根据流量模式调整容量。&lt;/p&gt;&lt;p&gt;正如我们从上面的写入模式中注意到的，分类账时间通常与当前挂钟时间相关。因此，这些值往往聚集在当前时间附近。如果我们基于&lt;strong&gt;G&lt;/strong&gt;个时间单位粒度对数据进行分区，那么&lt;strong&gt;G 个&lt;/strong&gt;时间单位中的所有写入都将进入同一个物理分区，从而导致热分区。 DynamoDB 在&lt;a href="https://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/" rel="noreferrer noopener" target="_blank"&gt;热分区&lt;/a&gt;的情况下对吞吐量有限制，导致写入请求受到限制，这在在线写入路径中是不可接受的。假设 1K 峰值 Uber 行程/秒，即使 G=1 秒也不是一个好值，因为它对应于 1K WCU（写入容量单位），这是发生&lt;a href="https://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/" rel="noreferrer noopener" target="_blank"&gt;限制&lt;/a&gt;之前允许的 QPS 峰值。&lt;/p&gt;&lt;p&gt;虽然看起来我们可以使分区更细粒度，但它仍然不是万无一失的，因为随着时间的推移，流量的增加可能会导致不稳定。这样做的另一个副作用是通过分散-聚集执行的累积读取量增加。因此，我们对 DynamoDB 所做的操作如下：&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-write-optimized-temporary-index-table-called-buffer-index"&gt; 写优化临时索引表（称为缓冲区索引）&lt;/h4&gt;&lt;p&gt;所有在线时间索引写入都会写入缓冲区索引表。插入的索引项根据相应记录的哈希模划分到&lt;strong&gt;&lt;em&gt;M 个&lt;/em&gt;&lt;/strong&gt;唯一的存储桶中，以在缓冲区索引表中的分区之间&lt;a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-partition-key-design.html" rel="noreferrer noopener" target="_blank"&gt;均匀分配&lt;/a&gt;负载，从而提高&lt;em&gt;写入效率&lt;/em&gt;。选择&lt;strong&gt;&lt;em&gt;M&lt;/em&gt;&lt;/strong&gt;的值，使其足够高，以便每个分区的负载量避免过度拆分。它也被选择得足够低，以限制分散-聚集的数量&lt;em&gt; &lt;/em&gt;在读取期间执行。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-read-optimized-permanent-index-table"&gt;读取优化的永久索引表&lt;/h4&gt;&lt;p&gt;对缓冲表进行分散&lt;em&gt;聚集&lt;/em&gt;读取的需要使得它们的读取效率不高，并且由于读取可能发生在表的整个生命周期中，因此我们需要对其进行优化。这就带来了对读取高效的永久索引表的需求。&lt;/p&gt;&lt;p&gt;永久时间范围索引表根据与特定持续时间&lt;strong&gt;&lt;em&gt;N&lt;/em&gt;&lt;/strong&gt; （例如 10 分钟）对齐的时间戳进行分区。缓冲表中的索引定期批量写入永久索引表。由于写入是在后台批量完成的，所以这里的任何写入节流都不会影响线上流量。批处理的另一个优点是写入流量可以跨分区分布，减少热分区。缓冲区索引表在将其索引卸载到永久索引表后将被删除，因为不再需要它们。对永久索引表的读取以&lt;strong&gt;&lt;em&gt;N&lt;/em&gt;&lt;/strong&gt;分钟为间隔完成，没有任何分散-聚集，使得该表的&lt;em&gt;读取效率很高&lt;/em&gt;。&lt;br /&gt;&lt;br /&gt;以下是 DynamoDB 情况下的时间范围索引流的描述。双表设计带来了状态管理和协调的需要，因此读取也会转到正确的索引表。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084328" height="1669" src="https://blog.uber-cdn.com/cdn-cgi/image/width=920,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig6-e1711743514668.png" width="1499" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：Dynamodb 上的时间范围索引设计。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-design-with-docstore"&gt;使用 Docstore 进行设计&lt;/h3&gt;&lt;p&gt;DynamoDB 的双表设计运行良好，可以处理高吞吐量，但在操作上带来了挑战。如果临时缓冲表没有及时创建，可能会因为无法接受写入而导致写入失败，这在过去曾引起过可用性问题。作为成本效率的一部分，我们将索引存储后端从 DynamoDB 重新架构为 Uber 的&lt;a href="https://www.uber.com/blog/schemaless-sql-database/" rel="noreferrer noopener" target="_blank"&gt;Docstore&lt;/a&gt;数据库。作为此重新架构的一部分，我们还通过利用两个 Docstore 属性改进了时间范围索引设计，以克服维护两个表的缺点：&lt;/p&gt;&lt;ol&gt;&lt;li&gt; &lt;a href="https://www.uber.com/blog/schemaless-sql-database/" rel="noreferrer noopener" target="_blank"&gt;Docstore&lt;/a&gt;是一个构建在 MySQL 之上的分布式数据库，固定数量的分片分配给可变数量的物理分区。随着数据大小的增长，物理分区的数量增加，一些现有的分片被重新分配给新的分区，从而导致物理分区的数量达到最大&lt;strong&gt;上限&lt;/strong&gt;。&lt;/li&gt;&lt;li&gt; Docstore中的数据以主键（分区+排序键）的&lt;strong&gt;排序&lt;/strong&gt;方式存储。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我们只维护一张时间范围索引表，其中索引条目根据完整时间戳值进行分区。由于时间戳非常细粒度，因此不存在热分区（因此不存在写入限制），因为大多数写入均匀分布在分区之间。&lt;/p&gt;&lt;p&gt;读取涉及对表的每个分片进行前缀扫描，直至达到特定的时间粒度。前缀扫描与表的常规扫描非常相似，不同之处在于每个扫描请求的边界由应用程序控制。因此，在下面的示例中，要读取 30 分钟的数据，可以从 2023–02-03 01:00:00 到 2023–02-03 01:10:00 每隔 10 分钟间隔读取一次，类似地对接下来的两个子窗口重复此操作。由于数据是按主键排序的，因此具有给定边界的前缀扫描可确保仅读取这些时间戳内的数据。&lt;/p&gt;&lt;p&gt;然后执行分散-聚集，然后执行跨分片的排序合并，以按排序的方式获取给定窗口中的所有时间范围索引条目。由于Docstore中分片的数量是固定的，因此我们可以精确地确定（并限制）需要执行的读取请求的数量。同样的技术不适用于 DynamoDB，因为随着表大小的增加，分区数量不断增加。这显着简化了设计并降低了时间索引的运营维护成本。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084329" height="964" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig7-e1711743568767.png" width="1080" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：Docstore 上的时间范围索引设计。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-index-lifecycle-management"&gt;索引生命周期管理&lt;/h2&gt;&lt;p&gt;定期定义新索引，并且也可以修改某些索引以发展用例。为了以最小的努力支持这一点并且不导致任何回归，我们需要一种机制来管理索引生命周期。以下是相同的组件：&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-index-lifecycle-state-machine"&gt;索引生命周期状态机&lt;/h3&gt;&lt;p&gt;该组件协调索引的生命周期，包括创建索引表、用历史索引条目回填索引表、验证它们的完整性、将旧索引与新索引交换以进行读/写，以及停用旧索引。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084330" height="660" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig8-e1711743614440.png" width="1800" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：索引生命周期状态机。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-historical-index-data-backfill"&gt;历史指数数据回填&lt;/h3&gt;&lt;p&gt;根据业务用例，需要定义新索引，并且必须回填历史索引条目以使其完整。该组件根据卸载到冷数据存储的历史数据构建索引，并以可扩展的方式将其回填到存储层。考虑到数据下载速度高于数据处理速度，该组件以可重用的方式构建了可配置的速率限制和批处理，因为我们可以将实际处理逻辑作为批处理器插件插入。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084331" height="821" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig9-e1711743676584.png" width="1420" /&gt;&lt;figcaption class="wp-element-caption"&gt;图9：为回填索引而定制的历史数据处理模块。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-index-validation"&gt;索引验证&lt;/h3&gt;&lt;p&gt;索引回填后，需要验证索引的完整性。这是通过离线作业来完成的，该作业在一定的时间窗口粒度上计算顺序无关的校验和，并在真实数据源和索引表之间进行比较。此步骤可识别索引回填过程中的任何错误，因为即使丢失了一个条目，该时间窗口的聚合校验和也会导致不匹配。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084332" height="560" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig10-e1711743725757.png" width="1640" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 10：索引完整性验证。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-highlights"&gt;强调&lt;/h2&gt;&lt;p&gt;我们是这样衡量这个关键项目是否成功的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们构建了超过 2 万亿个唯一索引，到目前为止，尚未检测到任何数据不一致，新架构已投入生产 6 个多月。&lt;/li&gt;&lt;li&gt;鉴于资金流动对 Uber 的重要性，在回填期间没有发现任何生产事故。&lt;/li&gt;&lt;li&gt;我们还将所有这些索引从 DynamoDB 移至 Docstore。因此该项目还实现了技术整合，减少了外部依赖。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;从业务影响的角度来看，由于 DynamoDB 支出减少，运营 LedgerStore 现在非常划算。预计每年可节省超过 600 万美元。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;账本是 Uber 资金流动事件的真相来源。我们构建的强大索引平台支持访问各种业务用例的真相分类账来源，我们期待将来在该平台上支持更多索引。&lt;/p&gt;&lt;p&gt;我们想总结一些关键要点： 在 OLTP 系统中维护 PB 级索引会带来一定的挑战，例如分区不平衡、读/写放大高、邻居噪声问题等。因此数据建模和隔离非常重要设计这些系统时要考虑的方面。此外，根据底层用于存储的实际数据库，设计方法可能会有很大不同，正如我们从两个不同分布式数据库上的时间范围索引的设计对比中看到的那样。&lt;/p&gt;&lt;p&gt;下周加入我们，观看 LedgerStore 系列的第二部分，我们将记录从 DynamoDB 到 LedgerStore 的迁移。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="h-acknowledgments"&gt;致谢&lt;/h2&gt;&lt;p&gt;如果没有以下团队的合作，这个项目就不可能实现，这些团队体现了&lt;a href="https://www.uber.com/in/en/careers/values/" rel="noreferrer noopener" target="_blank"&gt;Uber 的多项价值观&lt;/a&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.uber.com/blog/payments-platform/" rel="noreferrer noopener" target="_blank"&gt;湾流&lt;/a&gt;团队与 LedgerStore 团队密切合作，以实现共同目标并迁移到 LedgerStore 平台，这是一个多年项目。&lt;/li&gt;&lt;li&gt; Docstore 团队，负责不断发展&lt;a href="https://www.uber.com/en-IN/blog/schemaless-sql-database/" rel="noreferrer noopener" target="_blank"&gt;Docstore&lt;/a&gt;以满足 LedgerStore 索引的大规模需求。&lt;/li&gt;&lt;li&gt; LedgerStore 团队负责领导、构建和推动分类账索引的大规模采用。&lt;/li&gt;&lt;/ul&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Amazon Web Services、AWS、Powered by AWS 徽标和 Amazon DynamoDB 是 Amazon.com, Inc. 或其附属公司的商标。&lt;/em&gt;&lt;/p&gt;</description><pubDate>Thu, 04 Apr 2024 05:30:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/how-ledgerstore-supports-trillions-of-indexes/</guid></item><item><title>【Scaling AI/ML Infrastructure at Uber】扩展 Uber 的 AI/ML 基础设施</title><link>https://www.uber.com/blog/scaling-ai-ml-infrastructure-at-uber/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;&lt;strong&gt;介绍&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;自 2016 年我们首次开始为司机-乘客匹配和定价团队使用复杂的基于规则的机器学习模型以来，机器学习 (ML) 正在庆祝其在 Uber 的第八个年头。从那时起，我们取得了重大进展，转向采用深度学习学习模型是当今大多数关键业务应用程序的核心，同时积极探索生成式人工智能模型提供的可能性。随着 AI/ML 模型的复杂性和规模不断激增，对高效基础设施来有效支持这些模型的需求不断增长。在过去的几年里，我们战略性地实施了一系列以 CPU 和 GPU 为中心的基础设施解决方案，以动态扩展我们的系统并满足不断变化的 ML 用例环境。这一演变涉及定制硬件 SKU、软件库增强、各种分布式训练框架的集成以及对我们的端到端 Michaelangelo 平台的持续改进。这些迭代改进是由我们一路走来的经验教训以及对行业趋势和 Uber 发展轨迹的不断调整推动的，所有这些都是为了满足我们的合作伙伴和客户不断变化的需求。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-goal-and-key-metrics"&gt;&lt;strong&gt;目标和关键指标&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;当我们开始从内部部署向云基础设施的过渡（我们于 2023 年 2 月&lt;a href="https://www.wsj.com/articles/uber-signs-cloud-deals-with-google-and-oracle-b45a9372" rel="noreferrer noopener" target="_blank"&gt;宣布）&lt;/a&gt;时，我们跨团队的硬件/软件协同设计和协作是由以下具体目标驱动的：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;最大限度地利用现有基础设施&lt;/li&gt;&lt;li&gt;为新兴工作负载建立新系统，例如生成式人工智能&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为了实现这些目标，我们概述了指导我们进步的独特关键结果和指标。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可行性和可靠性：&lt;/strong&gt;机器学习用户期望在预期的时间范围内（根据复杂性，可以是几周或几个月）成功地融合他们的训练任务，并且不会出现错误。例如，训练 Falcon 180B™ 等更大、更复杂的模型可能需要数月时间，而较长的训练持续时间会增加出现可靠性问题的可能性。因此，我们的目标是为所有培训依赖项实现 99% 的正常运行时间 SLA，以确保一致且可靠的结果。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;效率：&lt;/strong&gt;我们对效率的关注涉及对不同 GPU 配置进行彻底的基准测试，并评估针对特定工作负载定制的本地和云 SKU 的性价比。我们使用模型触发器利用率 (MFU) 等指标来衡量训练效率，以保证最佳的 GPU 利用率。我们的目标是防止 GPU 闲置，通过反应式扩展在服务非高峰时段机会性地使用训练作业，并保持高利用率以最大限度地提高资源效率。我们希望做到这一点的同时也保持不同用户之间资源共享的公平性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;开发人员速度：&lt;/strong&gt;该指标通过我们的工程师在特定时间范围内可以进行的实验数量来量化。我们优先考虑成熟的生态系统来提高开发人员的速度，确保我们的团队高效工作以提供最佳解决方案。这种方法不仅简化了我们最先进的模型的生产过程，而且还减少了这一过渡所需的时间。&lt;/p&gt;&lt;p&gt;接下来是我们为使本地和云基础设施中的培训和服务部署高效且可扩展而采取的各种举措的结果摘要： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-optimizing-existing-on-prem-infrastructure"&gt;&lt;strong&gt;优化现有的本地基础设施&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-federation-of-batch-jobs"&gt;&lt;br /&gt;批处理作业联合会：&lt;/h3&gt;&lt;p&gt;我们的 GPU 资产分布在各个可用区和区域的多个&lt;a href="https://kubernetes.io/" rel="noreferrer noopener" target="_blank"&gt;Kubernetes&lt;/a&gt; ™ 集群中。这种分布主要是由于 GPU 可用性和单个 Kubernetes 集群内的节点数量限制。这种安排带来了两个主要挑战：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;向机器学习工程师展示基础设施的具体细节。&lt;/li&gt;&lt;li&gt;由于静态分配，跨集群的资源利用率不一致。虽然我们在每个集群内都有有效的资源共享系统，但我们缺乏集群间调度的能力。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为了解决这些问题，我们为批量工作负载创建了一个统一的联合层，包括&lt;a href="https://www.ray.io/" rel="noreferrer noopener" target="_blank"&gt;Ray&lt;/a&gt; ™ 和 Apache &lt;a href="https://spark.apache.org/" rel="noreferrer noopener" target="_blank"&gt;Spark&lt;/a&gt; ™，称为&lt;strong&gt;Michelangelo Job Controller&lt;/strong&gt; 。该组件充当所有工作负载调度的集中式接口，隐藏底层 Kubernetes 集群，并根据各种策略（负载感知、bin-pack）分配工作负载，包括计算和数据关联性考虑因素。我们计划在后续的博客文章中分享更多相关技术细节。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/BQBvxC9TSCSgAj8ZlAAL8Dkydbx3B__KT9nHfrs7eUfLEU6CVUiGo4uG6QUmWkJ0piVRdwkjSioJ-Q80JmKI7pFzlHOEssw3DTZlou544_4uJkyYHdbC55OkKSQfq7ZyL9x8yN8iuZ6a8Hv5RMg0-xk" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：用于 ML 工作负载分配的统一联合层。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-network-upgrade-for-llm-training-efficiency"&gt;网络升级提升LLM培训效率&lt;/h3&gt;&lt;p&gt;当扩展基础设施以适应生成式 AI 应用程序并提高分布式训练的效率，同时微调开源 LLM 时，重要的是要重点关注跨纵向扩展和横向扩展配置的网络带宽扩展。这就需要实现关键功能，例如 GPU 之间的全网状&lt;a href="https://www.nvidia.com/en-us/design-visualization/nvlink-bridges/" rel="noreferrer noopener" target="_blank"&gt;NVlink&lt;/a&gt; ™ 连接、网络链路速度升级、熟练的拥塞控制管理、QoS 控制以及专用机架和网络拓扑的建立以及其他基本功能。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1083848" height="593" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Fig2_network_upgrade-1024x593.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图2：通过网络链路容量升级提高训练效率。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们总结了大型语言模型 (LLM) 案例研究的结果，强调增强的网络带宽和拥塞控制机制对培训效果和性价比效率的巨大影响。我们的观察表明，与现有的网络互连相比，采用更高的网络带宽和更好的拥塞控制机制时，训练速度提高了近两倍，并且训练持续时间大幅缩短。在多节点训练期间，跨节点复制数据会增加本地内存需求并增加 IO 工作负载。我们的分析建议将每个 GPU 服务器上的网络链路容量增加 4 倍（25GB/s 至 100GB/s），从而可能使可用训练容量增加一倍。在构建这些服务的同时，我们还需要通过适当的隔离和 QoS 控制来确保大型训练运行生成的“大象流”不会对其他高优先级服务产生负面影响。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-memory-upgrade-to-improve-gpu-allocation-rates"&gt;&lt;br /&gt;内存升级以提高 GPU 分配率&lt;/h3&gt;&lt;p&gt;较新的 AI/ML 工作负载要求每个 GPU 工作线程使用比我们设计的更多的系统内存。固有的物理限制，例如每台服务器上的内存通道数量有限，以及 NPI（新产品推出）期间部署的 DIMM 容量限制了我们扩展 GPU 分配的能力。为了提高 GPU 分配率，我们已开始努力将这些服务器上的内存量增加一倍（每个 DIMM 通道 16GB 至 32GB）。此外，我们还在构建一个框架，以便在旧机架退役时重新利用和重复使用 DIMM。这种优化使我们能够最大限度地利用现有的机器学习基础设施，并充分利用我们当前的资源。我们将在下一篇文章中详细介绍通过这一举措所实现的效率提升。与此同时，我们已开始努力帮助调整培训工作的资源需求。正如其他人[&lt;a href="https://tianyin.github.io/pub/amp.pdf" rel="noreferrer noopener" target="_blank"&gt;参考文献&lt;/a&gt;]所证明的那样，手动请求最佳资源是一个难题，而自动化将有助于提高分配效率。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-building-new-infrastructure"&gt;&lt;strong&gt;建设新型基础设施&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-price-performance-evaluations-across-various-cloud-skus"&gt;&lt;br /&gt;各种云 SKU 的性价比评估&lt;/h3&gt;&lt;p&gt;2022 年底，当我们踏上向云过渡的旅程时，我们评估了不同云提供商提供的各种 CPU 和 GPU 模型。我们的目标是使用既定基准（从基于树的深度学习到大型语言模型）以及专有数据集和 Uber 模型（例如 deepETA 和 deepCVR）来比较它们的性价比。这些针对培训和服务目的进行的评估使我们能够选择针对特定工作负载进行优化的最合适的 SKU，同时考虑可行性、成本、吞吐量和延迟等因素。整个 2023 年，我们广泛测试了 17 种不同的 GPU 和 CPU SKU，采用了各种库和优化器，包括 Nvidia 的&lt;a href="https://github.com/NVIDIA/TensorRT" rel="noreferrer noopener" target="_blank"&gt;TensorRT&lt;/a&gt; ™(TRT) 和 TRT-LLM 优化。例如，如图 4 和图 5 所示，我们发现虽然 A10 GPU 可能无法为训练任务提供最具成本效益的吞吐量，但事实证明它们是我们服务用例的最佳选择，在提供最佳吞吐量的同时保持可接受的吞吐量。使用 TRT 的 SLA。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/6lE7W5fYhVSHGudF-A9Fu6wzvEQo4-S7ZjnN8dSgy3HcTmC4pqn-RT9VvBF0kTwZYY3rCz6OU4BVQfZ5erhWA2UMlK-7VbUYQkqKF6SUb58hKjHdzbzH7GK6Do40TLNw7bg0GTxgQYgzQDDV-jbkXxg" title="图表" /&gt;&lt;figcaption class="wp-element-caption"&gt;图3：深度学习训练和服务性能价格评估。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/jnlRbG2pls4P0xjxD9Pvv7fx4BW5_ZWXtSYLQLXfN317i1lPtxJPOxT6xbzNT8OIHEtAXarcDNNFeC-YRUAI0zh4t1sTBuPUfYeppJPdIwMpPDDJ7E8ddXBnNqde1rCZZVxCJiCIbpQ1qWd4oIGWyhk" title="图表" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：使用和不使用 TensorRT 优化的深度学习服务延迟。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; Uber 的众多生成式 AI 应用需要使用 Nvidia 最新的 H100 GPU 来满足严格的延迟要求。这一要求源自 H100 GPU 的功能，与上一代 A100 GPU 相比，它包括高达 4 倍 TFlops 和双倍的内存带宽。在试验 Meta™ &lt;a href="https://llama.meta.com/" rel="noreferrer noopener" target="_blank"&gt;Llama2&lt;/a&gt; ™ 模型系列（涉及各种批量大小、量化和模型参数）时，我们评估了各种开源和闭源框架，以进一步优化 LLM 服务性能。在图 6 和图 7 中，我们提出了一个具体案例，其中我们采用两个指标：每个令牌延迟（毫秒/令牌）和令牌/秒/gpu，来评估和比较两个表现最好的框架（TRT）的模型性能。 -LLM 和当前保密的框架），保持所有其他参数不变并使用 FP16 量化。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/qs9gWGpDUlhVZrug3qN88E-xDt8PKhA0Rd-R_WL8ECGq-DG50lJ7rz1nT37PxgIRyM0k2ypyN2Aq4v_FTnve8_tq9ayMOkm4cRd0UoTzSYbalhD2CDKQINp5F8uxVVDS8Y1ol-1MeKZK3pGzcSfd4dw" title="图表" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：按框架划分的 LLM 服务延迟比较 (H100)。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/rhL0z9GvoYxR0yiwFONGfGaHXsFNo_kORbuXeb9b2c8M0NEe_jJCbeEDThJUVHc05NeSt84xDjN7m5Skd2SvbzfHTUyz-MaaEhAffQoBtuKe3k7RZPVDQFDk7ZsgMYyFXfwCX-wL2dldeo2tHYzce-A" title="图表" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：使用相同延迟预算和所需 GPU 最少数量 (H100) 的框架的 LLM 服务吞吐量比较。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;这些实验结果清楚地表明，与 TRT-LLM 相比，框架 B 的延迟增加了两倍，吞吐量提高了六倍。它进一步强调了硬件/软件协同设计的重要性，并且为了充分利用硬件功能，必须在整个堆栈中拥有正确的解决方案。 &lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-llm-training-efficiency-improvements-with-memory-offload"&gt;&lt;br /&gt;通过内存卸载提高 LLM 培训效率&lt;/h3&gt;&lt;p&gt;在本节中，我们概述了有关大型语言模型的优化器状态、参数和从 GPU 内存到 CPU 内存或 NVMe 设备的梯度的放置的设计和实验框架。我们的目标是评估这种卸载对 GPU 可扩展性、训练效率和一系列系统指标的影响。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1083850" height="637" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Fig6_memory_offload_design_space-1024x637.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：内存卸载实验的设计框架。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们的实验结果表明，我们训练先前因 GPU 内存有限而受到阻碍的扩展模型的能力已得到显着增强。将内存从 GPU 内存卸载到系统内存甚至 NVMe 设备，通过在相同数量的 GPU 上使用更大的批量大小，有助于提高训练效率。这一转变使 MFU（模型触发器利用率）提高了 2 倍，同时 GPU 使用率降低了 34%。然而，值得注意的是，这种改进伴随着网络吞吐量的相应减少。有关此主题的详细开放计算机项目 ( &lt;a href="https://www.opencompute.org/" rel="noreferrer noopener" target="_blank"&gt;OCP&lt;/a&gt; ) 会议演讲可&lt;a href="https://www.youtube.com/watch?v=Ju0r8yU1_Lw" rel="noreferrer noopener" target="_blank"&gt;在此处&lt;/a&gt;找到。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/L8HJjzd4fJLc0rv2q8ArOqvVbN-mlHlKwGTqoYg6dPciNtvU6kjAn3NK3eVfjp1WdeqLgJu2zIhmRNxeM5vkX3E47bIRNezH-X9ytjOWzh7lRI0V9OFtZMzOtUbaZXJjf6HsXy4oznVON7V6JTQt7zc" title="图表" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：实施 Deepspeed 内存卸载优化的训练效率。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;最后，我们想向您提供三个关键见解。在快速应用和模型发展（从 XGboost 到深度学习推荐模型和大型语言模型）中设计单一的 AI/ML 系统面临着相当大的挑战。例如，虽然法学硕士需要高 TFlops，但深度学习模型可能会遇到内存限制。为了提高这些系统的成本效益，必须根据给定 SLA 内的服务成本和单位成本性能等效率指标探索工作负载优化的解决方案。最大限度地提高基础设施效率需要跨系统所有层的协作硬件和软件设计方法。在此背景下，我们在这篇文章中展示了各种示例，说明如何有效利用现有基础设施，同时构建新功能以有效扩展基础设施。最后，我们发出促进行业合作伙伴关系的邀请，敦促参与开源优化以提高效率，并就有效扩展基础设施交换想法和经验，以满足人工智能领域不断变化的需求。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="h-acknowledgments"&gt;&lt;strong&gt;致谢&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;非常感谢 UBER AI 基础设施、OCI、GCP 和 Nvidia 团队成员在上述工作中的合作。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Apache®、Apache Kafka、Kafka、Apache Spark、Spark 和星形徽标是 Apache Software Foundation 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Kubernetes® 及其徽标是 Linux Foundation® 在美国和其他国家/地区的注册商标。使用这些标记并不暗示 Linux 基金会的认可。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Falcon 180B® 及其徽标是 Technology Innovation Institute™ 在美国和其他国家/地区的注册商标。使用这些标志并不暗示技术创新学院的认可。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; LLaMA 2® 及其徽标是 Meta® 在美国和其他国家/地区的注册商标。使用这些标记并不暗示 Meta 的认可。&lt;/p&gt;</description><pubDate>Thu, 28 Mar 2024 07:28:34 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/scaling-ai-ml-infrastructure-at-uber/</guid></item><item><title>【Model Excellence Scores: A Framework for Enhancing the Quality of Machine Learning Systems at Scale】模型卓越分数：大规模提高机器学习系统质量的框架</title><link>https://www.uber.com/blog/enhancing-the-quality-of-machine-learning-systems-at-scale/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;机器学习 (ML) 是 Uber 运营战略不可或缺的一部分，影响着一系列关键业务决策。这包括预测乘客需求、识别欺诈活动、增强 Uber Eats 优食的食物发现和推荐，以及完善预计到达时间 (ETA)。尽管机器学习在各个组织中越来越普遍并产生越来越大的影响，但评估模型“质量”仍然是一个多方面的挑战。在线和离线模型评估之间存在显着区别。许多团队主要关注离线评估，偶尔会通过短期在线分析来补充。然而，随着模型在生产环境中变得更加集成和自动化，持续监控和测量常常被忽视。&lt;/p&gt;&lt;p&gt;通常，团队专注于 AUC 和 RMSE 等性能指标，而忽略其他重要因素，例如训练数据的及时性、模型再现性和自动再训练。缺乏全面的质量评估导致机器学习工程师和数据科学家对模型生命周期不同阶段的各种质量维度的了解有限。此外，这种差距阻碍了组织领导者就机器学习项目的质量和影响做出充分知情的决策。&lt;/p&gt;&lt;p&gt;为了弥补这一差距，我们建议为模型生命周期的每个阶段定义不同的维度，包括原型设计、训练、部署和预测（见图 1）。通过整合服务水平协议 (SLA) 概念，我们的目标是建立衡量和确保 ML 模型质量的标准。此外，我们正在开发一个统一的系统来跟踪和可视化模型的合规性和质量，从而为整个组织的机器学习计划提供更清晰、更全面的视图。请注意，模型卓越得分 (MES) 涵盖了 Uber 整体机器学习治理不可或缺的某些技术方面。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/isX-qlXXKvyRNL8ZrqG7ecOuLg3MzE-EeDYMT1JdrdIESlDE_PMXJcc7hHT0c4496eN18aSxij2pX5zVCRTGiovjtyGurwVEV9w1jaX-YUq2hj1huPJQM39GmLqyOlzl-HPxfhC8YP5Lp2KTLhlunbw" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：典型 ML 系统中的 ML 质量维度示例（黄色）。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-model-excellence-scores-mes"&gt;模型卓越分数 (MES)&lt;/h2&gt;&lt;p&gt;生产就绪的机器学习系统的开发和维护非常复杂，涉及模型生命周期的多个阶段和复杂的支持基础设施。通常，ML 模型会经历特征工程、训练、评估和服务等阶段。维持这一点的基础设施包括数据管道、特征存储、模型注册表、分布式训练框架、模型部署、预测服务等。&lt;/p&gt;&lt;p&gt;为了对这些阶段的模型质量进行全面评估，我们创建并引入了模型卓越评分 (MES) 框架。 MES 旨在衡量、监控和强化 ML 生命周期每个阶段的质量。该框架符合站点可靠性工程师 (SRE) 和 DevOps 专业人员常用的原则和术语，特别是那些用于管理生产环境中的微服务可靠性的原则和术语。&lt;/p&gt;&lt;p&gt; MES 围绕与服务级别目标 (SLO) 相关的三个基本概念：指标、目标和协议。指标是反映机器学习系统质量某些方面的精确定量度量。目标为这些指标设定了目标范围，而协议在 ML 用例级别组合了所有指标，根据指标结果指示总体通过/失败状态。&lt;/p&gt;&lt;p&gt; MES中的每个指标都有明确的定义，并为其指标值设定了目标范围，并指定了值更新的频率。如果某个指标在给定时间范围内未达到其目标，则将其标记为失败。封装了这些指标的协议代表了服务的承诺水平并提供了对其绩效的深入了解。图 2 说明了协议、指标和目标之间的相互关系，以及它们与特定用例和模型的关系。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/bvZ0Oj6F3DG-ZDLprNYgODtxB444TWmjTAEMqNlVxgeozimoLuFjXa6m6LVCKCAE7CrTaDD6t2SgvAUUPUmEQaYMe8bbfDOtMgsn10i2W1A3AtQemO7gpOORuYiFTPkjMhIst_8t9RtlITBHxK-dWWw" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：协议、指标、目标、用例和模型之间的关系。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;不同的指标可能需要不同的解决时间框架和不同的缓解策略。有些可能需要立即关注更高优先级的处理，特别是在未达到性能基准时。&lt;/p&gt;&lt;p&gt;同样重要的是要注意，与建模相关的角色和职责在组织之间可能存在很大差异。在某些情况下，单个团队可以处理整个流程，而在其他情况下，职责可能分布在多个团队或部门中。&lt;/p&gt;&lt;p&gt;在 Uber，每个模型的职责都分配给指定的主要团队。如协议中所述，该团队会收到与其模型相关的任何差异或问题的警报。团队可以根据 ML 用例的重要性和紧迫性灵活地定制这些警报。值得注意的是，一种模型的质量可以直接或间接影响另一种模型。例如，一个模型的输出可以作为另一个模型的输入或触发进一步的模型评估。为了解决这种相互关联性，我们实施了一个通知系统，通知服务和模型所有者相关 ML 模型中的任何质量违规情况。&lt;/p&gt;&lt;p&gt;图 3 描述了模型卓越评分 (MES) 框架与 Uber 其他 ML 系统之间的交互。MES 框架及其指标、目标和协议建立在几个关键原则之上：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;自动可测量性&lt;/strong&gt;：MES 中的每个指标均采用可量化和自动化的指标设计，确保仪器仪表基础设施的稳健性。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可操作性&lt;/strong&gt;：指标不仅是可衡量的，而且是可操作的。这意味着用户或平台可以采取明确的步骤来随着时间的推移根据其设定的目标改进这些指标。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可聚合性&lt;/strong&gt;：每个指标的指标都能够被聚合。这对于有效的报告和监控至关重要，可以根据组织的目标和关键结果 (OKR) 以及关键绩效指标 (KPI) 统一汇总指标。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;再现性&lt;/strong&gt;：每个指标的指标都是幂等的，这意味着它们的测量在回填时保持一致。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;责任&lt;/strong&gt;：每份协议都附有明确的所有权。指定所有者负责定义目标并确保实现这些目标。 &lt;/li&gt;&lt;/ul&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/QJtG_get-AGg37qbai6tkDE1-x9IXbOt28Xsk4tFbSBV6mGfC5jt0aOXtPOEAQpP3RIK8JiQuc2-B-HTUquxWMh0LAqWelYAIesr2YJ2z1cT9-UyyaAOaD_GHGt8iN2BY8Vj2IHOhECetrh84AZU9Tg" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：MES 框架与各种 ML 系统之间交互的高级视图。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们重点关注表1中相关文献中未广泛涵盖的一些指标。MES能够衡量公平性和隐私等方面，这些主题不在本次讨论的范围之内。我们在下表中概述了每个指标如何遵循这些设计原则，提供了可衡量指标的示例、可操作的改进步骤以及用于确保指标在不同用例中可聚合和一致的标准化方案。这些指标要么标准化为 [0,1] 范围，要么转换为百分比，要么在各种应用程序中保持一致的范围。&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;指标&lt;/th&gt;&lt;th&gt;描述&lt;/th&gt;&lt;th&gt;可能采取的行动&lt;/th&gt;&lt;th&gt;指标标准化&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;数据质量&lt;/td&gt;&lt;td&gt;衡量用于训练模型的输入数据集的质量。这是以下的堆肥分数：&lt;br /&gt; – 特征为空&lt;br /&gt;– 跨区域一致性&lt;br /&gt;– 丢失分区&lt;br /&gt;– 重复&lt;/td&gt;&lt;td&gt;– 回填丢失的分区&lt;br /&gt;– 跨区域和实例同步数据分区&lt;br /&gt;– 删除数据中的重复行&lt;/td&gt;&lt;td&gt;综合分数中的每个组成部分均按百分比标准化&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;数据集新鲜度&lt;/td&gt;&lt;td&gt;测量用于训练模型的输入数据集的新鲜度&lt;/td&gt;&lt;td&gt;– 使用新的输入数据集重新训练&lt;br /&gt;– 如果更新数据可用，则回填输入数据集&lt;/td&gt;&lt;td&gt;规模一致&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;特征和概念漂移&lt;/td&gt;&lt;td&gt;生产模型的目标和协变量分布以及两者之间的关系随时间的变化&lt;/td&gt;&lt;td&gt;– 应用加权训练或使用新数据重新训练模型&lt;br /&gt;– 验证上游功能ETL管道的正确性&lt;/td&gt;&lt;td&gt;使用归一化距离度量和重要性权重归一化为 [0,1]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;模型可解释性&lt;/td&gt;&lt;td&gt;衡量模型生成的每个预测的稳健特征解释的存在性和置信度&lt;/td&gt;&lt;td&gt;– 启用解释&lt;/td&gt;&lt;td&gt;标准化为 [0,1]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;预测精度&lt;/td&gt;&lt;td&gt;模型对生产流量的预测准确性（例如，AUC、归一化 RMSE）&lt;/td&gt;&lt;td&gt; – 更新训练数据集以解决训练-服务偏差&lt;br /&gt;– 检查功能或概念漂移&lt;/td&gt;&lt;td&gt;通过标准化精度指标标准化为 [0,1]&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class="wp-element-caption"&gt;表：指标样本。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-results"&gt;结果&lt;/h2&gt;&lt;p&gt;Uber 实施 MES 框架显着提高了组织内 ML 质量的可见性。这种透明度的提高有助于培育优先考虑质量的文化，从而影响业务决策和工程策略。随着时间的推移，我们在各个方面观察到在遵守 SLA 方面取得了重大进展。值得注意的是，我们模型的整体预测性能显着提高了 60%。&lt;/p&gt;&lt;p&gt;此外，从 MES 指标中收集的见解对于确定平台增强领域至关重要。这些见解带来的一个关键发展是引入了用于超参数调整的高级平台工具。这项创新可以自动定期重新调整所有模型，简化优化过程并确保一致的模型性能。这些改进凸显了 MES 框架在推动运营效率和技术进步方面的切实好处&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-lessons-learned"&gt;得到教训&lt;/h2&gt;&lt;p&gt;在 Uber 所有机器学习团队实施和监控关键指标的过程中，我们收集了一些重要的见解。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;激励机器学习从业者：&lt;/strong&gt;既定的框架可以对影响和针对质量改进的努力进行切实的衡量。通过采用标准且透明的报告系统，我们创建了一个环境，让机器学习从业者能够积极提高质量，因为他们知道他们的努力在整个组织中是可见的并得到认可的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;协调和行政支持：&lt;/strong&gt;最初，质量措施可能被视为额外的负担，除非它们从一开始就无缝地融入到日常实践中。实施质量跟踪框架可以揭示现有差距，需要在教育和意识方面付出额外努力来解决这些问题。与执行领导层保持一致至关重要，使团队能够优先考虑以质量为中心的任务。这种一致性逐渐导致全面转向更加积极主动、以质量为中心的文化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;平衡标准化与定制：&lt;/strong&gt;在设计框架时，我们的目标是实现一定程度的标准化，以便随着时间的推移进行一致的跟踪和明智的决策。然而，鉴于 Uber 的机器学习应用多种多样，允许对特定指标进行定制以准确反映每个用例的细微差别也至关重要。例如，在 ETA 预测模型中，我们采用平均平均误差作为比 RMSE 更符合上下文的指标。该框架适应了此类定制，同时保持了报告的标准化方法以确保一致性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;确定增量改进的优先级：&lt;/strong&gt;跨各种用例管理框架给确定优先级带来了重大挑战。我们开发了一个简单的优先级矩阵来确定哪些领域需要立即关注。认识到少数模型对影响的贡献最大，我们的重点是首先提高高影响力用例的质量。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;自动化的作用：&lt;/strong&gt;维持机器学习质量需要大量资源，并且在生产中手动管理模型可能会分散创新的精力。事实证明，生产生命周期自动化，包括使用新数据重新训练、重新验证和重新部署模型，是非常有价值的。这种自动化不仅增强了模型的新鲜度（如模型平均寿命的缩短所示），还使团队能够更多地关注创新，而不是维护。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;我们开发了一个全面的框架，概述了高质量机器学习 (ML) 模型在其生命周期不同阶段的关键维度。该框架受到服务级别协议 (SLA) 原则的启发，旨在监控和确保 ML 模型的质量。重要的是，它的结构可以容纳额外的质量维度，适应新兴的用例和该领域不断发展的最佳实践。&lt;/p&gt;&lt;p&gt;我们的讨论还包括该框架在组织各个层面生成富有洞察力的质量报告的应用。这些报告会定期审查，促进问责制并为战略规划提供宝贵的见解。至关重要的是，通过将机器学习质量嵌入到相关软件系统的整体服务质量中，我们促进了共享责任模型。应用科学家、机器学习工程师和系统工程师现在共同拥有机器学习质量。这种协作方法极大地弥合了这些职能之间的差距，在组织内培育了积极主动、注重质量的文化。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-acknowledgments"&gt;致谢&lt;/h3&gt;&lt;p&gt;如果没有 Uber 工程师和应用科学家团队的帮助，我们不可能完成本文中概述的技术工作。我们还要感谢各位技术项目经理（Gaurav Khillon、Nayan Jain 和 Ian Kelley），感谢他们在促进 Uber 不同组织采用和合规 MES 框架方面发挥的关键作用。&lt;/p&gt;</description><pubDate>Thu, 21 Mar 2024 05:30:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/enhancing-the-quality-of-machine-learning-systems-at-scale/</guid></item><item><title>【Balancing HDFS DataNodes in the Uber DataLake】平衡 Uber DataLake 中的 HDFS 数据节点</title><link>https://www.uber.com/blog/balancing-hdfs-datanodes-in-the-uber-datalake/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;&lt;strong&gt;介绍&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;Apache Hadoop &lt;sup&gt;Ⓡ&lt;/sup&gt;分布式文件系统 (HDFS) 是一种分布式文件系统，旨在以可靠且容错的方式跨多台计算机存储大型文件。它是 Apache Hadoop 框架的一部分，也是 Uber 数据堆栈的主要组件之一。&lt;/p&gt;&lt;p&gt; Uber 拥有世界上最大的 HDFS 部署之一，在数十个集群中拥有 EB 级的数据。不断扩展我们的数据基础设施并在效率、服务可靠性和高性能之间取得平衡非常重要，但也具有挑战性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/VaaufGJF2NoMmsAXqw0SjcSbkWbdPFm1-Kr_ZYFuHKKoFGozTrx0QEhYCk2vu7lAd8vai59XYBhIssXwY0LfI5kWh7AQGTKKYTM34rWx8Re1V8U7gEI0Z0O_vLgXLXT8af8frAQNJJQ_95n95isTgWw" /&gt;&lt;/figure&gt;&lt;p&gt;图 1：Uber 的 HDFS 基础设施。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-overview"&gt;&lt;strong&gt;概述&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;HDFS 平衡器是通过在集群中均匀地重新分配数据来保持 DataNode 健康的关键组件。随着我们的 HDFS 集群的节点停用越来越频繁，HDFS 平衡器必须更有效地平衡数据，以防止 DataNode 倾斜。节点退役需求来自区域退役、安全补丁自动集群更新以及DataNode托管等项目。&lt;/p&gt;&lt;p&gt;然而，HDFS开源自带的平衡器并没有开箱即用地满足这个要求。我们已经看到一个 DataNode 出现偏差的问题（即，与同一集群中的其他节点相比，存储更多数据），这会产生多种副作用：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;导致包含过多数据的主机上的高 I/O 带宽&lt;/li&gt;&lt;li&gt;高利用率的节点有更高的缓慢概率、更高的节点故障和数据丢失风险&lt;/li&gt;&lt;li&gt;集群中活跃且健康的节点较少，无法为客户提供写入流量&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面是一个数据不平衡的例子：在我们最大的集群中，数千个节点的磁盘利用率接近95%，该集群由数千个DataNode组成，容量为数百PB，而平衡吞吐量无法有效地将数据移动到其他新添加的DataNode。这种不平衡的数据分布是由热分层和 EC 转换 [1] 产生的突发写入流量、安全补丁的区域分解/集群周转导致的密集节点退役造成的。由于写入可靠性是第一要务，因此所有 DataNode 都通过可用的容量加权算法来服务写入流量。随着写入流量的增加，数据偏差也会更大。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1082498" height="212" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Figure-2-Argon-cluster-original-1024x212.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：我们最大的集群之一包含大约数千个 DataNode，容量为数百 PB，但 DataNode 出现了偏差。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;因此，我们需要优化HDFS平衡器，以增加从高使用率DataNode到另一个低占用DataNode的数据平衡。&lt;/p&gt;&lt;p&gt;考虑到 Uber 的数据存储规模，单个集群中会有超过 20 PB 的数据不平衡节点，集群数量为 7-8 个。为了解决 Uber DataLake 中平衡 HDFS DataNode 的问题，我们设计了一种新算法来增加 DataNode 之间形成的对的数量，这将在平衡数据的同时增加并行块移动。此外，我们还根据利用率对数据节点进行排序，以便优化形成的数据节点对，并且不会发生递归平衡。&lt;/p&gt;&lt;p&gt;该算法将继续增加用于平衡的吞吐量，即每秒从较高占用的数据节点移动到考虑平衡的较低占用的数据节点的数据大小。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-architecture-amp-design"&gt;&lt;strong&gt;架构设计&lt;/strong&gt;&lt;/h2&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/aypCjNKWlTTa6yQzeGj53GgpowcKkI2Sowy6KlqoObWeWb2sGt7QrR7AS5AEk8kjzHKseHi4zEbcG_HW31QNaglL96kh-0RzVIhXk8qVLmLMJbr5Qr_yULMeF-HVYBCBwknrf3UCeY1RRaNRv8vyLIk" style="width: 701px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：HDFS 平衡器架构。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;ol&gt;&lt;li&gt;初始化和设置：&lt;ol&gt;&lt;li&gt; HDFS 平衡器作为 Hadoop 集群中的服务在主机上运行。&lt;/li&gt;&lt;li&gt;要启动平衡过程，集群中需要存在具有平衡器角色的节点。没有两个平衡器可以同时运行。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;请求集群信息：&lt;ol&gt;&lt;li&gt;平衡器首先联系NameNode来请求有关集群内数据分布的信息。它向NameNode发送请求以获取有关数据块在DataNode上的分布的详细信息。&lt;/li&gt;&lt;li&gt; NameNode 以 DataNode 列表和它们包含的块以及它们的存储容量和其他相关信息进行响应。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;区块选择和规划：&lt;ol&gt;&lt;li&gt;根据从NameNode收到的信息，平衡器算法选择需要移动的块以实现更平衡的分布。&lt;/li&gt;&lt;li&gt;平衡器在规划块移动时会考虑 DataNode 利用率、机架信息、线程和存储容量等因素。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;数据移动的协调：&lt;ol&gt;&lt;li&gt;在确定要移动哪些块后，平衡器会协调 DataNode 之间的实际数据移动。&lt;/li&gt;&lt;li&gt;它与 NameNode 就借助心跳移动的块进行通信。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;块迁移：&lt;ol&gt;&lt;li&gt;平衡器通过直接与源和目标 DataNode 通信来启动块迁移。&lt;/li&gt;&lt;li&gt;它指示源DataNode将选定的块传输到目标DataNode，直接移动数据块。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;监控进度：&lt;ol&gt;&lt;li&gt;在整个数据移动过程中，平衡器持续监控进度。它跟踪已成功传输的块数量，并确保数据移动按照计划进行。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;完成和报告：&lt;ol&gt;&lt;li&gt;平衡操作完成后，平衡器会在日志中并通过指标报告已传输的数据和剩余待传输的数据。&lt;/li&gt;&lt;li&gt;它还可以提供有关平衡过程的统计数据和指标，包括移动的块数量和所花费的时间。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;终止：&lt;ol&gt;&lt;li&gt;在主机中，平衡器作为服务运行。因此，在集群达到平衡之前，它不会停止移动数据。 &lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-initial-optimizations"&gt;&lt;strong&gt;初始优化&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;br /&gt;由于我们的目标是提高吞吐量，以更快的速度平衡 DataNode，因此我们使用现有的 DataNode 属性优化了 HDFS 平衡器，以提高吞吐量。&lt;br /&gt;尽管我们将平衡器的速度提高到了 3 倍，但吞吐量仍然不够。我们有太多高度占用的节点，并且在现有算法中将数据传输到的 DataNode 对的数量会明显减少。此外，我们无法通过平衡器线程提高每个节点的吞吐量，因为增加吞吐量会增加节点的速度并影响读/写流量。因此，我们需要增加 DataNode 对的数量，这最终会导致平衡吞吐量的增加。&lt;br /&gt;&lt;br /&gt;我们使用的 DataNode 和 Balancer 配置如下所述。根据您的情况，您的工作负载的配置可能会有所不同。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;DataNode配置属性：&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-table has-small-font-size"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;财产&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;默认&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;快速模式&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;dfs.DataNode.balance.max.concurrent.moves&lt;/td&gt;&lt;td&gt; 5&lt;/td&gt;&lt;td&gt; 250&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; dfs.DataNode.balance.bandwidthPerSec&lt;/td&gt;&lt;td&gt; 1048576（1MB）&lt;/td&gt;&lt;td&gt; 1073741824（1GB）&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;平衡器配置属性：&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-table has-small-font-size"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;财产&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;默认&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;快速模式&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;dfs.DataNode.balance.max.concurrent.moves&lt;/td&gt;&lt;td&gt; 5&lt;/td&gt;&lt;td&gt; 250&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; dfs.balancer.moverThreads&lt;/td&gt;&lt;td&gt; 1000&lt;/td&gt;&lt;td&gt; 2000年&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;dfs.balancer.最大移动尺寸&lt;/td&gt;&lt;td&gt;10737418240（10GB）&lt;/td&gt;&lt;td&gt; 107374182400（100GB）&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; dfs.balancer.getBlocks.最小块大小&lt;/td&gt;&lt;td&gt;10485760 (10MB)&lt;/td&gt;&lt;td&gt; 104857600 (100MB) &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-algorithm-optimizations"&gt;&lt;strong&gt;算法优化&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-increasing-datanode-pairs-for-high-throughput"&gt;增加 DataNode 对以实现高吞吐量&lt;/h3&gt;&lt;p&gt;更多的 DataNode 对意味着我们可以有更多的并发块传输，因此一个关键的改进是构造更多的对。由于现有算法，高度倾斜的集群形成的数据节点对较少。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1082506" height="549" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Figure-4-Balancer-Original-Algo-1024x549.jpeg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：现有算法。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;在 HDFS Balancer 的现有算法中，高于集群平均利用率的 DataNode（即高于平均利用率和过度利用率的节点）的数量比低于平均利用率和利用率不足的节点要高得多。因此，我们面临着节点稀缺的问题，无法从高利用率的 DataNode 上移动数据，从而导致高利用率的 DataNode 无法快速停机。&lt;br /&gt;&lt;/p&gt;&lt;p&gt;在上图中，有 8 个 DataNode 高于平均利用率，4 个 DataNode 低于平均利用率，这将导致 4 个可以移动数据的目标。&lt;br /&gt;目的是修改 HDFS 算法，为 DataNode 形成更多对，从而从高使用率的 DataNode 中获得更多吞吐量，从而实现均匀利用率以及通过更大的 DataNode 覆盖范围快速降低使用率。&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们的想法是使用基于百分位数的算法来创建更多 DataNode 对。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/HlfZlWPK_wVdej0xQY_1gYkFAWt7JpDbSyPnbE4eLyQaV9-jk_XFbgFszAVnxWfTzTvMg_6MhjL3lsrAImSeStQrrcXNiIdM_W2zNWEHJlWnCsxhme1CD07Ju4Q8QoPHgBzqg-GDgSmcBSu7A8yh9RQ" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：新算法。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;在新算法中，我们根据百分位数创建了调整后的平均值，这将增加数据可以移动到的节点数量。高于平均水平/过度利用的 DataNode 将尝试接近整体集群利用率，而未充分利用/低于平均利用的节点将尝试接近调整后的百分位数平均值。通过基于百分位数的算法，我们的目标是使调整后的平均值接近整体集群利用率。&lt;/p&gt;&lt;p&gt;我们将使用基于百分位数的算法来增加 DataNode 对。在高度倾斜的集群中，百分位数相当高。以上图为例，我们将百分位数设为 P60，调整后的平均值现在为 86.7%。在这种情况下，过度利用/高于平均利用的节点的数量减少，而利用不足/低于平均利用的节点的数量增加。&lt;/p&gt;&lt;p&gt;现在，将有 5 个过度利用且高于平均利用率的节点和 7 个利用率不足且低于平均水平的节点，这将导致 4 对最多形成 7 对。&lt;/p&gt;&lt;p&gt;我们有一个新的 Hadoop 配置属性&lt;em&gt;dfs.balancer.separate-percentile&lt;/em&gt; ， &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/ouUojzw_My_1YuqQvm4oGFoXtN03qy9mBcdjsfcPCHi7thgD_wkYfo3lkzZN6AzFvG2rs2qDHuftg2D3D8vpFw03dk94_r_UhuSUvSfkUr7w2YGuCOP1tNO3QDEE9RV8LwCkjScxreh3_YXyC0vPkPc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：用于定义百分位的新 Hadoop 配置。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;默认为 0.5，表示第 50 个百分位。如果我们使用 -dynamicBalancer 部署平衡器命令，则该百分位数算法将生效，并且调整后的平均值将以更高的吞吐量出现。&lt;/p&gt;&lt;p&gt;我们还可以使用这个阈值来动态平衡。例如，如果 DataNodes 超过 90%，我们将积极平衡它们（即提高速度）。因此，我们将平衡前 20% 的 DataNode，这将导致将 moverThreads 集中在利用率最高的 20% 的源上，并且数据将从利用率高的 DataNode 移动得更快，并更快地降低使用率。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1082510" height="417" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Figure-7-Aggressive-balancer-code-1024x417.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：用于定义积极平衡的新 Hadoop 配置。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-moving-data-to-lower-occupied-datanodes"&gt;将数据移动到占用率较低的 DataNode&lt;/h3&gt;&lt;p&gt;由于自动化（即自动将DataNode中的数据移至其他DataNode进行维护），导致大型集群中的DataNode频繁退役，退役节点的数据被转移到其他节点，导致节点占用率增加。那些节点。出现的新节点慢慢平衡，因为它们没有得到优先级。&lt;br /&gt;另外，例如，如果平均利用率为 83%，阈值为 3%，则 90% 的 DataNode 将其部分数据移动到 79% 的节点，该节点变为 81%。现在，如果新客户端在 81% 时转储数据，则变为 87%，这可能需要进一步平衡该节点，从而分配调度程序和移动程序线程。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/lAap83ZaUUmXXZdZ45R2B9TuHzz3O8zzrYpaZpti5Srpdxga1oV2Ay6yBqrlLqRRfVYe5r0jiEYlyQe8EBhD_W9T5Z_QsbkvToqR1-VPXv-9grrMlFCNb61rpOZtsv4jG1EX4Q3loB-vg-C0236qxdc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：旧算法 – 形成对。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/xoqmBEJU1prJmh7xmVNllTySnh2KfypKUZXcfY2Kp4qG3XMWEVnNMkpOQjm9EwfarrVBwn4IlD5gnaScUKbt7jRDQnBziP4EcDQTxEErbfKzT-5xu7nzj8EpOjDxKS1aFImRaPN_U5Iz2EEKSpjJp8Q" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：旧算法 – 新的过度使用的节点出现。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/qmXk_2q380kv8Nmo5YBY-jL_T6o88ZDB9sZ_M2RG8FCQ_Cs8vCKV5YiP11ahdV98lhsqvkhhb1yxJwVHySa__dVbeW0EtUlS96qwxHwl0eGYnVAnc6kf7vnx-KZCXEtKxG0muax_12jqY5aYP0cZtgE" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 10：新算法 - 首选优化。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们的增强功能是通过按升序对未充分利用的节点或低于平均水平的节点进行排序来优先排序较小占用的DataNode，以首先平衡过度利用的节点中的数据，然后按降序排序高于平均水平的节点，以便平衡时，中间的节点不会进入图片，以防止递归平衡。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-better-observability"&gt;&lt;strong&gt;更好的可观察性&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;我们没有关于在同一节点组、同一机架和任何其他机架之间过度利用和未充分利用、过度利用和低于平均利用率以及未充分利用和高于平均利用率之间形成的 DataNode 对的度量以及其他相关度量。因此，我们无法校准这些对之间的流量分配。为了找出可以在哪里增加 DataNode 对以提高吞吐量，我们创建了一个新的仪表板。&lt;/p&gt;&lt;p&gt;最后，我们添加了 10 多个指标来跟踪算法更改的性能，这将有助于我们更多地校准平衡器的自定义算法。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/qymsO6tHpnV1x5Re2lVFYtX5UqTArgNP0PT7JTLi2aua8DL9-GTRTMbFQZ7fF-WccCBJvmv5zXP72Akx1ejdFgBH2YdtFa_4tgz1CHFWyonX74vzT8OpAjRaGqDTUdNFWPAYgnGiJXaq7bg_7UtwbEw" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 11：我们的指标仪表板快照。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-results"&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;通过平衡算法的优化，我们将吞吐量提高了 5 倍以上，没有任何 DataNode 的利用率高于 90%，并且总体上降低了 DataNode 的使用率。此外，现在不需要部署仅使用某些硬编码节点来平衡数据的手动平衡器，因为我们在算法中的优化已经解决了这一问题。&lt;/p&gt;&lt;p&gt;作为我们新算法的一部分 -&lt;/p&gt;&lt;ul&gt;&lt;li&gt;吞吐量增加——我们将吞吐量增加了 5 倍以上。&lt;/li&gt;&lt;li&gt;降低高使用率的数据节点——我们将利用率高于 90% 的数据节点降低到 0。&lt;/li&gt;&lt;li&gt;数据节点的利用率相同——减少数据节点的总体使用量并使它们的容量相同。对于我们最大的集群，所有 DataNode 的利用率都低于 85%。&lt;/li&gt;&lt;li&gt;更好地管理容量——HDFS 集群的集群利用率从 65-66% 增加到 85% 左右，但我们遇到了容量瓶颈。尽管集群利用率比以往任何时候都高，但我们现在没有高度占用的数据节点。 &lt;/li&gt;&lt;/ul&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/xLa6b1OocD2j8moRGaxLJL_qbjP_xD412Zib_vZv3uYV-tXefy1Vq8IZK4Y1k8F-B_lWdetYp4_-xunCBgCdB3Ov0hhpnuKlLVARGodpE6nUURsocv7menNOQKubFT5oiBwCM7yyYfsmw4R1P64UMZ4" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 12：由于算法更改，DataNode 处于类似水平，并且我们最大的集群的利用率低于 85%。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/eO5trlhcsa5iPseVoe0deceN0afiwUstj3oyk95aGYV4xV6vO9ap3juytv9bnLQMitL88-tnRmKblbiVzmE6Li9vmAG0aRWXQ_Y5rIzo8Z846ZFOtm6BMoaFwHcQzIw8BZVgW4n2-1OTRolCH9LSnRE" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 13：反映 DataNode 偏差减少的面板。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/uqyVOYZWIMQ33KfRVuA4LeLDiASqtaMThAef2CjJ8Qa2_mNvgi51nJcH2A1VmhML8yXyE7e_cHmD8_5-zgS2OUe6PqOaEZQBbfNYvo_npxkCxKaKisWB_ZRWyOQQiN8Ox8uomG_T6DGJjR4dRPVU7Lc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 14：平衡器算法更改之前 – 使用率高于 90% 的 Datanode 为 50.8%。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/8jioc04QB8VJcyCm7bKU-IEx6cbiTgLeBe9O0aRb9CR4nwU8o4IRzQScNFOjhSns5XDspdY-u3cK5iirYw7QH9dwrCNoFoUfstbTMRuciCWxR6CHZXFTDtT_p-wuCHVYko3wmssd4f2PJnUXPa6HbPU" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 15：平衡器算法更改后 – 使用率高于 90% 的 Datanode 低于 0。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-full is-resized"&gt;&lt;img alt="" class="wp-image-1082512" height="662" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Figure-16-Cluster-previous-capacity.png" style="width: 700px; height: auto;" width="844" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 16：我们的集群之一，集群利用率较低，约为 65%。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/FUzDUIGryAJWwVwckoZQPUKatRhcPpBWOxQrGHXh9P8-y3mOTVcgJEnJJjCHromXrwQtbz1T_7t7V7TEtQ9lNT9XI4IabGVADQ2rIzXK3FeDb4Zpd93h4i0a_3Y0oDCGRdxiNx6iGwomsnTU4tqmgBM" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 17：上述同一集群的集群利用率增加至 83% 左右。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/4xMTrAtGQ4KGaHED3rgIgLPSWn3YMy25QcXsCD4uhPn3YT8M9_PiyKp7NVwdqqJexncQPxAdWg7EFk_jIQR8nYO0hPn-IAU7QA2ho2syCDMroCNi7jSpnCDXDSuYOCQgf3EcoTwV4vT-Spp1WraoKkk" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 18：由于算法更改，吞吐量增加了 3 倍以上。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;在 HDFS 集群中，数据可能会在不同 DataNode 之间出现偏差，并可能导致节点上的 I/O 较高，从而导致速度缓慢或下降，从而导致数据丢失。新算法将有助于更快地平衡数据节点，以实现更高的效率、服务可靠性和高性能，同时防止更高的缓慢概率、更高的节点故障风险和数据丢失。&lt;/p&gt;&lt;p&gt;在 Uber 中，我们将此更改部署到多个集群以提高平衡吞吐量。我们正在为我们的优化提供一个开源补丁。 Uber HDFS 团队继续致力于解决类似的数据分布问题 - 考虑到我们的规模，即使是很小的改进也可以带来巨大的收益。&lt;/p&gt;&lt;p&gt; [1] Uber 将具有不同访问温度的数据保留在专用集群中，以实现更好的可靠性和成本效率。我们应用热分层将数据从热集群移动到热集群，并采用EC转换将数据移动到具有纠删码功能的集群，从而节省了50%的容量。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;“Apache®、Apache Hadoop® 和 Hadoop® 是 Apache Software Foundation 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。”&lt;/em&gt;&lt;/p&gt;</description><pubDate>Thu, 14 Mar 2024 05:30:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/balancing-hdfs-datanodes-in-the-uber-datalake/</guid></item><item><title>【Load Balancing: Handling Heterogeneous Hardware】负载平衡：处理异构硬件</title><link>https://www.uber.com/blog/load-balancing-handling-heterogeneous-hardware/</link><description>&lt;h1 class="wp-block-heading" id="h-overview"&gt;&lt;strong&gt;概述&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;这篇博文描述了 Uber 通过更好的负载平衡来高效利用硬件的历程。这里描述的工作持续了一年多，涉及多个团队的工程师，并实现了显着的效率节省。这篇文章介绍了技术解决方案以及我们实现这些解决方案的发现过程——在很多方面，旅程比目的地更艰难。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-background"&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://www.uber.com/blog/better-load-balancing-real-time-dynamic-subsetting/" rel="noreferrer noopener" target="_blank"&gt;更好的负载平衡：实时动态子集 | Uber 博客&lt;/a&gt;是一篇相关的博客文章，早于此处描述的工作。我们不会重复背景知识——我们建议浏览一下我们的服务网格的概述。我们还将重复使用相同的字典。这篇文章重点介绍通过上述服务网格进行通信的工作负载。这涵盖了我们绝大多数的无状态工作负载。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-problem-statement"&gt;&lt;strong&gt;问题陈述&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;2020 年，我们开始致力于提高 Uber 多租户平台的整体效率。我们特别注重减少运行无状态服务所需的容量。在这篇博文中，我们将介绍各个团队做出的理性决策如何导致资源使用效率低下，我们如何分析问题和不同的方法，以及如何通过改进负载分配，让团队安全地提高 CPU 利用率并降低成本。这篇文章仅关注 CPU，因为这是我们的主要限制。&lt;/p&gt;&lt;p&gt;首先，了解一些背景：在 Uber，大多数容量决策都是去中心化的。虽然我们的平台团队提供了推荐的目标和工具（例如自动缩放器），但采用特定目标的最终决定取决于每个产品团队/组织。预算流程的存在是为了限制无限的分配。&lt;/p&gt;&lt;p&gt;作为预算过程的一部分，我们注意到我们认为利用率水平不合理地低。然而，提高利用率的尝试引起了产品团队的担忧——他们正确地担心提高利用率会危及系统的可靠性并影响其可用性/延迟目标。&lt;/p&gt;&lt;p&gt;问题的原因被认为是网络负载平衡不理想。许多工作负载的任务的 CPU 使用率高于平均水平。这些异常值在正常操作期间工作得很好，但在故障转移期间却很困难，并且不违反 SLA 的愿望导致我们的平均利用率下降。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/VPz0oGg-6KU9AQlKl7p6jeMb71w1ExYry6MeA5yDkQD_XQb62eP9S48IH_ZfGItt4tzYYz6TlzmYYaShRNRFe2x01S75ACNiS_T-OjaLcGO6FyfmyJF21eH0ks9v1fxPzvkBA-3cl0CGBKT3bY8oP-E" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：典型的“不平衡图”。每一行代表容器的 CPU 使用率。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/gV0L88878EKTUFagchXUUUkaTB0AieIEAzm4DDNKfjaATpUjMR_0yFE8vK-OY5w37lFhRS6DIRFZxEa-LE_pGYsk2PU4wQdEOfanI9pXjzqnAClzepSHXlA78fUwifiXWWF7QWlhc4Bo9WWf4g8-yfk" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：一个不太明显的情况：容器利用率分布在一个频带内，但有些容器的利用率高于其他容器。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-asymmetry-of-impact"&gt;&lt;strong&gt;影响不对称&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;负载不平衡的一个重要方面是&lt;strong&gt;其影响的不对称性&lt;/strong&gt;。想象一下这样的场景：100 个工作负载中，有 5 个工作负载未得到充分利用。这会影响效率，但成本相对较低——我们没有尽可能高效地使用 5% 的机器。&lt;/p&gt;&lt;p&gt;如果情况相反，同样的5个工作负载被&lt;em&gt;过度&lt;/em&gt;利用，情况会严重得多。我们可能会影响客户体验并可能影响系统的可靠性。避免这些热点的简单解决方案是降低整个集群的平均利用率。这现在将产生&lt;em&gt;更显&lt;/em&gt;着的影响： &lt;strong&gt;95% 的工作负载未得到充分利用&lt;/strong&gt;，这意味着（财务）资源的浪费更加严重。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-forest-and-the-trees"&gt;&lt;strong&gt;森林和树木&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;由于异常值很容易发现，我们最初专注于一一修复和追踪它们，试图尽快找出根本原因并单独修复每个问题。这些单独修复的结果并不总是符合预期。我们的一些更改的影响低于预期或仅影响系统的一部分。同样，后来的其他变化也带来了意想不到的重大改进。这是由于几个独立的问题正在发挥作用。这种“问题森林”导致工作基本上是连续的——只有在更大的兄弟问题得到解决后，我们才会发现一个新的、更小的问题。&lt;/p&gt;&lt;p&gt;回想起来，“意外”部分可以通过更严格的分析来减轻——我们可以更多地了解系统并提前收集更多样本。不过，工作的顺序可能是相同的——只有通过我们学习如何理解和衡量系统的过程。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-measuring-the-impact"&gt;&lt;strong&gt;衡量影响&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;也许令人惊讶的是，直到最后，该项目最具争议的方面之一就是衡量影响。讨论涉及来自不同团队和组织的人员在不同时间加入和离开该项目。每个相关方对问题、优先级和潜在解决方案都有有价值但略有不同的观点。&lt;/p&gt;&lt;p&gt;仅仅持续衡量影响就非常复杂。显然，我们应该测量异常值 - 我们很快决定使用给定工作负载中利用率排名第 99 位的任务的 CPU 利用率。经过一番讨论，我们同意使用平均值作为基础，留下 p99/平均值作为&lt;em&gt;不平衡指标&lt;/em&gt;。&lt;/p&gt;&lt;p&gt;然而，即便如此，也令人惊讶地含糊不清：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;工作负载在跨多个区域的多个集群中运行。 p99/平均值应该在所有实例中计算还是单独为每个集群计算？如果是针对每个集群，我们如何权衡结果？这一决定&lt;em&gt;极大地&lt;/em&gt;影响了最终的数字。&lt;/li&gt;&lt;li&gt;工作负载在多个区域中运行，但与区域不同的是，我们的区域表现出很强的隔离性——向何处发送流量不受网络控制。因此，网络团队可能关心与业务不同的指标。&lt;/li&gt;&lt;li&gt;典型的工作负载具有周期性模式——服务可能在一周中的特定一天最繁忙，而在其他时间则未得到充分利用。我们应该只测量高峰时的不平衡情况还是全天测量不平衡情况？如果处于高峰期，多长时间的时间范围应被视为高峰期？我们只关心单周峰值吗？&lt;/li&gt;&lt;li&gt;我们的工作负载通常以主动-主动模式运行，每个区域都有一些备用容量用于潜在的故障转移。在这些故障转移期间，负载不平衡最为重要——我们是否应该在那时才尝试测量它？如果是这样，我们的测量频率将会减少——通常，我们每周都会得到一个简单的样本。&lt;/li&gt;&lt;li&gt;工作负载很吵。服务推出通常会导致不平衡峰值（随着新容器的到来并预热）。某些工作负载可能会很快推出（每次增量），但每天会通过 CD 管道推出数十次。其他工作负载要慢得多，单次部署可能需要几个小时。两种类型的推出都可以与高峰时间重叠。最重要的是，还有“非典型事件”，例如临时性能下降、流量耗尽、负载测试或与事件相关的问题。&lt;/li&gt;&lt;li&gt;大多数工作负载遵循“标准”模式，但一些（更关键的）服务已被划分为具有单独路由配置的自定义分片。同样，一小部分基本工作负载还可以通过自定义对等路由进行访问。最后，另一小部分服务在专用主机上运行。这些尺寸可能会影响我们的跟踪。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;一旦我们确定了每个工作负载指标，问题就会扩展到多服务：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们如何权衡最终得分中的各个工作负载？&lt;/li&gt;&lt;li&gt;每个服务的等级（优先级）如何影响其在最终得分中的权重？&lt;/li&gt;&lt;li&gt;不同的工作负载具有不同的周期模式这一事实是否会影响分数？工作负载通常有每周和每日的峰值，但这些峰值不是同时出现的。&lt;/li&gt;&lt;li&gt;我们能否将最终指标分解为子组件来跟踪各个区域或集群的不平衡情况？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些指标必须实时用于开发和监控——在这里，我们关心尽可能高的精度，通常是亚分钟级的。然而，相同的指标必须在很长一段时间内（数年）可用，我们需要将数据汇总成日大小的块，同时牢记之前的所有权重考虑因素。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-actual-numbers"&gt;&lt;strong&gt;实际数字：&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;最终，我们创建了一个“持续失衡指标”。对于每个工作负载，我们计算每分钟的 p99（例如，5 个核心）和平均（例如，4 个核心）CPU 利用率。结合容器的数量，我们可以计算出“浪费的核心”。对于上面的示例，10 个容器将导致 10*4=40（核心）&lt;em&gt;使用，&lt;/em&gt; (5-4)*10=10 个核心&lt;em&gt;浪费&lt;/em&gt;，最终指标为 1+10/40=1.25。这直观地映射到人类在实时调试时可以执行的“标准”p99/平均计算 125%。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/ZyU1H3XwK_fGjpDhsyhcKROE_XnjnbhmTKc_AkW1b-yvzLpTJ4TbnDiAqQ_b5jcOhM-4RFnaqrjVTFUHfNVqCRgh_299GXdMaUQeRX5Ca8eGP8mO8WrGDaHoo77l1OL5uOJJjHnNCFIqUEh3EgnzauY" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：不平衡的理论定义。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;随着时间的推移，这实际上变成了两条曲线下的面积比：p99 和平均利用率。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/Ed94kW9bEsKmlR9f6liB9hLJFJTRA2eWNbC61KrTCvqjRR16FF_17rG_29z2qqzrzobImlGT0S-GrF0ISBBjWaXnEV2TGRwIMFr_8R3E4lM5D1exq-LUcqAw4YjIVVjoVFbRYXowXbpESs_2zLlcIUM" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：实时仪表板上的连续不平衡指示器。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;这种方法的好处是，由于浪费和利用率是按核心的绝对数量计算的，因此它允许我们以自定义的任意维度聚合它们：每个服务、每个服务每个集群、每组服务、每个集群、每个区域。同样，任何时间窗口（小时、天、周）自然有效——就像对一系列整数求和一样简单。此外，该指标自然会给予“繁忙”时段更高的权重——高峰期的不平衡比非高峰期的不平衡更为严重。缺点是难以向人类解释该指标，但我们发现“加权 p99/平均值”的近似值是可以接受的。&lt;/p&gt;&lt;p&gt;另一种计算“每周 p99 的 p99”和“每周平均值”的比率的方法更容易在单个服务的基础上进行解释，但对随机事件（耗尽、故障转移、负载测试、部署）高度敏感，这让它变得很吵。此外，跨服务加权并不那么简单。&lt;/p&gt;&lt;p&gt;上述指标可通过 Grafana 中的实时指标和 Hive 中的长期存储来获取。我们需要编写自定义管道来每天预处理指标以实现可视化。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-different-slicing"&gt;&lt;strong&gt;不同切片&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;关于测量负载不平衡的一个特殊问题值得指出：如何分割数据会极大地影响结果。人们很容易从小部分（集群、区域、区域）开始，然后“平均”不平衡。遗憾的是，这在实践中行不通。例如，两个集群的（平均）p99/平均比率可能为 110%，但是当纵观整个工作负载时，不平衡可能要高得多，在我们的案例中高达 140%。同样，将两个较高不平衡性的集群组合起来可能会导致较低的不平衡性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-addressing-the-issues"&gt;&lt;strong&gt;解决问题&lt;/strong&gt;&lt;/h1&gt;&lt;h2 class="wp-block-heading" id="h-the-first-step-getting-hacky-data-first"&gt;&lt;strong&gt;第一步：首先获取（hacky）数据&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;我们首先构建 Grafana 仪表板以实现实时可观察性。这使我们能够实时单独衡量每个服务的影响，但无助于理解根本原因。虽然假设负载平衡有问题，但我们“真的”不知道。最初的问题是缺乏可观察性，我们面临两个问题。&lt;/p&gt;&lt;p&gt;首先，由于基数问题，我们的负载均衡器没有按每个后端实例发出统计信息。由于许多服务运行数千个容器和数百个程序，这会导致我们的代理中的内存使用量爆炸，并使统计数据无法查询，即使是中等规模的服务。幸运的是，那个夏天的一个实习生项目添加了在新的指标命名空间（保持现有统计数据不变）上选择性加入的统计数据（节省代理内存使用）的能力。与&lt;a href="https://chronosphere.io/learn/how-can-recording-and-roll-up-rules-help-your-metrics/" rel="noreferrer noopener" target="_blank"&gt;汇总规则&lt;/a&gt;一起，我们现在可以内省大多数服务（只要我们一次只为其中一些服务启用额外的可见性）。&lt;/p&gt;&lt;p&gt;其次，我们失去了跨计算和网络堆栈唯一识别实例的能力。当时，我们可以看到每个目标的 CPU 使用情况，但无法轻松地将其映射到容器。由于我们广泛的 IP 目标范围和动态端口使用&lt;em&gt;，主机：端口&lt;/em&gt;的可用“唯一标识符”会破坏我们的指标（同样， &lt;a href="https://chronosphere.io/learn/what-is-high-cardinality/" rel="noreferrer noopener" target="_blank"&gt;基数&lt;/a&gt;）。关于适当解决方案的讨论此前已停滞了几个季度。最终，网络堆栈实现了一个基于 IP 地址排序和发出基于整数的实例 ID 的短期解决方案。这些在部署中并不稳定，但加上一些更黑客的脚本，使我们能够获取所需的数据。&lt;/p&gt;&lt;p&gt;这一步提供了重要的教训：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;始终首先获取数据&lt;/li&gt;&lt;li&gt;恰到好处、有针对性、孤立的黑客攻击可能非常有用&lt;/li&gt;&lt;li&gt;您不需要完美的可观察性来得出正确的结论&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-manual-analysis"&gt;&lt;strong&gt;手动分析&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;一旦我们深入了解了这个问题，我们就挑选了一些大型服务并尝试分析根本原因。令人惊讶的是，负载平衡并没有出现问题——在 1 分钟窗口（我们当时的 CPU 统计分辨率）下，RPS 分布几乎是完美的。每个容器接收的请求数量几乎相同，大多数应用程序的差异低于 0.1%。然而，在同一窗口内，CPU 利用率差异很大。&lt;/p&gt;&lt;p&gt;经过几周的调查，我们能够量化几个独立的原因：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一些重要的流量来源被迫失衡。例如，我们的许多系统都是“城市感知”的，城市总是位于单个区域。这自然会为每个地区带来不同的交通量，并且随着城市的醒来和入睡，比例不断变化。&lt;/li&gt;&lt;li&gt;服务跨集群内和跨集群的多个硬件 SKU 运行。&lt;/li&gt;&lt;li&gt;即使理论上相同的硬件也表现出显着的性能差异。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;一些不平衡被留在“未知”的桶中。事实证明，其中大部分是我们的可观察性问题。我们目前将剩余部分（小于原​​始不平衡的 20%）归因于&lt;a href="https://en.wikipedia.org/wiki/Cloud_computing_issues#Performance_interference_and_noisy_neighbors" rel="noreferrer noopener" target="_blank"&gt;嘈杂的邻居&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;下图显示了对 2020 年我们最大的服务之一的初步分析。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/IovK_kUSNl_76Da7EKegaYqylzW4OiEV2s09RUzrt8Ow18SAqVzjyVT2Wrj3HNseZCmCS_J1WN-NQ0tNJAbVO5OvknwSFOnFDpAmldb5QDSGtTrFedRGz9OBgOnX2aMe1ymxQui-d4sEXFATK81vruM" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：了解不平衡。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-forced-to-build-long-term-aggregations"&gt;&lt;strong&gt;被迫建立长期聚合&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;那时，我们想从任何容易实现的目标开始。 &lt;a href="https://www.uber.com/blog/better-load-balancing-real-time-dynamic-subsetting/" rel="noreferrer noopener" target="_blank"&gt;更好的负载平衡：实时动态子集 | Uber 博客&lt;/a&gt;为我们提供了一些可以调整的旋钮。然而，这并不容易，反而提出了一个新问题。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/AHpjR9Jv7KdKJ-xuaOkLWwL9iswUHo2Of3qYZlMnURcDdhlawPN6XfL9pf96j3rFVjclApy_BT1IOEfX1w7HHzVBiuljPda6NKXGWgzQ839BfeZw53O1AYa-hYsk0qgq-2cAIEIF5RcnyaKf5ETUuSo" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：单个服务的每周 CPU 使用率模式。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们的服务表现出每日和每周的大量周期（见上文）。最重要的是，我们经常看到由故障、部署、故障转移或临时事件引起的峰值。推出更改后，人类只能发现巨大的改进（20%+），但我们的更改太微妙了。&lt;/p&gt;&lt;p&gt;这导致了前面段落中解释的可观察性决策。我们构建了基于稳定和峰值弹性指标来聚合长期数据的管道。最重要的是，我们可以按集群、区域、区域或服务组对指标进行切片——这反过来又可以让我们调查更多“可疑”行为。&lt;/p&gt;&lt;p&gt;一些预先存在的旋钮可以让我们减少服务网格引起的负载不平衡部分，但这只是整个问题的一小部分。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-possible-solutions"&gt;&lt;strong&gt;可能的解决方案&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;显然，第一步是查看底层硬件配置和操作系统设置。一些单独的线程开始研究这些。&lt;/p&gt;&lt;p&gt;解决硬件异构性需要更复杂的过程。许多方法都是可能的，来自：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;修改&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/sec-cpu" rel="noreferrer noopener" target="_blank"&gt;CFS 参数&lt;/a&gt;，使队列中的每个主机看起来相同，尽管底层硬件不同。&lt;ul&gt;&lt;li&gt;这个选项很有吸引力，但由于对各种软件堆栈（如&lt;a href="https://pkg.go.dev/runtime#GOMAXPROCS" rel="noreferrer noopener" target="_blank"&gt;GOMAXPROCS&lt;/a&gt; ）的影响不明确，最终被驳回。回想起来，这也阻止了我们使用&lt;a href="https://www.uber.com/blog/avoiding-cpu-throttling-in-a-containerized-environment/" rel="noreferrer noopener" target="_blank"&gt;cpu 集进行配置。&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;修改主机到群集的放置以实现统一的群集。&lt;/li&gt;&lt;li&gt;修改每个服务的集群布局以保证稳定但不统一的主机选择。&lt;/li&gt;&lt;li&gt;转向云式主机管理，每个团队将选择特定类型的硬件。&lt;/li&gt;&lt;li&gt;许多可能的服务网格更改可以实现更好的负载&lt;em&gt;平衡&lt;/em&gt;。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="Screenshot of a spreadsheet, fields colored by the feasibility" src="https://lh7-us.googleusercontent.com/YC4s0sGZby4epTYOC36Um_cXU12K4MNkNHr_RSpt31Nijf4xB2IrGiPs3TJosQOVCrfsNnNov_ym5o2A9SLApgHEQl3u3Uu_JpuEHsh4w2gHuytW0lxB09_iU0oOdzf0p_6tpnAq7muT8DtwhUhcBcw" title="可能的修复（故意不可读）" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：选项矩阵（故意模糊）&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;在可能的选项中，出于多种原因选择了对服务网格进行更改。从技术上讲，我们层上的更改不需要更改数据中心的物理布局，也不需要每个服务的迁移。从战术上讲，我们还可以快速地将更改交付给大多数服务。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-changes"&gt;&lt;strong&gt;变化&lt;/strong&gt;&lt;/h1&gt;&lt;h2 class="wp-block-heading" id="h-hardware"&gt;&lt;strong&gt;硬件&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;虽然硬件 SKU 内存在根本差异，但我们发现硬件、固件和低级软件存在许多问题。它们的范围包括操作系统设置、CPU 调速器设置、固件版本、驱动程序版本、CPU 微代码版本，甚至内核版本与 Intel HWP 不兼容。造成这种情况的一个普遍根本原因是，从历史上看，一旦硬件被摄取并出现在机群中，除非出现问题，否则它就不会受到影响。但随着时间的推移，这导致了机器之间的漂移。&lt;/p&gt;&lt;p&gt; Uber 在混合云/私有设置中运行，因此我们自然也遇到了特定于云的问题。与其他公司一样，我们已经看到了多个理论上相同配置的虚拟机性能不相似的情况（ &lt;a href="https://www.reddit.com/r/aws/comments/547xbx/netflix_found_5x_performance_variation_between/" rel="noreferrer noopener" target="_blank"&gt;这&lt;/a&gt;仍然是真实的）。同样，我们也看到过在本地运行良好的工作负载在云上引发问题的情况。更糟糕的是，云意味着底层基础设施细节的可见性降低。&lt;/p&gt;&lt;p&gt;如果没有最近完成的&lt;a href="https://www.uber.com/en-IN/blog/crane-ubers-next-gen-infrastructure-stack/" rel="noreferrer noopener" target="_blank"&gt;Crane 项目&lt;/a&gt;，解决所有这些问题几乎是不可能的——我们可以在没有人工参与的情况下测量、修复和推出对数万台机器的更改。现在，所有发现的问题都会被自动检测和修复。&lt;/p&gt;&lt;p&gt;这些修复的一个明显好处是它们适用于每个工作负载，无论它如何处理或发起其工作（Kafka、Cadence、RPC、计时器、批处理作业等）。除了改善负载不平衡之外，它们还为我们提供了有效的可用容量——一些 CPU 一夜之间“变得更快”。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-observability"&gt;&lt;strong&gt;可观察性&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;可观察性是这个问题的一个有趣的部分。在项目开始之前，我们知道由于 1 分钟窗口大小，我们在样本收集方面存在限制，但我们发现了更多问题。&lt;/p&gt;&lt;p&gt;从技术上讲，这些问题是由&lt;a href="https://en.wikipedia.org/wiki/Cgroups" rel="noreferrer noopener" target="_blank"&gt;cgroups、&lt;/a&gt; &lt;a href="https://github.com/google/cadvisor" rel="noreferrer noopener" target="_blank"&gt;cexporter&lt;/a&gt; 、我们内部&lt;a href="https://prometheus.io/" rel="noreferrer noopener" target="_blank"&gt;Prometheus&lt;/a&gt;指标抓取器和&lt;a href="https://github.com/m3db/m3" rel="noreferrer noopener" target="_blank"&gt;m3&lt;/a&gt;之间的交互引起的。特别是，由于指标以不断增加的方式发出，管道中任何地方统计数据收集的任何延迟都会导致百分位数计算中出现（大的）人为峰值。我们投入了大量的工作来保留样本的时间戳以及妥善处理目标和收集器服务的重新启动。一个示例 &lt;a href="https://github.com/google/cadvisor/issues/2913" rel="noreferrer noopener" target="_blank"&gt;问题&lt;/a&gt;是有效地破坏了任何足够大的服务的数据收集。&lt;/p&gt;&lt;p&gt;可观察性问题的一个令人着迷的方面与人类互动有关，或者说人类不可信这一事实。在项目早期，我们询问服务所有者什么级别的容器利用率会导致用户影响（延迟增加）。有趣的是，几个月后，当我们推出修复程序后，当我们再次询问时，我们收到了相同的答案。这两种说法都无效，因为我们知道旧数据是错误的。最终，人类的非理性导致了净效率的胜利：服务所有者最终（有效地）更热地运行他们的服务，同时认为什么都没有改变。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-load-balancing"&gt;&lt;strong&gt;负载均衡&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;正如&lt;a href="https://www.uber.com/blog/better-load-balancing-real-time-dynamic-subsetting/" rel="noreferrer noopener" target="_blank"&gt;更好的负载平衡：实时动态子集 |&lt;/a&gt;中所述。 &lt;a href="https://www.uber.com/blog/better-load-balancing-real-time-dynamic-subsetting/" rel="noreferrer noopener" target="_blank"&gt;Uber 博客&lt;/a&gt;，我们的服务网格在两个层面上工作。最初，控制平面发送&lt;em&gt;分配&lt;/em&gt;决定应向每个目标集群发送多少流量。这里决定了簇之间的不平衡性。&lt;br /&gt;随后，数据平面遵循此分配，但随后它负责选择正确的主机 - 这里发生第二级集群内负载平衡。虽然我们考虑改变这个模型，但我们保持不变，并为每个级别推出了两种解决方案。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-inter-cluster-imbalance"&gt;&lt;strong&gt;集群间不平衡&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;在 Uber，服务在多个地区的多个区域运行。由于每个区域在不同的时间出现，因此无法保证每个区域中的主机相同 - 通常，区域越新，它们拥有的硬件就越新。区域之间的性能差异会导致CPU不平衡。&lt;/p&gt;&lt;p&gt;我们最初的方法是为每个区域设置一个静态权重；然后，权重将用于负载平衡，以便具有更快硬件的区域接受更多请求。每个区域的权重计算为该区域中部署的每个主机的标准化计算单元 (NCU) 因子的平均值。 NCU 因子根据基准分数衡量主机 CPU/核心性能，其中分数取决于每周期核心指令（每个时钟周期核心完成多少工作）和核心频率（多少个时钟周期）的乘积每秒可用）。&lt;/p&gt;&lt;p&gt;然后，我们可以使用静态区域权重作为乘数，将更多流量发送到更强大/更快的区域。&lt;/p&gt;&lt;p&gt;具有更高乘数的更快区域将按比例路由更多流量，以提高 CPU 利用率，从而缓解 CPU 不平衡。&lt;/p&gt;&lt;p&gt;例如，如果某个服务在区域 A（权重 = 1）和 B（权重 = 1.2）中部署了 10 个实例，则负载均衡将按照 B 有 12 (10 * 1.2) 个实例进行，这样 B 将收到更多请求比 A。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/L22FN7eamJeUaNg5UhAokiSDGFniHnCMQqexYTjB-BIGI_bUVBreGefBUA1dqB3iOcbUUe6rVj9noQvx3Doqxjqigl7GkEk0aEYDYIOYmAVv9crDdtH6vwqrnQSwazMEU5nwjggUTjsRrhyDKWPqNkA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：区域权重&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;这种方法的效果出人意料地好——我们能够以相对较小的努力缓解大部分不平衡问题。然而，存在一些问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;区域权重是区域中所有主机的估计值（平均 NCU 因子）。然而，服务部署在区域中最快/最慢的主机上可能非常幸运/不幸。&lt;/li&gt;&lt;li&gt;尽管不经常发生，但我们经营的区域会因开工或停工而发生变化。此外，在启动期间，我们通常会逐渐摄取硬件，这可能需要多次更新。&lt;/li&gt;&lt;li&gt;有时，我们会将新硬件引入旧区域以调整其大小或更换损坏的硬件。该硬件可以是不同类型的，因此需要调整权重。&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-dynamic-host-aware-cluster-load-balancing"&gt;&lt;strong&gt;动态主机感知集群负载平衡&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;因此，我们重新审视了这个问题，并投资了一种先进的解决方案：主机感知流量负载平衡。&lt;/p&gt;&lt;p&gt;这种方法通过查看服务实例部署到的确切主机、收集其服务器类型，然后更新每个服务的集群之间的负载平衡来解决这些缺点。这是通过让我们的发现系统了解主机（通过 IP）、其主机类型和权重的映射来实现的，这样对于部署在集群中的给定服务，发现系统可以向我们的流量控制提供额外的权&lt;strong&gt;&lt;em&gt;重&lt;/em&gt;&lt;/strong&gt;信息系统。下图显示了一个示例： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/BTH2IqexwVovC1iquHIIHhv744jyBweDXUPMKK4a5bDezGdqTbhfxk3SVVl5SZCz5bvZhFdg1td0ptbM1Hmy5SxzxxRBkDstE-jwYQzPSWQIPoukzhtztVliK1Gp6f3k6VUM6uSH5jLKGOsew_h7eH8" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：动态主机感知集群负载平衡&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;对于服务 Foo，如果我们平等对待每个实例，负载均衡比例应该为&lt;strong&gt;37.5&lt;/strong&gt; %/ &lt;strong&gt;62.5&lt;/strong&gt; %，而不是示例中所示的&lt;strong&gt;&lt;em&gt;36&lt;/em&gt;&lt;/strong&gt; %/ &lt;strong&gt;&lt;em&gt;64&lt;/em&gt;&lt;/strong&gt; %。如果主机跨越多代（我们的机群中不同主机之间的权重差异高达 2 倍），则差异可能会变得更加显着。&lt;/p&gt;&lt;p&gt;与静态权重方法相比，主机感知负载平衡动态调整每个服务的权重，以减少集群间的不平衡。由于很少引入新的主机类型，因此维护起来也更加容易。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-intra-cluster-imbalance"&gt;&lt;strong&gt;集群内不平衡&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;如前所述，集群内不平衡是主机上代理（称为 Muttley）的责任。每个代理都可以完全控制为每个请求选择正确的对等点。所有服务使用的 Muttley 原始负载平衡算法是最少挂起的，该算法会将请求发送到已知未完成请求数量最少的对等点。虽然以 1 分钟为间隔测量时，这导致了 RPS 几乎完美的平衡，但由于不同的硬件类型，它仍然导致 CPU 利用率不平衡。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-assisted-load-balancing-alb"&gt;&lt;strong&gt;辅助负载平衡 (ALB)&lt;/strong&gt; &lt;/h3&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/_CL-GbcOXQlLQSs4Aq-a2Q7NaKUOA7HjoTu_P_nt0NnJM1biDm26uHcmmuVlePy5vgZenjeQsxii3KraWa3AU6ixB51OUDJehHqHMBQaM5co9vnXPy4AokvL1plsofFDmuqISUQ2drgx9sPcZylHFiQ" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 10：辅助负载平衡简而言之。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们构建了一个系统，其中每个后端&lt;em&gt;协助&lt;/em&gt;负载均衡器选择下一个对等点。应用程序中间件层将负载元数据作为标头附加到每个响应。我们有效地达成了一个无需中央协调的协调系统。以前，每个 Muttley 只知道它造成的负载（加上它可以从延迟推断出的一些信息），现在，它动态地了解每个后端的总状态。这种状态不仅受到后端本身的影响（例如，在较慢的硬件上运行），而且还受到其他 Muttley 做出的决策的影响。例如，如果（随机）将后端选择到太多子集中，则系统会动态调整。这让我们稍后可以减少 ALB 上服务的子集大小。&lt;/p&gt;&lt;p&gt;虽然&lt;a href="https://sre.google/sre-book/load-balancing-datacenter/#weighted-round-robin-eKspTGCm" rel="noreferrer noopener" target="_blank"&gt;Google SRE 书中&lt;/a&gt;的简短提及部分启发了这种方法，但我们做出了一些不同的选择。这两项更改彼此相关，并试图简化该方法。我们打算稍后开始、评估并转向更复杂的解决方案 - 幸运的是，我们不必这样做。在实施后期，我们发现了一篇&lt;a href="https://netflixtechblog.com/netflix-edge-load-balancing-695308b5548c" rel="noreferrer noopener" target="_blank"&gt;Netflix 博客文章&lt;/a&gt;，并且我们独立得出了类似的结论。&lt;/p&gt;&lt;p&gt;首先，作为负载元数据，我们使用正在处理的并发请求数，以整数形式报告（q=1、q=2、..、q=100 等）。我们也考虑了报告利用率，但这并不是立即显而易见的（报告的利用率是否应该基于&lt;a href="https://man7.org/linux/man-pages/man2/getrusage.2.html" rel="noreferrer noopener" target="_blank"&gt;getrusage&lt;/a&gt;还是&lt;a href="https://en.wikipedia.org/wiki/Cgroups" rel="noreferrer noopener" target="_blank"&gt;cgroups）。&lt;/a&gt; Cgroup 更为自然，因为服务所有者使用它来跟踪他们的目标。尽管如此，它们还是带来了更多挑战——我们的基础团队担心每个 docker 容器独立抓取 cgroup 的成本，以及如果 cgroup 布局发生变化（包括在 cgroupsv2 迁移期间）可能发生的紧密耦合。我们可以通过与收集统计数据的主机恶魔集成来解决这个问题，但我们希望避免添加新的运行时依赖项。最后，仅使用逻辑整数就足够了（进行一些调整，如下所述）。此外，它允许在不更改负载均衡器代码的情况下覆盖每个服务 - 虽然绝大多数应用程序使用标准负载指示器，但一些（异步）应用程序覆盖它以更好地反映其负载。&lt;/p&gt;&lt;p&gt;第二个出发点是&lt;a href="https://www.eecs.harvard.edu/~michaelm/postscripts/handbook2001.pdf" rel="noreferrer noopener" target="_blank"&gt;两个随机选择的力量，&lt;/a&gt;而不是加权循环赛。由于我们只有一个整数作为负载指示器，所以 pick-2 实现看起来更简单、更安全。与上面类似，这运行得很好，我们不需要改变它。事实证明，这种方法对我们整个应用程序范围内的故障非常宽容。除了典型的崩溃循环或 OOMing 应用程序之外，我们还遇到过中间件的错误/错误实现未导致事件的情况。我们推测，由于加权循环法更加精确和“严格”，因此在某些情况下它可能会表现“更好”，但可能会导致类似&lt;a href="https://en.wikipedia.org/wiki/Thundering_herd_problem" rel="noreferrer noopener" target="_blank"&gt;雷群&lt;/a&gt;的情况。&lt;/p&gt;&lt;p&gt;在实施方面，每个 Muttley 使用&lt;a href="https://en.wikipedia.org/wiki/Moving_average#Modified_moving_average" rel="noreferrer noopener" target="_blank"&gt;修改后的移动平均值&lt;/a&gt;来保持每个对等点的分数超过 25 个之前的请求——这个值在我们的测试中效果最好。为了在 RPS 较低的情况下获得有意义的数字，我们将每个报告的负载增加了 1000。&lt;/p&gt;&lt;p&gt; pick-2 负载均衡器的一个有趣问题是“负载最多”的对等点&lt;em&gt;永远&lt;/em&gt;不会被选择。而且因为我们被动地发现对等点负载，所以我们也会刷新其状态，从而使其有效地未被使用，直到另一个对等点变得更慢。我们最初通过实施“失败者惩罚”来缓解这一问题，每当一个节点失去选择时，其“负载值”就会在内部减少——因此，如果有足够的损失，该节点将再次被选择。事实证明，这对于大调用者实例计数低 RPS 的场景效果不佳，有时需要几分钟才能重新选择对等点。最终，我们将其更改为时间衰减，其中同行的分数根据上次选择时间而降低。我们目前使用 5 秒的半衰期来进行分数衰减。&lt;/p&gt;&lt;p&gt;我们还实现了一项内部称为“吞吐量奖励”的功能。这源于经验观察，即较新的硬件可以更好地处理并发请求。我们注意到，当不同硬件上的两个对等点之间进行负载平衡并且两个对等点报告相同的“负载值”时，我们如预期的那样，向速度更快的对等点发送更多请求。但是，较快对等点的 CPU 利用率（已处理=15，CPU=10%，Q=5）仍低于较慢对等点（已处理=10，CPU=12%，Q=5）。为了弥补这一点，每次对等点“完成”一个请求时，我们都会稍微减少其负载以向其推送更多请求。对等点相对于子集中其他对等点的速度越快，它获得的“吞吐量奖励”就越多。此功能使 P99 CPU 利用率降低了 2%。&lt;/p&gt;&lt;p&gt; ALB 设计文档的一个重要部分（大部分）致力于可能的替代方案。我们认真考虑过，不是将负载元数据附加到每个响应，而是使用中央组件来收集和分发数据。人们担心元数据可能会消耗大量可用带宽。我们内部有两个表面上看起来相关的系统。第一个是集中式健康检查系统，几乎实时收集车队中每个集装箱的健康状态。第二个是上一篇博文中描述的实时聚合系统。&lt;/p&gt;&lt;p&gt;&lt;br /&gt;事实证明，重用其中任何一个都是不可行的：健康检查系统可以轻松地从所有容器收集负载状态，但收集后，该系统被设计为很少分发健康变化——绝大多数时间，容器仍然存在健康。然而，负载平衡指标会根据设计不断变化。由于我们运行平面网格（每个容器都可以与每个容器通信），因此我们需要不断地将数百万个容器的数据分发到数十万台机器，或者构建一个新的聚合和缓存层。同样，负载报告聚合系统也不匹配——它以低几个数量级的基数对每个集群的聚合值进行操作。&lt;/p&gt;&lt;p&gt;&lt;br /&gt;最终，我们对所选择的（基于响应标头）方法感到满意。它实施起来很简单，并且使成本归因变得容易——推动更多 RPS 的服务会看到更高的带宽成本。从绝对数字来看，与每个请求附加的其他跟踪/身份验证元数据相比，额外元数据（每个请求约 8 个字节）的成本几乎是看不见的。&lt;/p&gt;&lt;p&gt;延迟是“分布式”与“集中式”负载数据收集的一个有趣的方面。从理论上讲，响应标头方法接近实时，因为负载附加到每个响应。然而，由于每个 Muttley 都需要独立发现这一点，然后对之前的响应进行平均，因此对于基于低 RPS 的场景，该发现可能需要一些时间。基于健康检查的方法需要完整的往返（通常约为 5 秒），但会立即分发到所有调用方实例。&lt;/p&gt;&lt;p&gt;&lt;br /&gt;然而，如果我们实现了它，由于上一段中列出的带宽问题，我们可能会将推送频率降低到 1 分钟左右。这可能足以修复硬件引起的偏斜，但可能没有其他问题，例如流量峰值，较慢的应用程序或故障转移。在不同情况下，两种方法的工作可能略有不同。不过，最终，我们对分布式方法很满意 - 它很容易推理，并且缺少可能失败的集中组件。&lt;/p&gt;&lt;p&gt;所选方法的一个缺点是它需要目标服务的合作。尽管需要最少的工作，但将其应用于数千个微服务将很艰巨。幸运的是，过去几年在Uber建造的大多数应用程序都使用了&lt;a href="https://github.com/yarpc/yarpc-go" rel="noreferrer noopener" target="_blank"&gt;通用框架&lt;/a&gt;，使我们能够快速插入所需的中间件。几项大型服务没有使用框架，但是同时进行的多年努力迁移了几乎所有服务。我们发现决定有利于该框架的决定，因为它具有复杂的效果 - 服务所有者还有一个理由投资移民。到我们写这篇文章时，几乎所有服务都在共同的框架上。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-static-component-alb-v1-1"&gt;&lt;strong&gt;静态组件 -  Alb V1.1&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;最初的推出不符合我们硬件引起的减少目标。主要原因是我们的硬件在大多数时间中都充分利用了不足 - 我们为区域故障转移和每周窥视提供了缓冲区。事实证明，凭借相对较低的容器利用率，旧硬件可能会爆发足够高，以使延迟差异在消耗更多的CPU时间时不可见期。尽管这意味着在压力下（当我们需要时）载荷平衡的效果要好得多，但它使产品工程师对我们的目标利用感到不舒服，但不平衡的不平衡看上去太高了。&lt;/p&gt;&lt;p&gt;我们在负载平衡中添加了第二个静态组件来解决这个问题。我们利用了一个事实，即在我们的设置中，主机的IP地址永远不会改变。由于代理自然知道目的地的IP地址，因此我们只需要将IP地址映射到相对主机性能。由于数据的静态性质，我们开始添加此信息作为构建时间配置的一部分。这种重量本身并不完美：不同的应用程序在相同的硬件类型上的性能不同。但是，结合ALB的动态部分，这效果很好 - 我们不需要添加特定于应用程序的权重。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-testing"&gt;&lt;strong&gt;测试&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;开发过程中的一个大问题是测试。虽然我们的登台环境有限，但需要使用许多参数的新解决方案：一些呼叫者或卡勒斯有三个实例，约三千个实例。一些后端的服务&amp;lt;1，有些后端&amp;gt; 1,000 rps。一些服务采用了一个同质的程序，而另一些服务的潜伏期从低毫秒到数十秒钟不等。最终，我们在生产中使用了虚拟服务，其中一组伪造的负载生成器配置为代表异构负载。在找到正确的参数并尝试推出生产服务之前，我们进行了300多个模拟。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-results"&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;我们对最终结果感到满意 - 确切的数字取决于服务和每个集群中的硬件混合物。尽管如此，平均而言，我们将P99 CPU利用率降低了12％，其中一些服务的收益超过30％。目标服务每个后端的目标服务越大 - 我们最关心的最大服务通常非常优化。同样的运气也适用于入职 - 虽然Uber拥有超过4,000个微服务，但入职前100名为我们带来了绝大部分潜在影响力。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-rollout-and-future-changes"&gt;&lt;strong&gt;推出和将来的变化&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;推广进行得很好 - 我们尚未确定材料错误。 Pick-2负载平衡和安全的后备被证明具有弹性。我们按地区划分的层面服务，试图找到代表性的服务类型。&lt;/p&gt;&lt;p&gt; Alb被推广到我们数百种最大的服务，并以最小的打ic或更改：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;em&gt;寿命长的RPC流&lt;/em&gt;。一小类服务正在将少量长寿命的RPC流与许多非常短暂的请求混合在一起。我们在那儿滚回去。&lt;/li&gt;&lt;li&gt;&lt;em&gt;缓慢启动的运行时间&lt;/em&gt;。推出大约两年后，我们对解决方案进行了调整以更好地处理缓慢启动（Java）服务。由于JIT，这些服务在启动后无法达到相同的请求率，但是记录的静态请求的热身效果不够好；我们需要以较低的速度使用真实请求来为服务加热。在这里，我们决定将每个同伴的初始“重量”播种，同时使算法的核心保持不变。我们发现这可以在各种服务中运行良好，我们很高兴这不需要任何静态窗口设置，与Envoy的&lt;a href="https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/upstream/load_balancing/slow_start" rel="noreferrer noopener" target="_blank"&gt;慢速启动模式&lt;/a&gt;不同，该算法会自动调整到一系列RPS。&lt;/li&gt;&lt;li&gt;&lt;em&gt;在启动时预取数据。&lt;/em&gt;另一个非常小的服务是在启动时预装静态数据几分钟。由于我们服务出版机制的特殊性，这些服务的实例在我们的服务发现中可见为“不健康”。旧算法强烈更喜欢健康的实例。当服务在临时超负荷后无法启动时，我们将其更改为ALB，以避免像雷声一样的情况（由于每个实例在依次变得健康时都会立即超负荷）。新算法非常喜欢健康的实例，但是在某些情况下，请求可能会发送给“不健康”节点。这对这些服务不起作用 - 虽然报告的错误&amp;lt;0.01％和0.002％，但我们正在探索与&lt;a href="https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/upstream/load_balancing/panic_threshold" rel="noreferrer noopener" target="_blank"&gt;恐慌阈值&lt;/a&gt;相似的变化，以使其完全消失。&lt;/li&gt;&lt;li&gt; &lt;em&gt;IP地址映射&lt;/em&gt;。 IP地址到服务器类型的静态映射工作2年以上，但是当我们&lt;a href="https://www.oracle.com/news/announcement/uber-selects-oracle-cloud-infrastructure-2023-02-13/" rel="noreferrer noopener" target="_blank"&gt;将工作负载移至云&lt;/a&gt;时，可能需要对其进行调整。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;有趣的是，两个服务覆盖了默认负载提供商，以根据后台作业处理来发射自定义负载指标。这证明了默认值在大多数服务方面效果很好，但是该解决方案足够灵活以支持其他用例。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-summary"&gt;&lt;strong&gt;概括&lt;/strong&gt;&lt;/h1&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/arrmQ21tVj4fLv6DVkrkdoYxp0bRT0f1Ab5Ha98zym8rjLVCbLymSXDdqyP_RJxBlIg5KE6zaAxzjYWdmgmq13h5M-GPgiEWTF5EczSNYkmFjn3sw0EiMlh97DhB32wtW0vjRSUqRGdPjC-rRQ_sebU" /&gt;&lt;figcaption class="wp-element-caption"&gt;图11：区域权重推出。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;该项目带来了非常重大的效率胜利。我们可以以较高的利用水平运行容器，而负载不平衡不再是无状态工作负载的问题。硬件配置的改进导致了减少失衡和纯计算能力的双重胜利。&lt;/p&gt;&lt;p&gt;更有趣的是，从工程博客的角度来看，该项目也导致了一些学习。&lt;/p&gt;&lt;p&gt;主要的是数据的重要性。问题是真实的，但是我们以错误的假设开始了该项目。我们不知道如何衡量它。一旦同意，我们就缺乏有效衡量它的工具，尤其是从长远来看。即使在那之后，我们也意识到我们从基础基础设施中收集样本的潜在方式也存在缺陷。同时，数据赢得了争论，帮助我们磨练问题，并将与其他团队的工作优先考虑。另一个数据课是为长期设置数据基础架构 - 在项目期间和之前也有所帮助。我们能够将现有的数据仓库用作基础，现在后来我们会定期收到有关负载不平衡的疑问。指向仪表板的链接通常回答所有问题。&lt;/p&gt;&lt;p&gt;第二堂课是在正确的位置添加解决方案，以获取我们需要的数据。建立适当的实时可观察性将花费我们数月或几个月的时间。尽管如此，我们很快就通过有针对性的黑客来得出了正确的结论，并有选择地将观察结果基于服务样本。与此相关的是愿意做很多手动咕unt的工作：为了建立理解，我们花了数周的时间盯着仪表板并在开始编码之前验证假设。后来，当实现ALB和区域/群集权重时，我们从相对较小的更改，经过验证的假设开始，然后迭代到下一个版本。&lt;/p&gt;&lt;p&gt;第三个可以说，第三次是可以信任平台的课程。我们打赌我们的微服务将迁移到共同的框架。同样，在实施时，我们建立了在平台上存在的多年投资（仪表板，仪表板，调试工具，操作知识，推出政策）的多年以上，我们可以快速，安全地进行重大变化。 。我们用平台的谷物构建，并避免了可能使该项目脱轨的重大重写。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-acknowledgments"&gt;&lt;strong&gt;致谢&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;该项目有很多人参与其中。我们感谢Avinash Palayadi，Prashant Varanasi，Zheng Shao，Hiren Panchasara和Ankit Srivastava的一般贡献。 Jeff Bean，Sahil Rihan，Vikrant Soman，Jon Nathan和Vaidas Zlotkus用于硬件帮助，Vytenis darulis可观察性修复程序，Jia Zhan和Eric Chung，用于Alb Reviews，Nisha Khater，Nisha khater，每年的lu yarpc for yarpc for yarpc for yarpc for yarpc全球。&lt;/p&gt;&lt;p class="has-small-font-size"&gt;徽标归因： &lt;a href="https://www.flickr.com/photos/141290938@N03" rel="noreferrer noopener" target="_blank"&gt;weiss_paarz_photos&lt;/a&gt;撰写的“ &lt;a href="https://www.flickr.com/photos/141290938@N03/26682754214" rel="noreferrer noopener" target="_blank"&gt;司法规模 - 法律 - 律师和律师&lt;/a&gt;”，根据&lt;a href="https://creativecommons.org/licenses/by-sa/2.0/?ref=openverse" rel="noreferrer noopener" target="_blank"&gt;CC BY-SA 2.0&lt;/a&gt;许可。&lt;/p&gt;</description><pubDate>Thu, 07 Mar 2024 07:00:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/load-balancing-handling-heterogeneous-hardware/</guid></item></channel></rss>