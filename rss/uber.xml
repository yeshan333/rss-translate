<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>优步工程博客</title><link>https://www.uber.com/blog/engineering</link><description>Uber 工程背后的技术 - 由 RSSHub 用爱制作(https://github.com/DIYgod/RSSHub)</description><lastBuildDate>Wed, 17 Apr 2024 06:00:37 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>将 Uber 的一万亿条账本数据从 DynamoDB 迁移到 LedgerStore</title><link>https://www.uber.com/blog/migrating-from-dynamodb-to-ledgerstore/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;上周，我们探索了&lt;a href="https://www.uber.com/blog/how-ledgerstore-supports-trillions-of-indexes/" rel="noreferrer noopener" target="_blank"&gt;LedgerStore&lt;/a&gt; (LSG)——Uber 的仅追加、分类账式数据库。本周，我们将深入探讨如何将 Uber 的关键业务账本数据迁移到 LSG。我们将详细介绍如何在不造成中断的情况下透明地移动超过一万亿个条目（构成几 PB 的数据），并且我们将讨论在迁移过程中学到的东西。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-history"&gt;历史&lt;/h3&gt;&lt;p&gt;湾流是 Uber 的支付平台。它&lt;a href="https://www.uber.com/blog/payments-platform" rel="noreferrer noopener" target="_blank"&gt;于 2017 年推出，&lt;/a&gt;使用 DynamoDB 进行存储。以 Uber 的规模，DynamoDB 变得昂贵。因此，我们开始在 DynamoDB 中仅保留 12 周的数据（即热数据），并开始使用 Uber 的 blobstore TerraBlob 来存储较旧的数据（即冷数据）。 TerraBlob 类似于 AWS S3。&lt;/p&gt;&lt;p&gt;对于长期解决方案，我们想使用&lt;a href="https://www.uber.com/blog/dynamodb-to-docstore-migration/" rel="noreferrer noopener" target="_blank"&gt;LSG&lt;/a&gt; 。它是专门为存储支付方式数据而构建的。其主要特点是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;它是可验证的不可变的（即，您可以使用加密签名检查记录是否未被更改）&lt;/li&gt;&lt;li&gt;分层存储以管理成本（热数据保存在最适合服务请求的位置，冷数据存储在针对存储优化的位置）&lt;/li&gt;&lt;li&gt;更好的延迟以实现最终一致的二级索引&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;因此，到 2021 年，湾流将使用 DynamoDB、TerraBlob 和 LSG 的组合来存储数据。&lt;/p&gt;&lt;ul&gt;&lt;li&gt; DynamoDB 过去 12 周的数据&lt;/li&gt;&lt;li&gt;TerraBlob，Uber 的内部 Blob 存储，用于存储冷数据&lt;/li&gt;&lt;li&gt;LSG，我们在其中写入数据，并希望迁移到它&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-why-migrate"&gt;为什么要迁移？&lt;/h2&gt;&lt;p&gt;由于 LSG 的不变性，它更适合存储分类帐类型的数据。迁移到 LSG 可以显着节省经常性成本。&lt;/p&gt;&lt;p&gt;从三个存储变为单个存储将简化负责与存储交互和创建索引的湾流服务的代码和设计。这反过来又使得服务的理解和维护变得容易。&lt;/p&gt;&lt;p&gt; LSG 承诺更短的索引延迟（即写入记录和创建辅助索引之间的时间）。此外，它还会给我们带来更快的网络延迟，因为它是在 Uber 数据中心内本地运行的。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/ImSq9jhPp_-uGFsvBU0tmJA1MiY42lmKUH1fLoNJ036l2w7W9uLx89xRnBO30l7lRkHXQ0XQv_flDWeZB0pfRyYzczFfayP_Vi4j217OZt8fG5WxpM2FKdt3lB34s0emy0gp6nUKNfS2q7MR5z8ZUbc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图1：迁移前后的数据流向&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-nature-of-data-amp-associated-risk"&gt;数据的性质和相关风险&lt;/h2&gt;&lt;p&gt;我们要迁移的数据是自 2017 年以来 Uber 所有业务的所有 Uber 账本数据：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;不可变记录 – 1.2 PB 压缩大小&lt;/li&gt;&lt;li&gt;二级索引 – 0.5 PB 未压缩大小&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不可变记录不应被修改。因此，出于所有实际目的，一旦我们编写了记录，就无法更改。我们确实可以灵活地修改二级索引数据来纠正问题。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="h-checks"&gt;支票&lt;/h2&gt;&lt;p&gt;为了确保回填在各个方面都是正确且可接受的，我们需要检查我们是否可以处理当前流量以及当前未访问的数据是否正确。其标准是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;完整性：所有记录均已回填。&lt;/li&gt;&lt;li&gt;正确性：所有记录均正确。&lt;/li&gt;&lt;li&gt;负载：LSG 应能够处理当前负载。&lt;/li&gt;&lt;li&gt;延迟：LSG 的 P99 延迟在可接受的范围内。&lt;/li&gt;&lt;li&gt;滞后：二级索引是在后台创建的。我们希望确保索引创建过程的延迟在可接受的范围内。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;检查是使用&lt;em&gt;影子验证&lt;/em&gt;和&lt;em&gt;离线验证&lt;/em&gt;相结合的方式完成的。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-shadow-validation"&gt;影子验证&lt;/h3&gt;&lt;p&gt;这将我们在迁移之前返回的响应与以 LSG 作为数据源返回的响应进行了比较。这有助于我们确保当前的流量不会因数据迁移问题或代码错误而中断。根据影子验证的测量，我们希望回填的完成度和正确率至少达到 99.99%。我们还设定了 99.9999% 的上限。设置上限的原因是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在迁移历史数据时，总会存在数据损坏的问题。有时这是因为在服务的初始开发期间数据写入不正确。由于规模的原因，也可能会出现数据损坏的情况。例如，S3 提供 11 个 9 的持久性保证，那么您可以预期 1 万亿条记录中会出现 10 次损坏。&lt;/li&gt;&lt;li&gt;索引最终是一致的，这意味着一些记录会在几秒钟后出现。因此，影子验证会将它们标记为丢失。这是大规模出现的误报。&lt;/li&gt;&lt;li&gt;对于 6 个 9，您必须查看 1 亿次比较的数据才能可靠地给出结果。这意味着，如果您的影子验证每秒比较 1,000 条记录，那么您需要等待一天以上才能收集足够的数据。如果有 7 个 9，则需要等待 12 天。实际上，这将导致项目陷入停滞。&lt;/li&gt;&lt;li&gt;有了明确定义的上限，您就不必被迫查看您怀疑的每个潜在问题。假设问题的出现次数是上限的 1/10，您甚至不需要调查它。&lt;/li&gt;&lt;li&gt;如果有 6 个 9，我们最终可能会得到略多于 100 万条的损坏记录。尽管确认 6 个 9 的正确性可能会给公司带来实际成本，但该项目带来的节省超过了潜在成本。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在影子验证期间，您实质上是在 LSG 上复制生产流量。因此，通过监控 LSG，我们可以验证它是否可以处理我们的生产流量，同时满足我们的延迟和滞后要求。它让我们对为访问 LSG 数据而编写的代码充满信心。此外，它还让我们对数据的完整性和正确性有一定的信心，特别是当前正在访问的数据。我们开发了一个通用影子验证代码，可以在迁移的不同部分多次重复使用。&lt;/p&gt;&lt;p&gt;在迁移过程中，我们发现了由于不同部分存在多个错误而导致的延迟和滞后问题，并修复了这些问题。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;分区键优化以更好地分布索引数据&lt;/li&gt;&lt;li&gt;索引问题导致扫描记录而不是点查找&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不幸的是，实时影子验证无法为我们很少访问的历史数据语料库提供强有力的保证。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-offline-validation-amp-incremental-backfill"&gt;离线验证和增量回填&lt;/h3&gt;&lt;p&gt;这会将来自 LSG 的完整数据与来自 DynamoDB 的数据转储进行比较。由于各种数据问题，您必须跳过不良记录以确保您的回填能够通过。此外，回填作业本身也可能存在错误。离线验证可确保数据回填正确发生并覆盖完整数据。除了影子验证之外，还必须执行此操作，因为实时流量往往只访问最近的数据。因此，如果不经常访问的冷数据中潜伏着任何问题，影子验证将无法捕获它。&lt;/p&gt;&lt;p&gt;离线验证的关键挑战是数据大小。我们处理的最大数据大小为 70 TB 压缩数据（估计未压缩数据为 300 TB），并且我们在单个作业中比较了 7600 亿条记录。这种类型的 Apache Spark &lt;sup&gt;TM&lt;/sup&gt;作业需要数据混洗，而&lt;a href="https://www.uber.com/blog/ubers-highly-scalable-and-distributed-shuffle-as-a-service/"&gt;分布式混洗即 Spark 服务&lt;/a&gt;与动态资源分配和推测执行相结合，让我们在资源限制下以合理的速度准确地做到这一点。&lt;/p&gt;&lt;p&gt;离线验证发现缺失记录，其输出用于增量回填。我们在离线验证和回填之间进行迭代，以确保所有记录都已写入。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-backfill-issues"&gt;回填问题&lt;/h2&gt;&lt;p&gt;每次回填都有风险。我们使用 Uber 内部提供的 Apache Spark 进行回填。以下是我们遇到的不同问题以及我们如何处理这些问题。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-scalability"&gt;可扩展性&lt;/h3&gt;&lt;p&gt;您希望从小规模开始，逐渐扩大规模，直到达到系统的极限。如果您只是盲目地超越这一点，那么您实际上就是在对自己的系统发起 DDoS 攻击。此时，您想要找到瓶颈，解决它，然后扩大您的工作规模。大多数时候，这只是扩大下游服务的问题，有时可能会更复杂。无论哪种情况，您都不希望将回填作业扩展到超出系统瓶颈的能力。最好以小增量的方式进行扩展，并在每次扩展后密切监控。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-incremental-backfills"&gt;增量回填&lt;/h3&gt;&lt;p&gt;当您尝试在 3 个月内回填 3 年的数据时，您生成的流量将是正常流量负载的 10 倍，并且系统可能无法处理此流量。例如，当您的生产通常处理 1K/秒的速率时，您将需要 120 天以 10K/秒的速率回填 100B 记录。因此，您可以预期系统会过载。即使回填作业极有可能导致持续出现问题，您也必须将其关闭。因此，期望回填作业能够一次性从开始运行到结束是不现实的，因此您必须增量运行回填。&lt;/p&gt;&lt;p&gt;一种简单而有效的方法是将回填分成可以一点一点完成的小批次，这样每批次都可以在几分钟内完成。由于您的作业可能会在批次中间关闭，因此它必须是幂等的。每次完成一个批处理时，您都希望将统计信息（例如读取的记录、回填的记录等）转储到文件中。随着回填的继续，您可以汇总其中的数字以检查进度。&lt;/p&gt;&lt;p&gt;如果您可以删除或更新现有记录，则可以降低回填期间出现错误和代码错误的风险和成本。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-rate-control"&gt;速率控制&lt;/h3&gt;&lt;p&gt;为了安全回填，您需要确保回填作业的行为一致。因此，您的作业应该具有可以轻松调整以放大或缩小的速率控制。在 Java/Scala 中，您可以使用 Guava 的 RateLimiter。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-dynamic-rate-control"&gt;动态速率控制&lt;/h3&gt;&lt;p&gt;在某些情况下，当生产流量较少时，您可能可以加快速度。为此，您需要监视系统的当前状态并查看是否可以加快速度。我们根据&lt;a href="https://en.wikipedia.org/wiki/Additive_increase/multiplicative_decrease" rel="noreferrer noopener" target="_blank"&gt;加法增加/乘法减少&lt;/a&gt;来调整 RPS。为了安全起见，我们对交通仍然有上限。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-emergency-stop"&gt;紧急停止&lt;/h3&gt;&lt;p&gt;迁移过程需要能够在出现中断甚至怀疑过载的情况下快速停止回填。停电期间的任何回填都必须停止，这既是预防措施，也是潜在的噪音源。即使在断电后，随着系统恢复，系统也往往会承受额外的负载。能够停止回填还有助于调试与规模相关的问题。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-size-of-data-file"&gt;数据文件大小&lt;/h3&gt;&lt;p&gt;转储数据时，将文件大小保持在 1GB 左右，两侧具有 10 倍的灵活性。如果文件太大，您会遇到&lt;a href="https://kb.databricks.com/cloud/s3-part-number-limit.html" rel="noreferrer noopener" target="_blank"&gt;不同工具的 MultiPart 限制&lt;/a&gt;等问题。如果您的文件很小，那么您的文件太多，甚至列出它们也将花费大量时间。在 shell 中运行命令时，您甚至可能开始达到 ARGMAX 限制。这变得足够重要，以确保每次对数据执行某些操作时，它都会应用于所有文件，而不仅仅是其中的一些文件。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-fault-tolerance"&gt;容错能力&lt;/h3&gt;&lt;p&gt;所有回填作业都需要某种数据转换。当您这样做时，您不可避免地会遇到数据质量/损坏问题。您不能每次发生这种情况时都停止回填作业，因为此类不良记录往往是随机分布的。但您也不能忽略它们，因为这也可能是由于代码错误造成的。为了解决这个问题，您可以单独转储有问题的记录并监视统计数据。如果失败率很高，那么您可以手动停止回填，修复问题，然后继续。否则，让回填继续并并行查看故障。&lt;/p&gt;&lt;p&gt;记录未写入的另一个原因是 RPC 超时。你可以重试，但在某些时候，你必须放弃并继续前进，无论出于什么原因，以确保你能够取得进展。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-logging"&gt;记录&lt;/h3&gt;&lt;p&gt;在回填期间记录日志以帮助调试和监控进度是很诱人的，但这可能是不可能的，因为这会给日志记录基础设施带来压力。即使您可以保留日志，也会有太多的日志数据需要保留。解决方案是使用速率限制器来限制您生成的日志数量。您只需对产生大部分日志的部分进行速率限制。如果错误很少发生，您甚至可以选择记录所有错误。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/xWcB-v0gyFB4920hZx1tevZiHiSLhUKPvA7TZMvkCN6bsEmh5bZiTcZ0xYumbfjsgsG6Oz-Xnl85XeLhD4ofUc07poJ1OnsB4WlNCEyZzYmY9kuvfgCkSxzC4nSvqcBEmYQvANytw4oOyXA4wyQDias" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-mitigating-risk"&gt;降低风险&lt;/h2&gt;&lt;p&gt;除了分析来自不同验证和回填统计数据的数据外，我们对 LSG 的推出也持保守态度。我们在几周内推出了它，并得到了我们服务的主要呼叫者的待命工程师的批准。我们最初推出了回退（即，如果在 LSG 中找不到数据，我们将尝试从 DynamoDB 获取数据）。在删除回退之前，我们查看了回退日志。对于回退日志中标记为丢失的每条记录，我们检查了 LSG 以确保它并未真正丢失。即使在那之后，我们仍将 DynamoDB 数据保留了一个月，然后才停止向其中写入数据、进行最终备份并删除该表。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/P7cnF5dxZX7H5rA82nfZgC1ICBQX7Q928jAexep0GBSR39-B2kDw44hHTtEQQuBNmqw9ZeFz_KYY39uqlUBSEErrb2XWhWagcpWKrsb8tiDX_6CYfOXACQst7Wak7mIewxy4WvI3gW3Vza3altpn0Tc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：LSG 推出&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;在本文中，我们介绍了将大量业务关键型货币数据从一个数据存储迁移到另一个数据存储的过程。我们涵盖了迁移的不同方面，包括迁移标准、检查、回填问题和安全性。我们能够在两年内完成此迁移，在迁移期间或迁移后没有任何停机或中断。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-acknowledgments"&gt;致谢&lt;/h3&gt;&lt;p&gt;感谢 Amit Garg 和 Youxian Chen 帮助我们将数据从 TerraBlob 迁移到 LSG。感谢 LSG 团队的 Jaydeepkumar Chovatia、Kaushik Devarajaiah 和 Rashmi Gupta 在整个工作中对我们的支持。感谢李梦涵为&lt;a href="https://www.uber.com/en-EG/blog/cashless-payments-with-uber-cash/" rel="noreferrer noopener" target="_blank"&gt;Uber Cash&lt;/a&gt;的账本迁移数据。&lt;/p&gt;&lt;p class="has-small-font-size"&gt;封面照片归属： &lt;a href="https://www.flickr.com/photos/51986662@N05"&gt;USFWS Mountain Prairie&lt;/a&gt;拍摄的“&lt;a href="https://www.flickr.com/photos/51986662@N05/51912457870"&gt;休伦湿地管理区日落时的水禽迁徙&lt;/a&gt;”，标有&lt;a href="https://creativecommons.org/publicdomain/mark/1.0/?ref=openverse"&gt;公共领域标记 1.0&lt;/a&gt; 。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Amazon Web Services、AWS、Powered by AWS 徽标[以及此类材料中使用的任何其他 AWS 标记的名称]是 Amazon.com, Inc. 或其附属公司的商标。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Apache®、Apache SparkTM 和 SparkTM 是 Apache Software Foundation 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/p&gt;</description><pubDate>Thu, 11 Apr 2024 05:30:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/migrating-from-dynamodb-to-ledgerstore/</guid></item><item><title>LedgerStore 如何支持 Uber 的数万亿个索引</title><link>https://www.uber.com/blog/how-ledgerstore-supports-trillions-of-indexes/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;Uber 将物理世界和数字世界连接起来，只需按一下按钮即可实现移动。每个季度，Uber 都会为收入者、消费者和商家进行数十亿次出行、送货和数百亿次金融交易。 LedgerStore 是 Uber 的一个不可变存储解决方案，提供可验证的数据完整性和正确性保证，以确保这些交易的数据完整性。&lt;/p&gt;&lt;p&gt;考虑到账本是 Uber 任何财务事件或数据移动的真实来源，因此能够通过索引从各种访问模式中查找账本非常重要。这就需要&lt;strong&gt;数万亿&lt;/strong&gt;个索引来索引数千亿的账本。之前的一篇&lt;a href="https://www.uber.com/en-US/blog/dynamodb-to-docstore-migration/" rel="noreferrer noopener" target="_blank"&gt;博文&lt;/a&gt;讨论了 LedgerStore 的背景以及存储后端是如何重新架构的。本博客介绍了 LedgerStore 索引及其架构的重要性，该架构为数万亿个索引提供支持，并具有 PB 级索引存储空间。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-types-of-indexes"&gt;索引类型&lt;/h1&gt;&lt;p&gt;账本需要支持各种类型的索引。让我们探索它们以及相应的用例。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="h-strongly-consistent-indexes"&gt;索引强一致&lt;/h2&gt;&lt;p&gt;其中一个用例是当乘客/食客使用 Uber 时处理信用卡授权流程。在优步行程开始时，乘客/乘客的信用卡上会被冻结。该保留应转换为费用或作废，具体取决于行程是进行还是取消，如下所示。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084314" height="618" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig1-e1711742633458.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：强一致性指数支持的 Uber Trip 信用卡支付流程。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;如果为保留服务的索引不是强一致的&lt;em&gt;，&lt;/em&gt;则读取时保留可能需要一段时间才能可见。这样做的结果是，可能会在用户的信用卡上重复收费，而原始保留仍保留在信用卡上。&lt;/p&gt;&lt;p&gt;现在，让我们深入研究如何构建强一致性索引，以确保一旦执行记录写入，任何后续读取都保证看到与该记录对应的索引。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-write-path"&gt;写入路径&lt;/h3&gt;&lt;p&gt;为了构建强一致性索引，我们使用两阶段提交来确保索引始终与记录强一致，如下所示。&lt;/p&gt;&lt;p&gt;插入操作从记录写入之前的索引意向写入开始。如果记录写入成功，这些意图将在记录写入操作后提交，并且这是异步完成的，以避免影响最终用户插入延迟。如果索引意图写入成功，但记录写入失败，则需要回滚索引意图，否则会导致未使用意图的累积，这将在读取时进行处理，如下所示。&lt;/p&gt;&lt;p&gt;需要注意的是，如果索引意图写入失败，则整个插入操作都会失败，因为我们无法保证索引与记录的一致性。因此，只有当用例强烈需要时才需要考虑强一致性索引。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084320" height="520" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig2-e1711742801993.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：强一致索引的两阶段提交写入流程。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-read-path"&gt;读取路径&lt;/h3&gt;&lt;p&gt;有两种情况索引可以在插入后处于意向状态：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;索引意向提交操作在写入路径中失败或&lt;/li&gt;&lt;li&gt;如果记录写入失败&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;此类意图通过提交或删除在读取路径上进行处理。当对这些索引进行读取时，如果索引处于 Intent 状态，则会读取相应的记录。如果记录存在，则提交索引，否则回滚。这些操作异步发生，以免影响最终用户的读取延迟。一般来说，只有很小一部分索引最终处于意图状态。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084321" height="791" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig3-e1711742960693.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：强一致索引的读取流程。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-eventually-consistent-indexes"&gt;最终一致的索引&lt;/h2&gt;&lt;p&gt;并非所有索引都需要强大的“读即写”保证。这种索引的一个例子是支付历史页面，其中，只要支付出现在页面上，几秒的延迟是可以接受的。&lt;/p&gt;&lt;p&gt;虽然强一致性索引提供了&lt;em&gt;读你所写的&lt;/em&gt;保证，但它们在某些情况下并不适合，因为它们会权衡以下属性来实现此保证：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;更高的写入延迟&lt;/strong&gt;&lt;br /&gt;由于索引意向写入操作和相应的记录写入必须是串行的，才能为记录提供索引的强一致性保证&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可用性较低&lt;/strong&gt;&lt;br /&gt;任何一个索引意图的写入失败都意味着整个写入应该失败，否则索引将与相应的记录不一致&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最终，与强一致索引相比，一致索引在这方面是相反的，因为它们是由与在线写入路径完全隔离的单独进程在后台构建的。因此，它们不会遭受&lt;em&gt;较高的写入延迟&lt;/em&gt;或导致 LedgerStore 服务的潜在&lt;em&gt;可用性较低&lt;/em&gt;。我们利用我们自己开发的&lt;a href="https://www.uber.com/blog/schemaless-sql-database/" rel="noreferrer noopener" target="_blank"&gt;Docstore&lt;/a&gt;数据库中名为“物化视图”的功能来生成这些索引。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084322" height="990" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig4-e1711743013811.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：最终一致索引提供的支付历史记录。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-time-range-indexes"&gt;时间范围索引&lt;/h2&gt;&lt;p&gt;账本由于其不可变的性质，会随着时间的推移而不断增长，从而增加其存储成本。因此，在 Uber，我们将时间范围内的旧账本分批卸载到更便宜的冷存储中。&lt;/p&gt;&lt;p&gt;每个账本都与一个称为业务或事件时间戳的时间戳相关联。为了将账本卸载到冷存储（也为了密封数据），我们需要一类索引来查询事件时间范围批次中的数据。该索引的不同之处在于，数据是在确定的时间范围批次中读取的，其数量级高于上述两种索引类型。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-full is-resized"&gt;&lt;img alt="" class="wp-image-1084325" height="591" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig5-e1711743069138.png" style="width: 701px; height: auto;" width="1020" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：数据分层中使用的时间范围索引。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;以下是如何在分类账上进行时间范围查询的示例：&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;从 LEDGER_TABLE 中选择 *&lt;/strong&gt; &lt;strong&gt;，其中&lt;/strong&gt;LedgerTime&lt;strong&gt;介于&lt;/strong&gt;1701252000000&lt;strong&gt;和&lt;/strong&gt;1701253800000 之间&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;分类帐&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;账本时间&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;{行程开始}&lt;/td&gt;&lt;td&gt;上午 10:01&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; {行程已完成且票价已调整}&lt;/td&gt;&lt;td&gt;上午 10:15&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; {行程后更正}&lt;/td&gt;&lt;td&gt;中午 12:01&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;有几种方法可以在分布式数据库中对此进行建模。我们将深入探讨在 Amazon DynamoDB 与 Docstore 数据库之上开发时间范围索引之间的主要区别。 DynamoDB 和 Docstore 都是分布式数据库，都提供数据建模构造作为分区和排序键。前者用于根据数据的值在分区之间均匀分布数据，后者用于控制数据的排序顺序。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-design-with-dynamodb"&gt;使用 DynamoDB 进行设计&lt;/h3&gt;&lt;p&gt;Dynamodb 提供两种管理表读/写&lt;a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html" rel="noreferrer noopener" target="_blank"&gt;容量&lt;/a&gt;的方法。我们使用预配置模式，因为流量不会太&lt;a href="https://docs.aws.amazon.com/wellarchitected/latest/serverless-applications-lens/capacity.html" rel="noreferrer noopener" target="_blank"&gt;突发，&lt;/a&gt;不需要按需模式。预配模式配置了&lt;a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html" rel="noreferrer noopener" target="_blank"&gt;自动缩放功能&lt;/a&gt;，可根据流量模式调整容量。&lt;/p&gt;&lt;p&gt;正如我们从上面的写入模式中注意到的，分类账时间通常与当前挂钟时间相关。因此，这些值往往聚集在当前时间附近。如果我们基于&lt;strong&gt;G&lt;/strong&gt;个时间单位粒度对数据进行分区，那么&lt;strong&gt;G 个&lt;/strong&gt;时间单位中的所有写入都将进入同一个物理分区，从而导致热分区。 DynamoDB 在&lt;a href="https://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/" rel="noreferrer noopener" target="_blank"&gt;热分区&lt;/a&gt;的情况下对吞吐量有限制，导致写入请求受到限制，这在在线写入路径中是不可接受的。假设 1K 峰值 Uber 行程/秒，即使 G=1 秒也不是一个好值，因为它对应于 1K WCU（写入容量单位），这是发生&lt;a href="https://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/" rel="noreferrer noopener" target="_blank"&gt;限制&lt;/a&gt;之前允许的 QPS 峰值。&lt;/p&gt;&lt;p&gt;虽然看起来我们可以使分区更加细粒度，但它仍然不是万无一失的，因为随着时间的推移，流量的增加可能会导致不稳定。这样做的另一个副作用是通过分散-聚集执行的累积读取量增加。因此，我们对 DynamoDB 所做的操作如下：&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-write-optimized-temporary-index-table-called-buffer-index"&gt; 写优化临时索引表（称为缓冲区索引）&lt;/h4&gt;&lt;p&gt;所有在线时间索引写入都会写入缓冲区索引表。插入的索引项根据相应记录的哈希模划分到&lt;strong&gt;&lt;em&gt;M 个&lt;/em&gt;&lt;/strong&gt;唯一的存储桶中，以在缓冲区索引表中的分区之间&lt;a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-partition-key-design.html" rel="noreferrer noopener" target="_blank"&gt;均匀分配&lt;/a&gt;负载，从而提高&lt;em&gt;写入效率&lt;/em&gt;。选择&lt;strong&gt;&lt;em&gt;M&lt;/em&gt;&lt;/strong&gt;的值，使其足够高，以便每个分区的负载量避免过度拆分。它也被选择得足够低，以限制分散-聚集的数量&lt;em&gt; &lt;/em&gt;在读取期间执行。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-read-optimized-permanent-index-table"&gt;读取优化的永久索引表&lt;/h4&gt;&lt;p&gt;对缓冲表进行分散&lt;em&gt;聚集&lt;/em&gt;读取的需要使得它们的读取效率不高，并且由于读取可能发生在表的整个生命周期中，因此我们需要对其进行优化。这就带来了对读取高效的永久索引表的需求。&lt;/p&gt;&lt;p&gt;永久时间范围索引表根据与特定持续时间&lt;strong&gt;&lt;em&gt;N&lt;/em&gt;&lt;/strong&gt; （例如 10 分钟）对齐的时间戳进行分区。缓冲表中的索引定期批量写入永久索引表。由于写入是在后台批量完成的，所以这里的任何写入节流都不会影响线上流量。批处理的另一个优点是写入流量可以跨分区分布，减少热分区。缓冲区索引表在将其索引卸载到永久索引表后将被删除，因为不再需要它们。对永久索引表的读取以&lt;strong&gt;&lt;em&gt;N&lt;/em&gt;&lt;/strong&gt;分钟为间隔完成，没有任何分散-聚集，使得该表的&lt;em&gt;读取效率很高&lt;/em&gt;。&lt;br /&gt;以下是 DynamoDB 情况下的时间范围索引流的描述。双表设计带来了状态管理和协调的需要，因此读取也会转到正确的索引表。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084328" height="1024" src="https://blog.uber-cdn.com/cdn-cgi/image/width=920,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig6-e1711743514668.png" width="920" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：Dynamodb 上的时间范围索引设计。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-design-with-docstore"&gt;使用 Docstore 进行设计&lt;/h3&gt;&lt;p&gt;DynamoDB 的双表设计运行良好，可以处理高吞吐量，但在操作上带来了挑战。如果临时缓冲表没有及时创建，可能会因为无法接受写入而导致写入失败，这在过去曾引起过可用性问题。作为成本效率的一部分，我们将索引存储后端从 DynamoDB 重新架构为 Uber 的&lt;a href="https://www.uber.com/blog/schemaless-sql-database/" rel="noreferrer noopener" target="_blank"&gt;Docstore&lt;/a&gt;数据库。作为此重新架构的一部分，我们还通过利用两个 Docstore 属性改进了时间范围索引设计，以克服维护两个表的缺点：&lt;/p&gt;&lt;ol&gt;&lt;li&gt; &lt;a href="https://www.uber.com/blog/schemaless-sql-database/" rel="noreferrer noopener" target="_blank"&gt;Docstore&lt;/a&gt;是一个构建在 MySQL 之上的分布式数据库，固定数量的分片分配给可变数量的物理分区。随着数据大小的增长，物理分区的数量增加，一些现有的分片被重新分配给新的分区，从而导致物理分区的数量达到最大&lt;strong&gt;上限&lt;/strong&gt;。&lt;/li&gt;&lt;li&gt; Docstore中的数据以主键（分区+排序键）的&lt;strong&gt;排序&lt;/strong&gt;方式存储。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我们只维护一张时间范围索引表，其中索引条目根据完整时间戳值进行分区。由于时间戳非常细粒度，因此不存在热分区（因此不存在写入限制），因为大多数写入均匀分布在分区之间。&lt;/p&gt;&lt;p&gt;读取涉及对表的每个分片进行前缀扫描，直至达到特定的时间粒度。前缀扫描与表的常规扫描非常相似，不同之处在于每个扫描请求的边界由应用程序控制。因此，在下面的示例中，要读取 30 分钟的数据，可以从 2023–02-03 01:00:00 到 2023–02-03 01:10:00 每隔 10 分钟间隔读取一次，类似地对接下来的两个子窗口重复此操作。由于数据是按主键排序的，因此具有给定边界的前缀扫描可确保仅读取这些时间戳内的数据。&lt;/p&gt;&lt;p&gt;然后执行分散-聚集，然后执行跨分片的排序合并，以按排序的方式获取给定窗口中的所有时间范围索引条目。由于Docstore中分片的数量是固定的，因此我们可以精确地确定（并限制）需要执行的读取请求的数量。同样的技术不适用于 DynamoDB，因为随着表大小的增加，分区数量不断增加。这显着简化了设计并降低了时间索引的运营维护成本。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084329" height="914" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig7-e1711743568767.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：Docstore 上的时间范围索引设计。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-index-lifecycle-management"&gt;索引生命周期管理&lt;/h2&gt;&lt;p&gt;定期定义新索引，并且也可以修改某些索引以发展用例。为了以最小的努力支持这一点并且不导致任何回归，我们需要一种机制来管理索引生命周期。以下是相同的组件：&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-index-lifecycle-state-machine"&gt;索引生命周期状态机&lt;/h3&gt;&lt;p&gt;该组件协调索引的生命周期，包括创建索引表、用历史索引条目回填索引表、验证它们的完整性、将旧索引与新索引交换以进行读/写，以及停用旧索引。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084330" height="375" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig8-e1711743614440.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：索引生命周期状态机。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-historical-index-data-backfill"&gt;历史指数数据回填&lt;/h3&gt;&lt;p&gt;根据业务用例，需要定义新索引，并且必须回填历史索引条目以使其完整。该组件根据卸载到冷数据存储的历史数据构建索引，并以可扩展的方式将其回填到存储层。考虑到数据下载速度高于数据处理速度，该组件以可重用的方式构建了可配置的速率限制和批处理，因为我们可以将实际处理逻辑作为批处理器插件插入。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084331" height="592" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig9-e1711743676584.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图9：为回填索引而定制的历史数据处理模块。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-index-validation"&gt;索引验证&lt;/h3&gt;&lt;p&gt;索引回填后，需要验证索引的完整性。这是通过离线作业来完成的，该作业在一定的时间窗口粒度上计算顺序无关的校验和，并在真实数据源和索引表之间进行比较。此步骤可识别索引回填过程中的任何错误，因为即使丢失了一个条目，该时间窗口的聚合校验和也会导致不匹配。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1084332" height="350" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/04/Fig10-e1711743725757.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 10：索引完整性验证。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-highlights"&gt;强调&lt;/h2&gt;&lt;p&gt;这是我们衡量这个关键项目成功与否的方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们构建了超过 2 万亿个唯一索引，到目前为止，尚未检测到任何数据不一致，新架构已投入生产 6 个多月。&lt;/li&gt;&lt;li&gt;鉴于资金流动对 Uber 的重要性，在回填期间没有发现任何生产事故。&lt;/li&gt;&lt;li&gt;我们还将所有这些索引从 DynamoDB 移至 Docstore。因此该项目还实现了技术整合，减少了外部依赖。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;从业务影响的角度来看，由于 DynamoDB 支出减少，运营 LedgerStore 现在非常划算。预计每年可节省超过 600 万美元。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;账本是 Uber 资金流动事件的真相来源。我们构建的强大索引平台支持访问各种业务用例的真相分类账来源，我们期待将来在该平台上支持更多索引。&lt;/p&gt;&lt;p&gt;我们想总结一些关键要点： 在 OLTP 系统中维护 PB 级索引会带来一定的挑战，例如分区不平衡、读/写放大高、邻居噪声问题等。因此数据建模和隔离非常重要设计这些系统时要考虑的方面。此外，根据底层用于存储的实际数据库，设计方法可能会有很大不同，正如我们从两个不同分布式数据库上的时间范围索引的设计对比中看到的那样。&lt;/p&gt;&lt;p&gt;下周加入我们，观看 LedgerStore 系列的第二部分，我们将记录从 DynamoDB 到 LedgerStore 的迁移。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="h-acknowledgments"&gt;致谢&lt;/h2&gt;&lt;p&gt;如果没有以下团队的合作，这个项目就不可能实现，这些团队体现了&lt;a href="https://www.uber.com/in/en/careers/values/" rel="noreferrer noopener" target="_blank"&gt;Uber 的多项价值观&lt;/a&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.uber.com/blog/payments-platform/" rel="noreferrer noopener" target="_blank"&gt;湾流&lt;/a&gt;团队与 LedgerStore 团队密切合作，以实现共同目标并迁移到 LedgerStore 平台，这是一个多年项目。&lt;/li&gt;&lt;li&gt; Docstore 团队，负责不断发展&lt;a href="https://www.uber.com/en-IN/blog/schemaless-sql-database/" rel="noreferrer noopener" target="_blank"&gt;Docstore&lt;/a&gt;以满足 LedgerStore 索引的大规模需求。&lt;/li&gt;&lt;li&gt; LedgerStore 团队负责领导、构建和推动分类账索引的大规模采用。&lt;/li&gt;&lt;/ul&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Amazon Web Services、AWS、Powered by AWS 徽标和 Amazon DynamoDB 是 Amazon.com, Inc. 或其附属公司的商标。&lt;/em&gt;&lt;/p&gt;</description><pubDate>Thu, 04 Apr 2024 05:30:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/how-ledgerstore-supports-trillions-of-indexes/</guid></item><item><title>扩展 Uber 的 AI/ML 基础设施</title><link>https://www.uber.com/blog/scaling-ai-ml-infrastructure-at-uber/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;&lt;strong&gt;介绍&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;自 2016 年我们首次开始为司机-乘客匹配和定价团队使用复杂的基于规则的机器学习模型以来，机器学习 (ML) 正在庆祝其在 Uber 的第八个年头。从那时起，我们取得了重大进展，转向采用深度学习学习模型是当今大多数关键业务应用程序的核心，同时积极探索生成式人工智能模型提供的可能性。随着 AI/ML 模型的复杂性和规模不断激增，对高效基础设施来有效支持这些模型的需求不断增长。在过去的几年里，我们战略性地实施了一系列以 CPU 和 GPU 为中心的基础设施解决方案，以动态扩展我们的系统并满足不断变化的 ML 用例环境。这一演变涉及定制硬件 SKU、软件库增强、各种分布式训练框架的集成以及对我们的端到端 Michaelangelo 平台的持续改进。这些迭代改进是由我们一路走来的经验教训以及对行业趋势和 Uber 发展轨迹的不断调整推动的，所有这些都是为了满足我们的合作伙伴和客户不断变化的需求。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-goal-and-key-metrics"&gt;&lt;strong&gt;目标和关键指标&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;当我们开始从内部部署向云基础设施的过渡（我们于 2023 年 2 月&lt;a href="https://www.wsj.com/articles/uber-signs-cloud-deals-with-google-and-oracle-b45a9372" rel="noreferrer noopener" target="_blank"&gt;宣布）&lt;/a&gt;时，我们跨团队的硬件/软件协同设计和协作是由以下具体目标驱动的：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;最大限度地利用现有基础设施&lt;/li&gt;&lt;li&gt;为新兴工作负载建立新系统，例如生成式人工智能&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为了实现这些目标，我们概述了指导我们进步的独特关键结果和指标。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可行性和可靠性：&lt;/strong&gt;机器学习用户期望在预期的时间范围内（根据复杂性，可以是几周或几个月）成功地融合他们的训练任务，并且不会出现错误。例如，训练 Falcon 180B™ 等更大、更复杂的模型可能需要数月时间，而较长的训练持续时间会增加出现可靠性问题的可能性。因此，我们的目标是为所有培训依赖项实现 99% 的正常运行时间 SLA，以确保一致且可靠的结果。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;效率：&lt;/strong&gt;我们对效率的关注涉及对不同 GPU 配置进行彻底的基准测试，并评估针对特定工作负载定制的本地和云 SKU 的性价比。我们使用模型触发器利用率 (MFU) 等指标来衡量训练效率，以保证最佳的 GPU 利用率。我们的目标是防止 GPU 闲置，通过反应式扩展在服务非高峰时段机会性地使用训练作业，并保持高利用率以最大限度地提高资源效率。我们希望做到这一点的同时也保持不同用户之间资源共享的公平性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;开发人员速度：&lt;/strong&gt;该指标通过我们的工程师在特定时间范围内可以进行的实验数量来量化。我们优先考虑成熟的生态系统来提高开发人员的速度，确保我们的团队高效工作以提供最佳解决方案。这种方法不仅简化了我们最先进的模型的生产过程，而且还减少了这一过渡所需的时间。&lt;/p&gt;&lt;p&gt;接下来是我们为使本地和云基础设施中的培训和服务部署高效且可扩展而采取的各种举措的结果摘要： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-optimizing-existing-on-prem-infrastructure"&gt;&lt;strong&gt;优化现有的本地基础设施&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-federation-of-batch-jobs"&gt;&lt;br /&gt;批处理作业联合会：&lt;/h3&gt;&lt;p&gt;我们的 GPU 资产分布在各个可用区和区域的多个&lt;a href="https://kubernetes.io/" rel="noreferrer noopener" target="_blank"&gt;Kubernetes&lt;/a&gt; ™ 集群中。这种分布主要是由于 GPU 可用性和单个 Kubernetes 集群内的节点数量限制。这种安排带来了两个主要挑战：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;向机器学习工程师展示基础设施的具体细节。&lt;/li&gt;&lt;li&gt;由于静态分配，跨集群的资源利用率不一致。虽然我们在每个集群内都有有效的资源共享系统，但我们缺乏集群间调度的能力。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为了解决这些问题，我们为批量工作负载创建了一个统一的联合层，包括&lt;a href="https://www.ray.io/" rel="noreferrer noopener" target="_blank"&gt;Ray&lt;/a&gt; ™ 和 Apache &lt;a href="https://spark.apache.org/" rel="noreferrer noopener" target="_blank"&gt;Spark&lt;/a&gt; ™，称为&lt;strong&gt;Michelangelo Job Controller&lt;/strong&gt; 。该组件充当所有工作负载调度的集中式接口，隐藏底层 Kubernetes 集群，并根据各种策略（负载感知、bin-pack）分配工作负载，包括计算和数据关联性考虑因素。我们计划在后续的博客文章中分享更多相关技术细节。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/BQBvxC9TSCSgAj8ZlAAL8Dkydbx3B__KT9nHfrs7eUfLEU6CVUiGo4uG6QUmWkJ0piVRdwkjSioJ-Q80JmKI7pFzlHOEssw3DTZlou544_4uJkyYHdbC55OkKSQfq7ZyL9x8yN8iuZ6a8Hv5RMg0-xk" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：用于 ML 工作负载分配的统一联合层。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-network-upgrade-for-llm-training-efficiency"&gt;网络升级提升LLM培训效率&lt;/h3&gt;&lt;p&gt;当扩展基础设施以适应生成式 AI 应用程序并提高分布式训练的效率，同时微调开源 LLM 时，重要的是要重点关注跨纵向扩展和横向扩展配置的网络带宽扩展。这就需要实现关键功能，例如 GPU 之间的全网状&lt;a href="https://www.nvidia.com/en-us/design-visualization/nvlink-bridges/" rel="noreferrer noopener" target="_blank"&gt;NVlink&lt;/a&gt; ™ 连接、网络链路速度升级、熟练的拥塞控制管理、QoS 控制以及专用机架和网络拓扑的建立以及其他基本功能。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1083848" height="593" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Fig2_network_upgrade-1024x593.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图2：通过网络链路容量升级提高训练效率。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们总结了大型语言模型 (LLM) 案例研究的结果，强调增强的网络带宽和拥塞控制机制对培训效果和性价比效率的巨大影响。我们的观察表明，与现有的网络互连相比，采用更高的网络带宽和更好的拥塞控制机制时，训练速度提高了近两倍，并且训练持续时间大幅缩短。在多节点训练期间，跨节点复制数据会增加本地内存需求并增加 IO 工作负载。我们的分析建议将每个 GPU 服务器上的网络链路容量增加 4 倍（25GB/s 至 100GB/s），从而可能使可用训练容量增加一倍。在构建这些服务的同时，我们还需要通过适当的隔离和 QoS 控制来确保大型训练运行生成的“大象流”不会对其他高优先级服务产生负面影响。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-memory-upgrade-to-improve-gpu-allocation-rates"&gt;&lt;br /&gt;内存升级以提高 GPU 分配率&lt;/h3&gt;&lt;p&gt;较新的 AI/ML 工作负载要求每个 GPU 工作线程使用比我们设计的更多的系统内存。固有的物理限制，例如每台服务器上的内存通道数量有限，以及 NPI（新产品推出）期间部署的 DIMM 容量限制了我们扩展 GPU 分配的能力。为了提高 GPU 分配率，我们已开始努力将这些服务器上的内存量增加一倍（每个 DIMM 通道 16GB 至 32GB）。此外，我们还在构建一个框架，以便在旧机架退役时重新利用和重复使用 DIMM。这种优化使我们能够最大限度地利用现有的机器学习基础设施，并充分利用我们当前的资源。我们将在下一篇文章中详细介绍通过这一举措所实现的效率提升。与此同时，我们已开始努力帮助调整培训工作的资源需求。正如其他人[&lt;a href="https://tianyin.github.io/pub/amp.pdf" rel="noreferrer noopener" target="_blank"&gt;参考文献&lt;/a&gt;]所证明的那样，手动请求最佳资源是一个难题，而自动化将有助于提高分配效率。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-building-new-infrastructure"&gt;&lt;strong&gt;建设新型基础设施&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-price-performance-evaluations-across-various-cloud-skus"&gt;&lt;br /&gt;各种云 SKU 的性价比评估&lt;/h3&gt;&lt;p&gt;2022 年底，当我们踏上向云过渡的旅程时，我们评估了不同云提供商提供的各种 CPU 和 GPU 模型。我们的目标是使用既定基准（从基于树的深度学习到大型语言模型）以及专有数据集和 Uber 模型（例如 deepETA 和 deepCVR）来比较它们的性价比。这些针对培训和服务目的进行的评估使我们能够选择针对特定工作负载进行优化的最合适的 SKU，同时考虑可行性、成本、吞吐量和延迟等因素。整个 2023 年，我们广泛测试了 17 种不同的 GPU 和 CPU SKU，采用了各种库和优化器，包括 Nvidia 的&lt;a href="https://github.com/NVIDIA/TensorRT" rel="noreferrer noopener" target="_blank"&gt;TensorRT&lt;/a&gt; ™(TRT) 和 TRT-LLM 优化。例如，如图 4 和图 5 所示，我们发现虽然 A10 GPU 可能无法为训练任务提供最具成本效益的吞吐量，但事实证明它们是我们服务用例的最佳选择，在提供最佳吞吐量的同时保持可接受的吞吐量。使用 TRT 的 SLA。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/6lE7W5fYhVSHGudF-A9Fu6wzvEQo4-S7ZjnN8dSgy3HcTmC4pqn-RT9VvBF0kTwZYY3rCz6OU4BVQfZ5erhWA2UMlK-7VbUYQkqKF6SUb58hKjHdzbzH7GK6Do40TLNw7bg0GTxgQYgzQDDV-jbkXxg" title="图表" /&gt;&lt;figcaption class="wp-element-caption"&gt;图3：深度学习训练和服务性能价格评估。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/jnlRbG2pls4P0xjxD9Pvv7fx4BW5_ZWXtSYLQLXfN317i1lPtxJPOxT6xbzNT8OIHEtAXarcDNNFeC-YRUAI0zh4t1sTBuPUfYeppJPdIwMpPDDJ7E8ddXBnNqde1rCZZVxCJiCIbpQ1qWd4oIGWyhk" title="图表" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：使用和不使用 TensorRT 优化的深度学习服务延迟。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; Uber 的众多生成式 AI 应用需要使用 Nvidia 最新的 H100 GPU 来满足严格的延迟要求。这一要求源于 H100 GPU 的功能，与上一代 A100 GPU 相比，它包括高达 4 倍 TFlops 和双倍的内存带宽。在试验 Meta™ &lt;a href="https://llama.meta.com/" rel="noreferrer noopener" target="_blank"&gt;Llama2&lt;/a&gt; ™ 模型系列（涉及各种批量大小、量化和模型参数）时，我们评估了各种开源和闭源框架，以进一步优化 LLM 服务性能。在图 6 和图 7 中，我们提出了一个具体案例，其中我们采用两个指标：每个令牌延迟（毫秒/令牌）和令牌/秒/gpu，来评估和比较两个表现最好的框架（TRT）的模型性能。 -LLM 和当前保密的框架），保持所有其他参数不变并使用 FP16 量化。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/qs9gWGpDUlhVZrug3qN88E-xDt8PKhA0Rd-R_WL8ECGq-DG50lJ7rz1nT37PxgIRyM0k2ypyN2Aq4v_FTnve8_tq9ayMOkm4cRd0UoTzSYbalhD2CDKQINp5F8uxVVDS8Y1ol-1MeKZK3pGzcSfd4dw" title="图表" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：按框架划分的 LLM 服务延迟比较 (H100)。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/rhL0z9GvoYxR0yiwFONGfGaHXsFNo_kORbuXeb9b2c8M0NEe_jJCbeEDThJUVHc05NeSt84xDjN7m5Skd2SvbzfHTUyz-MaaEhAffQoBtuKe3k7RZPVDQFDk7ZsgMYyFXfwCX-wL2dldeo2tHYzce-A" title="图表" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：使用相同延迟预算和所需 GPU 最少数量 (H100) 的框架的 LLM 服务吞吐量比较。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;这些实验结果清楚地表明，与 TRT-LLM 相比，框架 B 的延迟增加了两倍，吞吐量提高了六倍。它进一步强调了硬件/软件协同设计的重要性，并且为了充分利用硬件功能，必须在整个堆栈中拥有正确的解决方案。 &lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-llm-training-efficiency-improvements-with-memory-offload"&gt;&lt;br /&gt;通过内存卸载提高 LLM 培训效率&lt;/h3&gt;&lt;p&gt;在本节中，我们概述了有关大型语言模型的优化器状态、参数和梯度从 GPU 内存到 CPU 内存或 NVMe 设备的放置的设计和实验框架。我们的目标是评估这种卸载对 GPU 可扩展性、训练效率和一系列系统指标的影响。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1083850" height="637" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Fig6_memory_offload_design_space-1024x637.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：内存卸载实验的设计框架。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们的实验结果表明，我们训练先前因 GPU 内存有限而阻碍的扩展模型的能力已得到显着增强。将内存从 GPU 内存卸载到系统内存甚至 NVMe 设备，通过在相同数量的 GPU 上使用更大的批量大小，有助于提高训练效率。这一转变使 MFU（模型触发器利用率）提高了 2 倍，同时 GPU 使用率降低了 34%。然而，值得注意的是，这种改进伴随着网络吞吐量的相应减少。有关此主题的详细开放计算机项目 ( &lt;a href="https://www.opencompute.org/" rel="noreferrer noopener" target="_blank"&gt;OCP&lt;/a&gt; ) 会议演讲可&lt;a href="https://www.youtube.com/watch?v=Ju0r8yU1_Lw" rel="noreferrer noopener" target="_blank"&gt;在此处&lt;/a&gt;找到。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/L8HJjzd4fJLc0rv2q8ArOqvVbN-mlHlKwGTqoYg6dPciNtvU6kjAn3NK3eVfjp1WdeqLgJu2zIhmRNxeM5vkX3E47bIRNezH-X9ytjOWzh7lRI0V9OFtZMzOtUbaZXJjf6HsXy4oznVON7V6JTQt7zc" title="图表" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：实施 Deepspeed 内存卸载优化的训练效率。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;最后，我们想向您提供三个关键见解。在快速应用和模型发展（从 XGboost 到深度学习推荐模型和大型语言模型）中设计单一的 AI/ML 系统带来了相当大的挑战。例如，虽然法学硕士需要高 TFlops，但深度学习模型可能会遇到内存限制。为了提高这些系统的成本效益，必须根据给定 SLA 内的服务成本和单位成本性能等效率指标探索工作负载优化的解决方案。最大限度地提高基础设施效率需要跨系统所有层的协作硬件和软件设计方法。在此背景下，我们在这篇文章中展示了各种示例，说明如何有效利用现有基础设施，同时构建新功能以有效扩展基础设施。最后，我们发出促进行业合作伙伴关系的邀请，敦促参与开源优化以提高效率，并就有效扩展基础设施交换想法和经验，以满足人工智能领域不断变化的需求。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="h-acknowledgments"&gt;&lt;strong&gt;致谢&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;非常感谢 UBER AI 基础设施、OCI、GCP 和 Nvidia 团队成员在上述工作中的合作。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Apache®、Apache Kafka、Kafka、Apache Spark、Spark 和星形徽标是 Apache Software Foundation 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Kubernetes® 及其徽标是 Linux Foundation® 在美国和其他国家/地区的注册商标。使用这些标记并不暗示 Linux 基金会的认可。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Falcon 180B® 及其徽标是 Technology Innovation Institute™ 在美国和其他国家/地区的注册商标。使用这些标志并不暗示技术创新学院的认可。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; LLaMA 2® 及其徽标是 Meta® 在美国和其他国家/地区的注册商标。使用这些标记并不暗示 Meta 的认可。&lt;/p&gt;</description><pubDate>Thu, 28 Mar 2024 07:28:34 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/scaling-ai-ml-infrastructure-at-uber/</guid></item><item><title>模型卓越分数：大规模提高机器学习系统质量的框架</title><link>https://www.uber.com/blog/enhancing-the-quality-of-machine-learning-systems-at-scale/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;机器学习 (ML) 是 Uber 运营战略不可或缺的一部分，影响着一系列关键业务决策。这包括预测乘客需求、识别欺诈活动、增强 Uber Eats 优食的食物发现和推荐，以及改进预计到达时间 (ETA)。尽管机器学习在各个组织中越来越普遍并产生越来越大的影响，但评估模型“质量”仍然是一个多方面的挑战。在线和离线模型评估之间存在显着区别。许多团队主要关注离线评估，偶尔会通过短期在线分析来补充。然而，随着模型在生产环境中变得更加集成和自动化，持续监控和测量常常被忽视。&lt;/p&gt;&lt;p&gt;通常，团队专注于 AUC 和 RMSE 等性能指标，而忽略其他重要因素，例如训练数据的及时性、模型再现性和自动再训练。缺乏全面的质量评估导致机器学习工程师和数据科学家对模型生命周期不同阶段的各种质量维度的了解有限。此外，这种差距阻碍了组织领导者就机器学习项目的质量和影响做出充分知情的决策。&lt;/p&gt;&lt;p&gt;为了弥补这一差距，我们建议为模型生命周期的每个阶段定义不同的维度，包括原型设计、训练、部署和预测（见图 1）。通过整合服务水平协议 (SLA) 概念，我们的目标是建立衡量和确保 ML 模型质量的标准。此外，我们正在开发一个统一的系统来跟踪和可视化模型的合规性和质量，从而为整个组织的机器学习计划提供更清晰、更全面的视图。请注意，模型卓越得分 (MES) 涵盖了 Uber 整体机器学习治理不可或缺的某些技术方面。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/isX-qlXXKvyRNL8ZrqG7ecOuLg3MzE-EeDYMT1JdrdIESlDE_PMXJcc7hHT0c4496eN18aSxij2pX5zVCRTGiovjtyGurwVEV9w1jaX-YUq2hj1huPJQM39GmLqyOlzl-HPxfhC8YP5Lp2KTLhlunbw" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：典型 ML 系统中的 ML 质量维度示例（黄色）。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-model-excellence-scores-mes"&gt;模型卓越分数 (MES)&lt;/h2&gt;&lt;p&gt;生产就绪的机器学习系统的开发和维护非常复杂，涉及模型生命周期的多个阶段和复杂的支持基础设施。通常，ML 模型会经历特征工程、训练、评估和服务等阶段。维持这一点的基础设施包括数据管道、特征存储、模型注册表、分布式训练框架、模型部署、预测服务等。&lt;/p&gt;&lt;p&gt;为了对这些阶段的模型质量进行全面评估，我们创建并引入了模型卓越评分 (MES) 框架。 MES 旨在衡量、监控和强化 ML 生命周期每个阶段的质量。该框架符合站点可靠性工程师 (SRE) 和 DevOps 专业人员常用的原则和术语，特别是那些用于管理生产环境中的微服务可靠性的原则和术语。&lt;/p&gt;&lt;p&gt; MES 围绕与服务级别目标 (SLO) 相关的三个基本概念：指标、目标和协议。指标是反映机器学习系统质量某些方面的精确定量度量。目标为这些指标设定了目标范围，而协议在 ML 用例级别组合了所有指标，根据指标结果指示总体通过/失败状态。&lt;/p&gt;&lt;p&gt; MES中的每个指标都有明确的定义，并为其指标值设定了目标范围，并指定了值更新的频率。如果某个指标在给定时间范围内未达到其目标，则将其标记为失败。封装了这些指标的协议代表了服务的承诺水平并提供了对其绩效的深入了解。图 2 说明了协议、指标和目标之间的相互关系，以及它们与特定用例和模型的关系。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/bvZ0Oj6F3DG-ZDLprNYgODtxB444TWmjTAEMqNlVxgeozimoLuFjXa6m6LVCKCAE7CrTaDD6t2SgvAUUPUmEQaYMe8bbfDOtMgsn10i2W1A3AtQemO7gpOORuYiFTPkjMhIst_8t9RtlITBHxK-dWWw" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：协议、指标、目标、用例和模型之间的关系。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;不同的指标可能需要不同的解决时间框架和不同的缓解策略。有些可能需要立即关注更高优先级的处理，特别是在未达到性能基准时。&lt;/p&gt;&lt;p&gt;同样重要的是要注意，与建模相关的角色和职责在组织之间可能存在很大差异。在某些情况下，单个团队可以处理整个流程，而在其他情况下，职责可能分布在多个团队或部门中。&lt;/p&gt;&lt;p&gt;在 Uber，每个模型的职责都分配给指定的主要团队。如协议中所述，该团队会收到与其模型相关的任何差异或问题的警报。团队可以根据 ML 用例的重要性和紧迫性灵活地定制这些警报。值得注意的是，一种模型的质量可以直接或间接影响另一种模型。例如，一个模型的输出可以作为另一个模型的输入或触发进一步的模型评估。为了解决这种相互关联性，我们实施了一个通知系统，通知服务和模型所有者相关 ML 模型中的任何质量违规情况。&lt;/p&gt;&lt;p&gt;图 3 描述了模型卓越评分 (MES) 框架与 Uber 其他 ML 系统之间的交互。MES 框架及其指标、目标和协议建立在几个关键原则之上：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;自动可测量性&lt;/strong&gt;：MES 中的每个指标均采用可量化和自动化的指标设计，确保仪器仪表的基础设施稳健。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可操作性&lt;/strong&gt;：指标不仅是可衡量的，而且是可操作的。这意味着用户或平台可以采取明确的步骤来随着时间的推移根据其设定的目标改进这些指标。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可聚合性&lt;/strong&gt;：每个指标的指标都可以聚合。这对于有效的报告和监控至关重要，可以根据组织的目标和关键结果 (OKR) 以及关键绩效指标 (KPI) 统一汇总指标。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;再现性&lt;/strong&gt;：每个指标的指标都是幂等的，这意味着它们的测量在回填时保持一致。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;责任&lt;/strong&gt;：每份协议都附有明确的所有权。指定所有者负责定义目标并确保实现这些目标。 &lt;/li&gt;&lt;/ul&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/QJtG_get-AGg37qbai6tkDE1-x9IXbOt28Xsk4tFbSBV6mGfC5jt0aOXtPOEAQpP3RIK8JiQuc2-B-HTUquxWMh0LAqWelYAIesr2YJ2z1cT9-UyyaAOaD_GHGt8iN2BY8Vj2IHOhECetrh84AZU9Tg" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：MES 框架与各种 ML 系统之间交互的高级视图。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们重点关注表1中相关文献中未广泛涵盖的一些指标。MES能够衡量公平性和隐私等方面，这些主题不在本次讨论的范围之内。我们在下表中概述了每个指标如何遵循这些设计原则，提供了可衡量指标的示例、可操作的改进步骤以及用于确保指标在不同用例中可聚合和一致的标准化方案。这些指标要么标准化为 [0,1] 范围，要么转换为百分比，要么在各种应用程序中保持一致的范围。&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;指标&lt;/th&gt;&lt;th&gt;描述&lt;/th&gt;&lt;th&gt;可能采取的行动&lt;/th&gt;&lt;th&gt;指标标准化&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;数据质量&lt;/td&gt;&lt;td&gt;衡量用于训练模型的输入数据集的质量。这是以下的堆肥分数：&lt;br /&gt; – 特征为空&lt;br /&gt;– 跨区域一致性&lt;br /&gt;– 丢失分区&lt;br /&gt;– 重复&lt;/td&gt;&lt;td&gt;– 回填丢失的分区&lt;br /&gt;– 跨区域和实例同步数据分区&lt;br /&gt;– 删除数据中的重复行&lt;/td&gt;&lt;td&gt;综合分数中的每个组成部分均按百分比标准化&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;数据集新鲜度&lt;/td&gt;&lt;td&gt;测量用于训练模型的输入数据集的新鲜度&lt;/td&gt;&lt;td&gt;– 使用新的输入数据集重新训练&lt;br /&gt;– 如果更新数据可用，则回填输入数据集&lt;/td&gt;&lt;td&gt;规模一致&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;特征和概念漂移&lt;/td&gt;&lt;td&gt;生产模型的目标和协变量分布以及两者之间的关系随时间的变化&lt;/td&gt;&lt;td&gt;– 应用加权训练或使用新数据重新训练模型&lt;br /&gt;– 验证上游功能ETL管道的正确性&lt;/td&gt;&lt;td&gt;使用归一化距离度量和重要性权重归一化为 [0,1]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;模型可解释性&lt;/td&gt;&lt;td&gt;衡量模型生成的每个预测的稳健特征解释的存在性和置信度&lt;/td&gt;&lt;td&gt;– 启用解释&lt;/td&gt;&lt;td&gt;标准化为 [0,1]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;预测精度&lt;/td&gt;&lt;td&gt;模型对生产流量的预测准确性（例如，AUC、归一化 RMSE）&lt;/td&gt;&lt;td&gt; – 更新训练数据集以解决训练-服务偏差&lt;br /&gt;– 检查功能或概念漂移&lt;/td&gt;&lt;td&gt;通过标准化精度指标标准化为 [0,1]&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class="wp-element-caption"&gt;表：指标样本。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-results"&gt;结果&lt;/h2&gt;&lt;p&gt;Uber 实施 MES 框架显着提高了组织内 ML 质量的可见性。这种透明度的提高有助于培育优先考虑质量的文化，从而影响业务决策和工程策略。随着时间的推移，我们在各个方面观察到在遵守 SLA 方面取得了重大进展。值得注意的是，我们模型的整体预测性能显着提高了 60%。&lt;/p&gt;&lt;p&gt;此外，从 MES 指标中收集的见解对于确定平台增强领域至关重要。这些见解带来的一个关键发展是引入了用于超参数调整的高级平台工具。这项创新可以自动定期重新调整所有模型，简化优化过程并确保一致的模型性能。这些改进凸显了 MES 框架在推动运营效率和技术进步方面的切实好处&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-lessons-learned"&gt;得到教训&lt;/h2&gt;&lt;p&gt;在我们为 Uber 所有机器学习团队实施和监控关键指标的过程中，我们收集了一些重要的见解。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;激励机器学习从业者：&lt;/strong&gt;既定的框架可以对影响和针对质量改进的努力进行切实的衡量。通过采用标准且透明的报告系统，我们创建了一个环境，让机器学习从业者能够积极提高质量，因为他们知道他们的努力在整个组织中是可见的并得到认可的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;协调和行政支持：&lt;/strong&gt;最初，质量措施可能被视为额外的负担，除非它们从一开始就无缝地融入到日常实践中。实施质量跟踪框架可以揭示现有差距，需要在教育和意识方面付出额外努力来解决这些问题。与执行领导层保持一致至关重要，使团队能够优先考虑以质量为中心的任务。这种一致性逐渐导致全面转向更加积极主动、以质量为中心的文化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;平衡标准化与定制：&lt;/strong&gt;在设计框架时，我们的目标是实现一定程度的标准化，以便随着时间的推移进行一致的跟踪和明智的决策。然而，考虑到 Uber 的机器学习应用多种多样，允许对特定指标进行定制以准确反映每个用例的细微差别也至关重要。例如，在 ETA 预测模型中，我们采用平均平均误差作为比 RMSE 更符合上下文的指标。该框架适应了此类定制，同时保持了报告的标准化方法以确保一致性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;确定增量改进的优先级：&lt;/strong&gt;跨各种用例管理框架给确定优先级带来了重大挑战。我们开发了一个简单的优先级矩阵来确定哪些领域需要立即关注。认识到少数模型对影响的贡献最大，我们的重点是首先提高高影响力用例的质量。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;自动化的作用：&lt;/strong&gt;维持机器学习质量需要大量资源，并且在生产中手动管理模型可能会分散创新的精力。事实证明，生产生命周期自动化，包括使用新数据重新训练、重新验证和重新部署模型，是非常有价值的。这种自动化不仅增强了模型的新鲜度（如模型平均寿命的缩短所示），还使团队能够更多地关注创新，而不是维护。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;我们开发了一个全面的框架，概述了高质量机器学习 (ML) 模型在其生命周期不同阶段的关键维度。该框架受到服务级别协议 (SLA) 原则的启发，旨在监控和确保 ML 模型的质量。重要的是，它的结构可以容纳额外的质量维度，适应新兴的用例和该领域不断发展的最佳实践。&lt;/p&gt;&lt;p&gt;我们的讨论还涵盖了该框架在组织各个层面生成富有洞察力的质量报告的应用。这些报告会定期审查，促进问责制并为战略规划提供宝贵的见解。至关重要的是，通过将机器学习质量嵌入到相关软件系统的整体服务质量中，我们促进了共享责任模型。应用科学家、机器学习工程师和系统工程师现在共同拥有机器学习质量。这种协作方法极大地弥合了这些职能之间的差距，在组织内培育了积极主动、注重质量的文化。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-acknowledgments"&gt;致谢&lt;/h3&gt;&lt;p&gt;如果没有 Uber 工程师和应用科学家团队的帮助，我们不可能完成本文中概述的技术工作。我们还要感谢各位技术项目经理（Gaurav Khillon、Nayan Jain 和 Ian Kelley），感谢他们在促进 Uber 不同组织采用和合规 MES 框架方面发挥的关键作用。&lt;/p&gt;</description><pubDate>Thu, 21 Mar 2024 05:30:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/enhancing-the-quality-of-machine-learning-systems-at-scale/</guid></item><item><title>平衡 Uber DataLake 中的 HDFS 数据节点</title><link>https://www.uber.com/blog/balancing-hdfs-datanodes-in-the-uber-datalake/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;&lt;strong&gt;介绍&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;Apache Hadoop &lt;sup&gt;Ⓡ&lt;/sup&gt;分布式文件系统 (HDFS) 是一种分布式文件系统，旨在以可靠且容错的方式跨多台计算机存储大型文件。它是 Apache Hadoop 框架的一部分，也是 Uber 数据堆栈的主要组件之一。&lt;/p&gt;&lt;p&gt; Uber 拥有世界上最大的 HDFS 部署之一，在数十个集群中拥有 EB 级的数据。不断扩展我们的数据基础设施并在效率、服务可靠性和高性能之间取得平衡非常重要，但也具有挑战性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/VaaufGJF2NoMmsAXqw0SjcSbkWbdPFm1-Kr_ZYFuHKKoFGozTrx0QEhYCk2vu7lAd8vai59XYBhIssXwY0LfI5kWh7AQGTKKYTM34rWx8Re1V8U7gEI0Z0O_vLgXLXT8af8frAQNJJQ_95n95isTgWw" /&gt;&lt;/figure&gt;&lt;p&gt;图 1：Uber 的 HDFS 基础设施。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-overview"&gt;&lt;strong&gt;概述&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;HDFS 平衡器是通过在集群中均匀地重新分配数据来保持 DataNode 健康的关键组件。随着我们的 HDFS 集群的节点停用越来越频繁，HDFS 平衡器必须更有效地平衡数据，以防止 DataNode 倾斜。节点退役需求来自区域退役、安全补丁自动集群更新以及DataNode托管等项目。&lt;/p&gt;&lt;p&gt;然而，HDFS开源自带的平衡器并没有开箱即用地满足这个要求。我们已经看到一个 DataNode 出现偏差的问题（即，与同一集群中的其他节点相比，存储更多数据），这会产生多种副作用：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;导致包含过多数据的主机上的高 I/O 带宽&lt;/li&gt;&lt;li&gt;高利用率的节点有更高的缓慢概率、更高的节点故障和数据丢失风险&lt;/li&gt;&lt;li&gt;集群中活跃且健康的节点较少，无法为客户提供写入流量&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面是一个数据不平衡的例子：在我们最大的集群中，数千个节点的磁盘利用率接近95%，该集群由数千个DataNode组成，容量为数百PB，而平衡吞吐量无法有效地将数据移动到其他新添加的DataNode。这种不平衡的数据分布是由热分层和EC转换[1]产生的突发写入流量、安全补丁的区域分解/集群周转导致的密集节点退役造成的。由于写入可靠性是第一要务，因此所有 DataNode 都通过可用的容量加权算法来服务写入流量。随着写入流量的增加，数据偏差也会更大。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1082498" height="212" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Figure-2-Argon-cluster-original-1024x212.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：我们最大的集群之一包含大约数千个 DataNode，容量为数百 PB，但 DataNode 出现了偏差。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;因此，我们需要优化HDFS平衡器，以增加从高使用率DataNode到另一个占用率较低的DataNode的数据平衡。&lt;/p&gt;&lt;p&gt;考虑到 Uber 的数据存储规模，单个集群中会有超过 20 PB 的数据不平衡节点，集群数量为 7-8 个。为了解决 Uber DataLake 中平衡 HDFS DataNode 的问题，我们设计了一种新算法来增加 DataNode 之间形成的对的数量，这将在平衡数据的同时增加并行块移动。此外，我们还根据利用率对数据节点进行排序，以便优化形成的数据节点对，并且不会发生递归平衡。&lt;/p&gt;&lt;p&gt;该算法将继续增加用于平衡的吞吐量，即每秒从较高占用的数据节点移动到考虑平衡的较低占用的数据节点的数据大小。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-architecture-amp-design"&gt;&lt;strong&gt;架构设计&lt;/strong&gt;&lt;/h2&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/aypCjNKWlTTa6yQzeGj53GgpowcKkI2Sowy6KlqoObWeWb2sGt7QrR7AS5AEk8kjzHKseHi4zEbcG_HW31QNaglL96kh-0RzVIhXk8qVLmLMJbr5Qr_yULMeF-HVYBCBwknrf3UCeY1RRaNRv8vyLIk" style="width: 701px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：HDFS 平衡器架构。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;ol&gt;&lt;li&gt;初始化和设置：&lt;ol&gt;&lt;li&gt; HDFS 平衡器作为 Hadoop 集群中的服务在主机上运行。&lt;/li&gt;&lt;li&gt;要启动平衡过程，集群中需要存在具有平衡器角色的节点。没有两个平衡器可以同时运行。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;请求集群信息：&lt;ol&gt;&lt;li&gt;平衡器首先联系NameNode以请求有关集群内数据分布的信息。它向NameNode发送请求以获取有关数据块在DataNode上的分布的详细信息。&lt;/li&gt;&lt;li&gt; NameNode 以 DataNode 列表和它们包含的块以及它们的存储容量和其他相关信息进行响应。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;区块选择和规划：&lt;ol&gt;&lt;li&gt;根据从NameNode收到的信息，平衡器算法选择需要移动的块以实现更平衡的分布。&lt;/li&gt;&lt;li&gt;平衡器在规划块移动时会考虑 DataNode 利用率、机架信息、线程和存储容量等因素。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;数据移动的协调：&lt;ol&gt;&lt;li&gt;在确定要移动哪些块后，平衡器会协调 DataNode 之间的实际数据移动。&lt;/li&gt;&lt;li&gt;它与 NameNode 就借助心跳移动的块进行通信。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;块迁移：&lt;ol&gt;&lt;li&gt;平衡器通过直接与源和目标 DataNode 通信来启动块迁移。&lt;/li&gt;&lt;li&gt;它指示源DataNode将选定的块传输到目标DataNode，直接移动数据块。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;监控进度：&lt;ol&gt;&lt;li&gt;在整个数据移动过程中，平衡器持续监控进度。它跟踪已成功传输的块数量，并确保数据移动按照计划进行。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;完成和报告：&lt;ol&gt;&lt;li&gt;平衡操作完成后，平衡器会在日志中并通过指标报告已传输的数据和剩余待传输的数据。&lt;/li&gt;&lt;li&gt;它还可以提供有关平衡过程的统计数据和指标，包括移动的块数量和所花费的时间。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;终止：&lt;ol&gt;&lt;li&gt;在主机中，平衡器作为服务运行。因此，在集群达到平衡之前，它不会停止移动数据。 &lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-initial-optimizations"&gt;&lt;strong&gt;初始优化&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;br /&gt;由于我们的目标是提高吞吐量，以更快的速度平衡 DataNode，因此我们使用现有的 DataNode 属性优化了 HDFS 平衡器，以提高吞吐量。&lt;br /&gt;尽管我们将平衡器的速度提高到了 3 倍，但吞吐量仍然不够。我们有太多高度占用的节点，并且在现有算法中将数据传输到的 DataNode 对的数量会明显减少。此外，我们无法通过平衡器线程提高每个节点的吞吐量，因为增加吞吐量会增加节点的速度并影响读/写流量。因此，我们需要增加 DataNode 对的数量，这最终会导致平衡吞吐量的增加。&lt;br /&gt;&lt;br /&gt;我们使用的 DataNode 和 Balancer 配置如下所述。根据您的情况，您的工作负载的配置可能会有所不同。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;DataNode配置属性：&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-table has-small-font-size"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;财产&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;默认&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;快速模式&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;dfs.DataNode.balance.max.concurrent.moves&lt;/td&gt;&lt;td&gt; 5&lt;/td&gt;&lt;td&gt; 250&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; dfs.DataNode.balance.bandwidthPerSec&lt;/td&gt;&lt;td&gt; 1048576（1MB）&lt;/td&gt;&lt;td&gt; 1073741824（1GB）&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;平衡器配置属性：&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-table has-small-font-size"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;财产&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;默认&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;快速模式&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;dfs.DataNode.balance.max.concurrent.moves&lt;/td&gt;&lt;td&gt; 5&lt;/td&gt;&lt;td&gt; 250&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; dfs.balancer.moverThreads&lt;/td&gt;&lt;td&gt; 1000&lt;/td&gt;&lt;td&gt; 2000年&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;dfs.balancer.最大移动尺寸&lt;/td&gt;&lt;td&gt;10737418240（10GB）&lt;/td&gt;&lt;td&gt; 107374182400（100GB）&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; dfs.balancer.getBlocks.最小块大小&lt;/td&gt;&lt;td&gt;10485760 (10MB)&lt;/td&gt;&lt;td&gt; 104857600 (100MB) &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-algorithm-optimizations"&gt;&lt;strong&gt;算法优化&lt;/strong&gt;&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-increasing-datanode-pairs-for-high-throughput"&gt;增加 DataNode 对以实现高吞吐量&lt;/h3&gt;&lt;p&gt;更多的 DataNode 对意味着我们可以有更多的并发块传输，因此一个关键的改进是构造更多的对。由于现有算法，高度倾斜的集群形成的数据节点对较少。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1082506" height="549" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Figure-4-Balancer-Original-Algo-1024x549.jpeg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：现有算法。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;在 HDFS Balancer 的现有算法中，高于集群平均利用率的 DataNode（即高于平均利用率和过度利用率的节点）的数量比低于平均利用率和利用率不足的节点要高得多。因此，我们面临着节点稀缺的问题，无法从高利用率的 DataNode 上移动数据，这导致高利用率的 DataNode 无法快速停机。&lt;br /&gt;&lt;/p&gt;&lt;p&gt;在上图中，有 8 个 DataNode 高于平均利用率，4 个 DataNode 低于平均利用率，这将导致 4 个可以移动数据的目标。&lt;br /&gt;目的是修改 HDFS 算法，为 DataNode 形成更多对，从而从高使用率的 DataNode 中获得更多吞吐量，从而实现均匀利用率以及通过更大的 DataNode 覆盖范围快速降低使用率。&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们的想法是使用基于百分位数的算法来创建更多 DataNode 对。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/HlfZlWPK_wVdej0xQY_1gYkFAWt7JpDbSyPnbE4eLyQaV9-jk_XFbgFszAVnxWfTzTvMg_6MhjL3lsrAImSeStQrrcXNiIdM_W2zNWEHJlWnCsxhme1CD07Ju4Q8QoPHgBzqg-GDgSmcBSu7A8yh9RQ" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：新算法。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;在新算法中，我们根据百分位创建了调整后的平均值，这将增加数据可以移动到的节点数量。高于平均水平/过度利用的 DataNode 将尝试接近整体集群利用率，而未充分利用/低于平均利用的节点将尝试接近调整后的百分位数平均值。通过基于百分位数的算法，我们的目标是使调整后的平均值接近整体集群利用率。&lt;/p&gt;&lt;p&gt;我们将使用基于百分位数的算法来增加 DataNode 对。在高度倾斜的集群中，百分位数相当高。以上图为例，我们将百分位数设为 P60，调整后的平均值现在为 86.7%。在这种情况下，过度利用/高于平均利用的节点的数量减少，而利用不足/低于平均利用的节点的数量增加。&lt;/p&gt;&lt;p&gt;现在，将有 5 个过度利用且高于平均利用率的节点和 7 个利用率不足且低于平均水平的节点，这将导致 4 对最多形成 7 对。&lt;/p&gt;&lt;p&gt;我们有一个新的 Hadoop 配置属性&lt;em&gt;dfs.balancer.separate-percentile&lt;/em&gt; ， &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/ouUojzw_My_1YuqQvm4oGFoXtN03qy9mBcdjsfcPCHi7thgD_wkYfo3lkzZN6AzFvG2rs2qDHuftg2D3D8vpFw03dk94_r_UhuSUvSfkUr7w2YGuCOP1tNO3QDEE9RV8LwCkjScxreh3_YXyC0vPkPc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：用于定义百分位的新 Hadoop 配置。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;默认为 0.5，表示第 50 个百分位。如果我们使用 -dynamicBalancer 部署平衡器命令，则该百分位算法将生效，并且调整后的平均值将以更高的吞吐量出现。&lt;/p&gt;&lt;p&gt;我们还可以使用这个阈值来动态平衡。例如，如果 DataNodes 超过 90%，我们将积极平衡它们（即提高速度）。因此，我们将平衡前 20% 的 DataNode，这将导致将 moverThreads 集中在利用率最高的 20% 的源上，并且数据将从利用率高的 DataNode 移动得更快，并更快地降低使用率。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1082510" height="417" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Figure-7-Aggressive-balancer-code-1024x417.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：用于定义积极平衡的新 Hadoop 配置。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-moving-data-to-lower-occupied-datanodes"&gt;将数据移动到占用率较低的 DataNode&lt;/h3&gt;&lt;p&gt;由于自动化（即自动将DataNode中的数据移至其他DataNode进行维护），大型集群中的DataNode会频繁退役，退役节点的数据被转移到其他节点，导致节点占用率增加。那些节点。出现的新节点慢慢平衡，因为它们没有被赋予优先级。&lt;br /&gt;另外，例如，如果平均利用率为 83%，阈值为 3%，则 90% 的 DataNode 将其部分数据移动到 79% 的节点，该节点变为 81%。现在，如果新客户端在 81% 时转储数据，则变为 87%，这可能需要进一步平衡该节点，从而分配调度程序和移动程序线程。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/lAap83ZaUUmXXZdZ45R2B9TuHzz3O8zzrYpaZpti5Srpdxga1oV2Ay6yBqrlLqRRfVYe5r0jiEYlyQe8EBhD_W9T5Z_QsbkvToqR1-VPXv-9grrMlFCNb61rpOZtsv4jG1EX4Q3loB-vg-C0236qxdc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：旧算法 – 形成对。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/xoqmBEJU1prJmh7xmVNllTySnh2KfypKUZXcfY2Kp4qG3XMWEVnNMkpOQjm9EwfarrVBwn4IlD5gnaScUKbt7jRDQnBziP4EcDQTxEErbfKzT-5xu7nzj8EpOjDxKS1aFImRaPN_U5Iz2EEKSpjJp8Q" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：旧算法 – 新的过度使用的节点出现。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/qmXk_2q380kv8Nmo5YBY-jL_T6o88ZDB9sZ_M2RG8FCQ_Cs8vCKV5YiP11ahdV98lhsqvkhhb1yxJwVHySa__dVbeW0EtUlS96qwxHwl0eGYnVAnc6kf7vnx-KZCXEtKxG0muax_12jqY5aYP0cZtgE" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 10：新算法 - 首选优化。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们的增强功能是通过按升序对未充分利用的节点或低于平均水平的节点进行排序，对占用较小的 DataNode 进行优先排序，以首先平衡过度利用的节点中的数据，然后按降序排序高于平均水平的节点，以便平衡时，中间的节点不会进入图片，以防止递归平衡。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-better-observability"&gt;&lt;strong&gt;更好的可观察性&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;我们没有关于同一节点组、同一机架和任何其他机架之间过度利用和未充分利用、过度利用和低于平均利用率以及未充分利用和高于平均利用率之间形成的 DataNode 对的度量以及其他相关度量。因此，我们无法校准这些对之间的流量分配。为了找出可以在哪里增加 DataNode 对以提高吞吐量，我们创建了一个新的仪表板。&lt;/p&gt;&lt;p&gt;最后，我们添加了 10 多个指标来跟踪算法更改的性能，这将有助于我们更多地校准平衡器的自定义算法。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/qymsO6tHpnV1x5Re2lVFYtX5UqTArgNP0PT7JTLi2aua8DL9-GTRTMbFQZ7fF-WccCBJvmv5zXP72Akx1ejdFgBH2YdtFa_4tgz1CHFWyonX74vzT8OpAjRaGqDTUdNFWPAYgnGiJXaq7bg_7UtwbEw" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 11：我们的指标仪表板快照。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-results"&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;通过平衡算法的优化，我们将吞吐量提高了 5 倍以上，没有任何 DataNode 的利用率高于 90%，并且总体上降低了 DataNode 的使用率。此外，现在不需要部署仅使用某些硬编码节点来平衡数据的手动平衡器，因为我们在算法中的优化已经解决了这一问题。&lt;/p&gt;&lt;p&gt;作为我们新算法的一部分 -&lt;/p&gt;&lt;ul&gt;&lt;li&gt;吞吐量增加——我们将吞吐量增加了 5 倍以上。&lt;/li&gt;&lt;li&gt;降低高使用率的数据节点——我们将利用率高于 90% 的数据节点降低到 0。&lt;/li&gt;&lt;li&gt;数据节点的利用率相同——减少数据节点的总体使用量并使它们的容量相同。对于我们最大的集群，所有 DataNode 的利用率都低于 85%。&lt;/li&gt;&lt;li&gt;更好地管理容量——HDFS 集群的集群利用率从 65-66% 增加到 85% 左右，但我们遇到了容量瓶颈。尽管集群利用率比以往任何时候都高，但我们现在没有高度占用的数据节点。 &lt;/li&gt;&lt;/ul&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/xLa6b1OocD2j8moRGaxLJL_qbjP_xD412Zib_vZv3uYV-tXefy1Vq8IZK4Y1k8F-B_lWdetYp4_-xunCBgCdB3Ov0hhpnuKlLVARGodpE6nUURsocv7menNOQKubFT5oiBwCM7yyYfsmw4R1P64UMZ4" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 12：由于算法更改，DataNode 处于类似水平，并且我们最大的集群的利用率低于 85%。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/eO5trlhcsa5iPseVoe0deceN0afiwUstj3oyk95aGYV4xV6vO9ap3juytv9bnLQMitL88-tnRmKblbiVzmE6Li9vmAG0aRWXQ_Y5rIzo8Z846ZFOtm6BMoaFwHcQzIw8BZVgW4n2-1OTRolCH9LSnRE" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 13：反映 DataNode 偏差减少的面板。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/uqyVOYZWIMQ33KfRVuA4LeLDiASqtaMThAef2CjJ8Qa2_mNvgi51nJcH2A1VmhML8yXyE7e_cHmD8_5-zgS2OUe6PqOaEZQBbfNYvo_npxkCxKaKisWB_ZRWyOQQiN8Ox8uomG_T6DGJjR4dRPVU7Lc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 14：平衡器算法更改之前 – 使用率高于 90% 的 Datanode 为 50.8%。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/8jioc04QB8VJcyCm7bKU-IEx6cbiTgLeBe9O0aRb9CR4nwU8o4IRzQScNFOjhSns5XDspdY-u3cK5iirYw7QH9dwrCNoFoUfstbTMRuciCWxR6CHZXFTDtT_p-wuCHVYko3wmssd4f2PJnUXPa6HbPU" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 15：平衡器算法更改后 – 使用率高于 90% 的 Datanode 低于 0。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-full is-resized"&gt;&lt;img alt="" class="wp-image-1082512" height="662" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/03/Figure-16-Cluster-previous-capacity.png" style="width: 700px; height: auto;" width="844" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 16：我们的集群之一，集群利用率较低，约为 65%。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/FUzDUIGryAJWwVwckoZQPUKatRhcPpBWOxQrGHXh9P8-y3mOTVcgJEnJJjCHromXrwQtbz1T_7t7V7TEtQ9lNT9XI4IabGVADQ2rIzXK3FeDb4Zpd93h4i0a_3Y0oDCGRdxiNx6iGwomsnTU4tqmgBM" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 17：上述同一集群的集群利用率增加至 83% 左右。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/4xMTrAtGQ4KGaHED3rgIgLPSWn3YMy25QcXsCD4uhPn3YT8M9_PiyKp7NVwdqqJexncQPxAdWg7EFk_jIQR8nYO0hPn-IAU7QA2ho2syCDMroCNi7jSpnCDXDSuYOCQgf3EcoTwV4vT-Spp1WraoKkk" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 18：由于算法更改，吞吐量增加了 3 倍以上。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;在 HDFS 集群中，数据可能会在不同 DataNode 之间出现偏差，并可能导致节点上的 I/O 较高，从而导致速度缓慢或下降，从而导致数据丢失。新算法将有助于更快地平衡数据节点，以实现更高的效率、服务可靠性和高性能，同时防止更高的缓慢概率、更高的节点故障风险和数据丢失。&lt;/p&gt;&lt;p&gt;在 Uber 中，我们将此更改部署到多个集群以提高平衡吞吐量。我们正在为我们的优化提供一个开源补丁。 Uber HDFS 团队继续致力于解决类似的数据分布问题——考虑到我们的规模，即使是很小的改进也可以带来巨大的收益。&lt;/p&gt;&lt;p&gt; [1] Uber 将具有不同访问温度的数据保留在专用集群中，以实现更好的可靠性和成本效率。我们应用热分层将数据从热集群移动到热集群，并采用EC转换将数据移动到具有纠删码功能的集群，从而节省了50%的容量。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;“Apache®、Apache Hadoop® 和 Hadoop® 是 Apache Software Foundation 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。”&lt;/em&gt;&lt;/p&gt;</description><pubDate>Thu, 14 Mar 2024 05:30:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/balancing-hdfs-datanodes-in-the-uber-datalake/</guid></item><item><title>负载平衡：处理异构硬件</title><link>https://www.uber.com/blog/load-balancing-handling-heterogeneous-hardware/</link><description>&lt;h1 class="wp-block-heading" id="h-overview"&gt;&lt;strong&gt;概述&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;这篇博文描述了 Uber 通过更好的负载平衡来高效利用硬件的历程。这里描述的工作持续了一年多，涉及多个团队的工程师，并实现了显着的效率节省。这篇文章介绍了技术解决方案以及我们实现这些解决方案的发现过程——在很多方面，旅程比目的地更艰难。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-background"&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://www.uber.com/blog/better-load-balancing-real-time-dynamic-subsetting/" rel="noreferrer noopener" target="_blank"&gt;更好的负载平衡：实时动态子集 | Uber 博客&lt;/a&gt;是一篇相关的博客文章，早于此处描述的工作。我们不会重复背景知识——我们建议浏览一下我们的服务网格的概述。我们还将重复使用相同的字典。这篇文章重点介绍通过上述服务网格进行通信的工作负载。这涵盖了我们绝大多数的无状态工作负载。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-problem-statement"&gt;&lt;strong&gt;问题陈述&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;2020 年，我们开始致力于提高 Uber 多租户平台的整体效率。我们特别注重减少运行无状态服务所需的容量。在这篇博文中，我们将介绍各个团队做出的理性决策如何导致资源使用效率低下，我们如何分析问题和不同的方法，以及如何通过改进负载分配，让团队安全地提高 CPU 利用率并降低成本。这篇文章仅关注 CPU，因为这是我们的主要限制。&lt;/p&gt;&lt;p&gt;首先，了解一些背景：在 Uber，大多数容量决策都是分散的。虽然我们的平台团队提供了推荐的目标和工具（例如自动缩放器），但采用特定目标的最终决定取决于每个产品团队/组织。预算流程的存在是为了限制无限的分配。&lt;/p&gt;&lt;p&gt;作为预算过程的一部分，我们注意到我们认为利用率水平不合理地低。然而，提高利用率的尝试引起了产品团队的担忧——他们正确地担心提高利用率会危及系统的可靠性并影响其可用性/延迟目标。&lt;/p&gt;&lt;p&gt;问题的原因被认为是网络负载平衡不理想。许多工作负载的任务的 CPU 使用率高于平均水平。这些异常值在正常操作期间工作得很好，但在故障转移期间却很困难，并且不违反 SLA 的愿望导致我们的平均利用率下降。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/VPz0oGg-6KU9AQlKl7p6jeMb71w1ExYry6MeA5yDkQD_XQb62eP9S48IH_ZfGItt4tzYYz6TlzmYYaShRNRFe2x01S75ACNiS_T-OjaLcGO6FyfmyJF21eH0ks9v1fxPzvkBA-3cl0CGBKT3bY8oP-E" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：典型的“不平衡图”。每一行代表容器的 CPU 使用率。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/gV0L88878EKTUFagchXUUUkaTB0AieIEAzm4DDNKfjaATpUjMR_0yFE8vK-OY5w37lFhRS6DIRFZxEa-LE_pGYsk2PU4wQdEOfanI9pXjzqnAClzepSHXlA78fUwifiXWWF7QWlhc4Bo9WWf4g8-yfk" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：一个不太明显的情况：容器利用率分布在一个频带内，但有些容器的利用率高于其他容器。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-asymmetry-of-impact"&gt;&lt;strong&gt;影响不对称&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;负载不平衡的一个重要方面是&lt;strong&gt;其影响的不对称性&lt;/strong&gt;。想象一下这样的场景：100 个工作负载中，有 5 个工作负载未得到充分利用。这会影响效率，但成本相对较低——我们没有尽可能高效地使用 5% 的机器。&lt;/p&gt;&lt;p&gt;如果情况反过来，同样的5个工作负载被&lt;em&gt;过度&lt;/em&gt;利用，情况会严重得多。我们可能会影响客户体验并可能影响系统的可靠性。避免这些热点的简单解决方案是降低整个集群的平均利用率。这现在将产生&lt;em&gt;更显&lt;/em&gt;着的影响： &lt;strong&gt;95% 的工作负载未得到充分利用&lt;/strong&gt;，这意味着（财务）资源的浪费更加严重。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-forest-and-the-trees"&gt;&lt;strong&gt;森林和树木&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;由于异常值很容易发现，我们最初专注于一一修复和追踪它们，试图尽快找出根本原因并单独修复每个问题。这些单独修复的结果并不总是符合预期。我们的一些更改的影响低于预期或仅影响系统的一部分。同样，后来的其他变化也带来了意想不到的重大改进。这是由于几个独立的问题正在发挥作用。这种“问题森林”导致工作基本上是连续的——只有在更大的兄弟问题得到解决后，我们才会发现一个新的、更小的问题。&lt;/p&gt;&lt;p&gt;回想起来，“意外”部分可以通过更严格的分析来减轻——我们可以更多地了解系统并提前收集更多样本。不过，工作的顺序可能是相同的——只有通过我们学习如何理解和衡量系统的过程。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-measuring-the-impact"&gt;&lt;strong&gt;衡量影响&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;也许令人惊讶的是，直到最后，该项目最具争议的方面之一就是衡量影响。讨论涉及来自不同团队和组织的人员在不同时间加入和离开该项目。每个相关方对问题、优先级和潜在解决方案都有有价值但略有不同的观点。&lt;/p&gt;&lt;p&gt;仅仅持续衡量影响就非常复杂。显然，我们应该测量异常值 - 我们很快决定使用给定工作负载中利用率排名第 99 位的任务的 CPU 利用率。经过一番讨论，我们同意使用平均值作为基础，留下 p99/平均值作为&lt;em&gt;不平衡指标&lt;/em&gt;。&lt;/p&gt;&lt;p&gt;然而，即使这样也含糊得令人惊讶：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;工作负载在跨多个区域的多个集群中运行。 p99/平均值应该在所有实例中计算还是单独为每个集群计算？如果是针对每个集群，我们如何权衡结果？这一决定&lt;em&gt;极大地&lt;/em&gt;影响了最终的数字。&lt;/li&gt;&lt;li&gt;工作负载在多个区域中运行，但与区域不同的是，我们的区域表现出很强的隔离性——向何处发送流量不受网络控制。因此，网络团队可能关心与业务不同的指标。&lt;/li&gt;&lt;li&gt;典型的工作负载具有周期性模式——服务可能在一周中的特定一天最繁忙，而在其他时间则未得到充分利用。我们应该只测量高峰时的不平衡情况还是全天测量不平衡情况？如果处于高峰期，多长时间的时间范围应被视为高峰期？我们只关心单周峰值吗？&lt;/li&gt;&lt;li&gt;我们的工作负载通常以主动-主动模式运行，每个区域都有一些备用容量用于潜在的故障转移。在这些故障转移期间，负载不平衡最为重要——我们是否应该在那时才尝试测量它？如果是这样，我们的测量频率将会减少——通常，我们每周都会得到一个简单的样本。&lt;/li&gt;&lt;li&gt;工作负载很吵。服务推出通常会导致不平衡峰值（随着新容器的到来并预热）。某些工作负载可能会很快推出（每次增量），但每天会通过 CD 管道推出数十次。其他工作负载要慢得多，单次部署可能需要几个小时。两种类型的推出都可以与高峰时间重叠。最重要的是，还有“非典型事件”，例如临时性能下降、流量耗尽、负载测试或与事件相关的问题。&lt;/li&gt;&lt;li&gt;大多数工作负载遵循“标准”模式，但一些（更关键的）服务已被划分为具有单独路由配置的自定义分片。同样，一小部分基本工作负载还可以通过自定义对等路由进行访问。最后，另一小部分服务在专用主机上运行。这些尺寸可能会影响我们的跟踪。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;一旦我们确定了每个工作负载指标，问题就会扩展到多服务：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们如何权衡最终得分中的各个工作负载？&lt;/li&gt;&lt;li&gt;每个服务的等级（优先级）如何影响其在最终得分中的权重？&lt;/li&gt;&lt;li&gt;不同的工作负载具有不同的周期模式这一事实是否会影响分数？工作负载通常有每周和每日的峰值，但这些峰值不是同时出现的。&lt;/li&gt;&lt;li&gt;我们能否将最终指标分解为子组件来跟踪各个区域或集群的不平衡情况？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些指标必须实时用于开发和监控——在这里，我们关心尽可能高的精度，通常是亚分钟。然而，相同的指标必须在很长一段时间内（数年）可用，我们需要将数据汇总成日大小的块，同时牢记之前的所有权重考虑因素。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-actual-numbers"&gt;&lt;strong&gt;实际数字：&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;最终，我们创建了一个“持续失衡指标”。对于每个工作负载，我们计算每分钟的 p99（例如，5 个核心）和平均（例如，4 个核心）CPU 利用率。结合容器的数量，我们可以计算出“浪费的核心”。对于上面的示例，10 个容器将导致 10*4=40（核心）&lt;em&gt;使用，&lt;/em&gt; (5-4)*10=10 个核心&lt;em&gt;浪费&lt;/em&gt;，最终指标为 1+10/40=1.25。这直观地映射到人类在实时调试时可以执行的“标准”p99/平均计算 125%。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/ZyU1H3XwK_fGjpDhsyhcKROE_XnjnbhmTKc_AkW1b-yvzLpTJ4TbnDiAqQ_b5jcOhM-4RFnaqrjVTFUHfNVqCRgh_299GXdMaUQeRX5Ca8eGP8mO8WrGDaHoo77l1OL5uOJJjHnNCFIqUEh3EgnzauY" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：不平衡的理论定义。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;随着时间的推移，这实际上变成了两条曲线下的面积比：p99 和平均利用率。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/Ed94kW9bEsKmlR9f6liB9hLJFJTRA2eWNbC61KrTCvqjRR16FF_17rG_29z2qqzrzobImlGT0S-GrF0ISBBjWaXnEV2TGRwIMFr_8R3E4lM5D1exq-LUcqAw4YjIVVjoVFbRYXowXbpESs_2zLlcIUM" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：实时仪表板上的连续不平衡指示器。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;这种方法的好处是，由于浪费和利用率是按核心的绝对数量计算的，因此它允许我们以自定义的任意维度聚合它们：每个服务、每个服务每个集群、每组服务、每个集群、每个区域。同样，任何时间窗口（小时、天、周）自然有效——就像对一系列整数求和一样简单。此外，该指标自然会给予“繁忙”时段更高的权重——高峰期的不平衡比非高峰期的不平衡更为严重。缺点是难以向人类解释该指标，但我们发现“加权 p99/平均值”的近似值是可以接受的。&lt;/p&gt;&lt;p&gt;另一种计算“每周 p99 的 p99”和“每周平均值的平均值”比率的方法更容易在单个服务的基础上进行解释，但对随机事件（耗尽、故障转移、负载测试、部署）高度敏感，这让它很吵。此外，跨服务加权并不那么简单。&lt;/p&gt;&lt;p&gt;上述指标可通过 Grafana 中的实时指标和 Hive 中的长期存储来获取。我们需要编写自定义管道来每天预处理指标以实现可视化。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-different-slicing"&gt;&lt;strong&gt;不同切片&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;测量负载不平衡的一个特殊问题值得指出：如何分割数据会极大地影响结果。人们很容易从小部分（集群、区域、区域）开始，然后“平均”不平衡。遗憾的是，这在实践中行不通。例如，两个集群的（平均）p99/平均比率可能为 110%，但是当纵观整个工作负载时，不平衡可能要高得多，在我们的案例中高达 140%。同样，将两个较高不平衡性的集群组合起来可能会导致较低的不平衡性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-addressing-the-issues"&gt;&lt;strong&gt;解决问题&lt;/strong&gt;&lt;/h1&gt;&lt;h2 class="wp-block-heading" id="h-the-first-step-getting-hacky-data-first"&gt;&lt;strong&gt;第一步：首先获取（hacky）数据&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;我们首先构建 Grafana 仪表板以实现实时可观察性。这使我们能够实时单独衡量每个服务的影响，但无助于理解根本原因。虽然假设负载平衡有问题，但我们“真的”不知道。最初的问题是缺乏可观察性，我们面临两个问题。&lt;/p&gt;&lt;p&gt;首先，由于基数问题，我们的负载均衡器没有按每个后端实例发出统计信息。由于许多服务运行数千个容器和数百个程序，这会导致我们的代理中的内存使用量爆炸，并使统计数据无法查询，即使是中等规模的服务。幸运的是，那个夏天的一个实习生项目添加了在新的指标命名空间（保持现有统计数据不变）上选择性加入的统计数据（节省代理内存使用）的能力。与&lt;a href="https://chronosphere.io/learn/how-can-recording-and-roll-up-rules-help-your-metrics/" rel="noreferrer noopener" target="_blank"&gt;汇总规则&lt;/a&gt;一起，我们现在可以内省大多数服务（只要我们一次只为其中一些服务启用额外的可见性）。&lt;/p&gt;&lt;p&gt;其次，我们失去了跨计算和网络堆栈唯一识别实例的能力。当时，我们可以看到每个目标的 CPU 使用情况，但无法轻松地将其映射到容器。由于我们广泛的 IP 目标范围和动态端口使用&lt;em&gt;，主机：端口&lt;/em&gt;的可用“唯一标识符”会破坏我们的指标（同样， &lt;a href="https://chronosphere.io/learn/what-is-high-cardinality/" rel="noreferrer noopener" target="_blank"&gt;基数&lt;/a&gt;）。关于适当解决方案的讨论此前已停滞了几个季度。最终，网络堆栈实现了一个基于 IP 地址排序和发出基于整数的实例 ID 的短期解决方案。这些在部署中并不稳定，但与一些更黑客的脚本一起，使我们能够获取所需的数据。&lt;/p&gt;&lt;p&gt;这一步提供了重要的教训：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;始终首先获取数据&lt;/li&gt;&lt;li&gt;恰到好处、有针对性、孤立的黑客攻击可能非常有用&lt;/li&gt;&lt;li&gt;您不需要完美的可观察性来得出正确的结论&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-manual-analysis"&gt;&lt;strong&gt;手动分析&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;一旦我们深入了解了这个问题，我们就挑选了一些大型服务并尝试分析根本原因。令人惊讶的是，负载平衡并没有出现问题——在 1 分钟窗口（我们当时的 CPU 统计分辨率）下，RPS 分布几乎是完美的。每个容器接收的请求数量几乎相同，大多数应用程序的差异低于 0.1%。然而，在同一窗口内，CPU 利用率差异很大。&lt;/p&gt;&lt;p&gt;经过几周的调查，我们能够量化几个独立的原因：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一些重要的流量来源被迫失衡。例如，我们的许多系统都是“城市感知”的，城市总是位于单个区域。这自然会为每个地区带来不同的交通量，并且随着城市的醒来和入睡，比例不断变化。&lt;/li&gt;&lt;li&gt;服务跨集群内和跨集群的多个硬件 SKU 运行。&lt;/li&gt;&lt;li&gt;即使理论上相同的硬件也表现出显着的性能差异。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;一些不平衡被留在“未知”的桶中。事实证明，其中大部分是我们的可观察性问题。我们目前将剩余部分（小于原​​始不平衡的 20%）归因于&lt;a href="https://en.wikipedia.org/wiki/Cloud_computing_issues#Performance_interference_and_noisy_neighbors" rel="noreferrer noopener" target="_blank"&gt;嘈杂的邻居&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;下图显示了对 2020 年我们最大的服务之一的初步分析。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/IovK_kUSNl_76Da7EKegaYqylzW4OiEV2s09RUzrt8Ow18SAqVzjyVT2Wrj3HNseZCmCS_J1WN-NQ0tNJAbVO5OvknwSFOnFDpAmldb5QDSGtTrFedRGz9OBgOnX2aMe1ymxQui-d4sEXFATK81vruM" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：了解不平衡。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-forced-to-build-long-term-aggregations"&gt;&lt;strong&gt;被迫建立长期聚合&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;那时，我们想从任何容易实现的目标开始。 &lt;a href="https://www.uber.com/blog/better-load-balancing-real-time-dynamic-subsetting/" rel="noreferrer noopener" target="_blank"&gt;更好的负载平衡：实时动态子集 | Uber 博客&lt;/a&gt;为我们提供了一些可以调整的旋钮。然而，这并不容易，反而提出了一个新问题。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/AHpjR9Jv7KdKJ-xuaOkLWwL9iswUHo2Of3qYZlMnURcDdhlawPN6XfL9pf96j3rFVjclApy_BT1IOEfX1w7HHzVBiuljPda6NKXGWgzQ839BfeZw53O1AYa-hYsk0qgq-2cAIEIF5RcnyaKf5ETUuSo" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：单个服务的每周 CPU 使用率模式。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们的服务表现出每日和每周的大量周期（见上文）。最重要的是，我们经常看到由故障、部署、故障转移或临时事件引起的峰值。推出更改后，人类只能发现巨大的改进（20%+），但我们的更改太微妙了。&lt;/p&gt;&lt;p&gt;这导致了前面段落中解释的可观察性决策。我们构建了基于稳定和峰值弹性指标来聚合长期数据的管道。最重要的是，我们可以按集群、区域、区域或服务组对指标进行切片——这反过来又可以让我们调查更多“可疑”行为。&lt;/p&gt;&lt;p&gt;一些预先存在的旋钮可以让我们减少服务网格引起的负载不平衡部分，但这只是整个问题的一小部分。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-possible-solutions"&gt;&lt;strong&gt;可能的解决方案&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;显然，第一步是查看底层硬件配置和操作系统设置。一些单独的线程开始研究这些。&lt;/p&gt;&lt;p&gt;解决硬件异构性需要更复杂的过程。许多方法都是可能的，来自：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;修改&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/sec-cpu" rel="noreferrer noopener" target="_blank"&gt;CFS 参数&lt;/a&gt;，使队列中的每个主机看起来相同，尽管底层硬件不同。&lt;ul&gt;&lt;li&gt;这个选项很有吸引力，但由于对各种软件堆栈（如&lt;a href="https://pkg.go.dev/runtime#GOMAXPROCS" rel="noreferrer noopener" target="_blank"&gt;GOMAXPROCS&lt;/a&gt; ）的影响不明确，最终被驳回。回想起来，这也阻止了我们使用&lt;a href="https://www.uber.com/blog/avoiding-cpu-throttling-in-a-containerized-environment/" rel="noreferrer noopener" target="_blank"&gt;cpu 集进行配置。&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;修改主机到群集的放置以实现统一的群集。&lt;/li&gt;&lt;li&gt;修改每个服务的集群布局以保证稳定但不统一的主机选择。&lt;/li&gt;&lt;li&gt;转向云式主机管理，每个团队将选择特定类型的硬件。&lt;/li&gt;&lt;li&gt;许多可能的服务网格更改可以实现更好的负载&lt;em&gt;平衡&lt;/em&gt;。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="Screenshot of a spreadsheet, fields colored by the feasibility" src="https://lh7-us.googleusercontent.com/YC4s0sGZby4epTYOC36Um_cXU12K4MNkNHr_RSpt31Nijf4xB2IrGiPs3TJosQOVCrfsNnNov_ym5o2A9SLApgHEQl3u3Uu_JpuEHsh4w2gHuytW0lxB09_iU0oOdzf0p_6tpnAq7muT8DtwhUhcBcw" title="可能的修复（故意不可读）" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：选项矩阵（故意模糊）&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;在可能的选项中，出于多种原因选择了对服务网格进行更改。从技术上讲，我们层上的更改不需要更改数据中心的物理布局，也不需要每个服务的迁移。从战术上讲，我们还可以快速地将更改交付给大多数服务。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-changes"&gt;&lt;strong&gt;变化&lt;/strong&gt;&lt;/h1&gt;&lt;h2 class="wp-block-heading" id="h-hardware"&gt;&lt;strong&gt;硬件&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;虽然硬件 SKU 内存在根本差异，但我们发现硬件、固件和低级软件存在许多问题。它们的范围包括操作系统设置、CPU 调速器设置、固件版本、驱动程序版本、CPU 微代码版本，甚至内核版本与 Intel HWP 不兼容。造成这种情况的一个普遍根本原因是，从历史上看，一旦硬件被摄入并出现在机群中，除非出现问题，否则它就不会受到影响。但随着时间的推移，这导致了机器之间的漂移。&lt;/p&gt;&lt;p&gt; Uber 在混合云/私有设置中运行，因此我们自然也遇到了特定于云的问题。与其他公司一样，我们已经看到了多个理论上相同配置的虚拟机性能不相似的情况（ &lt;a href="https://www.reddit.com/r/aws/comments/547xbx/netflix_found_5x_performance_variation_between/" rel="noreferrer noopener" target="_blank"&gt;这&lt;/a&gt;仍然是真实的）。同样，我们也看到过在本地运行良好的工作负载在云上引发问题的情况。更糟糕的是，云意味着底层基础设施细节的可见性降低。&lt;/p&gt;&lt;p&gt;如果没有最近完成的&lt;a href="https://www.uber.com/en-IN/blog/crane-ubers-next-gen-infrastructure-stack/" rel="noreferrer noopener" target="_blank"&gt;Crane 项目&lt;/a&gt;，解决所有这些问题几乎是不可能的——我们可以在没有人工参与的情况下测量、修复和推出对数万台机器的更改。现在，所有发现的问题都会被自动检测和修复。&lt;/p&gt;&lt;p&gt;这些修复的一个明显好处是它们适用于每个工作负载，无论它如何处理或发起其工作（Kafka、Cadence、RPC、计时器、批处理作业等）。除了改善负载不平衡之外，它们还为我们提供了有效的可用容量——一些 CPU 一夜之间“变得更快”。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-observability"&gt;&lt;strong&gt;可观察性&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;可观察性是这个问题的一个有趣的部分。在项目开始之前，我们知道由于 1 分钟窗口大小，我们在样本收集方面存在限制，但我们发现了更多问题。&lt;/p&gt;&lt;p&gt;从技术上讲，这些问题是由&lt;a href="https://en.wikipedia.org/wiki/Cgroups" rel="noreferrer noopener" target="_blank"&gt;cgroups、&lt;/a&gt; &lt;a href="https://github.com/google/cadvisor" rel="noreferrer noopener" target="_blank"&gt;cexporter&lt;/a&gt; 、我们内部&lt;a href="https://prometheus.io/" rel="noreferrer noopener" target="_blank"&gt;Prometheus&lt;/a&gt;指标抓取器和&lt;a href="https://github.com/m3db/m3" rel="noreferrer noopener" target="_blank"&gt;m3&lt;/a&gt;之间的交互引起的。特别是，由于指标以不断增加的方式发出，管道中任何地方统计数据收集的任何延迟都会导致百分位数计算中出现（大的）人为峰值。我们投入了大量的工作来保留样本的时间戳以及妥善处理目标和收集器服务的重新启动。一个示例 &lt;a href="https://github.com/google/cadvisor/issues/2913" rel="noreferrer noopener" target="_blank"&gt;问题&lt;/a&gt;是有效地破坏了任何足够大的服务的数据收集。&lt;/p&gt;&lt;p&gt;可观察性问题的一个令人着迷的方面与人类互动有关，或者说人类不可信这一事实。在项目早期，我们询问服务所有者什么级别的容器利用率会导致用户影响（延迟增加）。有趣的是，几个月后，当我们推出修复程序后，当我们再次询问时，我们收到了相同的答案。这两种说法都无效，因为我们知道旧数据是错误的。最终，人类的非理性导致了净效率的胜利：服务所有者最终（有效地）更热地运行他们的服务，同时认为什么都没有改变。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-load-balancing"&gt;&lt;strong&gt;负载均衡&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;正如&lt;a href="https://www.uber.com/blog/better-load-balancing-real-time-dynamic-subsetting/" rel="noreferrer noopener" target="_blank"&gt;更好的负载平衡：实时动态子集 |&lt;/a&gt;中所述。 &lt;a href="https://www.uber.com/blog/better-load-balancing-real-time-dynamic-subsetting/" rel="noreferrer noopener" target="_blank"&gt;Uber 博客&lt;/a&gt;，我们的服务网格在两个层面上工作。最初，控制平面发送&lt;em&gt;分配&lt;/em&gt;决定应向每个目标集群发送多少流量。这里决定了簇之间的不平衡性。&lt;br /&gt;随后，数据平面遵循此分配，但随后它负责选择正确的主机 - 这里发生第二级集群内负载平衡。虽然我们考虑改变这个模型，但我们保持不变，并为每个级别推出了两种解决方案。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-inter-cluster-imbalance"&gt;&lt;strong&gt;集群间不平衡&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;在 Uber，服务在多个地区的多个区域运行。由于每个区域在不同的时间出现，因此无法保证每个区域中的主机相同 - 通常，区域越新，它们拥有的硬件就越新。区域之间的性能差异会导致CPU不平衡。&lt;/p&gt;&lt;p&gt;我们最初的方法是为每个区域设置一个静态权重；然后，权重将用于负载平衡，以便具有更快硬件的区域接受更多请求。每个区域的权重计算为该区域中部署的每个主机的标准化计算单元 (NCU) 因子的平均值。 NCU 因子根据基准分数衡量主机 CPU/核心性能，其中分数取决于每周期核心指令（每个时钟周期核心完成多少工作）和核心频率（多少个时钟周期）的乘积每秒可用）。&lt;/p&gt;&lt;p&gt;然后，我们可以使用静态区域权重作为乘数，将更多流量发送到更强大/更快的区域。&lt;/p&gt;&lt;p&gt;具有更高乘数的更快区域将按比例路由更多流量，以提高 CPU 利用率，从而缓解 CPU 不平衡。&lt;/p&gt;&lt;p&gt;例如，如果某个服务在区域 A（权重 = 1）和 B（权重 = 1.2）中部署了 10 个实例，则负载平衡将按照 B 有 12 (10 * 1.2) 个实例进行，这样 B 将收到更多请求比 A。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/L22FN7eamJeUaNg5UhAokiSDGFniHnCMQqexYTjB-BIGI_bUVBreGefBUA1dqB3iOcbUUe6rVj9noQvx3Doqxjqigl7GkEk0aEYDYIOYmAVv9crDdtH6vwqrnQSwazMEU5nwjggUTjsRrhyDKWPqNkA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：区域权重&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;这种方法的效果出人意料地好——我们能够以相对较小的努力缓解大部分不平衡问题。然而，存在一些问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;区域权重是区域中所有主机的估计值（平均 NCU 因子）。然而，服务部署在区域中最快/最慢的主机上可能非常幸运/不幸。&lt;/li&gt;&lt;li&gt;尽管不经常发生，但我们经营的区域会因开工或停工而发生变化。此外，在启动期间，我们通常会逐渐摄取硬件，这可能需要多次更新。&lt;/li&gt;&lt;li&gt;有时，我们会将新硬件引入旧区域以调整其大小或更换损坏的硬件。该硬件可以是不同类型的，因此需要调整权重。&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-dynamic-host-aware-cluster-load-balancing"&gt;&lt;strong&gt;动态主机感知集群负载平衡&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;因此，我们重新审视了这个问题，并投资了一种先进的解决方案：主机感知流量负载平衡。&lt;/p&gt;&lt;p&gt;这种方法通过查看服务实例部署到的确切主机、收集其服务器类型，然后更新每个服务的集群之间的负载平衡来解决这些缺点。这是通过让我们的发现系统了解主机（通过 IP）、其主机类型和权重的映射来实现的，这样对于部署在集群中的给定服务，发现系统可以向我们的流量控制提供额外的权&lt;strong&gt;&lt;em&gt;重&lt;/em&gt;&lt;/strong&gt;信息系统。下图显示了一个示例： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/BTH2IqexwVovC1iquHIIHhv744jyBweDXUPMKK4a5bDezGdqTbhfxk3SVVl5SZCz5bvZhFdg1td0ptbM1Hmy5SxzxxRBkDstE-jwYQzPSWQIPoukzhtztVliK1Gp6f3k6VUM6uSH5jLKGOsew_h7eH8" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：动态主机感知集群负载平衡&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;对于服务 Foo，如果我们平等对待每个实例，负载均衡比例应该为&lt;strong&gt;37.5&lt;/strong&gt; %/ &lt;strong&gt;62.5&lt;/strong&gt; %，而不是示例中所示的&lt;strong&gt;&lt;em&gt;36&lt;/em&gt;&lt;/strong&gt; %/ &lt;strong&gt;&lt;em&gt;64&lt;/em&gt;&lt;/strong&gt; %。如果主机跨越多代（我们的机群中不同主机之间的权重差异高达 2 倍），则差异可能会变得更加显着。&lt;/p&gt;&lt;p&gt;与静态权重方法相比，主机感知负载平衡动态调整每个服务的权重，以减少集群间的不平衡。由于很少引入新的主机类型，因此维护起来也更加容易。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-intra-cluster-imbalance"&gt;&lt;strong&gt;集群内不平衡&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;如前所述，集群内不平衡是主机上代理（称为 Muttley）的责任。每个代理都可以完全控制为每个请求选择正确的对等点。所有服务使用的 Muttley 原始负载平衡算法是最少挂起的，它将请求发送到已知未完成请求数量最少的对等点。虽然以 1 分钟为间隔测量时，这导致了 RPS 几乎完美的平衡，但由于不同的硬件类型，它仍然导致 CPU 利用率不平衡。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-assisted-load-balancing-alb"&gt;&lt;strong&gt;辅助负载平衡 (ALB)&lt;/strong&gt; &lt;/h3&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/_CL-GbcOXQlLQSs4Aq-a2Q7NaKUOA7HjoTu_P_nt0NnJM1biDm26uHcmmuVlePy5vgZenjeQsxii3KraWa3AU6ixB51OUDJehHqHMBQaM5co9vnXPy4AokvL1plsofFDmuqISUQ2drgx9sPcZylHFiQ" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 10：辅助负载平衡简而言之。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们构建了一个系统，其中每个后端&lt;em&gt;协助&lt;/em&gt;负载均衡器选择下一个对等点。应用程序中间件层将负载元数据作为标头附加到每个响应。我们有效地达成了一个无需中央协调的协调系统。以前，每个 Muttley 只知道它造成的负载（加上它可以从延迟推断出的一些信息），现在，它动态地了解每个后端的总状态。这种状态不仅受到后端本身的影响（例如，在较慢的硬件上运行），而且还受到其他 Muttley 做出的决策的影响。例如，如果（随机）将后端选择到太多子集中，则系统会动态调整。这让我们稍后可以减少 ALB 上服务的子集大小。&lt;/p&gt;&lt;p&gt;虽然&lt;a href="https://sre.google/sre-book/load-balancing-datacenter/#weighted-round-robin-eKspTGCm" rel="noreferrer noopener" target="_blank"&gt;Google SRE 书中&lt;/a&gt;的简短提及部分启发了这种方法，但我们做出了一些不同的选择。这两项更改彼此相关，并试图简化该方法。我们打算稍后开始、评估并转向更复杂的解决方案 - 幸运的是，我们不必这样做。在实施后期，我们发现了一篇&lt;a href="https://netflixtechblog.com/netflix-edge-load-balancing-695308b5548c" rel="noreferrer noopener" target="_blank"&gt;Netflix 博客文章&lt;/a&gt;，并且我们独立得出了类似的结论。&lt;/p&gt;&lt;p&gt;首先，作为负载元数据，我们使用正在处理的并发请求数，以整数形式报告（q=1、q=2、..、q=100 等）。我们也考虑了报告利用率，但这并不是立即显而易见的（报告的利用率是否应该基于&lt;a href="https://man7.org/linux/man-pages/man2/getrusage.2.html" rel="noreferrer noopener" target="_blank"&gt;getrusage&lt;/a&gt;还是&lt;a href="https://en.wikipedia.org/wiki/Cgroups" rel="noreferrer noopener" target="_blank"&gt;cgroups）。&lt;/a&gt; Cgroup 更为自然，因为服务所有者使用它来跟踪他们的目标。尽管如此，它们还是带来了更多挑战——我们的基础团队担心每个 docker 容器独立抓取 cgroup 的成本，以及如果 cgroup 布局发生变化（包括在 cgroupsv2 迁移期间）可能发生的紧密耦合。我们可以通过与收集统计数据的主机恶魔集成来解决这个问题，但我们希望避免添加新的运行时依赖项。最后，仅使用逻辑整数就足够了（进行一些调整，如下所述）。此外，它允许在不更改负载均衡器代码的情况下覆盖每个服务 - 虽然绝大多数应用程序使用标准负载指示器，但一些（异步）应用程序覆盖它以更好地反映其负载。&lt;/p&gt;&lt;p&gt;第二个出发点是&lt;a href="https://www.eecs.harvard.edu/~michaelm/postscripts/handbook2001.pdf" rel="noreferrer noopener" target="_blank"&gt;两个随机选择的力量，&lt;/a&gt;而不是加权循环赛。由于我们只有一个整数作为负载指示器，所以 pick-2 实现看起来更简单、更安全。与上面类似，这工作得很好，我们不需要改变它。事实证明，这种方法对我们整个应用程序范围内的故障非常宽容。除了典型的崩溃循环或 OOMing 应用程序之外，我们还遇到过中间件的错误/错误实现未导致事件的情况。我们推测，由于加权循环法更加精确和“严格”，因此在某些情况下它可能会表现“更好”，但可能会导致类似&lt;a href="https://en.wikipedia.org/wiki/Thundering_herd_problem" rel="noreferrer noopener" target="_blank"&gt;雷群&lt;/a&gt;的情况。&lt;/p&gt;&lt;p&gt;在实施方面，每个 Muttley 使用&lt;a href="https://en.wikipedia.org/wiki/Moving_average#Modified_moving_average" rel="noreferrer noopener" target="_blank"&gt;修改后的移动平均值&lt;/a&gt;来保持每个对等点的分数超过 25 个之前的请求——这个值在我们的测试中效果最好。为了在 RPS 较低的情况下获得有意义的数字，我们将每个报告的负载增加了 1000。&lt;/p&gt;&lt;p&gt; pick-2 负载均衡器的一个有趣问题是“负载最多”的对等点&lt;em&gt;永远&lt;/em&gt;不会被选择。而且因为我们被动地发现对等点负载，我们也会刷新其状态，从而使其有效地未被使用，直到另一个对等点变得更慢。我们最初通过实施“失败者惩罚”来缓解这一问题，每当一个节点失去选择时，其“负载值”就会在内部减少——因此，如果有足够的损失，该节点将再次被选择。事实证明，这对于大调用者实例计数低 RPS 的场景来说效果不佳，有时需要几分钟才能重新选择对等点。最终，我们将其更改为时间衰减，其中同行的分数根据上次选择时间而降低。我们目前使用 5 秒的半衰期来进行分数衰减。&lt;/p&gt;&lt;p&gt;我们还实现了一项内部称为“吞吐量奖励”的功能。这源于经验观察，即较新的硬件可以更好地处理并发请求。我们注意到，当在不同硬件上的两个对等点之间进行负载平衡并且两个对等点报告相同的“负载值”时，我们如预期的那样，向速度更快的对等点发送更多请求。但是，较快对等点的 CPU 利用率（已处理=15，CPU=10%，Q=5）仍低于较慢对等点（已处理=10，CPU=12%，Q=5）。为了弥补这一点，每次对等点“完成”一个请求时，我们都会稍微减少其负载以向其推送更多请求。对等点相对于子集中其他对等点的速度越快，它获得的“吞吐量奖励”就越多。此功能使 P99 CPU 利用率降低了 2%。&lt;/p&gt;&lt;p&gt; ALB 设计文档的一个重要部分（大部分）致力于可能的替代方案。我们认真考虑过，不是将负载元数据附加到每个响应，而是使用中央组件来收集和分发数据。人们担心元数据可能会消耗大量可用带宽。我们内部有两个表面上看起来相关的系统。第一个是集中式健康检查系统，几乎实时收集车队中每个集装箱的健康状态。第二个是上一篇博文中描述的实时聚合系统。&lt;/p&gt;&lt;p&gt;&lt;br /&gt;事实证明，重用其中任何一个都是不可行的：运行状况检查系统可以轻松地从所有容器收集负载状态，但收集后，该系统被设计为很少分发运行状况更改 - 绝大多数时间，容器仍然存在健康。然而，负载平衡指标会根据设计不断变化。由于我们运行平面网格（每个容器都可以与每个容器通信），因此我们需要不断地将数百万个容器的数据分发到数十万台机器，或者构建一个新的聚合和缓存层。同样，负载报告聚合系统也不匹配——它以低几个数量级的基数对每个集群的聚合值进行操作。&lt;/p&gt;&lt;p&gt;&lt;br /&gt;最终，我们对所选择的（基于响应标头）方法感到满意。它实施起来很简单，并且使成本归因变得容易——推动更多 RPS 的服务会带来更高的带宽成本。从绝对数字来看，与每个请求附加的其他跟踪/身份验证元数据相比，额外元数据（每个请求约 8 个字节）的成本几乎是看不见的。&lt;/p&gt;&lt;p&gt;延迟是“分布式”与“集中式”负载数据收集的一个有趣的方面。从理论上讲，响应标头方法接近实时，因为负载附加到每个响应。然而，由于每个 Muttley 都需要独立地发现这一点，然后对之前的响应进行平均，因此对于基于低 RPS 的场景，该发现可能需要一些时间。基于健康检查的方法需要完整的往返（通常约为 5 秒），但会立即分发到所有调用方实例。&lt;/p&gt;&lt;p&gt;&lt;br /&gt;然而，如果我们实现了它，由于上一段中列出的带宽问题，我们可能会将推送频率降低到 1 分钟左右。这可能足以修复硬件引起的偏斜，但可能没有其他问题，例如流量峰值，缓慢启动的应用程序或故障转移。在不同情况下，两种方法的工作可能略有不同。不过，最终，我们对分布式方法很满意 - 它很容易推理，并且缺少可能失败的集中组件。&lt;/p&gt;&lt;p&gt;所选方法的一个缺点是它需要目标服务的合作。尽管需要最少的工作，但将其应用于数千个微服务将很艰巨。幸运的是，过去几年在Uber建造的大多数应用程序都使用了&lt;a href="https://github.com/yarpc/yarpc-go" rel="noreferrer noopener" target="_blank"&gt;通用框架&lt;/a&gt;，使我们能够快速插入所需的中间件。几项大型服务没有使用框架，但是同时进行的多年努力迁移了几乎所有服务。我们发现决定有利于该框架的决定，因为它具有更复杂的效果 - 服务所有者还有更多的理由投资移民。到我们写这篇文章时，几乎所有服务都在共同的框架上。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-static-component-alb-v1-1"&gt;&lt;strong&gt;静态组件 -  Alb V1.1&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;最初的推出不符合我们硬件引起的减少目标。主要原因是我们的硬件在大多数时间中都充分利用了不足 - 我们为区域故障转移和每周窥视提供了缓冲区。事实证明，使用相对较低的容器利用率，旧硬件可能会爆发足够高，以使延迟差异在消耗更多的CPU时间时不可见期。尽管这意味着在压力下（当我们需要时）载荷平衡的效果要好得多，但它使产品工程师对我们的目标利用感到不舒服，但不平衡的不平衡看上去太高了。&lt;/p&gt;&lt;p&gt;我们在负载平衡中添加了第二个静态组件来解决这个问题。我们利用了一个事实，即在我们的设置中，主机的IP地址永远不会改变。由于代理自然知道目的地的IP地址，因此我们只需要将IP地址的映射提供给相对主机性能。由于数据的静态性质，我们开始添加此信息作为构建时间配置的一部分。这种重量本身并不完美：不同的应用程序在相同的硬件类型上的性能不同。但是，结合ALB的动态部分，这效果很好 - 我们不需要添加特定于应用程序的权重。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-testing"&gt;&lt;strong&gt;测试&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;开发过程中的一个大问题是测试。虽然我们的登台环境有限，但需要使用许多参数的新解决方案：一些呼叫者或卡勒斯有三个实例，约三千个实例。一些后端的服务&amp;lt;1，有些后端&amp;gt; 1,000 rps。一些服务采用了一个同质的程序，而另一些服务的潜伏期从低毫秒到数十秒钟不等。最终，我们在生产中使用了虚拟服务，其中一组伪造的负载生成器配置为代表异构负载。在找到正确的参数并尝试推出生产服务之前，我们进行了300多个模拟。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-results"&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;我们对最终结果感到满意 - 确切的数字取决于服务和每个集群中的硬件混合物。尽管如此，平均而言，我们将P99 CPU利用率降低了12％，其中一些服务的收益超过30％。目标服务每个后端的目标服务越大 - 非常非常优化，我们所关心的最大服务通常是足够优化的。同样的运气也适用于入职 - 虽然Uber拥有超过4,000个微服务，但入职前100位为我们带来了大部分潜在影响力。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-rollout-and-future-changes"&gt;&lt;strong&gt;推出和将来的变化&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;推广进行得很好 - 我们尚未确定材料错误。 Pick-2负载平衡和安全的后备被证明具有弹性。我们按地区划分的层面服务，试图找到代表性的服务类型。&lt;/p&gt;&lt;p&gt; Alb被推广到我们数百种最大的服务，并以最小的打ic或更改：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;em&gt;寿命长的RPC流&lt;/em&gt;。一小类服务正在将少量长寿命的RPC流与许多非常短暂的请求混合在一起。我们在那儿滚回去。&lt;/li&gt;&lt;li&gt;&lt;em&gt;缓慢启动的运行时间&lt;/em&gt;。推出大约两年后，我们对解决方案进行了调整以更好地处理缓慢启动（Java）服务。由于JIT而启动后，这些服务无法达到相同的请求率，但是记录的静态请求的热身效果不够好；我们需要以较低的速度使用真实请求来为服务加热。在这里，我们决定将每个同伴的初始“重量”播种，同时使算法的核心保持不变。我们发现这可以在各种服务中运行良好，我们很高兴这不需要任何静态窗口设置，与Envoy的&lt;a href="https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/upstream/load_balancing/slow_start" rel="noreferrer noopener" target="_blank"&gt;慢速启动模式&lt;/a&gt;不同，该算法会自动调整到一系列RPS。&lt;/li&gt;&lt;li&gt;&lt;em&gt;在启动时预取数据。&lt;/em&gt;另一个非常小的服务是在启动几分钟内预加载静态数据。由于我们服务出版机制的特殊性，这些服务的实例在我们的服务发现中可以看到“不健康”。旧算法强烈更喜欢健康的实例。当服务在临时超负荷后无法启动时，我们将其更改为ALB，以避免像雷声一样的情况（由于每个实例在依次变得健康时都会立即超负荷）。新算法非常喜欢健康的实例，但是在某些情况下，请求可能会发送给“不健康”节点。这对这些服务不起作用 - 虽然报告的错误&amp;lt;0.01％和0.002％，但我们正在探索类似于&lt;a href="https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/upstream/load_balancing/panic_threshold" rel="noreferrer noopener" target="_blank"&gt;恐慌阈值&lt;/a&gt;的变化，以使其完全消失。&lt;/li&gt;&lt;li&gt; &lt;em&gt;IP地址映射&lt;/em&gt;。 IP地址到服务器类型的静态映射工作2年以上，但是当我们&lt;a href="https://www.oracle.com/news/announcement/uber-selects-oracle-cloud-infrastructure-2023-02-13/" rel="noreferrer noopener" target="_blank"&gt;将工作负载移至云&lt;/a&gt;时，可能需要对其进行调整。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;有趣的是，两个服务覆盖了默认负载提供商，以根据后台作业处理来发射自定义负载指标。这证明了默认值在大多数服务方面效果很好，但是该解决方案足够灵活以支持其他用例。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-summary"&gt;&lt;strong&gt;概括&lt;/strong&gt;&lt;/h1&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/arrmQ21tVj4fLv6DVkrkdoYxp0bRT0f1Ab5Ha98zym8rjLVCbLymSXDdqyP_RJxBlIg5KE6zaAxzjYWdmgmq13h5M-GPgiEWTF5EczSNYkmFjn3sw0EiMlh97DhB32wtW0vjRSUqRGdPjC-rRQ_sebU" /&gt;&lt;figcaption class="wp-element-caption"&gt;图11：区域权重推出。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;该项目带来了非常重大的效率胜利。我们可以以较高的利用水平运行容器，而负载不平衡不再是无状态工作负载的问题。硬件配置的改进导致了减少失衡和纯计算能力的双重胜利。&lt;/p&gt;&lt;p&gt;更有趣的是，从工程博客的角度来看，该项目也导致了一些学习。&lt;/p&gt;&lt;p&gt;主要的是数据的重要性。问题是真实的，但是我们以错误的假设开始了该项目。我们不知道如何衡量它。一旦同意，我们就缺乏有效衡量它的工具，尤其是从长远来看。即使在那之后，我们也意识到我们从基础基础设施中收集样本的潜在方式也存在缺陷。同时，数据赢得了争论，帮助我们磨练问题，并将与其他团队的工作优先考虑。另一个数据课是为长期设置数据基础架构 - 在项目期间和以前也有所帮助。我们能够将现有的数据仓库用作基础，现在后来我们会定期收到有关负载不平衡的疑问。指向仪表板的链接通常回答所有问题。&lt;/p&gt;&lt;p&gt;第二堂课是在正确的位置添加解决方案，以获取我们需要的数据。建立适当的实时可观察性将花费我们数月或几个月的时间。尽管如此，我们很快就通过有针对性的黑客来得出了正确的结论，并有选择地将观察结果基于服务样本。与此相关的是愿意做很多手动咕unt的工作：为了建立理解，我们花了数周的时间盯着仪表板并在开始编码之前验证假设。后来，在实现ALB和区域/群集权重时，我们从相对较小的更改，验证的假设开始，然后迭代到下一个版本。&lt;/p&gt;&lt;p&gt;第三个可以说，第三个是可以信任平台的。我们打赌我们的微服务将迁移到共同的框架。同样，在实施时，我们建立了在平台上存在的多年投资（仪表板，仪表板，调试工具，操作知识，推出政策）的多年以上，我们可以快速，安全地进行重大变化。 。我们用平台的谷物构建，并避免了可能使该项目脱轨的重大重写。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-acknowledgments"&gt;&lt;strong&gt;致谢&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;该项目有很多人参与其中。我们感谢Avinash Palayadi，Prashant Varanasi，Zheng Shao，Hiren Panchasara和Ankit Srivastava的一般贡献。 Jeff Bean，Sahil Rihan，Vikrant Soman，Jon Nathan和Vaidas Zlotkus用于硬件帮助，Vytenis darulis可观察性修复程序，Jia Zhan和Eric Chung，用于Alb Reviews，Nisha Khater，Nisha khater，每年的lu yarpc for yarpc for yarpc for yarpc for yarpc全球。&lt;/p&gt;&lt;p class="has-small-font-size"&gt;徽标归因： &lt;a href="https://www.flickr.com/photos/141290938@N03" rel="noreferrer noopener" target="_blank"&gt;weiss_paarz_photos&lt;/a&gt;撰写的“ &lt;a href="https://www.flickr.com/photos/141290938@N03/26682754214" rel="noreferrer noopener" target="_blank"&gt;司法规模 - 法律 - 律师和律师&lt;/a&gt;”，根据&lt;a href="https://creativecommons.org/licenses/by-sa/2.0/?ref=openverse" rel="noreferrer noopener" target="_blank"&gt;CC BY-SA 2.0&lt;/a&gt;许可。&lt;/p&gt;</description><pubDate>Thu, 07 Mar 2024 07:00:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/load-balancing-handling-heterogeneous-hardware/</guid></item><item><title>使用 Aristotle v2 进行网络 IDS 规则集管理</title><link>https://www.uber.com/blog/network-ids-ruleset-management-with-aristotle-v2/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;如果您向一位经验丰富的 SOC（安全运营中心）分析师询问有关网络 IDS（入侵检测系统）或 IPS（入侵防御系统）的问题，他的回答可能会包含&lt;em&gt;“警报太多”&lt;/em&gt;和&lt;em&gt;“误报”等短语。&lt;/em&gt;在 Uber，我们面临着同样的数量、准确性和可管理性挑战。每天多次解析、分析、更新、过滤并部署超过 90,000 个 IDS 规则到我们的网络传感器。 &lt;a href="https://github.com/secureworks/aristotle/releases/tag/v2.0.0" rel="noreferrer noopener" target="_blank"&gt;Aristotle v2 的&lt;/a&gt;创建是为了使我们能够自动化此过程，应用基于归纳的情报提取，并增强规则元数据以减少误报并帮助确保适当的 IDS 警报得到适当的关注。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-overview"&gt;概述&lt;/h2&gt;&lt;p&gt;Uber 的 IDS 规则集更新过程涉及多个步骤，如图 1 所示。整理和分发规则非常简单，并且对于所有 Suricata™ 部署都是通用的。决定要包含哪些规则以及如何修改它们是第 4 步“过滤规则集”中发生的事情，这将是本博客的重点。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/6EfyApi87FAXsUWWOQm_9Dx78vMvI3h_N7q8faeJeghq0NI_U1tlQEGEXVwcKik1oxxRBBGJbhjjQ3SEhL9Cx4hPIwFHr8yUcMaXKLVdmz4DbRINAF4LBgk92UJKZAR993YpZQ3IsPgMauY88YLib5I" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;图 1：IDS 规则集更新流程。&lt;/em&gt; &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-background"&gt;背景&lt;/h2&gt;&lt;p&gt;IDS 警报由按照规则（或“规则集”）管理的逻辑运行的 IDS 引擎生成。在基本层面上，IDS 规则可以被视为针对网络流量和连接状态的高级模式匹配。最流行的开源网络 IDS 引擎是&lt;a href="https://suricata.io/" rel="noreferrer noopener" target="_blank"&gt;Suricata&lt;/a&gt;和&lt;a href="https://snort.org/" rel="noreferrer noopener" target="_blank"&gt;Snort&lt;/a&gt; ™。本文重点介绍 Suricata，但其中的概念和实践也适用于 Snort。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-ids-rule-selection-approaches"&gt; IDS 规则选择方法&lt;/h2&gt;&lt;p&gt;选择应用于特定传感器的规则可能会对误报率、不需要的 IDS 警报和引擎性能产生重大影响。例如，保护 Linux® Web 服务器池的传感器不需要运行旨在检测针对 Windows® 文件共享的攻击的规则。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-rule-classification"&gt;规则分类&lt;/h3&gt;&lt;p&gt;从历史上看，规则集使用者在选择启用或禁用哪些规则时使用两个大“旋钮”。第一个是“classtype”，这是一个具有有限选项集的本机规则关键字，这些选项由规则集提供者定义并尝试对规则进行分类。通常，定义的类类型类别不超过几十个，常见值包括“trojan-activity”、“attempted-dos”和“bad-unknown”。第二个旋钮是规则集提供者放置规则的文件的文件名，规则集提供者通常会将规则分隔到不同的文件中，名称如“sql.rules”、“scan.rules”和“trojan.rules”。&lt;/p&gt;&lt;p&gt;这些“旋钮”的一个主要问题是它们不允许一对多映射。每个仅支持单个规则的单个值。这种缺乏灵活性可能会受到限制。例如，检测最近发现的漏洞利用工具包活动的规则是否应该放入“current-events.rules”、“exploit.rules”或“web-client.rules”文件（仅举几个选项）？ “classtype”字段也存在类似的挑战，其中检测到的活动可以合法地分为多个类别。这些有限、生硬的规则分类机制过于广泛，无法支持现代部署所需的规则集微调灵活性。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-manual-review"&gt;人工审核&lt;/h3&gt;&lt;p&gt;为了针对特定环境优化规则集，必须对它们进行调整。这通常会导致不平凡的、持续的、手动的工作。事实上，一些公司的日常任务是手动检查每条新规则，决定是否应将其包含在内，然后根据需要进行调整。然而，这很快就会变得繁重，并且显然无法扩展，特别是如果现有规则也必须定期重新调整的话。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-metadata"&gt;元数据&lt;/h3&gt;&lt;p&gt;存在一个由 Suricata 和 Snort 等 IDS 引擎支持的“元数据”关键字，它允许将任意键值对嵌入到每个规则中。这对于决定启用哪些规则非常有帮助，因为可以根据元数据的内容过滤规则。 Suricata 还将在 IDS 警报中包含元数据，可用于更明智的后处理、决策和关联。&lt;/p&gt;&lt;p&gt;与传统规则分类相比，元数据键值对具有明显的优势，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;一对多映射：&lt;/strong&gt;例如，“protocols”元数据键可以具有值“http”和“tcp”&lt;/li&gt;&lt;li&gt;&lt;strong&gt;任意键名称和值：&lt;/strong&gt;分类不必局限于预定义的有限选项&lt;/li&gt;&lt;/ul&gt;&lt;h4 class="wp-block-heading" id="h-a-better-way"&gt;更好的方法&lt;/h4&gt;&lt;p&gt;&lt;a href="https://better-schema.readthedocs.io/" rel="noreferrer noopener" target="_blank"&gt;BETTER&lt;/a&gt; （更好的增强型目的和分类嵌入规则）模式于 2019 年提出，用于基于键值的 IDS 规则元数据。它认识到一对多元数据映射的需求，并尝试为常用元数据带来一些结构和标准化键和（在某些情况下）值。 &lt;a href="https://www.secureworks.com/" rel="noreferrer noopener" target="_blank"&gt;Secureworks&lt;/a&gt; ® 是一家供应商，在其 Suricata 规则集产品中完全实施了 BETTER，而&lt;a href="https://rules.emergingthreats.net/" rel="noreferrer noopener" target="_blank"&gt;Proofpoint ET Pro&lt;/a&gt; ® 等其他供应商则拥有部分兼容的规则集。 BETTER 从未得到广泛的行业采用，但其主要概念仍然存在，并且使用元数据进行规则集过滤仍然是一个可靠的策略。&lt;/p&gt;&lt;p&gt;许多规则集提供商确实会填充元数据，但几乎所有规则集提供商这样做的方式都严重限制了使用元数据作为规则过滤手段的有效性。具体来说，规则集具有以下一个或多个缺点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;缺少元数据&lt;/strong&gt;：规则集中未使用适用的元数据键值对，或者选择性地而不是普遍应用元数据键值对。如果所有适用的元数据都应用于所有适用的规则，则基于元数据过滤规则集是最有用的，而当情况并非如此时，实用性会急剧下降。例如，当还有 400 多个可以以相同方式分类的规则时，在规则集中的 20 条规则上设置元数据“攻击目标 http-server”，使得基于该键值对的过滤的值有限。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;值格式不一致&lt;/strong&gt;：例如，“cve”键值可能显示为“cve_2023_1234”、“cve_2023_1234_cve_2023_2468”、“2023_1234”、“2023-1234”等。如果没有标准化的命名法，精确过滤将变得具有挑战性。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;值格式不佳&lt;/strong&gt;：这包括在指定时间/日期字符串时不使用&lt;a href="https://www.iso.org/iso-8601-date-and-time-format.html" rel="noreferrer noopener" target="_blank"&gt;ISO 8601&lt;/a&gt;等标准日期时间格式等。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-aristotle-v1"&gt;亚里士多德 v1&lt;/h2&gt;&lt;p&gt; 2019 年， &lt;a href="https://www.secureworks.com/" rel="noreferrer noopener" target="_blank"&gt;Secureworks&lt;/a&gt;发布了&lt;a href="https://github.com/secureworks/aristotle/releases/tag/1.0.5" rel="noreferrer noopener" target="_blank"&gt;Aristotle (v1)&lt;/a&gt; ，这是一款开源 Python 工具，允许用户根据元数据键值对“过滤”（启用或禁用）规则。通过使用具体的布尔代数，可以定义“过滤字符串”来控制规则选择。这可能非常强大，但 Aristotle v1 的实用性受到所提供规则中元数据的丰富性（或者更确切地说，缺乏元数据）的限制，这些元数据由规则集供应商控制并且手动维护繁重。由于大多数规则集供应商不提供全面的元数据和/或没有具有精确编程过滤所需的精度和一致性的元数据，因此需要比 Aristotle v1 更高的东西。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-metadata-and-beyond"&gt;元数据及其他&lt;/h1&gt;&lt;h2 class="wp-block-heading" id="h-aristotle-v2"&gt;亚里士多德 v2&lt;/h2&gt;&lt;p&gt; Uber 最近对&lt;a href="https://github.com/secureworks/aristotle/" rel="noreferrer noopener" target="_blank"&gt;Aristotle&lt;/a&gt;做出了重大改进，产生了&lt;a href="https://github.com/secureworks/aristotle/releases/tag/v2.0.0" rel="noreferrer noopener" target="_blank"&gt;Aristotle v2&lt;/a&gt; 。这些更新增加了对元数据标准化、增强和操作的支持。图 2 显示了 Aristotle v2 的不同组件，我们将对此进行更详细的讨论。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/xD-k_zGYrP0E2OvjjvYtxgHwHQ7JUMBexQANRA_Eu2aYPDpoMzEIrchMQf6wgIw2xjEyog4IaHfNg6sV20TwqA3Y71iIrf_Pd8w1_vgx7AWalDiYxSbndXriycNrLGhRqS_Gr3r2kjZ46tzqJqN6zOM" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;图 2：Aristotle v2 组件。&lt;/em&gt; &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-filtering"&gt;过滤&lt;/h3&gt;&lt;p&gt;Aristotle v1（基本上是“过滤规则集”步骤）在支持元数据的布尔过滤方面做得很好，甚至包括为某些键指定数字关系的能力（例如，“created_at &amp;gt; 2023-01-01”）。在支持此类比较的键列表中，Aristotle v2 添加了&lt;strong&gt;risk_score&lt;/strong&gt; （稍后会详细介绍该键）。&lt;/p&gt;&lt;p&gt;此外，Aristotle v2 中还引入了基于正则表达式的过滤功能。虽然这确实会影响过滤性能，因为它将非文字元素添加到布尔表达式中，但它确实提供了强大且经常需要的功能。具体来说，正则表达式匹配可以使用“rule_regex”关键字应用于整个规则，也可以使用“msg_regex”关键字将范围限制到“msg”字段。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-normalization"&gt;正常化&lt;/h3&gt;&lt;p&gt;为了解决由于缺乏一致的元数据值格式而带来的过滤挑战，Aristotle v2 支持某些元数据键值的规范化。具体来说，支持以下标准化：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;strong&gt;CVE&lt;/strong&gt;键值标准化为格式&lt;em&gt;YYYY-&amp;lt;num&amp;gt;&lt;/em&gt; 。如果值中表示多个 CVE 并用“_”串在一起（例如“cve_2021_27561_cve_2021_27562”[&lt;em&gt;原文如此&lt;/em&gt;]），则所有已识别的 CVE 将被标准化并包含在内。&lt;/li&gt;&lt;li&gt;来自非 BETTER 模式键&lt;strong&gt;mitre_technique_id&lt;/strong&gt;和&lt;strong&gt;mitre_tropic_id&lt;/strong&gt;的值将被放入符合标准的&lt;strong&gt;mitre_attack&lt;/strong&gt;键中。&lt;/li&gt;&lt;li&gt;日期键值（由任何以“_at”或“-at”结尾的键名称确定，例如， &lt;strong&gt;created_at&lt;/strong&gt; ）将尝试标准化为 ISO 8601 格式&lt;em&gt;YYYY-MM-DD&lt;/em&gt; 。&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-enhancement"&gt;强化&lt;/h3&gt;&lt;p&gt;虽然标准化元数据是必要且有用的，但它无法解决元数据丢失的问题。然而，规则不仅仅是它的元数据，因此我们提出了这样的问题：“&lt;em&gt;我们能否从规则的本体中识别、推论、归纳或以其他方式推断细节，并用该信息增强规则元数据？&lt;/em&gt; ” 这导致了亚里士多德 v2 能够分析每个规则的本体并通过以下&lt;a href="https://aristotle-py.readthedocs.io/en/latest/usage.html#enhance" rel="noreferrer noopener" target="_blank"&gt;增强功能&lt;/a&gt;添加/更新元数据：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;流键&lt;/strong&gt;的值标准化为“to_server”或“to_client”&lt;/li&gt;&lt;li&gt;&lt;strong&gt;协议&lt;/strong&gt;键和适用值&lt;/li&gt;&lt;li&gt;&lt;strong&gt;cve&lt;/strong&gt;键和适用值。这些值基于从原始规则中提取的数据，例如“msg”字段、“reference”关键字等。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;mitre_attack&lt;/strong&gt;键和适用的值。这些值基于从规则的“参考”关键字中提取的数据&lt;/li&gt;&lt;li&gt;&lt;strong&gt;敌对&lt;/strong&gt;密钥和适用值（“dest_ip”或“src_ip”）—这些值是从“target”关键字获取的值的倒数&lt;/li&gt;&lt;li&gt;&lt;strong&gt;类类型&lt;/strong&gt;键和适用值&lt;/li&gt;&lt;li&gt;&lt;strong&gt;文件名&lt;/strong&gt;键和适用的值 - 如果规则是从文件加载的，则该值将是规则来源的文件名&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Original_disabled&lt;/strong&gt;键和布尔值在内部添加到每个规则上，用于过滤&lt;/li&gt;&lt;li&gt;&lt;strong&gt;检测方向&lt;/strong&gt;键（见下文）&lt;/li&gt;&lt;/ul&gt;&lt;h4 class="wp-block-heading" id="h-detection-direction"&gt;检测方向&lt;/h4&gt;&lt;p&gt;虽然网络 IDS 规则可以是单向的，但绝大多数都是针对客户端-服务器通信的一侧而编写的。此外，规则的范围通常是通过指定源和目标的 IP 地址组来确定的。 IP 地址组是用户定义的，但几乎总是包含变量“HOME_NET”和“EXTERNAL_NET”。这个想法是 HOME_NET 是用户或公司拥有的一组 IP 地址，旨在受到保护； EXTERNAL_NET 是用户网络（通常是一般互联网）“外部”的 IP 组。 EXTERNAL_NET 通常（但不一定）定义为 HOME_NET 中未指定的所有内容。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;detector_direction&lt;/strong&gt;元数据键尝试标准化规则检测到的流量的方向性。为此，需要对规则的源部分和目标部分进行处理并缩减为“$HOME_NET”、“$EXTERNAL_NET”、“any”或“UNDETERMINED”，并用于设置&lt;strong&gt;detector_direction&lt;/strong&gt;值，如图 3 所示。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/rwHiJEqmAcq7pqON8pnrpt2Tp9XmvhGxRSe5Vcc-i1bpiIPwjm73jvH_0raA3E9dWOkzWzd4C3vlaM7oeCUvzUacl8uKFArxQSCNCb71h1-QLfNXZD736JMmp7FwkeLGdFhj5jZZajAfVmwdP0SbDoU" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;图 3：检测方向值和条件。&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;了解规则的“检测方向”对于确定其所检测内容的重要性和严重性非常重要。例如，考虑一条检测已知由感染 Mirai 恶意软件的设备生成的流量的规则。此类入站流量（来自 EXTERNAL_NET 并定向到 HOME_NET）通常可归类为扫描，并被认为只不过是互联网噪音。然而，此类出站流量（来自 HOME_NET 并定向到 EXTERNAL_NET）很好地表明您的网络上存在受感染的设备，并且它是活动僵尸网络的一部分。后一种情况比前一种情况更为严重，应按前一种情况处理。规则及其关联的 IDS 警报需要能够传达这些现实情况。准确地对规则及其 IDS 警报进行分类，以便能够以编程方式对其进行响应非常重要，而这正是后置过滤器修改发挥作用的地方。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-pfmod-post-filter-modification"&gt; PFMod（后置滤波器修改）&lt;/h3&gt;&lt;p&gt; Aristotle v2 提供了在规范化、增强和初始过滤字符串应用后进一步过滤和修改规则集的选项。这称为 PFMod（ &lt;a href="https://aristotle-py.readthedocs.io/en/latest/post_filter_mod.html" rel="noreferrer noopener" target="_blank"&gt;过滤器后修改&lt;/a&gt;），允许根据过滤器字符串识别规则，然后对这些规则采取特定的“操作”。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-pfmod-actions"&gt; PFMod 操作&lt;/h4&gt;&lt;p&gt;PFMod 操作包括添加/删除元数据、启用/禁用规则、设置优先级以及对完整规则执行基于正则表达式的“查找和替换”的功能。支持的 PFMod 操作包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;禁用&lt;/strong&gt;：禁用该规则。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;启用&lt;/strong&gt;：启用规则。请注意，要使“禁用”规则进入 PFMod 进行考虑，它们必须首先在初始过滤器字符串匹配阶段进行匹配。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;add_metadata&lt;/strong&gt; ：YAML 键值对，其中 (YAML) 值是要添加的元数据键值对，例如“协议 http”。请注意，如果已经存在使用给定键的元数据，则不会覆盖它，除非值也相同，在这种情况下，不会添加任何内容，因为它已经存在。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;add_metadata_exclusive&lt;/strong&gt; ：YAML 键值对，其中 (YAML) 值是要添加的元数据键值对（例如，“优先级高”）。如果给定的元数据键已存在，请使用新值覆盖它。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;delete_metadata&lt;/strong&gt; ：如果给出了元数据键值对（例如，“former_category 恶意软件”），则从规则中删除该键值对。如果仅给出了元数据键名称（例如“former_category”），则使用给定键删除所有元数据，无论值如何。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;regex_sub&lt;/strong&gt; ：对规则执行正则表达式查找和替换。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;set_&amp;lt;keyword&amp;gt;&lt;/strong&gt; ：将 IDS 规则字符串中的&lt;em&gt;&amp;lt;keyword&amp;gt;&lt;/em&gt;设置为给定值。如果规则不包含给定关键字，则添加它并将值设置为给定值。支持的关键字包括“priority”、“sid”、“gid”、“rev”、“msg”、“classtype”、“reference”、“target”、“threshold”和“flow”。对于整数关键字（“priority”、“rev”、“gid”和“sid”），可以通过在整数值前面添加“+”或“-”来使用相对值。例如，操作“set_priority“-1””将导致规则中现有的优先级值减1。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;set_&amp;lt;任意_整数_元数据&amp;gt;&lt;/strong&gt; ：与“add_metadata_exclusive”类似，允许设置或更改任意基于整数的元数据键值，但也支持相对值以及默认值。格式如图4所示。 &lt;/li&gt;&lt;/ul&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/cDFJsx8a4aR3fzcHxzT5t7BZxYGOGfujqynX60OfUBJAWhp_kRonpAJJymbKHMKiwUzKGqDCVOlqw5YiAe6XLh6PfDVvMeAUWV3vwCTgRpSBLFmsNjhRAw9nfA-NBrRJppAEuYIlP9T7Fq-5apCTUAg" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;图 4：用于设置任意基于整数的元数据的 PFMod 操作语法。&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;笔记：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;em&gt;&amp;lt;任意整数元数据&amp;gt;&lt;/em&gt;字符串对应于元数据键名称，并且必须至少包含一个下划线 (&amp;#39;_&amp;#39;) 字符。&lt;/li&gt;&lt;li&gt;被引用的元数据键应该具有与整数相对应的值。&lt;/li&gt;&lt;li&gt;给定 &amp;lt;value&amp;gt; 前面的“+”或“-”将导致规则中的现有元数据值分别增加或减少给定的&lt;em&gt;&amp;lt;value&amp;gt;&lt;/em&gt; 。如果元数据键不存在，则该值将设置为给定的&lt;em&gt;&amp;lt;default&amp;gt;&lt;/em&gt;值（如果提供），否则不会进行任何更改。&lt;/li&gt;&lt;li&gt;示例如图 5 所示。 &lt;/li&gt;&lt;/ul&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/8H_XGd2h-bhRh3_3TU3DOSXxru4ndUFegnldYy6niuSgJxr5fuWo721rruZzI-nUFTGNo0g9RMEwEXPthNZQxvrqa_Anwi37gcTuely-ZGlcZopCI8gu0RmZOQhsWioYFRD-BR16fG8Bonr4HgUdV_w" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;图 5：设置任意基于整数的元数据键值对的示例 PFMod 操作。&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;h4 class="wp-block-heading" id="h-pfmod-rules"&gt; PFMod 规则&lt;/h4&gt;&lt;p&gt;PFMod 条件和操作由 PFMod 规则控制（不要与 IDS“规则”混淆）。 PFMod 规则在 YAML 文件中定义，并以深度优先、线性方式处理。这意味着您可以定义广泛应用于许多（或所有）规则的操作，然后拥有更具体的 PFMod 规则，将更精确的操作应用于这些规则的子集。如图 6 所示，PFMod 规则文件可以“包含”其他 PFMod 规则文件，以便于组织。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/qYBdFR47BWVJxSUSy7f1-35up1H8fsOESih8Vy2oX_MT0mjf-dKWSyd83FEhgW-2tVZTOpZyeuaKX1zTCHarBkDhuI92DMehaMcs1gmrXy2rhsQ0V00a8HPQz3EOkEM9J_IYm4pcvklTxDtSiMiqyoQ" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;图 6：使用&lt;/em&gt;&lt;strong&gt;&lt;em&gt;include&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;加载多个 PFMod 文件的示例文件。&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;除了&lt;strong&gt;include&lt;/strong&gt;语句之外，PFMod 规则文件还可以包含多个规则。图 7 显示了更新 IDS 规则和元数据的 PFMod 规则文件示例。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/3omcuZfAMQjK8WXdHLOLj1ITew4Nu75Ha9jPFbjPZiV7aIo3jYiHTTQY0lN0txuMFxS-VCJMtnSZegFxZux-XxMphuu4gZHLjBkaAMutOjnO66o_liREiFfbWrn2mbT9bib9G-1X-Cwz8GiAOocgNy4" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;图 7：&lt;/em&gt;指定&lt;strong&gt;&lt;em&gt;规则&lt;/em&gt;&lt;/strong&gt;的 PFMod 文件示例&lt;em&gt;。&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;h4 class="wp-block-heading" id="h-risk-score"&gt;风险评分&lt;/h4&gt;&lt;p&gt;Uber 部署的每条 Suricata 规则都会收到一个“风险评分”。这些风险评分在规则集编译时自动生成，并由 PFMod 规则作为元数据值应用。规则元数据（包括&lt;strong&gt;risk_score&lt;/strong&gt; ）包含在Suricata 警报中，并在事件处理中发挥重要作用。稍后会详细介绍这一点。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-maintenance"&gt;维护&lt;/h3&gt;&lt;p&gt;当新规则添加到 Uber 使用的规则集中时（这种情况每天都会发生），它们会自动服从我们现有的 Aristotle v2 管道，其中包括过滤和应用重要的 PFMod 逻辑来相应地形成和分类每个规则。因此，通过使用 Aristotle v2 作为可靠的“设置后忘记它”机制，可以避免对每个新规则进行手动分析和调整。当然，偶尔会明智地重新审视规则集过滤和 PFMod 逻辑，以使规则集与当前环境和预期流量模式保持一致。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-documentation"&gt;文档&lt;/h3&gt;&lt;p&gt;有关 Aristotle v2 以及如何使用它的更多详细信息可以在 &lt;a href="https://aristotle-py.readthedocs.io/en/latest/" rel="noreferrer noopener" target="_blank"&gt;在线文档&lt;/a&gt;中找到。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-aggregation-correlation-risk-score-and-alerting"&gt;聚合、相关性、风险评分和警报&lt;/h1&gt;&lt;p&gt;Uber 每天处理数十亿个事件，其中包括数十万个 IDS 警报。事件来自多种来源，包括日志文件、供应商产品、内部系统、自定义检测和 IDS 等传感技术。安全相关事件（称为“信号”）接收由单个整数表示并与信号关联的“风险评分”值。信号的风险评分值在下游聚合和相关算法中发挥着重要作用，这些算法最终确定一个信号或一组信号是否符合需要响应的正式元警报。换句话说，“风险评分”值量化了响应的必要性和适当水平。根据保证的级别，响应通常采取安全分析师手动调查的形式，和/或安全编排和响应 (SOAR) 管道中的一系列编程操作。&lt;/p&gt;&lt;p&gt; Uber 的信号评估、聚合和关联是一个复杂的过程（更不用说响应管道），其复杂的细节超出了本文的范围。然而，总体策略围绕着我们所说的“基于实体的警报”。对于给定的时间窗口，信号按实体（例如，IP 地址、主机、用户等）分组，并应用相关算法来确定是否应创建可操作的元警报。来自各个信号的风险评分值在此计算中发挥着重要作用，因为它们被加权并相加在一起，并最终与用于做出最终决定的阈值进行比较。信号的权重（可以被认为是向上或向下调整风险评分）基于各种标准，包括实体特征，并且通常涉及与其他数据源的相关性。例如，用户是管理员的用户实体的信号的权重高于与非管理员用户相关的信号。类似地，涉及来自已知认可的漏洞扫描器的 IP 地址实体的信号将被赋予较低的权重，而涉及已知是负责金融交易的隔离网络的一部分的 IP 地址实体的事件将被赋予较高的权重。请注意，给定足够高的风险评分和/或权重修改，单个信号足以生成元警报和响应。&lt;/p&gt;&lt;p&gt;在实践中，聚合和关联与常见实体相关的信号已被证明是识别值得响应的事件和事件组合的有效方法。借助 IDS 警报，Aristotle v2 在能够选择启用哪些规则、包含哪些元数据以及每个规则应携带哪些风险评分值方面发挥着至关重要的作用。 IDS 警报元数据，尤其是风险评分值，可以更好地管理 Suricata 警报，使分析人员不会因警报或误报而不知所措。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;通过使用 Aristotle v2 规范、增强和操作规则元数据，可以准确地描述规则、以编程方式理解规则并随意修改规则。对元数据键值对应用具体的布尔代数会产生强大的过滤功能，使我们能够管理 Suricata 规则集，以便仅在特定环境中运行适用的规则。规则根据明确的和推断的目的论动机和本体论现实自动调整。诸如“risk_score”之类的自定义元数据值被智能地添加到每个规则中，从而实现有效的下游关联，从而最大限度地减少误报并使值得注意的警报得到适当的关注。其结果是一个可扩展、可控且准确的 Suricata 规则集管理和响应解决方案。&lt;/p&gt;</description><pubDate>Thu, 29 Feb 2024 07:00:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/network-ids-ruleset-management-with-aristotle-v2/</guid></item><item><title>构建可扩展的实时聊天以改善客户体验</title><link>https://www.uber.com/blog/building-scalable-real-time-chat/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;优步是一家全球性企业，拥有遍布世界各地的客户群。 Uber 的客户群分为多个用户角色，主要是乘客、司机、食客、快递员和商家。作为一家全球性企业，Uber 的客户也期望在全球范围内获得支持。我们的客户通过各种实时（聊天、电话）和非实时（应用内消息传递）渠道与我们联系，并期望迅速解决他们的问题。 Uber 客户每周都会提出数百万次支持互动（内部称为&lt;em&gt;联系人&lt;/em&gt;），我们的目标是在预定义的服务级别协议 (SLA) 内解决这些联系人问题。客户创建的联系人可以通过自动化或在客户支持代理的帮助下解决。&lt;/p&gt;&lt;p&gt;对于代理联系人来说，解决工单的成本在 Uber 如何构建其支持渠道以及确定不同实时和非实时渠道的交易量方面发挥着重要作用。聊天渠道的每次联系成本 (CPC) 和 FCR（首次联系解决率）在不同的实时渠道中最为有效，因为它们允许客服人员同时处理多个聊天联系人，同时保持比电话等渠道更低的平均成本。这个渠道对 Uber 来说是最佳选择，因为它具有良好的&lt;a href="https://www.qualtrics.com/au/experience-management/customer/what-is-csat/" rel="noreferrer noopener" target="_blank"&gt;CSAT&lt;/a&gt;分数（客户满意度评分，衡量范围为 1 到 5），同时通常会降低每次点击费用。该渠道可以实现更高的自动化率、更高的人员配备效率（因为座席可以同时处理多个聊天）和高 FCR，这些都对 Uber 有利，同时为客户提供优质支持。&lt;/p&gt;&lt;p&gt;从历史上看，从 2019 年到 2023 年初，所有联系人中的 1% 是通过实时聊天渠道提供服务的，58% 是通过应用内消息通道（非实时渠道）提供服务的，其余的则通过电话等另一个实时渠道提供服务。为了实现更高的 CSAT 和 FCR，工程团队需要扩展聊天基础设施以满足 Uber 不断增长的业务需求，并促进大量应用内消息和电话渠道联系人迁移到聊天渠道。本文将重点关注聊天直播频道。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-challenges"&gt;挑战&lt;/h2&gt;&lt;p&gt;为了扩展聊天渠道以支持路由到代理的 Uber 联系量的 40% 以上，以下是团队面临的一些主要挑战：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;将消息从后端系统传递到代理浏览器的可靠性问题&lt;ol&gt;&lt;li&gt;46% 源自尝试联系代理的客户的事件未及时传送，导致客户双方均出现延迟并浪费代理的带宽。请注意，这里的 46% 并不是指唯一联系人的数量，而是指所有聊天联系人的事件总数。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;缺失的见解&lt;ol&gt;&lt;li&gt;无法观察到跟踪聊天联系人的健康状况。&lt;/li&gt;&lt;li&gt;由于客服人员闲置了很长一段时间，但队列也不是空的，运营人员想知道他们是否人满为患，或者是否是技术问题导致数量不成比例（称为技术与人员配置问题）。 &lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-legacy-architecture-related-challenges"&gt;遗留架构相关的挑战&lt;/h2&gt;&lt;p&gt;我们的旧架构是使用&lt;a href="https://wamp-proto.org/index.html" rel="noreferrer noopener" target="_blank"&gt;WAMP 协议&lt;/a&gt;构建的，该协议主要用于消息传递和基于 WebSocket 的 PubSub，以将联系信息中继到代理的计算机。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large is-resized"&gt;&lt;img alt="" class="wp-image-1078909" height="416" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Fig1_old_arch-1-1024x416.png" style="width: 700px; height: auto;" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：描述了聊天联系人从创建到路由到前端代理的先前高级流程。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;&lt;em&gt;注意：这与涉及客户和 Uber 支持人员之间聊天消息交换的数据路径不同，后者通过 HTTP 服务器发送事件 (SSE) 实现。为此，Uber 使用 Ramen 作为内部服务，在控制和数据路径中发挥双重作用。在控制路径中，Ramen 为客户端到移动用例提供双向支持，从而实现有效的通信。同时，在数据路径中，Ramen&lt;/em&gt;&lt;em&gt;为客户端到 Web 用例&lt;/em&gt;提供&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events" rel="noreferrer noopener" target="_blank"&gt;&lt;em&gt;SSE&lt;/em&gt;&lt;/a&gt;功能。&lt;/p&gt;&lt;p&gt;&lt;em&gt;然而，数据路径中出现了一个值得注意的区别，特别是对于客户端到 Web 的用例，Ramen 的成功交付率为 94.5%。它以单向方式运行，因此需要新的控制流。这些新的控制流对于检测和管理客户端不再响应的情况至关重要，从而解决数据路径中的单向限制。在本博客中，我们将介绍新的控制流，将事件从后端传递&lt;/em&gt;到&lt;em&gt;代理的浏览器 (Web)，以使代理能够进行第一次回复。&lt;/em&gt;&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;该团队在生产中启动了 E2E 架构，并开始发现问题。不是立即，但随着流量超出了通过的少数票证，团队意识到该架构无法轻松超出其初始功能，并且生产管理也不是那么简单。下面列出了其中一些核心问题：&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-reliability"&gt;可靠性&lt;/h3&gt;&lt;p&gt;我们面临 1.5 倍扩展流量的可靠性问题，导致后端多达 46% 的事件未传送到代理的浏览器。这增加了客户与客服人员交谈的等待时间。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-scale"&gt;规模&lt;/h3&gt;&lt;p&gt;除了 &amp;gt;~10 左右的低 RPS 之外，由于高内存使用率或文件描述符泄漏，从后端传递联系人的系统性能显着恶化。由于使用旧版本 WAMP 库的限制，不支持水平可扩展性，并且升级它是一项巨大的工作。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-observability-debuggability-nbsp"&gt;可观察性/可调试性&lt;/h3&gt;&lt;p&gt;以下是与可观测性相关的主要问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;跟踪聊天联系人的运行状况很困难，即聊天联系人是否由于工程相关问题或人员配置相关问题而缺少 SLA。&lt;/li&gt;&lt;li&gt;聊天联系人未加入基于队列的架构，导致由于代理的属性匹配流，超过 8% 的聊天量未路由到任何代理。&lt;/li&gt;&lt;li&gt;使用的 WAMP 协议和库（ &lt;a href="https://github.com/crossbario/autobahn-js"&gt;eg1&lt;/a&gt; 、 &lt;a href="https://github.com/gammazero/nexus/tree/v2"&gt;eg2&lt;/a&gt; ）已被弃用，并且没有提供很多关于内部工作原理的见解，导致调试变得更加困难。此外，我们没有实施端到端的 Chat 联系人生命周期调试，并且我们无法准确检测整个平台上的 Chat SLA 缺失。&lt;/li&gt;&lt;/ol&gt;&lt;h3 class="wp-block-heading" id="h-stateful"&gt;有状态的&lt;/h3&gt;&lt;p&gt;这些服务是有状态的，使维护和重启变得复杂，从而导致消息传递时间和损失激增。添加 WebSocket 代理来执行授权，而且由于服务整体是有状态的，因此这极大地增加了延迟。当任何一方断开连接时，双套接字代理都会引起问题。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-tech-requirements"&gt;技术要求&lt;/h2&gt;&lt;p&gt;以下是技术团队正在努力实现的一些目标：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;到 2023 年底，将聊天流量从占总联系量的 1% 扩大到 40%（每周 150 万票）&lt;ol&gt;&lt;li&gt;在队列上加入并扩展聊天流量以支持与队列相关的洞察&lt;/li&gt;&lt;li&gt;到 2024 年底，扩大规模以处理 Uber 总联系量的 80% 以上（每周 300 万张罚单）。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;通过代理管道（称为推送管道）的预订（在识别代理后首次尝试将客户连接到代理）成功率应 &amp;gt;= 99.5%&lt;/li&gt;&lt;li&gt;构建整个聊天流程端到端的可观察性和可调试性。&lt;/li&gt;&lt;li&gt;无状态服务，如果水平扩展或实例因任何原因发生故障，则不需要重新校准&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-solution"&gt;解决方案&lt;/h2&gt;&lt;p&gt;新架构需要简单，以提高其内部运作的透明度，并使团队能够轻松扩展。该团队决定继续使用 Push Pipeline，这将是一个简单、无冗余的 WebSocket 服务器，代理计算机将连接到该服务器并能够通过一个通用套接字通道发送和接收消息。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-high-level-architecture"&gt;高层架构&lt;/h3&gt;&lt;p&gt;目前存在的新架构如下所示： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1078914" height="517" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Fig2_new_arch-1024x517.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：描述了通过路由到前端代理创建聊天联系人的整个过程中的新高级流程。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;该架构有以下部分：&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-front-end"&gt;前端&lt;/h3&gt;&lt;p&gt;代理使用前端 UI 与客户交互。代理可以使用小部件和不同的操作来调查客户并采取适当的操作。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-contact-reservation"&gt;联系预订&lt;/h3&gt;&lt;p&gt;路由器是在代理和联系人之间找到最合适匹配的服务。在找到最适合客服人员的联系人后，该联系人将被推送到该客服人员的保留状态。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-push-pipeline"&gt;推送管道&lt;/h3&gt;&lt;p&gt;成功预订代理联系人后，匹配的信息将发布到 Apache Kafka®。通过 GraphQL 订阅通过套接字接收此信息后，前端会加载代理的联系人以及使代理能够响应用户的所有必要的小部件和操作。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-agent-state"&gt;代理状态&lt;/h3&gt;&lt;p&gt;任何需要开始工作的代理都需要通过前端上的切换开关上线，触发时会使用相关代理的新状态更新代理状态服务。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-edge-proxy"&gt;边缘代理&lt;/h3&gt;&lt;p&gt;客户端浏览器和后端服务之间的任何连接都通过边缘代理进行，边缘代理作为防火墙和代理层保护 Uber 服务。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-ease-of-operations-and-better-insights"&gt;易于操作和更好的洞察力&lt;/h3&gt;&lt;p&gt;以下是要点：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在队列上加入聊天流量，订阅的代理将根据代理配置文件的并发集接收联系人。并发性定义了客服人员可以同时处理的聊天联系人的数量。&lt;/li&gt;&lt;li&gt;队列的座席人员配备本质上是决定性的，基于 SLA 的路由（根据队列 SLA 确定聊天联系人的优先级）、粘性路由（粘性重新打开与座席的联系）和优先级路由（根据队列上定义的不同规则确定优先级）等功能都已成为决定性因素。默认支持。&lt;/li&gt;&lt;li&gt;通过队列加入，仪表板被重新调整/增强，以便运维团队查看聊天队列 SLA 和客服人员可用性及其实时状态，包括联系人生命周期状态、队列流入/流出、客服人员的会话计数等。 &lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-gql-subscription-service"&gt; GQL订阅服务&lt;/h2&gt;&lt;p&gt;与 GraphQL 订阅相关的主要亮点是：&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-reconnection-on-disconnection"&gt;断开连接时重新连接&lt;/h4&gt;&lt;p&gt;我们在 GraphQL 订阅套接字上启用了 ping pong，以确保在连接不可靠的情况下自动断开套接字。当套接字断开连接时，相应的代理就没有资格接收新的联系人。自动重新尝试 Web 套接字重新连接。成功重新连接后，将获取所有保留/分配的联系人，以便客服人员可以接受它们。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-push-pipeline-reliability-nbsp"&gt;推动管道可靠性&lt;/h4&gt;&lt;p&gt;对于给定座席的保留联系人，如果前端未向聊天服务发回确认，我们会尝试为另一个可用座席保留相同的联系人。我们通过 GraphQL 订阅发送心跳来检查代理浏览器的 Web 套接字和 http 协议是否正常工作，响应是通过代理浏览器的 HTTP API 调用发送的，以检查代理是否在线。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-technical-choices"&gt;技术选择&lt;/h2&gt;&lt;p&gt;下面概述了我们为提高聊天系统的可靠性和稳健性而做出的一些技术选择，同时还考虑了我们的选择对用户感知等待时间的端到端延迟影响。为此，我们需要简化该系统，同时启用选定的产品增强功能。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-using-graphql-over-websocket-with-graphql-subscriptions"&gt;通过带有 GraphQL 订阅的 websocket 使用 GraphQL&lt;/h3&gt;&lt;p&gt;前端团队广泛利用 GraphQL 在其前端服务上进行 HTTP 调用。这导致团队选择 GraphQL 订阅来将数据从服务器推送到客户端。客户端将通过订阅请求向服务器发送消息，服务器在匹配查询时将消息发送回代理计算机。以下部分介绍了有关 GraphQL 订阅的更多信息。&lt;/p&gt;&lt;p&gt; &lt;a href="https://github.com/enisdenjo/graphql-ws" rel="noreferrer noopener" target="_blank"&gt;graphql-ws&lt;/a&gt;库给了我们信心，因为它&lt;a href="https://www.npmjs.com/package/graphql-ws" rel="noreferrer noopener" target="_blank"&gt;每周的下载量为 230 万次&lt;/a&gt;，被&lt;a href="https://www.apollographql.com/docs/react/data/subscriptions/#setting-up-the-transport" rel="noreferrer noopener" target="_blank"&gt;Apollo 推荐&lt;/a&gt;，并且有 0 个未解决的问题。它还以&lt;a href="https://github.com/enisdenjo/graphql-ws/blob/master/PROTOCOL.md" rel="noreferrer noopener" target="_blank"&gt;基于 WS 协议的标准 GraphQL&lt;/a&gt;为模型，并完全根据该协议调整其选项，使其成为此处使用的理想选择。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-stateless-services"&gt;无状态服务&lt;/h3&gt;&lt;p&gt;将创建的新服务需要无状态才能水平扩展，并且不需要时不时地重新平衡。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-websocket-without-http-fallback"&gt;没有 HTTP 回退的 Websocket&lt;/h3&gt;&lt;p&gt;由于系统需要代理计算机和代理层之间的双向通信，因此 HTTP 回退实际上不会对系统的 SLA 产生任何影响。因此，团队专注于通过以下方式提高套接字与代理连接的可用性：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;双向 ping pong 消息可防止套接字挂起&lt;/li&gt;&lt;li&gt;断开连接后回退重新连接，以防止并发重新连接导致服务不堪重负。&lt;/li&gt;&lt;li&gt;单个代理连接套接字而无需任何切换&lt;/li&gt;&lt;/ol&gt;&lt;h3 class="wp-block-heading" id="h-using-apache-kafka-as-a-message-service-on-the-backend"&gt;使用 Apache Kafka® 作为后端的消息服务&lt;/h3&gt;&lt;p&gt;联系消息在到达代理层之前已经通过 Kafka 流经各个服务。我们决定继续并扩展 Kafka 的使用，因为它可靠、快速且支持广播 (PubSub) 功能。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-testing-amp-launch"&gt;测试与发布&lt;/h1&gt;&lt;p&gt;我们进行了功能和非功能测试，以确保为客户和代理提供端到端的最佳体验。为了预测性能，在发布前完成的一些测试是：&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-load-tests"&gt;负载测试&lt;/h3&gt;&lt;p&gt;可以从一台机器建立约 10K 的套接字连接，随着我们添加更多机器，该连接将进一步水平扩展。我们成功测试了以旧堆栈的 20 倍推送事件。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-shadow-traffic-flows"&gt;影子流量&lt;/h3&gt;&lt;p&gt;现有流量通过旧系统和新管道进行引导，以测试其每天 40,000 个联系人和 2,000 个座席的容量。此过程没有发现任何问题，数据指标显示延迟和可用性令人满意并达到所需的阈值。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-reverse-shadow-traffic-flows"&gt;反向影子流量&lt;/h3&gt;&lt;p&gt;现有流量通过新系统和旧的代理用户界面进行引导，作为关键的可靠性测试。这是新系统的首次使用，它成功地管理了流量，同时将延迟保持在定义的 SLA 范围内。&lt;/p&gt;&lt;p&gt;在我们进行过程中，我们遇到了独特的系统和代理行为问题，并进行了一些修复以提高可靠性并减少整体管道的延迟。一些主要问题是：&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-deletion-of-cookies-from-the-browser"&gt;从浏览器中删除 cookie&lt;/h3&gt;&lt;p&gt;浏览器 cookie 被清除后，会产生与身份验证和后续 API 失败相关的问题，从而阻止前端对推送的事件采取行动。在这种情况下，客服人员通常会保持在线状态，而不处理任何联系人。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-bugs-in-auto-logout-flows"&gt;自动注销流程中的错误&lt;/h3&gt;&lt;p&gt;过去，客服人员不会因故障或事件丢失等问题而注销。完成当天工作的客服人员只需关闭选项卡即可在系统中保持在线状态。由于管道试图将事件推送给这些不在线的客服人员，这导致客户等待时间增加。然后，我们开始根据最近的确认失误自动注销代理，并从整体上追踪注销的正确原因，以提高对系统的信心。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-results"&gt;结果&lt;/h2&gt;&lt;p&gt;聊天渠道已经能够扩展到 Uber 全部联系量（路由到客服人员）的&lt;strong&gt;36%&lt;/strong&gt;左右，未来几个月还会有更多渠道出现。团队似乎已经重新获得了对扩展聊天渠道以及改善整体客户体验的信任。该团队还能够大幅提高可靠性，旧堆栈中传递联系的错误率约为 46%，而新堆栈中的错误率约为 0.45%。每次交付失败后，客户的工单都会在 30 秒的延迟后退回，然后重试交付，将这一数字大规模降低 0.45% 以下对于客户和代理的整体体验而言意义重大。&lt;/p&gt;&lt;p&gt;我们在这一领域还取得了其他胜利，其中最好的胜利可能是简单性。新架构在系统中内置了&lt;strong&gt;更少的服务、更少的协议和更好的可观察性，&lt;/strong&gt;以便了解联系传递指标、系统内的延迟和端到端延迟。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion-and-next-steps"&gt;结论和后续步骤&lt;/h1&gt;&lt;p&gt;新的推送管道使团队能够加入其他推送用例，并通过为代理提供实时信息来采取行动，从而为改善用户体验打开了大门。一些与 Greenlight 预约和代理工作在联系人上重叠相关的用例将很快转移到这个新堆栈上，作为下一阶段的一部分。&lt;/p&gt;&lt;p&gt;聊天频道的用户体验的进一步改善也将作为一个整体进行，重点是增强和系统架构调整。这将基于产品扩展的经验教训以及解决客户和代理商报告的问题来完成。&lt;/p&gt;&lt;p class="has-small-font-size"&gt;&lt;em&gt;封面图片可在此链接找到：&lt;a href="https://openverse.org/image/2b3fadf3-2490-4a0c-906d-f7cf1c13a4cb?q=customer%20support"&gt;来源&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description><pubDate>Tue, 20 Feb 2024 07:00:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/building-scalable-real-time-chat/</guid></item><item><title>Uber 如何使用集成缓存从在线存储中提供每秒超过 4000 万次的读取服务</title><link>https://www.uber.com/blog/how-uber-serves-over-40-million-reads-per-second-using-an-integrated-cache/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;&lt;a href="https://eng.uber.com/schemaless-sql-database/" rel="noreferrer noopener" target="_blank"&gt;Docstore&lt;/a&gt;是 Uber 在 MySQL® 之上构建的内部分布式数据库。它存储数十 PB 的数据并每秒处理数千万个请求，是 Uber 最大的数据库引擎之一，被所有业务垂直领域的微服务所使用。自 2020 年推出以来，Docstore 用户和用例不断增长，请求量和数据占用量也在不断增长。&lt;/p&gt;&lt;p&gt;业务垂直领域和产品的需求不断增长，引入了复杂的微服务和依赖关系调用图。因此，应用程序要求数据库具有低延迟、更高的性能和可扩展性，同时产生更高的工作负载。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-challenges"&gt;挑战&lt;/h2&gt;&lt;p&gt;Uber 的大多数微服务都使用基于磁盘的存储支持的数据库来保存数据。然而，每个数据库都面临着为需要低延迟读取访问和高可扩展性的应用程序提供服务的挑战。&lt;/p&gt;&lt;p&gt;当一个用例需要比我们任何现有用户更高的读取吞吐量时，这就达到了沸点。 Docstore 可以满足他们的需求，因为它由 NVMe SSD 支持，可提供低延迟和高吞吐量。然而，在上述场景中使用 Docstore 成本高昂，并且需要许多扩展和运营挑战。&lt;/p&gt;&lt;p&gt;在深入研究挑战之前，让我们先了解一下 Docstore 的高级架构。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-docstore-architecture"&gt;文档库架构&lt;/h2&gt;&lt;p&gt;Docstore主要分为三层：无状态查询引擎层、有状态存储引擎层、控制平面。对于本博客的范围，我们将讨论其查询和存储引擎层。&lt;/p&gt;&lt;p&gt;无状态查询引擎层负责查询规划、路由、分片、模式管理、节点健康监控、请求解析、验证和AuthN/AuthZ。&lt;/p&gt;&lt;p&gt;存储引擎层负责通过 Raft 达成共识、复制、事务、并发控制和负载管理。分区通常由 NVMe SSD 支持的 MySQL 节点组成，能够处理繁重的读写工作负载。此外，数据使用 Raft 跨多个分区进行分片，其中包含一个领导者节点和两个跟随者节点，以达成共识。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/GBkXOF__0QtOHj5Bkl_OeqGLk9LRI9iDFVs6e3J_eZJBuvIPUBGBQCGzIcwJISdPj-jIDeYjjByFDh9m5OBobGXhZYkU4xEQIP7MDQf9-iPDp0p1oOOYniJuDvo7BJeMgP-oabTjG37spd5tJFw18B8" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：Docstore 架构。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;现在让我们看看当服务需要大规模低延迟读取时所面临的一些挑战：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;从磁盘检索数据的速度有一个阈值：&lt;/strong&gt;优化应用程序数据模型和查询以改善数据库延迟和性能的程度是有限的。除此之外，不可能获得更多的性能。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;垂直扩展：&lt;/strong&gt;分配更多资源或升级到具有更高性能的更好主机有其局限性，其中数据库引擎本身成为瓶颈。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;水平扩展：&lt;/strong&gt;将分片进一步分割到更多的分区有助于在一定程度上解决挑战，但这样做在操作上是一个更加复杂和漫长的过程。我们必须确保数据的持久性和弹性，而不会造成任何停机。此外，该解决方案并不能完全帮助解决热键/分区/分片的问题。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;请求不平衡：&lt;/strong&gt;读请求的传入速率通常比写请求高几个数量级。在这种情况下，底层 MySQL 节点将难以跟上繁重的工作负载并进一步影响延迟。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;成本：&lt;/strong&gt;从长远来看，通过垂直和水平扩展来改善延迟的成本很高。处理两个区域的 3 个有状态节点中的每一个的成本都会增加 6 倍。此外，扩展并不能完全解决问题。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为了克服这个问题，微服务利用缓存。在 Uber，我们提供 Redis™ 作为分布式缓存解决方案。微服务的典型设计模式是写入数据库和缓存，同时从缓存中读取数据以改善延迟。然而，这种方法存在以下挑战：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;每个团队都必须为其各自的服务配置和维护自己的 Redis 缓存&lt;/li&gt;&lt;li&gt;缓存失效逻辑在每个微服务中分散实现&lt;/li&gt;&lt;li&gt;在区域故障转移的情况下，服务要么必须维持缓存复制以保持热状态，要么在其他区域的缓存预热时遭受更高的延迟&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;各个团队必须花费大量的精力来使用数据库实现自己的自定义缓存解决方案。迫切需要找到一种更好、更高效的解决方案，不仅能够以低延迟满足请求，而且易于使用并提高开发人员的工作效率。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-cachefront-nbsp"&gt;缓存前端&lt;/h2&gt;&lt;p&gt;我们决定构建一个集成的缓存解决方案 CacheFront for Docstore，并考虑到以下目标：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;最大限度地减少垂直和/或水平缩放的需要以支持低延迟读取请求&lt;/li&gt;&lt;li&gt;减少数据库引擎层的资源分配；缓存可以从相对便宜的主机上构建，因此整体成本效率得到提高&lt;/li&gt;&lt;li&gt;改善 P50 和 P99 延迟，并稳定微突发期间的读取延迟峰值&lt;/li&gt;&lt;li&gt;替换大多数由各个团队构建（或将要构建）以满足其需求的定制缓存解决方案，特别是在缓存不是团队核心业务或能力的情况下&lt;/li&gt;&lt;li&gt;通过重用现有的 Docstore 客户端来使其透明，无需任何额外的样板，以便从缓存中受益&lt;/li&gt;&lt;li&gt;提高开发人员的工作效率，并允许我们以对客户透明的方式发布新功能或替换底层缓存技术&lt;/li&gt;&lt;li&gt;将缓存解决方案与 Docstore 的底层分片方案分离，以避免因热键、分片或分区引起的问题&lt;/li&gt;&lt;li&gt;允许我们独立于存储引擎水平扩展缓存层&lt;/li&gt;&lt;li&gt;将维护和调用 Redis 的所有权从功能团队转移到 Docstore 团队&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-cachefront-design"&gt;缓存前端设计&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-docstore-query-patterns"&gt;文档库查询模式&lt;/h3&gt;&lt;p&gt;Docstore 支持通过主键或分区键进行查询的不同方式，并可以选择过滤数据。从高层次来看，它主要可以分为以下几部分：&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;按键式/过滤器&lt;/td&gt;&lt;td&gt;没有过滤器&lt;/td&gt;&lt;td&gt;按 WHERE 子句过滤&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;行数&lt;/td&gt;&lt;td&gt;读取行&lt;/td&gt;&lt;td&gt;–&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;分区&lt;/td&gt;&lt;td&gt;读分区&lt;/td&gt;&lt;td&gt;查询行&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;我们希望从最常见的查询模式开始逐步构建我们的解决方案。事实证明，超过 50% 的 Docstore 查询都是 ReadRows 请求，而且由于这也恰好是最简单的用例（没有过滤器和点读取），因此很自然地从集成开始。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-high-level-architecture"&gt;高层架构&lt;/h3&gt;&lt;p&gt;由于Docstore的查询引擎层负责为客户端提供读写服务，因此非常适合集成缓存层。它还将缓存与基于磁盘的存储分离，使我们能够独立扩展它们中的任何一个。查询引擎层实现了一个 Redis 接口，用于存储缓存数据以及使缓存条目失效的机制。高级架构如下所示： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/Rmm5BmifYPw54KnH74kaCJWK5L-FuymknafE9zQIhfeD4NpY0voHwI_3EtWXx90vPdGl63U9Ukz3ZsZQ0hwlntl55ofun8yhFL4489HMETZ2Jkkp7662u2-mIjOojJW5irCtwyb1xybqRJMlrS-2apM" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：CacheFront 设计。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; Docstore 是一个强一致性数据库。尽管集成缓存提供了更快的查询响应，但在使用缓存时，关于一致性的一些语义可能无法为每个微服务所接受。例如，缓存失效可能会失败或滞后于数据库写入。因此，我们将集成缓存作为一项可选功能。服务可以基于每个数据库、每个表甚至每个请求配置缓存使用情况。&lt;/p&gt;&lt;p&gt;如果某些流需要强一致性（例如获取食客购物车中的商品），则可以绕过缓存，而其他写入吞吐量较低的流（例如获取餐厅的菜单）将从缓存中受益。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-cached-reads"&gt;缓存读取&lt;/h3&gt;&lt;p&gt;CacheFront 使用缓存旁路策略来实现缓存读取：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;查询引擎层收到多一行的读取请求&lt;/li&gt;&lt;li&gt;如果启用了缓存，请尝试从 Redis 获取行；将响应流式传输给用户&lt;/li&gt;&lt;li&gt;从存储引擎检索剩余行（如果有）&lt;/li&gt;&lt;li&gt;使用剩余行异步填充 Redis&lt;/li&gt;&lt;li&gt;将剩余行流式传输给用户&lt;/li&gt;&lt;/ol&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/TZIbPhOxvXtUMaxrn0LukNpglUsFD6CWoliV6z0OhW92wZh2wrYi6XO5-fwQyEkjGztPuGhP2j-BGxDO5Rg7MJ-lURrhwN_1Cxgt-s7i5JPNUWcm_k9s7Khb8K-_AwxOvdkni_83QqGDmuq5jOOzQC4" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：CacheFront 读取路径。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-cache-invalidation"&gt;缓存失效&lt;/h2&gt;&lt;blockquote class="wp-block-quote"&gt;&lt;p&gt;&lt;em&gt;“计算机科学中只有两件难事：缓存失效和命名。”&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;cite&gt;——菲尔·卡尔顿&lt;/cite&gt;&lt;/blockquote&gt;&lt;p&gt;虽然上一节中的缓存策略看起来很简单，但为了确保缓存正常工作，必须考虑很多细节，尤其是缓存失效。如果没有任何显式缓存失效，缓存条目将在配置的 TTL（默认情况下为 5 分钟）内过期。虽然这在某些情况下可能没问题，但大多数用户希望更改的反映速度比 TTL 更快。默认的 TTL 可以降低，但这会降低我们的缓存命中率，而不会显着提高一致性保证。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-conditional-update"&gt;有条件更新&lt;/h3&gt;&lt;p&gt;Docstore 支持条件更新，可以根据过滤条件更新一行或多行。例如，更新指定地区所有连锁餐厅的假期安排。由于给定过滤器的结果可能会更改，因此我们的缓存层无法确定哪些行将受到条件更新的影响，直到数据库引擎中更新了实际行。因此，我们无法在无状态查询引擎层的写入路径中使缓存行无效并填充以进行条件更新。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-leveraging-change-data-capture-for-cache-invalidation-nbsp"&gt;利用变更数据捕获来使缓存失效&lt;/h3&gt;&lt;p&gt;为了解决这个问题，我们利用了 Docstore 的变更数据捕获和流服务 Flux。 Flux 跟踪存储引擎层中每个集群的&lt;a href="https://dev.mysql.com/doc/internals/en/binary-log-overview.html" rel="noreferrer noopener" target="_blank"&gt;MySQL binlog&lt;/a&gt;事件，并将事件发布到消费者列表。 Flux 为 Docstore CDC（更改数据捕获）、复制、物化视图、数据湖摄取以及验证集群中节点之间的数据一致性提供支持。&lt;/p&gt;&lt;p&gt;编写了一个新的消费者，它订阅数据事件并使 Redis 中的新行无效或更新。现在，使用此失效策略，条件更新将导致受影响的行发生数据库更改事件，这些事件将用于使缓存中的行失效或填充。因此，我们能够在数据库更改后的几秒钟内（而不是几分钟）使缓存保持一致。此外，通过使用二进制日志，我们不会冒让未提交的事务污染缓存的风险。&lt;/p&gt;&lt;p&gt;缓存失效后的最终读写路径如下所示： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/05_8F32Yokun9_DucegrI80UJbwUwj5kulbM56xBrKCaNT2-NklDzrubhI-E7kJh3CK7Y9eQ2hggkhaXmECvSn9AZZV7ARUqiejCDk9H1SDehB_tJ3zPGmgg6UsVZKEViJM51qqqhcR-bhsS4L_DNN8" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：失效的 CacheFront 读写路径。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-deduplicating-cache-writes-between-query-engine-and-flux"&gt;在查询引擎和 Flux 之间删除重复的缓存写入&lt;/h3&gt;&lt;p&gt;然而，上述缓存失效策略有一个缺陷。由于写入在读取路径和写入路径之间同时发生在缓存中，因此我们可能会无意中将过时的行写入缓存，从而覆盖从数据库检索到的最新值。为了解决这个问题，我们根据 MySQL 中行集的时间戳来删除重复写入，这实际上作为其版本。时间戳是从 Redis 中的编码行值中解析出来的（请参阅后面有关编解码器的部分）。&lt;/p&gt;&lt;p&gt; Redis 支持使用&lt;a href="https://redis.io/commands/eval/"&gt;EVAL&lt;/a&gt;命令自动执行自定义 Lua 脚本。该脚本采用与&lt;a href="https://redis.io/commands/eval/" rel="noreferrer noopener" target="_blank"&gt;MSET&lt;/a&gt;相同的参数，但是，它还执行重复数据删除逻辑，检查已写入缓存的任何行的时间戳值并确保要写入的值是较新的。通过使用 EVAL，所有这些都可以在单个请求中执行，而不需要在查询引擎层和缓存之间进行多次往返。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-stronger-consistency-guarantees-for-point-writes"&gt;更强的点写入一致性保证&lt;/h3&gt;&lt;p&gt;虽然 Flux 允许我们比仅仅依赖 Redis TTL 来使缓存条目失效更快，但它仍然为我们提供了最终一致性语义。然而，某些用例需要更强的一致性，例如读自己写，因此对于这些场景，我们向查询引擎添加了专用 API，允许用户在相应的写入完成后显式使缓存的行无效。这使我们能够为点写入提供更强的一致性保证，但不能为条件更新提供更强的一致性保证，条件更新仍然会被 Flux 失效。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-table-schemas"&gt;表模式&lt;/h3&gt;&lt;p&gt;在深入了解有关实现的更多细节之前，我们先定义一些关键术语。 Docstore 表有一个&lt;em&gt;主键&lt;/em&gt;和&lt;em&gt;分区键&lt;/em&gt;。&lt;/p&gt;&lt;p&gt;主键（通常称为&lt;em&gt;行键&lt;/em&gt;）唯一标识 Docstore 表中的行并强制执行唯一性约束。每个表都必须有一个主键，它可以由一列或多列组成。&lt;/p&gt;&lt;p&gt;分区键是整个主键的前缀，决定了该行将驻留在哪个分片中。它们并不是完全独立的——相反，分区键只是主键的一部分（或等于）。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/3Et4lJLc7ohCnbi7oWQ5MvAnNTBN9KbRZZwVaoPf16QtK3VDpvKfr39gi4I3pdx7B5FE_IHi7Iz_tU9i4lAlEi6I_P4kPvb71vGRNxjSzCVbVe5Jr92fMfpi8tqtXh0nsqStymKUr3UymWlYmx5p9Ac" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：Docstore 架构和数据建模示例。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;在上面的示例中， &lt;strong&gt;person_id&lt;/strong&gt;是&lt;strong&gt;person&lt;/strong&gt;表的主键和分区键。而对于&lt;strong&gt;订单&lt;/strong&gt;表， &lt;strong&gt;cust_id&lt;/strong&gt;是分区键， &lt;strong&gt;cust_id&lt;/strong&gt;和&lt;strong&gt;order_id&lt;/strong&gt;一起形成主键。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-redis-codec"&gt; Redis 编解码器&lt;/h3&gt;&lt;p&gt;由于我们主要将缓存行读取，因此我们可以使用给定的行键唯一地标识行值。由于 Redis 键和值存储为字符串，因此我们需要一个特殊的编解码器以 Redis 接受的格式对 MySQL 数据进行编码。&lt;/p&gt;&lt;p&gt;选择了以下编解码器，因为它允许不同数据库共享缓存资源，同时仍保持数据隔离。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1078207" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Screenshot-2024-02-07-at-12.36.06%E2%80%AFPM-1024x267.png" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/DYQl48pmuGDctmIRBUVlDoOQ1stF1w2I9swtVZL8SlPJZZ1jVSa7klvG_SurVWfDzwi6DE_7fwkWkWTyPqyd_8NBdd02Vv9g6j-lwp5NENw5IbSeOPeWPKCzg1WZ1uMIT6jLW7lGEmmb3WLBPE4gBLA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：CacheFront Redis 编解码器。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-features"&gt;特征&lt;/h3&gt;&lt;p&gt;完成高级设计后，我们的解决方案就可以运行了。现在是我们考虑规模和弹性的时候了：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;如何实时验证数据库和缓存的一致性&lt;/li&gt;&lt;li&gt;如何容忍可用区/区域故障&lt;/li&gt;&lt;li&gt;如何容忍 Redis 故障&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-compare-cache"&gt;比较缓存&lt;/h3&gt;&lt;p&gt;如果不可测量，所有关于提高一致性的讨论都毫无意义，因此我们添加了一种特殊模式，可以隐藏对缓存的读取请求。回读时，我们比较缓存数据和数据库数据并验证它们是否相同。任何不匹配（缓存中存在的过时行或缓存中存在的行（但数据库中不存在））都会被记录并作为指标发出。通过使用 Flux 添加缓存失效功能，缓存的一致性达到 99.99%。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/5WXplUI4vPGJbSdkMGUjTl2XRN4wM8i2X6tY_SXFf_FRDWIlNCuPaTwQ-MCN-bLSWZ8k4Gp_xPZ578KB7LV8DEKvMKa6FfCByfm1BJc8_f1KRvsKuSPTnQs3KYbyj7lt2BbU6ysXVw4auVPDfoqtB30" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：比较缓存设计。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-cache-warming"&gt;缓存预热&lt;/h3&gt;&lt;p&gt;Docstore 实例会产生两个不同的地理区域，以确保高可用性和容错能力。部署是主动-主动的，这意味着可以在任何区域发出和服务请求，并且所有写入都跨区域复制。如果一个区域发生故障转移，另一个区域必须能够满足所有请求。&lt;/p&gt;&lt;p&gt;此模型对 CacheFront 提出了挑战，因为跨区域的缓存应始终保持温暖。如果不是，区域故障转移将增加对数据库的请求数量，因为故障区域中最初服务的流量的缓存未命中。这将阻止我们缩小存储引擎并回收任何容量，因为数据库负载将与没有任何缓存的情况一样高。&lt;/p&gt;&lt;p&gt;冷缓存问题可以通过跨区域Redis复制来解决，但是它带来了一个问题。 Docstore有自己的跨区域复制机制。如果我们使用Redis跨区域复制来复制缓存内容，我们将有两个独立的复制机制，这可能会导致缓存与存储引擎的不一致。为了避免CacheFront的这种缓存不一致问题，我们通过添加新的缓存预热模式来增强Redis跨区域复制组件。&lt;/p&gt;&lt;p&gt;为了确保缓存始终处于热状态，我们跟踪 Redis 写入流并将密钥复制到远程区域。在远程区域中，读取请求不是直接更新远程缓存，而是发送到查询引擎层，查询引擎层在缓存未命中时，从数据库读取数据并写入缓存，如设计的&lt;strong&gt;缓存读取&lt;/strong&gt;部分所述。通过仅在缓存未命中时发出读取请求，我们还可以避免存储引擎不必要的过载。从查询引擎层读取行的响应流被简单地丢弃，因为我们对结果并不真正感兴趣。&lt;/p&gt;&lt;p&gt;通过复制键而不是值，我们始终确保缓存中的数据与各自区域的数据库一致，并且在两个区域的 Redis 中保留相同的缓存行工作集，同时也限制了跨区域的数量使用的带宽。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/cbUIurHsBaCU231zyyfsEcF0aiSL_Tqyy8x03_I3tp66sO1BwcnmPVykW93xFdePIt1JaT2ZZYWRO0RAznx0fogY1C5rahduCC5TvagTpWrxNgB7QfoKPAupt3Ts24S4EbxW9xoCaTkbCvjtdICNgKc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：缓存预热设计。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-negative-caching"&gt;负缓存&lt;/h3&gt;&lt;p&gt;在许多读取都是针对不存在的行的情况下，最好缓存负结果，而不是每次都出现缓存未命中并查询数据库。为了实现这一点，我们在 Cachefront 中内置了负缓存。与常规缓存填充策略（将从数据库返回的所有行都写入缓存）类似，我们还跟踪已查询但未从数据库读取的任何行。这些不存在的行会使用特殊标志写入缓存，在将来的读取中，如果找到该标志，我们在查询数据库时会忽略该行，并且不会将该行的任何数据返回给用户。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-sharding"&gt;分片&lt;/h3&gt;&lt;p&gt;虽然Redis并没有受到热分区问题的严重影响，但Docstore的一些大客户会产生大量的读写请求，这对于在单个Redis集群中进行缓存来说是一个挑战，通常会受到其可以拥有的最大节点数量的限制。为了缓解这个问题，我们允许单个 Docstore 实例映射到多个 Redis 集群。这还可以避免数据库完全崩溃，如果单个 Redis 集群中的多个节点发生故障并且缓存对于某些范围的键不可用，则可能会对其发出大量请求。&lt;/p&gt;&lt;p&gt;然而，即使数据跨多个 Redis 集群分片，单个 Redis 集群出现故障也可能会在数据库上产生热分片问题。为了缓解这个问题，我们决定通过分区键对Redis集群进行分片，这与Docstore中的数据库分片方案不同。现在，当单个 Redis 集群出现故障时，我们可以避免单个数据库分片过载。来自失败的 Redis 分片的所有请求将分布在所有数据库分片中，如下所示： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/_NOpBAx6pbT-B-CetPrxh1Vjvj3Ref86cqNIE4WbvS00ESPzYVwI_AFpPHKFvINL6IRTZtivXpMMF5FkTuWyuAAc6ssQxp3EqkYOKh13Ici5NTl8d5U9lU02en9uYptdB902RDmBa6YBI_CloUcHwB0" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：Redis 分片请求流。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-circuit-breakers"&gt;断路器&lt;/h3&gt;&lt;p&gt;如果 Redis 节点出现故障，我们希望能够短路对该节点的请求，以避免 Redis 获取/设置请求的不必要的延迟损失，因为我们非常有信心该请求将会失败。为了实现这一目标，我们使用滑动窗口断路器。我们统计每个时间段每个节点上的错误数量，并计算滑动窗口宽度中的错误数量。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1078102" height="365" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/figure10-sliding-window-1024x365.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 10：滑动窗口设计。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;断路器配置为短路该节点的一部分请求，与错误计数成比例。一旦达到最大允许错误计数，断路器就会跳闸，并且在滑动窗口过去之前不能向节点发出更多请求。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-adaptive-timeouts"&gt;自适应超时&lt;/h3&gt;&lt;p&gt;我们意识到有时很难为 Redis 操作设置正确的超时。超时时间太短会导致 Redis 请求过早失败，浪费 Redis 资源并给数据库引擎带来额外负载。超时太长会影响 P99.9 和 P99.99 延迟，在最坏的情况下，请求可能会耗尽查询中传递的整个超时。虽然可以通过配置任意低的默认超时来缓解这些问题，但我们可能会面临将超时设置得太低的风险，因为许多请求会绕过缓存并转到数据库，或者将超时设置得太高，这会导致我们回到最初的问题。&lt;/p&gt;&lt;p&gt;我们需要自动、动态地调整请求超时，以便对 Redis 的 P99 请求在分配的超时内成功，同时完全减少延迟的长尾。配置自适应超时意味着允许动态调整 Redis 获取/设置超时值。通过允许自适应超时，我们可以设置相当于缓存请求的 P99.99 延迟的超时，从而让 99.99% 的请求进入缓存并快速响应。剩下的 0.01% 的请求（这会花费太长时间）可以更快地取消并从数据库中提供服务。&lt;/p&gt;&lt;p&gt;启用自适应超时后，我们不再需要手动调整超时来匹配所需的 P99 延迟，而只能设置最大可接受的超时限制，超过该限制框架就不允许（因为设置了最大超时）无论如何，应客户要求）。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/BFgKW0IWMozMuBjKyv8UvqNzBesswYoRMhegElEZLSlF8aBI5WT81GdZ7gHYqRX9FalcrFtlt3_Li7sd3PbxnqV5Fj0gAsl0W4SeM7-6caHi5dZDElaOvYdMEh383DXLFnnEPxPmguu5FYVS3rNaF8A" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 11：自适应超时延迟改进。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-results"&gt;结果&lt;/h2&gt;&lt;p&gt;那么我们成功了吗？我们最初打算构建一个对用户透明的集成缓存。我们希望我们的解决方案能够帮助改善延迟、易于扩展、帮助控制存储引擎的负载和成本，同时具有良好的一致性保证。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/k8nIx9d66HktdxoS2Hl1WQHvf17lZoYz1-CBKXi9HBwVIs2JPakyPe0XZN55LnqVsDP0jJTmOWsj3iI5wiDqIfBm_ldkjXAjtBEy_ql-WeUE5l7Xs54OUEFEefGlx6P9_V3IrUZsiWlUT0HTWEE6h6A" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 12：缓存与存储引擎延迟比较。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;ol&gt;&lt;li&gt;具有集成缓存的请求延迟明显更好。 P75 延迟下降了 75%，P99.9 延迟下降了 67% 以上，同时也限制了延迟峰值，如上所示。&lt;/li&gt;&lt;/ol&gt;&lt;ol start="2"&gt;&lt;li&gt;使用 Flux 和 Compare 缓存模式进行缓存失效可以帮助我们确保良好的一致性。&lt;/li&gt;&lt;li&gt;由于它位于我们现有的 API 后面，因此对用户来说是透明的，并且可以在内部进行管理，同时仍然通过基于标头的选项为用户提供灵活性。&lt;/li&gt;&lt;li&gt;分片和缓存预热使其具有可扩展性和容错性。事实上，我们最大的初始用例之一驱动了超过 6M RPS，缓存命中率高达 99%，并且经过验证，故障转移成功，所有流量都重定向到远程区域。&lt;/li&gt;&lt;li&gt;相同的用例最初需要大约 60K CPU 内核才能直接从存储引擎提供 6M RPS 服务。借助 CacheFront，我们仅用 3K Redis 核心即可实现约 99.9% 的缓存命中率，从而减少了容量。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;如今，CacheFront 支持生产中所有 Docstore 实例每秒超过 4000 万个请求，而且这个数字还在不断增长。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/pTmRmm5OFwqZ9bmcvsp_Lskq3PTyxOP8XaRaJ-OWGrg3Vy3I4rPFX5ApmE9cOCH9kvfZZRJHfHw4r9ZM0dWj27QltRed9gQJnoPZdYhYOy-tMOec-kAhQ_452oHVYgtVqPWA66dzfu1y4ClxFraeBQM" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 13：所有实例的缓存读取总数。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们已经解决了通过 CacheFront 扩展 Docstore 上的读取工作负载的核心挑战之一。它不仅可以满足需要高吞吐量和低延迟读取的大规模用例，还可以帮助我们减轻存储引擎的负载并节省资源，提高存储的整体成本，让开发人员能够专注于构建产品而不是管理基础设施。&lt;/p&gt;&lt;p&gt;如果您喜欢与分布式系统、数据库、存储和缓存相关的挑战，请&lt;a href="https://www.uber.com/us/en/careers/list/?query=storage&amp;amp;department=Engineering" rel="noreferrer noopener" target="_blank"&gt;在此处&lt;/a&gt;探索并申请空缺职位。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Oracle、Java、MySQL 和 NetSuite 是 Oracle 和/或其附属公司的注册商标。其他名称可能是其各自所有者的商标。&lt;/em&gt;&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Redis 是 Redis Labs Ltd 的商标。其中的任何权利均归 Redis Labs Ltd 保留。此处的任何使用仅供参考，并不表明 Redis 与 Uber 之间有任何赞助、认可或从属关系。&lt;/em&gt;&lt;/p&gt;</description><pubDate>Thu, 15 Feb 2024 07:00:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/how-uber-serves-over-40-million-reads-per-second-using-an-integrated-cache/</guid></item><item><title>Jupiter：配置驱动的 Adtech 批量摄取平台</title><link>https://www.uber.com/blog/jupiter-batch-ingestion-platform/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;Uber 的使命是重新构想世界变得更美好的方式，并通过其市场在全球范围内提供盈利机会。让 Uber 品牌和市场更贴近人们的一种有效方法是投资付费营销策略。&lt;/p&gt;&lt;p&gt;要实现市场的最佳平衡，就必须持续保持供需平衡。这需要创造一个消费者负担得起的环境，同时为赚钱者保留良好的赚钱机会。实现这一目标的一种方法是不断向市场引入新用户，这是一个持续的过程，涉及在 Google、Meta、Apple 等不同的营销平台上推广 Uber 的市场产品。&lt;/p&gt;&lt;p&gt;鉴于这些是付费广告，我们的营销团队不断制定策略，以快速吸引更多用户加入该平台。因此，及时接收来自这些供应商的信号对于我们有效改进我们的方法至关重要。&lt;/p&gt;&lt;p&gt;这篇博文旨在探讨我们的传统摄取系统 MaRS（营销报告服务）遇到的限制和困难，该系统负责定期从外部广告合作伙伴收集广告信号。此外，我们将讨论如何通过技术进步来增强我们的营销业务，并通过实施我们的新系统 Jupiter 来实现可扩展性。&lt;/p&gt;&lt;p&gt;在本博客中，我们将付费营销描述为一个域，而广告技术代表同一域内的系统。这些术语在此上下文中可以互换使用。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-what-is-the-performance-marketing-user-flow"&gt;什么是效果营销用户流程？&lt;/h2&gt;&lt;p&gt;总体而言，后续序列提供了完整用户旅程的完整轮廓：从接触广告开始，导航到 Uber 平台，最后实现转化。这一行动对我们的业务很有价值，在我们的背景下，可能涉及注册 Uber、通过 Uber Eats 下单或乘车。&lt;/p&gt;&lt;p&gt;经过上述操作后，会触发后续事件：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;转化事件&lt;/strong&gt;：当用户点击广告下载 Uber 应用时，标记特定于该广告的转化。这是与下载相关的一种转化事件。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;支出事件&lt;/strong&gt;：当用户查看广告时，表示向用户展示该广告的支出。&lt;/p&gt;&lt;p&gt;来自广告合作伙伴的这些支出事件需要被摄取、处理并向下游传输。这样做是为了衡量和优化广告的效果。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large is-resized"&gt;&lt;img alt="" class="wp-image-1077751" height="1363" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Figure1-edited-1.png" style="width: 767px; height: auto;" width="1817" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：Adtech 中的用户流程。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;h5 class="wp-block-heading" id="h-sample-user-flow"&gt;&lt;strong&gt;用户流程示例&lt;/strong&gt;&lt;/h5&gt;&lt;ul&gt;&lt;li&gt;第 1 步：用户点击合作伙伴页面上的 Uber 广告&lt;/li&gt;&lt;li&gt;第 2 步：用户到达 Uber 应用程序 [转化事件]&lt;/li&gt;&lt;li&gt;第 3 步：Adtech 系统从合作伙伴 [摄取平台] 检索数据&lt;/li&gt;&lt;li&gt;步骤 4：计算性能指标 ( &lt;a href="https://www.singular.net/glossary/return-on-ad-spend-roas" rel="noreferrer noopener" target="_blank"&gt;ROAS&lt;/a&gt; )&lt;/li&gt;&lt;li&gt;第 5 步：优化引擎通过根据计算的指标调整出价算法来增强出价算法。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-why-is-timely-ingestion-critical"&gt;为什么及时摄入很重要？&lt;/h2&gt;&lt;p&gt;及时、准确地吸收这些广告信号对于 Uber 的整体绩效营销至关重要。即使是最小的延迟或对来自外部合作伙伴的及时广告信号的不准确处理也会影响 Uber 在这些平台上投放广告的能力。因此，这可能会影响进入该平台的用户数量。&lt;/p&gt;&lt;p&gt;举例来说，在持续两天的中断期间，我们无法从单个合作伙伴获取数据，下游关键绩效指标 ( &lt;a href="https://en.wikipedia.org/wiki/Performance_indicator" rel="noreferrer noopener" target="_blank"&gt;KPI&lt;/a&gt; )（特别是&lt;a href="https://www.singular.net/glossary/return-on-ad-spend-roas" rel="noreferrer noopener" target="_blank"&gt;ROAS&lt;/a&gt; ）的创建被延迟。这种延迟导致我们的出价和优化系统中的机器学习算法错误地得出我们的广告表现不佳的结论，从而导致广告支出停止。&lt;/p&gt;&lt;p&gt;结果，我们吸引新用户的能力受到损害，导致供需不平衡。所有这一切都是由于一次集成中断而发生的。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-problem-statement"&gt;问题陈述&lt;/h2&gt;&lt;p&gt;由于优步在全球众多国家/地区开展业务，我们与各种本地和全球广告合作伙伴或广告商合作开展付费营销工作。这导致了不同技术成熟度的多种不同技术系统的集成，具有异构的数据模式、格式、不同的传输协议以及数据新鲜度、沿袭性和完整性方面的差异。&lt;/p&gt;&lt;p&gt;广告技术行业正在经历一场重大变革，合作伙伴、移动测量平台 (MMP) 和外部广告技术平台正在从基于用户的广告跟踪过渡到一系列以隐私为中心的替代方案。这种转变催生了合作伙伴之间标准不同的多元化生态系统，带来了复杂性，例如数据模式频繁且不可预测的变化，挑战了营销和广告领域的历史假设。&lt;/p&gt;&lt;p&gt;由于其快速发展、规模以及所涉及数据集的多样性，这种复杂性给摄取系统带来了复杂的挑战。&lt;/p&gt;&lt;p&gt;以下是问题类别的细分以及摄取团队之前投入的时间： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1077758" height="862" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Figure2-edited.jpeg" width="1324" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：问题类别的划分。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-reliability"&gt;可靠性&lt;/h2&gt;&lt;p&gt;从数据中可以明显看出，大部分时间都用于确保摄取系统的可靠性。造成这种情况的主要因素可分为以下几类：&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-high-latency-nbsp"&gt;高延迟&lt;/h3&gt;&lt;p&gt;确保仓库中数据的及时可用性对于减少异常平均检测时间 (MTTD) 和提高广告技术系统的整体性能至关重要。&lt;/p&gt;&lt;p&gt;由于数据不完整或数据延迟问题，营销人员很难区分季节性和实际广告效果。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-no-partial-data-availability"&gt;没有部分数据可用性&lt;/h3&gt;&lt;p&gt;由于营销数据随着时间的推移而变化（例如超过 24 小时的支出数据和超过 28 天的转化数据），向下游系统提供部分数据变得非常重要。当合作伙伴端在特定广告帐户级别出现问题时，这一点尤其重要。考虑到此类问题的发生频率，拥有此功能本来可以防止大量数据中断。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-enhancements-in-technology-stack"&gt;技术堆栈的增强&lt;/h3&gt;&lt;p&gt;遗留系统 MaRS 旨在与旧的广告格式/域紧密耦合。对 MaRS 进行微小改进通常会导致工程周期延长或导致多项技术倒退。因此，在系统中容纳新的用例会导致系统变得笨重且难以管理。&lt;/p&gt;&lt;p&gt;此外，我们过时的基于 Python® 的技术堆栈导致速度变慢。利用这种情况，我们发起了升级。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-third-party-dependencies"&gt;第三方依赖项&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-standardization"&gt;标准化&lt;/h3&gt;&lt;p&gt;在我们的全球和本地广告合作伙伴中，有些拥有用于数据共享的高级 API。然而，有些规模较小的合作伙伴由于成熟度有限，通过电子邮件和 SFTP 等更多手动方法共享数据。因此，单个系统必须能够处理来自多种来源的数据提取。&lt;/p&gt;&lt;p&gt;此外，所有合作伙伴的数据格式和服务级别协议 (SLA) 也不一致。标准化的缺乏给维护带来了挑战。因此，有必要在所有合作伙伴之间建立统一的数据标准，以便下游系统无缝消费。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-rate-limits"&gt;速率限制&lt;/h3&gt;&lt;p&gt;引入新的合作伙伴数据、为现有合作伙伴引入新数据或在数据处理层中遇到错误，都需要摄取系统导入多年的历史数据（回填）。此过程会产生严重的延迟，通常需要几天到几周的时间，而且由于合作伙伴的速率限制，它还阻碍了日常管道的正常流动。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-high-maintenance"&gt;高维护成本&lt;/h3&gt;&lt;p&gt;维持合作伙伴特定的 SDK/API 需要大量的维护费用，包括专门的人员分配，以进行频繁的更新和错误修复，这最终降低了开发人员的生产力。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-scale"&gt;规模&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-huge-lead-time-to-market"&gt;上市时间长&lt;/h3&gt;&lt;p&gt;由于大量积压，我们只能满足 P0 营销请求。积压的主要原因是，过去加入新合作伙伴需要花费数周的时间，这阻碍了我们快速实验的能力。&lt;/p&gt;&lt;p&gt;例如，对于新兴合作伙伴，如果我们想在他们的平台上投放广告，我们必须等待几个月才能有资源来完成入职流程。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-high-dependency-on-eng-nbsp"&gt;对工程的高度依赖&lt;/h3&gt;&lt;p&gt;目前，任何合作伙伴的入职都严重依赖工程资源来编写用于 API 集成、数据转换、验证和测试的样板代码。这消耗了入职流程的很大一部分。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-solution-strategies"&gt;解决策略&lt;/h2&gt;&lt;p&gt;起初，MaRS 的构建受到了有限广告支出的限制。随着优步在全球范围内扩张，本地和全球市场对日益个性化营销的需求都在增长。这就需要一个能够快速适应和纳入特定细微差别的系统。&lt;/p&gt;&lt;p&gt;营销人员需要为我们的衡量渠道中的新合作伙伴提供更快的入职流程，以促进实验。他们还以更高的频率寻求数据以加速取得成果，从而使他们能够相应地调整营销策略。&lt;/p&gt;&lt;p&gt;因此，我们开发了一个系统，通过采用高度松散耦合的架构来解决技术堆栈中的差距并满足未来的业务需求。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-build-vs-buy"&gt;建造与购买&lt;/h3&gt;&lt;p&gt;我们对外部第三方供应商的广告信号摄取进行了评估，而不是仅仅依赖内部解决方案。这主要是为了简化维护成本。&lt;/p&gt;&lt;p&gt;此外，营销团队还制定了强有力的业务指令，要求获得更大的灵活性和对主要渠道（支出较高的顶级渠道）（如 Google、Apple 和 Meta）的控制。&lt;/p&gt;&lt;p&gt;因此，我们选择了混合架构，允许将外部供应商数据与来自合作伙伴的直接内部检索相结合。在入职期间采用哪种方法的决定将取决于集成的业务关键性。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-plug-and-play-architecture"&gt;即插即用架构&lt;/h3&gt;&lt;p&gt;我们需要为各种内部用例获取广告技术内部现有数据类别以外的数据，并且许多短间隙解决方案都是在筒仓中构建的。我们需要设想一个专门针对数据集的单一摄取系统，并且我们需要轻松且轻松地完成它。&lt;/p&gt;&lt;p&gt;我们为所有组件整合了即插即用架构，因此任何摄取都可以轻松地将其内部组件更改为其他组件。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-domain-agnostic-data-ingestion"&gt;与领域无关的数据摄取&lt;/h3&gt;&lt;p&gt;在我们追求为各种数据创建包容性摄取系统的过程中，我们需要分离特定领域的复杂性，并通过完全自助服务、基于配置的架构实现可配置性。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-reliability-0"&gt;可靠性&lt;/h3&gt;&lt;p&gt;由于与各种各样的合作伙伴打交道，我们的系统必须处理大量不成熟的数据格式、不一致的 SLA 和意外场景。这些广告信号的大小也有很大差异，在特定情况下从几 GB 到 TB 不等。 Jupiter 经过专门设计，能够以灵活的方式熟练地管理这些不同的场景。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-architecture"&gt;建筑学&lt;/h1&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1077763" height="421" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Figure3-1-1024x421.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：Jupiter 架构。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;h3 class="wp-block-heading" id="h-multi-vendor-integration"&gt;多供应商集成&lt;/h3&gt;&lt;p&gt;我们有各种业务场景，需要将来自不同供应商的不同数据集集成到我们的平台中。这些集成需要考虑特定因素，例如数据格式、摄取频率和数据成熟度级别。&lt;/p&gt;&lt;p&gt;因此，该平台的架构旨在适应任何供应商的任何数据摄取流程，从而允许以最少的配置进行无缝更改。&lt;/p&gt;&lt;p&gt;集成新供应商涉及配置其特定的集成细节，之后平台的其余部分将与其无缝连接。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-multi-source-integrations-nbsp"&gt;多源集成&lt;/h3&gt;&lt;p&gt;鉴于我们与众多供应商的互动，我们自然会遇到需要摄取的不同数据源。为了解决这个问题，我们实现了可配置的数据源，并通过配置定义了其特定属性。与供应商一样，这些数据源可以随时切换，只需最少的配置工作。&lt;/p&gt;&lt;p&gt;目前，我们已与 Amazon Web Services、Google Drive、电子邮件、API 等源集成。添加新源涉及配置其集成细节，之后平台的其余部分将无缝适应它。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-non-transformed-data-sets"&gt;未转换的数据集&lt;/h3&gt;&lt;p&gt;为了满足我们的业务需求，我们发现有必要在更长的时间间隔内提取数据，而不受合作伙伴能力的限制。此外，我们对快速检测任何异常趋势 (MTTD) 的迫切需求促使我们实施数据复制过程，而不应用任何转换。&lt;/p&gt;&lt;p&gt;这种方法使我们能够加快任何问题的调试，并在必要时有效地回填数据。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-config-driven-transformation-layer"&gt;配置驱动转换层&lt;/h3&gt;&lt;p&gt;由于我们管理的数据模式多种多样，定制转换对于标准化至关重要。&lt;/p&gt;&lt;p&gt;样板代码的很大一部分专门用于这个特定的组件。为了实现完全自助的摄取系统，我们的目标是为每个不同的用例配置此组件。&lt;/p&gt;&lt;p&gt;因此，我们为这个转换层开发了一个内部库。该库包含用户定义的转换，范围从行到行、列到列到聚合转换。我们在内部系统和类似用例中利用了这个库，以实现可重用性。附件是一个示例配置。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-full"&gt;&lt;img alt="" class="wp-image-1077942" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/02/Screenshot-2024-02-05-at-1.59.18%E2%80%AFPM.png" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;h3 class="wp-block-heading" id="h-self-serve-ingestion-onboarding"&gt;&lt;br /&gt;自助摄取入门&lt;/h3&gt;&lt;p&gt;我们优化了平台摄取流程的整个入职流程，将其转变为具有基本保障措施的自助服务模式。此转换涉及实现&lt;strong&gt;基于触发器的机制&lt;/strong&gt;，该机制在所有组件之间无缝运行，从从源获取数据、启动转换、进行测试、在所有检查后验证和升级以及触发验证后程序开始。以下是附上的高级流程供参考。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/50cHgz3rK-Vua-iE0-r2NLsMM-sAX6Mdt6468e_JwQwyiima0Yqo_XAR8ymryQRJdW_NicyVnJ5f9_1FUVH77rGb_Lic15xQ6rl2lQxIo2bpV4ewbmaZtFC_pZuaQSTjxdEzCeq5KePOQ__W6UVl4cY" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：流程图。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;由于这些改进，该流程的责任已转移给运营团队，从而消除了持续参与工程的必要性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-impact"&gt;影响&lt;/h2&gt;&lt;p&gt;目前，现有系统已完全淘汰并过渡到木星。下面，我们概述了这两个系统的指标：&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;公制&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;改进 ％&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;入职时间 – 新摄取&lt;/td&gt;&lt;td&gt;&amp;gt; 90%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;入职时间 – 新供应商&lt;/td&gt;&lt;td&gt;&amp;gt; 75%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;入职时间 – 新来源&lt;/td&gt;&lt;td&gt;&amp;gt; 75%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;数据摄取频率&lt;/td&gt;&lt;td&gt;&amp;gt; 75%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;数据摄取延迟&lt;/td&gt;&lt;td&gt;&amp;gt; 70% &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;我们概述了与广告技术领域网络相关的困难和潜在优势，以及从中获取可靠数据和实施复杂转换以满足各种业务需求的过程。目前，我们已经退役了以前的系统，并将所有用例转移到新平台，并在可行的情况下纳入新的数据增强功能。&lt;/p&gt;&lt;p&gt;我们已经成功实现了我们的主要目标，即加快新合作伙伴的入职流程，并通过为利益相关者提供自助服务方法确保数据可靠性。然而，仍有更复杂的用例需要解决。例如，到目前为止，我们专注于下载单个报告结构并应用转换。我们的下一个挑战是下载多个结构，合并它们，并通过统一的工作流程提供单个或多个数据集。下一个重要步骤是将该平台扩展到其当前特定用例支持之外，并将其转变为多租户系统。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-acknowledgments"&gt;致谢&lt;/h2&gt;&lt;p&gt;我们对核心工程和产品团队表示特别感谢，其中包括 Prathamesh Gabale（工程经理）、Akshit Jain（软件工程师）、Sarthak Chhillar（软件工程师）、Saurav Pradhan（软件工程师）和 Piyush Choudhary（产品）经理），感谢他们在确保这一旅程成功方面发挥的关键作用。&lt;/p&gt;&lt;p&gt;我们还要感谢 Devesh Kumar、Diwakar Bhatia 和 Vijayasaradhi Uppaluri 的宝贵反馈和坚定支持。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Amazon Web Services、AWS、Powered by AWS 徽标和 S3 是 Amazon.com, Inc. 或其附属公司的商标。&lt;/em&gt;&lt;/p&gt;</description><pubDate>Tue, 06 Feb 2024 07:00:00 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/jupiter-batch-ingestion-platform/</guid></item></channel></rss>