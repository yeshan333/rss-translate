<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>优步工程博客</title><link>https://www.uber.com/blog/engineering</link><description>Uber 工程背后的技术 - 由 RSSHub 用爱制作(https://github.com/DIYgod/RSSHub)</description><lastBuildDate>Sat, 22 Jun 2024 03:06:00 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>【How Uber ensures Apache Cassandra®’s tolerance for single-zone failure】</title><link>https://www.uber.com/blog/single-zone-failure-tolerance/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;&lt;a href="https://www.uber.com/blog/how-uber-optimized-cassandra-operations-at-scale/" rel="noreferrer noopener" target="_blank"&gt;Uber 已经运行开源 Apache Cassandra &lt;sup&gt;®&lt;/sup&gt;数据库即服务&lt;/a&gt;，为各种关键任务在线事务处理 (OLTP) 工作负载提供支持，目前已达到 Uber 规模，每秒有数百万次查询和 PB 级数据。由于 Uber 在多个地区的多个专区运营数据中心，因此 Uber 的 Cassandra 集群的节点通常分布在多个专区和地区。由于高可用性对于 Uber 的业务至关重要，因此我们希望 Cassandra 的可用性在单个区域出现故障的情况下不受影响。本博客展示了我们如何确保 Cassandra 的单区容错能力，特别是我们如何将大型 Cassandra 队列以零停机时间实时从非区域容错转换为单区容错。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-terminology"&gt;术语&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;SZFT&lt;/strong&gt; ：单区容错&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-background"&gt;背景&lt;/h2&gt;&lt;p&gt;Cassandra 天然支持数据的多副本。拥有多个数据副本的最大好处之一是高可用性：如果少数副本不可用，大多数副本仍然可以访问。当 Cassandra 集群跨多个可用区部署时，我们希望理想情况下将所有副本均匀分布在这些区域中，以便对区域的影响不会影响用户请求。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcSTnDyAkLVo_Z0_2lEv-UqaswqOQAZup6hMZKsVASGPumgKy0uf5wCQdcYGmCaI2vFl0U-bVkUY8dz3hfPZATIx7Hzr-HbtdDc53mSvXCfAMUoWI8-kx3MghC73muhugYyr71fk18Au-vNl8eGN5W5uFm9?key=AZe-MVriCM2tBK0R_Gauew" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：单区域故障和可用性影响。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;图 1 说明了该问题。在此示例中，复制因子为 3。当数据记录的大部分副本可用时，该数据记录被视为可用。当区域 1 关闭时，数据记录 1 将变得不可用，因为它丢失了大部分（两个）副本。但与此同时，数据记录 2 仍然可用，因为它恰好将少数（只有一个）副本放置在故障区域中。如果所有数据记录的副本都以与数据记录 2 相同的方式放置，&lt;strong&gt;其中&lt;/strong&gt;&lt;strong&gt;副本均匀分布在各个区域中，使得每个区域仅包含少数副本&lt;/strong&gt;，则任何单个区域的故障都不会影响到整个数据记录。整体可用性。&lt;/p&gt;&lt;p&gt; Cassandra 本质上支持通过对节点进行逻辑分组的功能来分离副本。然后副本按组分开。分组是通过名为&lt;em&gt;cassandra-rackdc.properties&lt;/em&gt;的文件完成的。&lt;/p&gt;&lt;p&gt;在此功能中，每个 Cassandra 节点都分配有两个属性： &lt;em&gt;dc&lt;/em&gt;和&lt;em&gt;rack&lt;/em&gt; 。例如，区域 1 中的 Cassandra 节点将配置如下： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090731" height="377" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1-1024x377.png" width="1024" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;当复制策略为&lt;a href="https://cassandra.apache.org/doc/4.1/cassandra/architecture/dynamo.html#network-topology-strategy" rel="noreferrer noopener" target="_blank"&gt;&lt;em&gt;NetworkTopologyStrategy&lt;/em&gt;&lt;/a&gt;时，在&lt;em&gt;DC&lt;/em&gt;内，&lt;strong&gt;对于任何数据记录，Cassandra 的副本放置算法会将副本放置到尽可能多的&lt;em&gt;机架&lt;/em&gt;上&lt;/strong&gt;。如下图所示： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXegRc24Cr4H85C9-HrRQ-xwAG1MIjpD5JJssb_oLn96JwP4lqx631rWoB5Vq_0vzWcCJmrOmFx5fLvimGURLmBi18tWM_LyYbngSsFq9oEJopiGCtpi1BxEsrVDHC2UU_7ADVBMbc457vFs1rkOXj81_Co?key=AZe-MVriCM2tBK0R_Gauew" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：所需的设置：按区域对节点进行分组。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;图 2 中的设置（假设复制因子为 3）是理想的 SZFT（单区域容错）设置。无论哪个区域出现故障，其他区域中仍然会有两个健康的副本为任何数据记录提供读取和写入服务。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-why-was-cassandra-at-uber-not-szft"&gt;为什么 Uber 的 Cassandra 不是 SZFT&lt;/h2&gt;&lt;p&gt; Uber 没有使用图 3 中的设置——我们只是没有利用“机架”属性。所有 Cassandra 节点都被分配了相同的机架属性“默认”值，导致该区域中只有一个唯一的机架值。无法正确分离副本，因为要分离副本，需要多个机架属性值。因此，大多数或可能所有副本都可以放置在同一个区域中，如下图所示： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfHvNOqIU6eb_3TL4Xjq32UOYUMe-vrXXI-ZriBakzeWwFkn2FuW-BUakKJAIujnE3tS8zljn1XXGk9w9pVglzfMur7NB8PNxhlcGHGHRqQzy6ZeVFWoPG3QjRNZCoKlpHitu14LgFXiBSvIpNaClZ6qHsn?key=AZe-MVriCM2tBK0R_Gauew" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：Uber 的旧设置：单个独特的机架。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;从较高层面来看，解决 Uber 的问题本质上意味着从单机架设置（如图 3 所示）过渡到采用基于区域的机架分配策略的多机架设置（如图 2 所示）。这一转变带来了多重挑战。让我们看看它们是什么以及我们在 Uber 如何克服它们。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-challenge-1-in-place-transition-not-an-option"&gt;挑战 1：就地过渡不是一种选择&lt;/h1&gt;&lt;p&gt;事实证明，将区域中的现有节点从单机架设置&lt;strong&gt;过渡&lt;/strong&gt;到多机架设置是&lt;strong&gt;不切实际的&lt;/strong&gt;。这是因为，如果将与新机架关联的节点引入到现有的单机架节点设置中，它将立即使新成员成为热点。如前所述，Cassandra 的副本放置算法将副本放置到尽可能多的独特机架上。当节点将第二个机架引入 Cassandra 时，所有数据记录都会将一个副本放置到新机架上，即使其中只有一个节点！图4很好地说明了这个问题： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090555" height="1024" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4-1007x1024.png" width="1007" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：在单机架设置中引入新机架时的热点问题。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;由于副本放置算法的限制，我们只剩下一个选项，从高层次来看，如下所示：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在同一区域内创建一个新的 Cassandra 环，或一个新的“dc”（如 NetworkTopologyStrategy 中所示）。新环是通过多机架设置创建的，以满足 SZFT 要求。&lt;/li&gt;&lt;li&gt;通过从旧的活动环&lt;a href="https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/rebuild.html" rel="noreferrer noopener" target="_blank"&gt;重建&lt;/a&gt;来重建新创建的环。&lt;/li&gt;&lt;li&gt;通过将客户流量从一个环移动到另一个环，透明地交换新环与旧环。&lt;/li&gt;&lt;li&gt;取下旧环。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我们为整个迁移制定了以下原则：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;零客户参与——我们的利益相关者不得参与或暴露于迁移（例如，更改服务逻辑、客户端代码或路由）&lt;/li&gt;&lt;li&gt;高可用性——迁移期间无停机时间&lt;/li&gt;&lt;li&gt;维护预先存在的性能 SLO，例如延迟&lt;/li&gt;&lt;li&gt;回滚功能，以便我们可以在旧环和新环之间来回切换，作为紧急措施&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-the-rebuild-procedure"&gt;重建程序&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-phase-1-provision-a-new-set-of-offline-multi-rack-nodes-in-the-region"&gt;第一阶段：在该地区提供一组新的“离线”多机架节点&lt;/h3&gt;&lt;p&gt;在选定的区域中，将新的节点环添加到集群中。分配给新节点的硬件资源（例如，节点数、CPU 核心、内存、磁盘大小）需要与该区域中的现有环相同。将新节点均匀分布在各个区域中。通过配置每个节点的&lt;em&gt;cassandra-rackdc.properties&lt;/em&gt;文件，使用基于区域的策略对它们进行分组，如下所示： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcH74hsYf-WXgoNrypJz7LTOJWRLDvYZIIguWfE3jCblgpTyxzh28JN2ORfhR_odddRm1wXerjO-rUZj0A0qruZ6TXDxTHwvWHxBXnebkbT4fGIEfLhcEa5s9LsNCnzmWVoJ7gmv0t0MAhSgBAirKebyVxP?key=AZe-MVriCM2tBK0R_Gauew" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;最后，所有新节点应在&lt;a href="https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/disablebinary.html" rel="noreferrer noopener" target="_blank"&gt;禁用本机传输的&lt;/a&gt;情况下创建，以防止与它们的 CQL 连接。这对于以后从现有环到新环的无缝流量切换至关重要。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090556" height="729" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5-1024x729.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：第 1 阶段：配置一组新的禁用二进制的多机架节点。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-phase-2-data-sync-for-live-writes"&gt;第 2 阶段：实时写入的数据同步&lt;/h3&gt;&lt;p&gt;由于我们的最终目标是让新环取代旧环，因此我们需要将所有数据复制并存在于两个环中。这包括实时写入的数据以及历史数据。对于来自实时写入的数据，我们需要将新环添加到所有键空间的复制设置中，以便借助 Cassandra 的跨 DC 复制，它们可以开始间接接收实时写入。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090732" height="381" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333-1024x381.png" width="1024" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090557" height="720" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6-1024x720.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：第 2 阶段：在复制中包含新的节点集。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-phase-3-data-sync-for-historical-data"&gt;第三阶段：历史数据同步&lt;/h3&gt;&lt;p&gt;对于历史数据，我们需要让新环从旧环中流式传输。尽管新节点现在正在接收实时写入，但它们仍然缺少过去的所有数据。 Cassandra 提供了一个工具，可以使用 nodetool重建命令来流式传输此类数据。需要在&lt;em&gt;region1_new&lt;/em&gt;的每个新节点上运行以下命令以流式传输来自&lt;em&gt;region1&lt;/em&gt;的数据： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090734" height="138" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild-1024x138.png" width="1024" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXft9Qy90P61zHHyDGRk1L-IrXN866dHr8WMyGbEe-_05rtLUdE_171HSBDlkFowzOnG9Ka40w79XsIiT91h2md32ikNehFv86ncC0xmN-G6aDa7S5yUS1eRhB_-sfHRy7veOzNTt0lSRc9FjuzEMpFDDD9D?key=AZe-MVriCM2tBK0R_Gauew" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：第 3 阶段：同步旧数据。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-phase-4-traffic-switch"&gt;第四阶段：流量切换&lt;/h3&gt;&lt;p&gt;历史数据传输完毕后，我们就可以让 Cassandra 客户端连接到新的节点环并停止连接到旧的节点环。这是通过在新环中的所有节点上&lt;a href="https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/enablebinary.html" rel="noreferrer noopener" target="_blank"&gt;启用本机传输&lt;/a&gt;，然后在旧环中的所有节点上&lt;a href="https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/disablebinary.html" rel="noreferrer noopener" target="_blank"&gt;禁用本机传输来&lt;/a&gt;完成的。我们已经消除了在客户端执行任何操作的需要，其原因将在下一节中讨论，我们将看到我们在 Uber 所做的 Cassandra 客户端增强。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXf6wcyJD06iUE8_JWw81JUucwUyHl-xEeQRmUNftN2rLvtBeU0vgE53GWTIYQvWhGvMFM7Stbz4hUuuBGTpQX1qBDikqwrHNa__Y3tkcvdnoRk3MA3f97eyOHW0sXJahDq2I1PaxzPxcNet7SNYvVGpoNiP?key=AZe-MVriCM2tBK0R_Gauew" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：第 4 阶段：流量切换。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-phase-5-remove-old-nodes"&gt;第 5 阶段：删除旧节点&lt;/h3&gt;&lt;p&gt;首先，需要更改所有键空间的复制设置，以便旧环不再是数据复制的一部分。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090735" height="339" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333-1024x339.png" width="1024" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;完成此操作后，旧环中的节点将退役。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcDvHs74P1MCQgreqSpD_eOglh3jidW2ydJN4TthFJGd5BOMq6tTk-FE04jLk-LFacE1cRXKQGH6nvmXzP1FDpO7TiQefYYl8dhEV34zSMIZ1uPfQZu66743WCZrHkz3aloDsPF8qVOs_fZhgUM_TyoncnY?key=AZe-MVriCM2tBK0R_Gauew" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：第 5 阶段：删除旧的节点集。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-phase-6-repeat-for-the-other-regions"&gt;第 6 阶段：对其他区域重复&lt;/h3&gt;&lt;p&gt;所选区域中的 Cassandra 集群现在是 SZFT。其他区域需要重复相同的过程。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-cassandra-client-enhancement"&gt; Cassandra 客户端增强&lt;/h2&gt;&lt;p&gt;在上述过程中，不涉及客户端操作。这是因为在 Uber，我们有一个 GoCQL 和 Java 驱动程序的分支，我们对它们进行了增强，使其能够动态地将流量从一个环切换到另一个环，而无需重新启动。&lt;/p&gt;&lt;p&gt;为了实现无缝流量切换，Cassandra 客户端的期望是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;始终从客户端所在的同一区域提供初始 Cassandra 联系点（即用于初始拓扑发现的 Cassandra 节点）。&lt;/li&gt;&lt;li&gt;始终从客户端所在的同一区域选择协调器节点。&lt;/li&gt;&lt;li&gt;在启用本机传输并在旧环的节点上禁用本机传输后，自动连接到新环的节点，如重建过程的第 4 阶段所示。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;要求 1 是通过一个新的微服务来满足的，该服务致力于发布 Cassandra 集群的联系信息。它与我们的 Cassandra 控制平面集成，从而了解每个 Cassandra 集群的拓扑。该服务的使用者（在本例中为 Cassandra 客户端）发送仅包含目标 Cassandra 集群名称的请求。该服务返回&lt;strong&gt;属于与消费者位于同一区域的&lt;/strong&gt;集群的所有节点的联系信息（例如，IP 和端口）。&lt;/p&gt;&lt;p&gt;上述逻辑对客户端 API 是隐藏的，我们的 Cassandra 用户只需更改为客户端提供联系点的方式，如下所示： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090736" height="91" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder-1024x91.png" width="1024" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;要求 #2 是通过我们在 Uber 在 Cassandra 客户端中实施的新主机过滤器来完成的。这个新的主机过滤器排除了位于客户端远程区域的所有协调器节点。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090737" height="105" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy-1024x105.png" width="1024" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;要求 #3 是通过将负载平衡策略指定为 TokenAware + RoundRobin 来实现的。真正重要的不是这些策略的使用，而是消除 DCAwarePolicy 的使用。 DCAwarePolicy 曾经出现在 Uber 的许多 Cassandra 应用程序中，它将协调器节点选择固定到旧环。开源客户端已经能够及时捕获与本机传输相关的更改，自动断开与禁用本机传输的节点的连接并自动连接到新启用本机传输的节点。因此，我们需要做的就是允许客户端连接到同一区域中的任何环。&lt;/p&gt;&lt;p&gt;最后，我们在 Uber 标准化了 Cassandra 客户端配置，如下所示： &lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="" class="wp-image-1090738" height="337" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder-1024x337.png" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;客户端中的这些增强功能巧妙地将用户与 Cassandra 集群的低级拓扑细节分离，例如 IP、端口、dc（如 NetworkTopologyStrategy 中的）等。它为重建第 4 阶段的无缝流量切换铺平了道路程序。此外，基于区域的协调器选择与“LOCAL_QUORUM”读写相结合，可确保在一个区域的重建过程中，其他区域的 Cassandra 客户端不会受到任何影响，因为它们始终直接与其他区域的 Cassandra 节点交换数据。他们当地的区域，允许逐个区域的 SZFT 过渡。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-challenge-2-nbsp-lack-of-uniform-spare-server-capacity-across-zones"&gt;挑战2：跨区域缺乏统一的备用服务器容量&lt;/h1&gt;&lt;p&gt;对于每个 Cassandra 机架都是一个区域的多机架设置，我们需要确保始终有足够的可用区域（即区域数量≥replication_factor）。此外，每个可用区的备用容量需要统一，以便在集群扩展时每个机架均等扩展。&lt;/p&gt;&lt;p&gt;如果集群规模较小，因此所需的扩展量较小，或者所有区域中的备用容量都有更强的保证，则这似乎不那么具有挑战性。然而在实践中，可用容量很可能不均匀地分布在各个区域中。在这种情况下，执行集群的潜在紧急水平扩展将不可避免地导致牺牲集群的 SZFT 属性。&lt;/p&gt;&lt;p&gt;无论容量情况如何，我们都应该做好应对这种情况的准备。当SZFT属性和对水平扩展的迫切需求无法同时满足时，我们必须通过水平扩展来优先考虑集群的即时性能需求。重要的是要记住，一旦额外的容量最终到达其他区域，我们应该能够以最少的节点替换数量将扩展过程中添加的节点“重新定位”到所需的区域，最终实现 SZFT。整个过程对操作要求相当高，我们需要精细化的自动化来大幅减少人工工作量。&lt;/p&gt;&lt;p&gt;我们不会在本博客中详细讨论这一挑战，因为它涉及服务器容量管理方面。得益于运行底层存储管理和控制平面平台的&lt;em&gt;状态平台&lt;/em&gt;团队，Uber 确保准备好以完全自动化的方式应对此类场景。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-highlights"&gt;强调&lt;/h2&gt;&lt;p&gt;这一关键项目的成功衡量标准如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;绝大多数 Cassandra 机群已完成部署。推出后的几个月里，没有发现任何问题。&lt;/li&gt;&lt;li&gt;推广期间，未发生重大事故。&lt;/li&gt;&lt;li&gt;整个过程对我们的利益相关者来说是完全透明的。&lt;/li&gt;&lt;li&gt;我们进行了多次测试，几乎关闭了整个生产区，而 Cassandra 的利益相关者没有受到影响！ &lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;在本文中，我们展示了 Uber 的 Cassandra 部署。我们还强调了实现单区容错的挑战，并深入研究了解决方案。&lt;/p&gt;&lt;p class="has-small-font-size"&gt;&lt;strong&gt;封面照片归属&lt;/strong&gt;：该图像是使用 ChatGPT 生成的。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Apache® 和 Apache Cassandra® 是 Apache Software Foundation 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Oracle、Java、MySQL 和 NetSuite 是 Oracle 和/或其附属公司的注册商标。其他名称可能是其各自所有者的商标。&lt;/p&gt;</description><pubDate>Thu, 20 Jun 2024 07:33:46 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/single-zone-failure-tolerance/</guid></item><item><title>【Debugging with Production Neighbors – Powered by SLATE】</title><link>https://www.uber.com/blog/debugging-with-production-neighbors/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;软件开发是一个迭代的分阶段过程，需要在功能、组件和服务级别进行验证和测试。在基于微服务的架构中，与依赖服务结合开发变得更加重要。基于微服务的架构提供了独特的优势，使我们能够扩展、维护和抽象职责。越抽象，我们就越容易开发和定义业务逻辑。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.uber.com/blog/simplifying-developer-testing-through-slate/" rel="noreferrer noopener" target="_blank"&gt;SLATE&lt;/a&gt;是一种端到端测试工具，它允许部署被测服务并与生产上游和下游服务一起工作，从而弥补了这一差距。这允许开发人员生成镜像生产调用流程的测试请求，但目标是测试中的服务。此类功能有助于各种用例，包括生产环境中的功能开发或复制生产错误，这通常需要对代码和配置进行故障排除。为了帮助或简化故障排除过程并使其更接近本地体验，我们开发了一些功能来支持对 SLATE 环境中部署的服务进行调试。&lt;/p&gt;&lt;p&gt;在本博客中，我们将探索在 SLATE 上开发的不同调试选项，这些选项可模拟生产上游和下游的测试中服务的行为。&lt;/p&gt;&lt;p&gt;让我们详细检查以下三个高级选项：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;远程调试 SLATE 部署的实例&lt;/li&gt;&lt;li&gt;笔记本电脑/开发 Pod 机器中的本地调试&lt;/li&gt;&lt;li&gt;通过过滤监控来调试问题&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-debugging-until-now"&gt;调试到现在&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-debug-via-logs"&gt;通过日志调试&lt;/h3&gt;&lt;p&gt;使用日志进行调试是一种基本实践，可以深入了解程序的执行情况。日志使开发人员能够识别问题。然而，低效的日志记录可能会用不相关的信息使系统变得混乱，从而导致调试过程变得复杂而不是有帮助。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-debug-via-staging"&gt;通过暂存进行调试&lt;/h3&gt;&lt;p&gt;暂存环境是开发人员控制的环境，反映了生产设置。&lt;/p&gt;&lt;p&gt;虽然登台环境非常有益，但它们仍然可能与现场环境不同，并且会提供较长周转时间的错误信心。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-debug-locally"&gt;本地调试&lt;/h3&gt;&lt;p&gt;本地调试对于更快地迭代以隔离测试服务至关重要。然而，由于同时调试多个服务的限制，调试用户场景可能具有挑战性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-remote-debugging-of-slate-instance"&gt; SLATE实例的远程调试&lt;/h2&gt;&lt;p&gt;SLATE 上的测试和调试依赖于正在测试的服务的日志。仅仅依靠日志来理解复杂的过程是不切实际的。此外，添加新日志需要新的部署，从而导致延迟。远程调试可以通过让开发人员逐步执行语句和监视变量来解决这些问题，从而消除提交和部署迭代的需要。与生产基础设施协作，需要平衡安全性和开发人员体验。&lt;/p&gt;&lt;p&gt;这就需要增强代码的可见性以进行运行时调试，这可以通过断点、单步执行或动态跟踪点来实现。远程调试仅限于处理测试请求的 SLATE 实例，以确保生产安全。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-high-level-goals"&gt;高级别目标&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;在 SLATE 容器上部署可调试的二进制文件/代码&lt;/li&gt;&lt;li&gt;能够向被测服务添加断点和跟踪点&lt;/li&gt;&lt;li&gt;能够在遇到断点的控件上查看不同参数的值&lt;/li&gt;&lt;li&gt;创建类似于远程调试的无缝开发人员体验&lt;/li&gt;&lt;li&gt;设计符合安全和隐私问题的解决方案&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-design"&gt;设计&lt;/h3&gt;&lt;p&gt;SLATE 利用生产基础设施来生成容器、编译代码和执行服务。然而，需要对构建和部署基础设施进行修改，以便于调试部署在 SLATE 上的服务的功能。这涉及三项重大改进。首先，使用集成的调试工具和功能生成构建。其次，使用远程调试选项配置软件执行。第三，通过分配和公开所述容器的端口，促进开发人员访问远程容器。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-debuggable-deployment"&gt;可调试部署&lt;/h3&gt;&lt;p&gt;当前的部署管道不灵活，无法支持生成可调试和生产二进制文件的不同选项。为了能够生成和部署可调试的二进制文件，管道的多个组件应该实现二进制文件的类型并相应地配置其功能。该图指示了功能开发期间将涉及的组件。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090425" height="285" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2-1024x285.jpeg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：对部署管道进行修改以支持 SLATE 调试。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-allocating-ports"&gt;分配端口&lt;/h3&gt;&lt;p&gt;SLATE 容器与生产主机一起创建。为了能够连接到调试器，我们必须公开一个新的调试端口，类似于 gRPC/HTTP 端口。目前UP负责分配随机端口并将其映射到主机端口。新端口的公开将仅针对可调试的 SLATE 部署开放，并且 SLATE 按设计隐式处理​​测试请求。这个新的端口暴露需要进行安全审查。下图显示了高层交互。&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-"&gt;&lt;img height="173.47872782612586" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfNB42pjNG_DCuxWPz9gEvHHrE9XBFFcsEvj1tsaIr7Hn2pTk6nl3ghqed81UCUzrhbtFUaWYoageTGPGBuZJXXTNq_Zx8lT-RoppYjT3hjsjxuViujT4oCun8CeDLuQqzNyIV2C8GjgTr6m1Hs73MActat?key=Ermx74NMIF5DAzxh8Wqoiw" width="695.85121602289" /&gt;&lt;/h2&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090426" height="283" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1-1024x283.jpeg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：分配和安全公开调试端口。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-reaching-debuggable-service"&gt;实现可调试服务&lt;/h3&gt;&lt;p&gt;为了提高安全性，避免恶意访问，SLATE调试需要进行访问控制。这将确保只有服务所有者才能连接调试器。下图显示了将访问权限限制为仅服务的 LDAP 用户的访问控制。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090429" height="357" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1-1024x357.jpeg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：从开发人员计算机到远程主机的基于密码的 SSH 隧道。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-debugger-execution"&gt;调试器执行&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;调试器在专用调试服务器中运行应用程序&lt;/li&gt;&lt;li&gt;进程阻塞，等待调试器客户端附加&lt;/li&gt;&lt;li&gt;调试器进程侦听特定的 TCP/IP 网络端口（称为调试端口）&lt;/li&gt;&lt;/ul&gt;&lt;h4 class="wp-block-heading" id="h-controlling-program-execution"&gt;控制程序执行&lt;/h4&gt;&lt;p&gt;调试客户端（例如 VSCode、GoLand、JetBrains）通过调试端口连接。客户端发出命令来执行各种调试任务，例如设置断点、显示局部变量和函数参数、打印 CPU 寄存器内容等。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-remote-debugging-with-debug-port"&gt;使用调试端口进行远程调试&lt;/h4&gt;&lt;p&gt;远程调试支持在不同的环境、配置或架构上进行调试。对于解决无法本地复制的特定场景或硬件/软件相关问题非常有用。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-access-control"&gt;访问控制&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-restricting-for-ldap-users"&gt;限制 LDAP 用户&lt;/h3&gt;&lt;p&gt;在调试会话期间，用户将调试器附加到应用程序以干预程序执行并收集调试信息。这也意味着尝试识别并解决程序中的错误。这意味着如果允许每个用户访问一些敏感的服务信息。因此，限制 LDAP 用户（服务开发人员/所有者）对于确保最低安全性非常重要。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-secure-ssh-connection"&gt;安全 SSH 连接&lt;/h3&gt;&lt;p&gt;对于远程调试，在本地和远程系统之间建立安全的 SSH 连接。这将允许本地端口转发并通过 SSH 隧道重定向调试请求。该隧道将确保加密通信和安全数据传输。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-ssh-authorization"&gt; SSH授权&lt;/h3&gt;&lt;p&gt;要开始 SSH 连接，用户需要链接到“slatedev”帐户的正确密码。该密码是服务容器内文件中随机生成的 16 位代码。密码是在主服务应用程序运行之前容器启动期间生成的。该密码只能由容器访问组（即服务所有者 LDAP）访问。 LDAP 用户可以通过 Compute CLI 访问密码，从而使他们能够建立 SSH 连接并执行调试任务。计算 CLI 确保对非 LDAP 用户的访问受到限制，即不允许密码访问。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-limitations"&gt;局限性&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;生产基础设施上的远程调试对动态修改有限制，因此仅限于只读&lt;/li&gt;&lt;li&gt;迭代时间长，因为每次更改都涉及构建、部署和测试&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-local-debugging-using-slate-attach"&gt;使用 SLATE Attach 进行本地调试&lt;/h2&gt;&lt;p&gt;远程调试允许在生产基础设施上进行只读调试。处于生产基础设施中可以实现与上游和下游服务/工具的无缝连接。对于开发人员来说，体验可调试环境以及更快的迭代来修复和测试相同的环境非常重要。这一差距可以通过创建与生产上游和下游服务相关的本地调试体验来填补。 SLATE Attach 填补了这一空白，并允许在附加本地环境上快速开发。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-high-level-goals-0"&gt;高级别目标&lt;/h3&gt;&lt;p&gt;主要目标是通过使用本地开发实例（笔记本电脑或开发机器）提供端到端测试来缩短代码部署测试周期（从而缩短验证迭代更改的时间），确保生产隔离和安全。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-iteration-cycle"&gt;迭代周期&lt;/h3&gt;&lt;p&gt;在这种情况下，迭代周期是指更改代码和验证代码之间的时间。迭代周期越小，开发人员对后续变更进行端到端验证的时间就越有效。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-full"&gt;&lt;img alt="" class="wp-image-1090430" height="221" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig4.jpeg" width="820" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：使用 SLATE 进行开发的迭代步骤。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-need-for-slate-attach"&gt;需要 SLATE Attach&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;迭代开发以更快的速度生成构建二进制文件&lt;/li&gt;&lt;li&gt;缩短代码部署测试周期&lt;/li&gt;&lt;li&gt;更快地识别和解决本地、端到端故障&lt;/li&gt;&lt;li&gt;更快的设置时间&lt;/li&gt;&lt;li&gt;避免服务变更或入职培训的需要&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-design-0"&gt;设计&lt;/h2&gt;&lt;p&gt;此设计旨在引入一个 SLATE 代理，用于处理针对 SLATE 实例的所有测试请求以进行本地调试。然后，这些请求将被重定向到适当的本地开发人员计算机以进行调试和开发。这使得用户能够更快地迭代并提高开发人员的生产力。&lt;/p&gt;&lt;p&gt;该功能主要在 SLATE 环境生命周期的 2 个上下文中启用：&lt;/p&gt;&lt;ol&gt;&lt;li&gt; &lt;strong&gt;SLATE 将本地笔记本电脑/devpod 映射到 slate 环境的控制平面&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;测试请求数据平面&lt;/strong&gt;，将请求重定向到开发人员的笔记本电脑&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-control-plane"&gt;控制平面&lt;/h2&gt;&lt;p&gt;控制平面的主要功能是使本地笔记本电脑或 devpod 中运行的服务能够附加到 SLATE 环境。打算运行该服务的本地笔记本电脑/devpod 必须将本地环境凭据附加到 SLATE 环境，以便测试请求在本地路由。此附件的先决条件是创建 SLATE 环境。这将允许路由控制数据库和本地路由数据库中的映射更新。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090431" height="560" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5-1024x560.jpg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：用于测试在开发人员计算机上运行的代码的请求调用流程&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-call-flow"&gt;通话流程&lt;/h4&gt;&lt;ol&gt;&lt;li&gt;用户从本地笔记本电脑/devpod 启动 SLATE 连接&lt;/li&gt;&lt;li&gt;SLATE CLI 调用 SLATE 后端的 Attach() API&lt;/li&gt;&lt;li&gt; SLATE 后端从 SLATE 代理获取代理信息（主机：端口）&lt;/li&gt;&lt;li&gt; SLATE 后端使用获取的代理信息更新路由控制数据库中的路由覆盖&lt;/li&gt;&lt;li&gt;用户使用 Cerberus CLI 启动 SSH 会话&lt;/li&gt;&lt;li&gt;Cerberus 网关将代理租赁/UUID 的映射添加到 Flipr DB 中的笔记本电脑凭据，并为笔记本电脑创建 SSH 会话&lt;/li&gt;&lt;/ol&gt;&lt;h4 class="wp-block-heading" id="h-routing-control-db"&gt;路由控制数据库&lt;/h4&gt;&lt;p&gt;路由控制数据库将测试租用映射到路由覆盖，将用户帐户 UUID 映射到测试租用。它针对测试中的服务存储 SLATE 代理主机：端口，并确保针对特定 SLATE 环境的所有请求都到达 SLATE 代理。 SLATE Proxy 最终将请求路由到在用户计算机中运行的开发实例。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-local-routing-db"&gt;本地路由数据库&lt;/h4&gt;&lt;p&gt;本地路由数据库包含已附加到 SLATE 环境的开发实例的凭据。 SLATE Proxy 与本地路由数据库交互以获取路由凭证，并最终将请求路由到在本地环境中运行的被测服务&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-data-plane"&gt;数据平面&lt;/h2&gt;&lt;p&gt;本节主要讨论来自不同客户端（移动端、工作室、Web 等）的测试请求的流程。该数据平面主要涉及2个实体：路由覆盖标头和主机租赁映射。下图显示了不同的测试请求如何通过 SLATE 代理到达本地笔记本电脑。控制平面确保路由覆盖和主机映射维护在不同的数据库中。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090432" height="520" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6-1024x520.jpeg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：用于将测试请求路由到开发人员计算机的代理设置。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;以上是针对本地笔记本电脑以及生产上游和下游的测试请求流程：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;测试帐户请求来自移动客户端&lt;/li&gt;&lt;li&gt;E2E测试代理检索路由覆盖并将路由标头注入测试请求&lt;/li&gt;&lt;li&gt;测试请求通过 Mutley 在生产服务中传播，直到请求具有服务 3 目标&lt;/li&gt;&lt;li&gt;请求重定向到 SLATE 代理，因为路由覆盖具有针对服务 3 的 slate 代理主机：端口&lt;/li&gt;&lt;li&gt;SLATE 代理根据 Cerberus-deputy Flipr 命名空间中的主机：端口配置将请求转发到 Cerberus-gateway 上的开放端口，该配置由用户在运行 Cerberus CLI 时设置&lt;/li&gt;&lt;li&gt;Cerberus-gateway将请求转发到用户本地开发机，供用户调试&lt;/li&gt;&lt;li&gt;从本地笔记本电脑，请求最终将通过 Cerberus 转发到生产下游&lt;/li&gt;&lt;/ol&gt;&lt;h3 class="wp-block-heading" id="h-limitations-0"&gt;局限性&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;对于某些复杂的服务来说，在本地运行服务可能不可行，因为它们需要支持某些依赖项，例如只能存在于生产基础设施中的扳手&lt;/li&gt;&lt;li&gt;这仅限于测试请求，因为它可以动态更改请求，从而保护生产流量&lt;/li&gt;&lt;li&gt;本地等待调试请求时间较长时请求超时&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-impact"&gt;影响&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;即插即用的开发环境，提高开发人员的工作效率&lt;/li&gt;&lt;li&gt;能够为开发者创造与生产协同的本地体验&lt;/li&gt;&lt;li&gt;提高开发人员速度：生产调试可以帮助开发人员更有效地识别和修复问题&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090433" height="280" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7-1024x280.jpeg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7. 使用 SLATE 附加功能提高开发速度的影响数据。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-what-s-next"&gt;下一步是什么&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;SLATE Sniffer 通过监控来调试问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;远程和本地调试主要允许测试请求进行调试。除了 uMonitor 工具中出现的日志之外，还需要对生产进行可观察性。我们的目标是使用 SLATE Sniffer 精确地按需创建这种可观察性。  SLATE Sniffer 的主要目标包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;捕获请求和响应作为服务和 UUID 的过滤器&lt;/li&gt;&lt;li&gt;能够支持和过滤生产和测试请求&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;我们的目标是增强 SLATE 平台，将其定位为调试生产问题的主要工具。集成到 SLATE 中的调试功能在安全性和开发人员的要求之间取得了平衡。 SLATE 为开发人员的代码相关活动和服务引导引入了新的范例。我们期待与不同的团队合作，将质量左移并在开发的早期阶段就潜在问题建立可见性。&lt;/p&gt;</description><pubDate>Tue, 18 Jun 2024 07:21:37 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/debugging-with-production-neighbors/</guid></item><item><title>【Personalized Marketing at Scale: Uber’s Out-of-App Recommendation System】</title><link>https://www.uber.com/blog/personalized-marketing-at-scale/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;应用外 (OOA) 通信（例如电子邮件、推送和短信）是 Uber 的重要增长杠杆。它允许营销人员、产品所有者和运营团队就大量主题与用户建立联系，包括用户促销、新餐厅和最喜欢的餐厅等。构建一个系统来个性化这些通信提出了独特且令人兴奋的挑战。在这篇博文中，我们将介绍这些挑战以及我们应对这些挑战的历程。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-challenges-nbsp"&gt;挑战&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-lack-of-recommendation-context"&gt;缺乏推荐背景&lt;/h3&gt;&lt;p&gt;第一个挑战是 OOA 通信中缺乏用户上下文。这些个性化通信的核心是餐厅推荐和商家报价推荐。这些推荐是高度本地化的（即用户只能从附近的餐馆订购）。在标准产品推荐系统中，用户在进入应用程序时会看到推荐。用户的位置和意图通常都是已知的。另一方面，OOA 通信中的推荐会主动推送给用户，以供不确定的未来观看。即使在没有关键用户上下文的情况下，确保推荐保持相关性也是我们系统面临的一项重大挑战。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-incorporating-campaign-objectives"&gt;纳入活动目标&lt;/h3&gt;&lt;p&gt;第二个挑战是 OOA 通信中的建议需要与最终用户和通信上下文相关。关于会员福利的电子邮件应包括独家餐厅的促销活动，而庆祝城市社区的电子邮件应突出当地人最喜欢的餐厅。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-system-costs"&gt;系统成本&lt;/h3&gt;&lt;p&gt;最后，能够以具有成本效益的方式大规模应对上述挑战是我们面临的另一个挑战。该系统目前负责向所有地理区域和业务线的用户发送超过 40 亿条个性化消息。生成 OOA 建议的成本主要包括三个方面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;在线特征存储&lt;/strong&gt;：这涉及与推荐系统中使用的特征的存储、检索和管理相关的费用。在线特征存储有助于快速访问和处理用户、项目和交互特征，这对于实时个性化至关重要。这里的成本是由对可扩展、高性能数据库的需求驱动的，这些数据库可以以低延迟处理大量数据。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;在线预测：&lt;/strong&gt;运行复杂的模型进行实时预测会产生巨大的成本。这些模型比我们之前的架构中的模型更加复杂，需要大量的计算资源来进行连续的数据处理和分析。与运行这些模型所需的计算能力相关的费用，包括服务器成本以及用于实验目的的额外计算资源的维护和扩展。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;高吞吐量和广泛的受众：&lt;/strong&gt;为迎合更多受众和处理更高消息吞吐量而进行的扩展进一步增加了成本。随着系统扩展以适应更多用户和更广泛的营销场景，基础设施也必须扩展。要处理超过数十亿条消息的实时个性化，所需的吞吐量可以达到应用内推荐系统的10倍。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;有效管理这些成本对于我们新架构的可持续性至关重要，需要在性能、可扩展性和成本效率之间取得平衡。优化算法以获得更好的性能、利用经济高效的自动扩展基础设施以及优化功能策略等技术可以显着帮助控制这些费用。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-nbsp-architecture-overview-nbsp"&gt;架构概述&lt;/h2&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfgrQtPFPJjdzvNKpMosLG74j6oOD8dEA602cpHo6_OeMD6HJ-2NJBPXMWB5ApZFJASs1SRJCniWle1RK8JOjxusx10elXiP1mdX2oHl6sdV17iS2d-Ijaz4z4P0_QNXdyx5bPRRD-1FXDVhpS9ghLK0q8?key=DgmRI0YIzHZkraGCSk9ZeA" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：营销个性化架构。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;&lt;strong&gt;候选检索&lt;/strong&gt;：此过程涉及为每个用户确定一组广泛的潜在推荐。该系统使用基于位置的首次通过排名算法，扫描大量商品，考虑用户历史记录、商店受欢迎度和上下文数据等各种因素，以检索候选推荐的初步列表。&lt;/p&gt;&lt;p&gt;&lt;em&gt;核心技术：Local Graph（Uber的知识图谱）&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;混合&lt;/strong&gt;：一旦检索到候选者，它们就会经历过滤和混合过程。该步骤根据预定义的业务规则和标准淘汰不太相关或不需要的选项。它确保最终的建议符合用户的偏好和任何业务限制。&lt;/p&gt;&lt;p&gt;&lt;em&gt;核心技术：&lt;/em&gt;&lt;a href="https://github.com/google/cel-spec" rel="noreferrer noopener" target="_blank"&gt;&lt;em&gt;基于CEL的&lt;/em&gt;&lt;/a&gt;&lt;em&gt;规则引擎&lt;/em&gt;（使用&lt;a href="https://www.uber.com/blog/flipr/" rel="noreferrer noopener" target="_blank"&gt;Flipr&lt;/a&gt; ）&lt;/p&gt;&lt;p&gt;&lt;strong&gt;排名&lt;/strong&gt;：在排名阶段，对候选者进行排名以确定其呈现给用户的顺序。该排名基于一整套排名功能，用于评估每个项目与用户上下文和偏好的相关性。目的是将最相关和最具吸引力的推荐放在顶部，最大限度地提高用户参与的可能性。&lt;/p&gt;&lt;p&gt;&lt;em&gt;核心技术： &lt;a href="https://www.uber.com/blog/palette-meta-store-journey/" rel="noreferrer noopener" target="_blank"&gt;Palette Feature Store&lt;/a&gt; 、 &lt;a href="https://www.uber.com/blog/michelangelo-machine-learning-platform/" rel="noreferrer noopener" target="_blank"&gt;Michelangelo&lt;/a&gt;&lt;/em&gt; &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-solution-formulation-nbsp"&gt;溶液配方&lt;/h2&gt;&lt;p&gt;为了解决我们的三个主要挑战，我们对架构的每个部分都进行了增强，以便在高效且可扩展的系统中向用户提供相关且主题一致的内容。我们将在下面详细讨论每项增强功能。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-candidate-list-generation-nbsp"&gt;候选列表生成&lt;/h3&gt;&lt;p&gt;Uber Eats 优食推荐的一个独特部分是针对用户位置高度本地化的候选列表。当用户打开 Uber Eats 优食应用程序时，系统会向他们推荐可以送货到当前位置或最近订单位置的餐厅、杂货店和零售店。对于我们的 OOA 推荐系统，我们的候选列表生成中缺少这一关键上下文。我们开发了两种解决方案来克服这一障碍。&lt;/p&gt;&lt;p&gt;对于一般推荐用例，我们开发了一个机器学习解决方案来确定用户接下来最有可能收到订单的社区。由于我们的系统支持针对频繁、不频繁和新 Uber Eats 用户的营销活动，因此该 ML 解决方案需要集成来自 Uber Eats 和 Uber 应用程序多年时间范围内的高和低吞吐量信号。为了确保该解决方案的可扩展性，以适应与活动所有者沟通的数亿 Uber 用户，我们专注于将这些信号减少到一小组约 10 个功能，机器学习解决方案利用这些功能来定义用户的下一个可能的订单位置。利用这个可能的位置，通过查找向该位置送货的所有餐馆、杂货店或零售店来生成用户的候选列表。&lt;/p&gt;&lt;p&gt;虽然这个基本解决方案为我们的 OOA 推荐系统提供了重要的上下文，但它并不总是为每个活动提供正确的上下文。在用户可能旅行的活动设置中（例如，机场旅行、Uber Reserve、Uber for Business），上述 ML 解决方案可能没有必要的上下文来反映用户最近的行为变化。在此设置中，我们利用基于事件的覆盖来更新用户的候选列表，以包含送货到最近社区的餐馆、杂货店和零售店。通过更新此候选列表，我们提高了用户沟通的相关性，并为活动所有者提供了控制这些候选列表的灵活性，以确保其活动的主题一致性。&lt;/p&gt;&lt;p&gt;这些解决方案共同将关键的用户元数据注入用户的候选列表中，确保我们的建议与用户相关并反映他们最近的行为。通过为所有 Uber 用户提供通用的机器学习解决方案，活动所有者可以确信用户的候选列表是准确的，并且可以满足他们的活动目标。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-first-pass-ranking"&gt;首过排名&lt;/h3&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcpvTCnINAXH7xDcMWM5D7jUOEVwOrEsKKugQ4byxZxyT47qLsOM8tcHZwRhy6n-0YCXX4AbYrvS80h2tFTkka94fyYIEZpYxFZ_rrFj5GuBBpvEZlgEkgWSC7Qnrawk0sHnUfLyH4p1OpyapRuYIsUI1IM?key=DgmRI0YIzHZkraGCSk9ZeA" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图2：首次通过排名。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;首遍排名的主要目标是快速将所有符合条件的候选商户集合减少到每个用户的较小的潜在商户集合。这有助于节省系统带宽并降低与机器学习相关的成本。&lt;/p&gt;&lt;p&gt;根据用户位置检索到所有候选者后，我们启动初步过滤过程。此阶段根据不可用和无效送达能力（例如跨境商家）等标准排除候选者。&lt;/p&gt;&lt;p&gt;在某些广告系列中，我们会展示各种餐厅类型。为了完善我们的选择，候选人会根据特定用例进行额外的筛选。例如，我们的主要推荐策略是根据用户过去与 Uber Eats 优食的互动来评估候选者的相关性。我们还介绍提供促销活动的候选者，并通过向用户推荐尚未订购但可能有吸引力的餐厅的候选者来激励用户。&lt;/p&gt;&lt;p&gt;对于每个用例，我们都会对所有符合条件的候选商家应用低成本评分功能。该函数是一小组特征的简单线性组合，包括用户和商家之间过去的交互。调整权重以最大化召回指标。&lt;/p&gt;&lt;p&gt;最后，为了确保用户有多种选择，我们运行了重复数据删除过程。此步骤删除属于同一父链的候选者，避免重复推荐。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-second-pass-ranking"&gt;第二关排名&lt;/h3&gt;&lt;p&gt;第二排名阶段的目标是对从第一次排名中检索到的一小组商家进行排名，以最大化用户参与的可能性。为此，我们利用一些功能来捕获用户过去的订单历史记录、应用内和应用外的参与度以及商家的质量、可靠性和承受能力。其中许多功能也被家庭提要排名系统所利用，并通过 Uber 的在线功能商店&lt;a href="https://www.uber.com/blog/palette-meta-store-journey/" rel="noreferrer noopener" target="_blank"&gt;Palette&lt;/a&gt;共享。通过在推荐服务之间共享功能集，我们促进了应用内和应用外界面的用户体验的平等。这些功能在学习排名 LTR 建模框架中使用，并具有自定义相关权重，以鼓励理想的用户行为。&lt;/p&gt;&lt;p&gt;虽然以用户为中心的功能对于经常使用的用户来说很丰富，但对于新用户和流失的用户来说通常无法使用。由于 OOA 系统主要迎合不频繁的用户群体，因此我们必须依赖长期的用户信号才能提供良好的推荐。此外，我们需要能够以经济高效的方式存储和使用此类信号。为了通过餐厅推荐克服这一挑战，我们构建了一个轻量级功能集，总结了用户在整个 Uber Eats 优食历史中的美食偏好。在 Uber，我们为每家餐厅标记了商家提供的一组美食，我们利用这些美食创建一个总结用户美食偏好的特征向量。我们每天使用贝叶斯更新逻辑更新此功能，并增加最近订单的权重，以反映用户最近的行为变化。在最近的在线实验中，将此功能纳入我们的第二次排名系统中，电子邮件的点击率提高了 4%。&lt;/p&gt;&lt;p&gt;我们的第二遍排名系统中使用的许多功能有效地总结了用户过去的订单行为，但没有透露用户接下来可能有兴趣尝试哪些餐厅。由于 Uber Eats 优食订单的地理限制，协作推荐系统技术很难学习餐厅相似性。例如，不同社区的两家餐馆可能以相似的价格提供相似的菜肴，但由于地理差异而没有共同的顾客。虽然通过基于协作的方法来学习餐厅相似性很困难，但利用基于内容的推荐方法和餐厅的美食标签提供了学习餐厅相似性的机会，并鼓励用户在 Uber Eats 优食上探索新餐厅。我们假设用户会对提供与他们过去订购的菜肴相似的菜肴的新餐厅感兴趣。在此前提下，我们进行了一项分析来量化菜系之间的相似性。我们对正则化的美食共现矩阵进行了谱聚类，该矩阵捕获了同一家餐厅经常提供哪些菜肴。从这个聚类练习中，我们发现，虽然商家可以提供数百种菜肴，但这些菜肴可以自然地归入少数几个类别。在图 3 中，我们可视化通过 t-SNE 映射到二维空间的每种美食的嵌入向量，突出显示了这些自然美食集群。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXclTIOVrXS9GosD3MlTmw3WJ6vNDCKLZ5P8yDa5Fru2bv4mhA4sGVo29-KyGWF7GZpO8axvCO52o_w_Xs4IwW_wW3rYodhyYhan-2PRcl5NBdd6mBWGKWIQifmwnWmtHePk-5xBREjN3xNW10pp9C54_As?key=DgmRI0YIzHZkraGCSk9ZeA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：基于相似性分析的美食分类。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;这些分组促使我们根据这些菜肴的相似性来平滑每个用户的菜肴偏好特征。在我们的第二次排名系统中利用这个平滑的特征向量为我们的系统提供了一个探索杠杆，鼓励用户尝试与他们喜欢的美食相似的新美食，同时保持推荐相关性。除了这种探索杠杆之外，这些分组还为我们提供了降低系统成本的机会。通过根据这些菜系分组嵌入菜系偏好功能，我们将该功能的大小缩小了 10 倍，降低了在线存储成本，同时保留了该功能的大部分信号。此外，通过利用轻量级嵌入方案，我们能够通过简单的分布式矩阵乘法有效地执行此特征嵌入，这可以在任何标准 ETL 管道框架中执行。&lt;/p&gt;&lt;p&gt;通过构建一个轻量级的功能集来总结用户在整个 Uber Eats 优食历史中的美食偏好，我们为我们的第二次通过排名模型提供了重要的背景。这种背景为我们的推荐系统提供了探索杠杆，鼓励用户探索新的美食和商家，并确保不常使用 Uber Eats 优食的用户收到相关的餐厅推荐。通过嵌入这些美食偏好功能，我们可以大大降低在线存储成本，并确保推荐系统可以支持针对任何 Uber 用户群的活动。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-re-ranking-amp-blending-nbsp"&gt;重新排名和混合&lt;/h3&gt;&lt;p&gt;由于 CRM 沟通来自不同的内部利益相关者，系统需要一种机制来针对不同的品牌战略和营销优先事项定制嵌入式建议。因此，我们在基于机器学习的第二遍排名后引入了重新排名和混合层。例如，我们允许利益相关者根据特定的营销策略来提高商家的知名度（图4）。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfaBCsP7f9PtQJIas64-wKhFJSRYAN7bn0uOjMvJfrKrAmIK-BN5YuVxqKTy2UWASUp8PwClRpu5GsXceUirADVn2Wpy_I-N3953rek6wl5T1Yxx_pmchFXQFMzWlvSp2EyzPa4ac565MAjz5TaPqNAujEa?key=DgmRI0YIzHZkraGCSk9ZeA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图4：提升精选商户的知名度。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;通过我们的配置引擎，本地营销团队可以以最少的工作灵活地定义自己的策略。这是通过不同地理区域级别的自动分层配置合并和覆盖来实现的。例如，纽约市可以继承美国的大部分重新排名策略，但纽约市本地营销团队可以对特定参数应用一些部分覆盖。图 5 演示了增强图 4 中所选商家的配置。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdJ5NWHGLcrbj4jUtlNt2EQ5D2ZC11o_EJnaOArqzUgVf3-iKqGbyrULBZ5OpxAH_H7OrkQhFrFBn5sNlYOCtq6gW8elbCvzVAPLf7f42NxPVeqDomvf54fiS5myotklOMEPHLi15npddLftZtdb6pGmGrf?key=DgmRI0YIzHZkraGCSk9ZeA" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：通过分层覆盖增强选定商家的配置。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-next-steps"&gt;下一步&lt;/h1&gt;&lt;p&gt;虽然早期的大部分工作都集中在提供商家推荐上，但 Uber 对个性化营销的需求超出了我们的送货业务范围。我们平台的后续步骤是将相同的个性化功能引入其他业务领域，特别是乘客和赚钱者通信。为了更好地服务这些新的业务面，该团队计划扩展我们的个性化内容存储库，并向 Uber 的合作伙伴团队采购。新的发展包括动态创意，以统一个性化推荐和其他营销创意；个性化的旅游推荐；以及个性化的盈利机会来推动市场需求和供应。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="h-acknowledgements"&gt;致谢&lt;/h2&gt;&lt;p&gt;如果没有多个增长和营销团队的贡献，这是不可能实现的。我们要感谢以下人员的贡献：Isabella Huang、Ajit Pawar、Apoorv Sharma、Jennifer Li、Hari Thadakamalla、Cameron Kalegi、Nikhil Anantharaman、Vladimir Schipunov、Denis Perino、Shelley Hatting、April Chu、Nora Murphy、Fernanda戈麦斯、艾比·布莱克、卡罗莱纳·阿普雷亚、玛丽·奥奎特、安·帕登、迈克尔·谭。&lt;/p&gt;&lt;p&gt;特别感谢 LocalGraph 团队（Jiaxin Lin、Kaymyar Arbabifard、Santosh Golecha）、Delivery Intelligence 团队（Yifan Ma、Tiejun Wang）、Michelangelo 团队（Jin Sun、Paarth Chothani、Nicholas Marcott、Victoria Wu）和 Offers 的技术合作伙伴&amp;amp; 可负担性团队（Shirley Ye、Boyang Li、Jun Yao）帮助我们设计系统并利用 Uber 范围内的人工智能构建模块。&lt;/p&gt;</description><pubDate>Thu, 13 Jun 2024 07:02:17 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/personalized-marketing-at-scale/</guid></item><item><title>【Flaky Tests Overhaul at Uber】</title><link>https://www.uber.com/blog/flaky-tests-overhaul/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;几年前，我们开始&lt;a href="https://www.uber.com/en-US/blog/handling-flaky-tests-java/" rel="noreferrer noopener" target="_blank"&gt;解决不稳定的测试&lt;/a&gt;，以稳定我们单一存储库中的 CI 体验。该项目首先在我们的 Java monorepo 中首次亮相，并在减少开发人员工作流程中的摩擦方面取得了良好的成果。然而，随着我们发展 CI 基础设施并开始将其加入我们拥有最多用户的最大存储库&lt;a href="https://www.uber.com/blog/how-we-halved-go-monorepo-ci-build-time/" rel="noreferrer noopener" target="_blank"&gt;Go Monorepo&lt;/a&gt; ，权宜之计的解决方案在扩展到范围方面变得越来越具有挑战性。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-visibility"&gt;&lt;strong&gt;能见度&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;遗留服务有一个内置的分析器，它根据历史测试运行的窗口对测试进行分类。然而，大多数时候它在沙箱中工作，几乎无法了解细节，例如它检查了测试的历史记录、决策背后的原因是什么或有关测试的其他信息。因此，经常有一些测试被错误分类，但我们不知道原因，不得不手动重新分类。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-customization"&gt;&lt;strong&gt;定制化&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;它也几乎没有支持不同策略来对测试进行分类的可扩展性。它仅支持滑动窗口策略对测试进行分类。遗留测试模型是专门为 Java 定制的，假设输入如测试套件、参数、注释等，而这些输入在其他语言中并不总是可用。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-complexity"&gt;&lt;strong&gt;复杂&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;“串行”和“并行”概念在每个 monorepo 的 CI 端添加了额外的逻辑，以做出不同的响应。此外，由于它封装了许多场景——分类、转换、CI 中的恢复、通知等——当它需要足够通用以容纳每个存储库并且足够有效以不错过任何脆弱性时，复杂性会大大增加。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-actionability"&gt;&lt;strong&gt;可操作性&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;当时我们还没有就如何定义跨存储库的所有权达成共识。因此，我们最终在 CI 中忽略了许多不稳定的测试，但没有负责任的跟踪。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-the-big-picture"&gt;大局观&lt;/h2&gt;&lt;p&gt;在 Uber，我们在不同的开发阶段在 CI 管道中运行了大量的测试。通常，我们每天会验证 2,500 多个差异（代码更改，又名拉取请求），并且平均每个差异运行超过 10k 次测试。我们的最终目标是通过&lt;a href="https://www.uber.com/blog/research/keeping-master-green-at-scale/" rel="noreferrer noopener" target="_blank"&gt;保持主分支始终绿色来&lt;/a&gt;确保开发人员对主分支有信心。不稳定的测试破坏了 CI 管道的可靠性，导致开发人员体验混乱——一个错误会变成更多错误。&lt;/p&gt;&lt;p&gt;此外，通过我们的&lt;a href="https://www.uber.com/blog/bypassing-large-diffs-in-submitqueue/" rel="noreferrer noopener" target="_blank"&gt;SubmitQueue 推测&lt;/a&gt;架构，修订失败可能会产生级联效应，使队列中的其他修订无效并导致阻塞。当存在影响整个存储库并触发所有测试的横切更改时，情况会变得更糟，这对于进行代码更改将是一场噩梦。这可能会导致开发人员不断重试他们的构建，直到构建变得绿色，从而浪费工程时间和 CI 资源。&lt;/p&gt;&lt;p&gt;迫切需要开发一个有效的、可扩展的、可配置的系统，该系统可以轻松采用并响应数千个测试的状态变化。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-introducing-testopedia"&gt;睾丸介绍&lt;/h2&gt;&lt;p&gt;我们需要了解在 Uber 中运行的所有测试，以验证用户的更改。这种可见性包括可靠性特征（即，不稳定控制）和性能特征（即，延迟控制）。因此，我们需要一个集中式系统来跟踪所有测试，并为 CI 或任何其他消费者提供足够的背景信息，以便就这些测试做出决策。我们将这些职责分离到一个独立的服务 Testopedia 中。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-design-overview"&gt;设计概述&lt;/h3&gt;&lt;p&gt;Testopedia 位于报告和消费者之间的 CI 基础设施中，如下所示： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfgB7JBfGgSObLdUa7d6nIlquv_YK9ctd5SfEZbKGIsvHozIPyvlh4Tt3vZAQSW5WmiH4xkalc01ZcY_cOTyFHtbFa2gcuyIp-oWqoWRcLQ-5vlSW-rjSFBJyh4u2YqUmd_LItqVcMO_-WekoYw0-sTqTua?key=6gZ2dLlV7xzsqb0CRMkSGA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：示例管道。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-what-it-does"&gt;它能做什么&lt;/h3&gt;&lt;p&gt;我们决定让它与语言/存储库无关，而不是让 Testopedia 处理片状测试的所有方面。这意味着该服务不关心它是什么类型的测试，是测试套件还是测试用例，名称的格式如何，如何报告，如何在 CI 中处理等。它只是在“测试实体， ”，它是系统中的最小基本单元，由“完全限定名称”(FQN) 唯一标识。此外，我们还引入了 FQNs 的分组概念——realm，它封装了特定使用域下的所有测试，例如 Golang 单元测试、Java 单元测试、Docker 集成测试等。 Realms 属于特定平台团队所有，每个团队都可以构建根据自己的喜好进行 FQN。&lt;/p&gt;&lt;p&gt;接下来，在较高的层面上，我们为服务分配了 3 个功能域：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;读&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;检索单个测试的统计信息，包括不稳定状态、可靠性、陈旧性、聚合执行时间、历史运行统计信息和其他元数据（如果有）。&lt;/li&gt;&lt;li&gt;检索一组测试的统计数据，即上述列表。&lt;/li&gt;&lt;li&gt;检索测试的状态更改。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;写&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;将测试运行结果上传至系统。&lt;/li&gt;&lt;li&gt;它可以是文件或流的形式，但需要遵循预定义的模式。&lt;/li&gt;&lt;li&gt;禁用/启用/删除系统中某些测试的管理操作。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;通知&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;每当测试变得不健康时，我们需要触发 JIRA 票证，并将截止日期分配给所属团队。 &lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-how-it-works"&gt;怎么运行的&lt;/h3&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdQvxdjfAvik1VtI7t-b2HiGn1Wk5CeNvZFhe2QBoHN7S_Bsid3wZV-fKRW3SLudKuP0KfcIA4vQDi0zd8txYN95hqLVktKT7tMjp2tcIS5Pg8-XCT_yaM5Vef7MeQm0_Wh8mnXKySoP93kE0Hxm-DKKe4?key=6gZ2dLlV7xzsqb0CRMkSGA" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：Testopedia 架构图。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; Testopedia 通过历史数据来推断测试是否健康。但 Testopedia 并没有专注于定期作业，而是接受所有测试数据源，无论它是来自定期验证作业还是常规验证作业。每份报告都将相应地标有其来源。然后每个分析器都可以访问所有这些信息，并采取不同的策略来响应它们（稍后将详细介绍“分析器”）。&lt;/p&gt;&lt;p&gt;分析器完成对测试的运行分析后，结果将具体化到存储中以供稍后查询，并且根据结果，将按照领域的分组规则将票证提交给测试的所属团队（更多信息请参阅通知）。&lt;/p&gt;&lt;p&gt;请注意，从分析器到票务，每种策略都可以在 Testopedia 核心逻辑之外进行扩展和配置，从而为领域所有者提供最大程度的可定制性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-implementation-highlights"&gt;实施亮点&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-fully-qualified-name-fqn"&gt;&lt;strong&gt;完全限定名称 (FQN)&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt; Testopedia 设计的关键部分是能够使用名为“完全限定名称”或简称 FQN 的唯一字符串标识符来处理我们在 Uber 执行的每个测试。系统只需要专注于FQN的分析和记账，而将处理实现留给各自的平台，而无需了解每个测试框架的任何细节。&lt;/p&gt;&lt;p&gt;所有测试都分为&lt;em&gt;领域&lt;/em&gt;。领域名称以 FQN 字符串开头，代表测试所属的更广泛的域。领域的一个示例是“golang.unit_test”或“android.integration_test”。&lt;/p&gt;&lt;p&gt;作为“Golang 单元测试”领域下有效 FQN 的示例，我们可以将如下所示的字符串放在一起： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdwZlzY61MzQ6qnqQP7nlyAoUcTSIcRFIUVgDPADDe9qg0Z6o2zvD-N2KVItlya7T7SAA7KlAUouQJ0p6gGVIyWmw1wyM5DyfFtIQPggGE8hUtL9za1BNIT9WjvH32gPt4yWoNyBo5tiSs3DLsyXtyBqCM?key=6gZ2dLlV7xzsqb0CRMkSGA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：完全限定名称示例。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;整个 FQN 可以由领域所有者自定义为任何格式。通常根据测试代码所在的文件系统结构来对标识符进行建模。毫不奇怪，FQN 看起来非常像 Internet URL，因为它具有唯一标识资源的类似目的。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-finite-state-machine-fsm-model"&gt;&lt;strong&gt;有限状态机 (FSM) 模型&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;Testopedia 利用强大的有限状态机实现来捕获和记录测试的事务状态。允许测试实体在以下状态之间进行交易：新的、稳定的、不稳定的、禁用的和已删除的。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcXC3fSUSBxx6UimzGX5-eCWvAIxT8GjmpP1o7M-BtFAxVQaTipK4mEkvNUNglokw3lhVe07hG2qNVUy2t5OlVE8FpsrTj2bkmOaF2aj977cXflVwvBBCTFOONK_VLgejYZVyHmY4783oVBCRbyLd1kBNPf?key=6gZ2dLlV7xzsqb0CRMkSGA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：Testopedia 状态机。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;每个状态都可以自定义自己的进入和退出操作。例如，当 FSM 进入不稳定状态时，会触发一个操作来提交 JIRA 票证；当 FSM 进入稳定或已删除状态时，关联的 JIRA 票证将关闭。&lt;/p&gt;&lt;p&gt;坚持 FSM 设计，我们能够节省样板代码，否则我们必须编写和支持这些代码。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-scalability"&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXf_fs9-Fg36HOnQqalDoe134ZcOVaRT4vbMCEdBG1aRd7-OZ8Sff4CP9oRkvptXWULIw2gbhfg4QHiw4R2hBBHXZ_U_Qh6wV4-iKvi9GOofM0jaoKSAxwSJ1FGEl8KWd9u-OP9QyO4N5qudDX_U7EMzxBgJ?key=6gZ2dLlV7xzsqb0CRMkSGA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：通过线程池的数据流示例。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;为了最大限度地提高效率，我们选择使用 gRPC 流来实现导入 API，而不是要求用户上传大块数据。除此之外，我们还实现了线程池来消耗数据流。这不仅允许通过长期连接进行更易于管理的数据传输，而且还通过客户端和服务器端的并行处理确保更好的资源利用率。&lt;/p&gt;&lt;p&gt;此外，我们在设计后端数据库时考虑了可扩展性，通过允许灵活的分区，以便支持更复杂的读取场景（下一节将详细介绍这一点）。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-cone-queries-and-dynamic-partitioning"&gt;&lt;strong&gt;锥体查询和动态分区&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;因为片状测试会受到 CI 的大量查询，所以支持按前缀查询是很自然的要求，例如“golang.unit/src/uber.com/infrastruct/*”，在 Testopedia API 模型中称为&lt;em&gt;锥体查询&lt;/em&gt;。&lt;/p&gt;&lt;p&gt;在非常常见的 Monorepo 设置中，CI 构建作为多个并行作业执行，并按相似的路径前缀划分。因此，每个 CI 作业只对了解特定存储库文件夹下的片状测试感兴趣，而不是全部。&lt;/p&gt;&lt;p&gt;当我们跟踪数百万个测试时，迭代整个数据库来查找前缀匹配的性能并不好。我们自然会想到分片，但是，我们不想只在固定长度的前缀上进行分片，因为锥体查询可以是任意长度，例如“golang.unit/a/b/c/*”、“ golang.unit/a/b/*”、“golang.unit/a/*”等。为了有效地做到这一点，我们实现了一种灵活的分桶算法：&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;写：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;当新的 FQN 到达系统时，请说“golang.unit/a/b/c/d:test”，&lt;/li&gt;&lt;li&gt;首先我们为它随机生成一个整数桶ID，比如说10&lt;/li&gt;&lt;li&gt;然后我们剥离领域并识别前 3 个前缀：&lt;ul&gt;&lt;li&gt; [a/b/c，a/b，a]&lt;/li&gt;&lt;li&gt; （这里的3是深度的可配置值，只是一个例子）&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;接下来，我们通过附加将存储桶 ID 以及所有前缀存储在单独的表中：&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;前缀表&lt;/td&gt;&lt;td&gt;插入之前（其他 FQN 创建的现有存储桶 ID）&lt;/td&gt;&lt;td&gt;插入后&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;a/b/c&lt;/td&gt;&lt;td&gt; []&lt;/td&gt;&lt;td&gt; [ &lt;strong&gt;10&lt;/strong&gt; ]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; a/b&lt;/td&gt;&lt;td&gt; [2]&lt;/td&gt;&lt;td&gt; [2, &lt;strong&gt;10&lt;/strong&gt; ]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; A&lt;/td&gt;&lt;td&gt; [2, 3]&lt;/td&gt;&lt;td&gt; [ &lt;strong&gt;2,3,10&lt;/strong&gt; ]&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class="wp-element-caption"&gt;在上面的示例中，前缀为“a/b”的 FQN 必须位于存储桶 2 或 10 下。&lt;/figcaption&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;ul&gt;&lt;li&gt;最后，我们将存储桶 ID 与 FQN 本身一起存储在按存储桶 ID 分区的单独 FQN 表中&lt;/li&gt;&lt;/ul&gt;&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p&gt;# FQN 表&lt;/p&gt;&lt;p&gt;golang.unit/a/b/c/d:测试，10&lt;/p&gt;&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;不同的存储桶可能可以持久保存到不同的数据库服务器中，从而使设置几乎可以无限扩展&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;读：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;当我们发出锥体查询时，说“golang.unit/a/b/*”&lt;/li&gt;&lt;li&gt;我们首先找到领域“golang.unit”，然后找到前缀“a/b”&lt;/li&gt;&lt;li&gt;然后我们引用分区表并获取所有桶ID [2, 10]&lt;/li&gt;&lt;li&gt;然后我们可以快速查找FQN表中桶ID为2或10的记录；读取应该非常快，因为它是分区键；我们还可以并行执行此类查找&lt;/li&gt;&lt;li&gt;最后，我们迭代选定的记录并过滤那些满足查询要求的记录&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;请注意，我们跟踪存储桶 ID 的路径深度是 config.json 中的预定义值。因此，对于较长的查询，例如“golang.unit/a/b/c/d/e/*”，我们在最大深度“a/b/c”处停止并读取桶ID为10的所有记录。&lt;/p&gt;&lt;p&gt;这样我们就可以显着减少从数据库读取的记录数量。此外，每个领域可以根据其查询模式配置自己的深度和存储桶数量。由于存储桶 ID 是动态生成的，而不是依赖于静态输入，因此它有助于在存储桶之间更均匀地分配数据，而不管它们在存储库中的物理位置如何。&lt;/p&gt;&lt;p&gt;这种设计实现了一个重要的好处：非常传统的关系数据库（例如多分片配置中的 MySQL）可用于为存储后端提供动力并以亚秒级延迟执行复杂的锥形查询。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-data-agnostic-ingestion"&gt;&lt;strong&gt;与数据无关的摄取&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;目前，Uber 为每种主要语言托管了一个 monorepo，每种语言都有自己专用的 CI 管道。我们对 Testopedia 的愿景是创建一个与语言无关的平台，使所有 CI 管道受益。每个语言存储库都拥有一个领域，定义自己的 FQN 格式，并负责启动监视作业，该作业将测试历史数据流发送到 Testopedia。数据必须遵循预定义的通用模式，这是报告者和服务之间的唯一协议。&lt;/p&gt;&lt;p&gt;消费者可以自由决定如何从 Testopedia 进行消费。这种方法有效地将系统逻辑与任何特定于语言的概念（例如 Java 中的测试套件或 Go 中的子测试）解耦，从而确保无论格式如何，都具有适应性。因此，开发人员可以将该服务无缝集成到他们的 CI 基础设施中。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-configurable-analyzers"&gt;&lt;strong&gt;可配置的分析仪&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;Testopedia 中的分析模块也是高度可配置的。它提供了一个通用接口，每个领域的所有者可以使用我们的默认线性分析器或提交根据其特定检测要求定制的自己的实现。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfXR6FbFHBhtN50OQzqS604yTm6dfdZqED0A7D0igC6a4VR9ZS9OTznHMl831T1H7H1T41bE_iKk7-D5Fh5il6LK-gb9COoe8JMdXRsU4hvxQj7UzLcG92tC33Pv0YY6TXcG7pQpmOV3Y3KUt16oHb1_5Ns?key=6gZ2dLlV7xzsqb0CRMkSGA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：分析仪界面。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;此外，用户可以重用任何分析器实现，并根据结果、回溯窗口、阈值、状态模式定义规则，以有效地识别特定于其自己领域的片状测试（下一节将详细介绍这一点）。&lt;/p&gt;&lt;p&gt;这种定制在最大限度地减少误报和捕获真正的片状测试之间取得了适当的平衡。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-configurable-ticketing-system-and-storage"&gt;&lt;strong&gt;可配置的票务系统和存储&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;我们还对该系统进行了模块化，以适应 Uber 不断发展的基础设施。这样用户就可以连接其他 Scrum 解决方案，例如 JIRA、Phabricator 以及用于存储测试和历史记录的各种 DB 解决方案。有关此内容的更多信息，请参阅“管理不稳定测试”部分。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-visibility-and-usage"&gt;&lt;strong&gt;可见性和使用情况&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;Testopedia 的主要功能之一是它能够提供测试历史记录的全面可见性。每个状态转换以及相关的作业和元数据都会被记录下来，为测试所有者创建透明的审计跟踪，以便调试和调查异常发生的时间和地点、错误是什么、错误的频率、提交的时间等。此外，我们还在其之上构建了 CLI 和 Web UI，以便每个人都可以轻松检查他们的测试。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-analyzing-flaky-tests"&gt;分析片状测试&lt;/h2&gt;&lt;p&gt;在识别单一存储库设置中的脆弱性时，我们希望足够准确，以便我们及时捕获它们，从而防止它们的爆炸半径扩展到其他工程师的工作流程，并且足够宽容，以便我们不会忽略它们，并且仍然有足够的覆盖范围在我们的代码中进行保护。&lt;/p&gt;&lt;p&gt;在 Go Monorepo 中，我们使用有限的资源定期执行主分支下的所有测试。通过这种方式，我们可以在资源密集型测试中暴露出更多的脆弱性。然后我们将结果按原样发送到 Testopedia，后者通过线性分析器运行它们，根据它们的历史确定测试的状态。&lt;/p&gt;&lt;p&gt;如果测试在运行的最后一个 X 窗口中失败一次，则将其归类为不稳定。另一方面，由于机器上的资源被故意损害，某些测试可能会更频繁地超时，但这不是他们的错。在这种情况下，分析器还为每个测试授予超时阈值 M。要将测试分类为稳定，测试必须连续通过 N 次。我们还认识到，测试可能会因错误而持续失败，并相应地对其进行标记，因此稍后将通知用户此更改。&lt;/p&gt;&lt;p&gt;此外，我们还发送来自常规登陆 CI 管道的结果数据。因为我们在那里有重试逻辑，如果测试第一次失败但通过了相同的重试，我们就知道这个测试是不稳定的。我们对导入流进行不同的标记，并使分析器 Testopedia 能够感知，因此它们不会相互干扰。&lt;/p&gt;&lt;p&gt;有了上述所有内容，我们将有一个如下所示的配置： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXeMCzGfKOmguHaw5yyslTacjboR8yIY7TytrD8OqSdyd4Q44BVTCPSWFg9HTJ4oTmCDsxBwr5aq_QVf3rMci0ZsIfv87RJh4fzZKT-b1wIRmhXWEp99gwMoroFjGaMonto9_TVxoY99CN6Dz1-5wPpMjKc?key=6gZ2dLlV7xzsqb0CRMkSGA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：分析仪配置。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;如上所述，分析器的所有这些行为都是高度可扩展的。例如，集成测试可能更容易出现超时和不稳定的情况。标准线性分析仪不太合适。在这种情况下，将为它们实施不同的基于百分比的分析器。如果最后 N 次运行中的失败百分比超过特定阈值，它将测试归类为片状测试。其他分析器也可以轻松插入。这些分析器可能包括设计用于检查特定错误消息的分析器、对超时敏感的分析器或优先检测故障趋势的分析器等。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-managing-flaky-tests-nbsp"&gt;管理不稳定的测试&lt;/h2&gt;&lt;p&gt;发现这些不稳定的测试后，我们需要对其进行处理并通知所属团队。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-treating-flaky-tests"&gt;处理不稳定的测试&lt;/h3&gt;&lt;p&gt;在 Monorepo 设置中，影响许多库及其测试的大型差异可能非常具有挑战性，而且当它们的测试不稳定时，情况会更糟。不是由差异本身引起的一种片状故障可能会导致整个作业的完全重建。&lt;/p&gt;&lt;p&gt;我们的一般指导是避免在 CI 中运行不稳定的测试。然而，当工程师尝试修复不稳定的测试并提交差异时，问题很快就会出现。如果它在 CI 中仍然被忽略，那么我们不知道该修复是否有效。或者更糟糕的是，它可能完全破坏了测试，但因为 CI 不验证它，所以我们永远不知道它被破坏了。&lt;/p&gt;&lt;p&gt;因此，我们围绕此实施了多种策略：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;无论是否不稳定，都会在 CI 作业上运行专门标记为“关键”的测试&lt;/li&gt;&lt;li&gt;工程师可以在差异中专门添加标签或关键字来选择退出该行为&lt;/li&gt;&lt;li&gt;其他片状测试（例如集成测试）以非阻塞模式运行，仅供参考&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-reducing-impact-of-flaky-tests"&gt;减少不稳定测试的影响&lt;/h3&gt;&lt;p&gt;在 CI 阶段跳过不稳定测试的策略由每个领域所有者实施。例如，Golang 和 Java 可能具有非常不同的测试运行器模式，因此使用不同的测试过滤器机制。&lt;/p&gt;&lt;p&gt;例如，在 Go Monorepo 中，我们有不同的方法来跳过测试用例和测试目标。为了跳过测试目标，我们排除直接在 CI 中运行片状测试目标，但仍然确保目标是可构建的。如果目标仅包含某些片状测试用例而其他测试用例仍然有用怎么办？我们在&lt;a href="https://github.com/bazelbuild/rules_go/blob/master/docs/go/core/rules.md#go_test"&gt;rules_go&lt;/a&gt;中实现了一个功能，通过&lt;a href="https://tip.golang.org/doc/go1.20#go-command"&gt;Go 1.20 -skip&lt;/a&gt;测试标志并解析&lt;a href="https://github.com/bazelbuild/rules_go/pull/3618"&gt;TESTBRIDGET_TEST_ONLY&lt;/a&gt;环境变量来跳过测试用例。这样，有关片状测试的信息与 Bazel 规则的输入隔离，并且无论片状情况如何，测试缓存都可以保持稳定。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-accountability"&gt;问责制&lt;/h3&gt;&lt;p&gt;现在我们发现了一些不稳定的测试并在 CI 中采取了相应的行动。下一步是什么？&lt;/p&gt;&lt;p&gt;我们需要将这些发现通知测试作者，并鼓励他们尽快修复测试。我们可以通过立即调用 JIRA、Slack 等票务模块来做到这一点。然而，在 Uber，即使是最小的领域也有数千次测试，显然我们无法承受等待外部系统的延迟和成本。为每一个人做出回应或提交票据。因此，我们在 Testopedia 中设计了一个异步系统，可以根据分组规则提交票证。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXefNJ-bMu_P-R7GsX8K7fqdWfWwcOMx8HDY1RZom-bf92pEGA9FSKufI5KEuoPsq6ZCnLR_pokvWi8i45Vg9q9Ta9fS8plpLT_mNbXDlq4O7uXQP7SqdwYuD-hmK4tItY_XEc73ucAql6xJIoxwjncBwLNl?key=6gZ2dLlV7xzsqb0CRMkSGA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：票据归档图。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;当分析器确定测试不健康时，除了在数据库中更新之外，还会将其插入消息队列中。然后，节奏工作流程会触发队列，再次检查这些测试，并调用 JIRA 向所属团队提交票据。 Bazel 测试目标可以有多个测试用例，我们将每个测试用例作为 FQN 进行跟踪，但我们只想为每组类似测试提交一张票以减少噪音。因此，我们提出了一个分组概念，通过构建目标或正则表达式将所有不健康的 FQN 放入每个组的一张票据中。&lt;/p&gt;&lt;p&gt;我们还对整个模块进行了可定制，用户可以自定义分组规则、工单类型、优先级，甚至工单描述模板。典型的任务配置如下所示： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcOx9cAS4GShBGqQ2zpaS0C0nOYLfRj6oITaJzZS1zphl94Xa8Yh_F3CgcWaiiCgVe5PmdjrwZdkjG-XhDHvqzymBqPDBp6oPS1bm7dtuNKJje1tSzcv_e-JttdXGfhtrTimkxGKj-nP3mbUNjavDYVeSAB?key=6gZ2dLlV7xzsqb0CRMkSGA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：票据归档配置。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;这样，团队将拥有不同的测试结构，并根据用户体验定义自己的通知策略。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-future-plans"&gt;未来的计划&lt;/h2&gt;&lt;p&gt;Uber 正在积极&lt;a href="https://www.uber.com/blog/generative-ai-for-high-quality-mobile-testing/" rel="noreferrer noopener" target="_blank"&gt;开发各种法学硕士&lt;/a&gt;，以改善我们的开发者体验。我们设想未来将这些尖端技术融入到系统中：&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-integrate-genai-for-automated-flaky-tests-resolution"&gt;&lt;strong&gt;集成 GenAI 以实现自动化片状测试解决方案&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;导入和分析 FQN 并访问其所有历史数据和其他测试失败模式后，我们可以使用 GenAI 自动生成该测试的修复程序。我们正在探索 Uber 内部构建的 GenAI 集成，以帮助集中减少 Monorepos 中不健全测试的数量，而测试所有者的投入最少。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-more-granular-failure-categorization-and-sub-categorization"&gt;&lt;strong&gt;更细粒度的故障分类和子分类&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;当前的 FSM 模型提供了通用的分类桶，但是，并非所有测试失败都是相同的。子分类是在领域级别明确完成的。通过利用人工智能分析故障模式，我们可以根据错误日志和类型、测试环境或故障代码上下文等因素自动将测试故障分类为更具体的子组。这种增强的分类系统将使我们能够更有效地进行故障排除和解决。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;现在，Uber 的所有主要 Monorepos 都已加入 Testopedia，并且随着内部算法和基础设施组件的大量优化，它比以往任何时候都更加稳定。在 Go Monorepo 中，我们在总共 600K 测试中稳定地检测到大约 1000 个片状测试，其中 Java 测试中有 1K/350K。我们还观察到 CI 可靠性显着提高，重试次数大幅减少。使用包含正确信息的 Jira 票据来烦扰开发人员，极大地帮助扭转了不稳定测试数量不断增加的趋势。&lt;/p&gt;</description><pubDate>Tue, 04 Jun 2024 07:25:02 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/flaky-tests-overhaul/</guid></item><item><title>【Modernizing Uber’s Batch Data Infrastructure with Google Cloud Platform】</title><link>https://www.uber.com/blog/modernizing-ubers-data-infrastructure-with-gcp/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;Uber 运行着世界上最大的 Hadoop 安装之一。我们的&lt;a href="https://www.uber.com/blog/uber-big-data-platform/" rel="noreferrer noopener" target="_blank"&gt;Hadoop 生态系统&lt;/a&gt;在两个区域的数万台服务器上托管着超过 1EB 的数据。开源数据生态系统，包括之前&lt;a href="https://www.uber.com/blog/engineering/data/" rel="noreferrer noopener" target="_blank"&gt;工程博客&lt;/a&gt;中讨论的Hadoop生态系统，一直是我们数据平台的核心。&lt;/p&gt;&lt;p&gt;在过去的几个月里，我们一直在评估我们的平台和基础设施需求，以确保我们能够很好地实现大数据基础设施的现代化，以满足 Uber 不断增长的需求。&lt;/p&gt;&lt;p&gt;今天，我们很高兴地宣布，我们正在与 Google Cloud Platform (GCP) 合作，将批量数据分析和机器学习训练堆栈迁移到 GCP。&lt;/p&gt;&lt;p&gt; Uber 数据平台的使命是通过直观、可靠且高效的数据产品，使数据驱动的业务决策民主化。利用 GCP 实现现代化将大大提高用户工作效率、工程速度、提高成本效率、获得新创新并扩展数据治理。&lt;/p&gt;&lt;h1 class="wp-block-heading" id="h-strategy"&gt;战略&lt;/h1&gt;&lt;p&gt;我们最初迁移到 GCP 的策略是利用云的对象存储作为数据湖存储，同时将其余数据堆栈迁移到云 IaaS（基础设施即服务）。这种方法有助于实现快速迁移路径，同时最大限度地减少对现有作业和管道的干扰，因为我们可以在 IaaS 上复制本地软件堆栈、引擎和安全模型的精确版本。我们计划在最初迁移到 GCP 后采用适用的 PaaS（平台即服务）产品，例如 GCP Dataproc 或 BigQuery，以充分利用云原生服务提供的弹性和性能优势。我们的计划是在接下来的几个季度执行这一战略，通过一系列博客文章（这是第一篇）记录我们的进展并分享我们的经验教训。因此，请将此博客添加为书签并继续关注！ &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/Wx5iHeuUr_MaCochwvxq39y6wvy3aP3z8euxLBVPwOIujVTJ7GPvI8jyKFH4-JhfSps-0dQeWb9PJ7-fMn2Qgs1LXnmnOfxg8XeodrfTcnrrj8S8OZLEx_taJfS1JTrJ0c2_MZ27nPTq_6JfxFk6BWc" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/vJcumVtF5yY4yqe5-7chOwkB6uyypCxfeuj9YVNhO3Xyi3YBjdig7sYRDC4RAU5IUh9XWbcWH-1D8KJs9ilaWkwsOAPKKmsbpV23AR5mxSGPRYXbSlREjembU5CMm4FLq_1RYHvloRng1Jz7xADjq6E" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-migration-principles"&gt;迁移原则&lt;/h2&gt;&lt;p&gt;以下是我们在这次艰巨的迁移中牢记的核心原则：&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-avoid-painful-migrations-for-data-users"&gt;避免数据用户痛苦的迁移&lt;/h3&gt;&lt;p&gt;通过将大部分批处理数据堆栈按原样转移到云 IaaS 上，我们希望保护仪表板所有者、管道作者、机器学习从业者等用户免于对其工件或服务进行任何更改。我们将利用众所周知的抽象和开放标准，使迁移对数据用户尽可能透明。&lt;/p&gt;&lt;p&gt;我们将严重依赖云存储连接器，该连接器实现 Google Cloud Storage 的 Hadoop 文件系统接口，提供 HDFS 兼容性。我们将利用&lt;a href="https://parquet.apache.org/" rel="noreferrer noopener" target="_blank"&gt;Apache Parquet&lt;/a&gt; ™ 文件格式、 &lt;a href="https://hudi.apache.org/" rel="noreferrer noopener" target="_blank"&gt;Apache Hudi&lt;/a&gt; ™ 表格式、 &lt;a href="https://spark.apache.org/"&gt;Apache Spark&lt;/a&gt; ™、 &lt;a href="https://prestodb.io/" rel="noreferrer noopener" target="_blank"&gt;Presto 的&lt;/a&gt;SQL 方言、 &lt;a href="https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html" rel="noreferrer noopener" target="_blank"&gt;Apache Hadoop YARN&lt;/a&gt; ™ 和&lt;a href="https://kubernetes.io/" rel="noreferrer noopener" target="_blank"&gt;K8s&lt;/a&gt;等开放标准，最大限度地减少数据平台组织内团队的迁移挑战。我们将标准化我们的&lt;a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" rel="noreferrer noopener" target="_blank"&gt;Apache Hadoop HDFS&lt;/a&gt; ™ 客户端，以抽象本地 HDFS 实施细节。因此，现在访问本地 HDFS 的所有服务都将与基于 GCP 托管的对象存储的存储层无缝集成，无需任何更改。标准化 HDFS 客户端将被修改为通过“路径转换服务”将 HDFS 路径转换为基于对象存储的路径。我们将在未来的博客文章中分享更多相关细节。 &lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-enhance-data-access-proxies-to-federate-traffic-across-on-prem-or-cloud"&gt;增强数据访问代理以联合本地或云端的流量&lt;/h3&gt;&lt;p&gt;我们开发了数据访问代理（适用于&lt;a href="https://www.uber.com/blog/presto/" rel="noreferrer noopener" target="_blank"&gt;Presto&lt;/a&gt; 、 &lt;a href="https://www.uber.com/blog/uscs-apache-spark/" rel="noreferrer noopener" target="_blank"&gt;Spark&lt;/a&gt;和 Hive），可以抽象出底层物理计算集群的详细信息。在测试阶段，这些代理将支持选择性地将测试流量路由到相应的基于云的 Presto 或 YARN（适用于 Spark 和 Hive）集群。在完全迁移期间，提交给这些代理的所有查询或作业都将路由到基于云的堆栈。 &lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-leverage-uber-s-existing-cloud-agnostic-container-and-deployment-infrastructure"&gt;利用 Uber 现有的与云无关的容器和部署基础设施&lt;/h3&gt;&lt;p&gt;批量数据堆栈位于 Uber 的基础设施构建块之上，例如 Uber 的&lt;a href="https://www.uber.com/blog/hadoop-container-blog/" rel="noreferrer noopener" target="_blank"&gt;容器环境&lt;/a&gt;、计算平台和部署工具，这些工具的构建&lt;a href="https://www.uber.com/blog/crane-ubers-next-gen-infrastructure-stack/" rel="noreferrer noopener" target="_blank"&gt;与云和本地之间无关&lt;/a&gt;。这些平台使我们能够轻松地将批量数据生态系统微服务扩展到云IaaS上。 &lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-forecast-potential-data-governance-issues-from-cloud-services"&gt;预测云服务中潜在的数据治理问题&lt;/h3&gt;&lt;p&gt;作为一个平台团队，我们将构建和增强现有的数据管理服务，以仅支持云供应商产品组合中选定和批准的数据服务，以避免未来数据治理的复杂性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-major-workstreams"&gt;主要工作流程&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-bucket-mapping-and-cloud-resources-layout"&gt;桶映射与云资源布局&lt;/h3&gt;&lt;p&gt;在迁移数据时，我们需要将源集群中的HDFS文件和目录映射到驻留在一个或多个存储桶中的云对象。我们还需要在不同的粒度级别（例如存储桶、前缀或对象级别）应用 IAM 策略。对存储桶和对象的常见约束包括每个组织的存储桶数量、存储桶的读/写吞吐量、IOPS 限制以及 ACL 数量（可通过存储桶策略应用）。&lt;/p&gt;&lt;p&gt;该工作流的目标是制定满足这些约束的映射算法并创建相应的云存储桶。我们还计划结合&lt;a href="https://martinfowler.com/articles/data-mesh-principles.html" rel="noreferrer noopener" target="_blank"&gt;数据网格原则，&lt;/a&gt;以以组织为中心的分层方式组织这些数据资源，从而实现更好的数据管理和管理。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-security-integration"&gt;安全集成&lt;/h3&gt;&lt;p&gt;我们现有的基于 Kerberos 的令牌和 Hadoop 委托令牌将无法直接与云 PaaS（特别是 GCS 对象存储）配合使用。云提供商通常没有现成的 PaaS 解决方案来实现此类互操作性。&lt;/p&gt;&lt;p&gt;此工作流的目标是为所有用户、组和服务帐户提供无缝支持，以便继续根据对象存储数据湖和任何其他云 PaaS 进行&lt;a href="https://www.uber.com/blog/scaling-adoption-of-kerberos-at-uber/" rel="noreferrer noopener" target="_blank"&gt;身份验证&lt;/a&gt;。从此以后还要保持与本地相同的授权访问级别。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-data-replication"&gt;数据复制&lt;/h3&gt;&lt;p&gt;HiveSync 是 Uber 构建的权限感知、双向数据复制服务（基于&lt;a href="https://github.com/airbnb/reair" rel="noreferrer noopener" target="_blank"&gt;ReAir&lt;/a&gt; / &lt;a href="https://hadoop.apache.org/docs/stable/hadoop-distcp/DistCp.html" rel="noreferrer noopener" target="_blank"&gt;distcp&lt;/a&gt; ）。 HiveSync 允许我们以主动-主动模式运行，并具有批量和增量复制功能，使两个区域的数据湖保持同步。&lt;/p&gt;&lt;p&gt;该工作流的目标是扩展 HiveSync 的功能和 Hudi 库功能，以将本地数据湖的数据复制到基于云的数据湖和相应的 Hive Metastore。这包括一次性引导（批量迁移），然后持续增量更新，直到基于云的堆栈成为主要堆栈。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-yarn-and-presto-clusters"&gt; YARN 和 Presto 集群&lt;/h3&gt;&lt;p&gt;我们将从 GCP 在 IaaS 上配置新的 YARN 和 Presto 集群。然后，将查询和作业流量联合到这些集群的现有数据访问代理将通过迁移将流量路由到基于云的堆栈。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-challenges-and-initiatives"&gt;挑战与举措&lt;/h2&gt;&lt;p&gt;这次迁移是一项艰巨的任务，我们意识到我们面临的典型挑战&lt;/p&gt;&lt;p&gt;可能会面临。以下是我们预计将面临的一些大类挑战以及应对这些挑战的缓解措施和举措：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;性能&lt;/strong&gt;：对象存储和 HDFS 之间的功能和性能特征存在一些众所周知的差异。 （例如，原子重命名、文件列表性能等）。我们将利用开源的 Hadoop 连接器并帮助它们发展以最大限度地提高性能。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;使用治理&lt;/strong&gt;：如果我们不&lt;a href="https://www.uber.com/blog/cost-efficient-big-data-platform/" rel="noreferrer noopener" target="_blank"&gt;有效&lt;/a&gt;、主动地管理云相关的使用成本，它们可能会失控。我们将利用云的弹性来抵消这些成本。我们还将与内部容量工程团队合作，建立更精细的归因机制和跟踪。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;应用程序&lt;/strong&gt;&lt;strong&gt;对 HDFS 的非分析/ML 特定使用&lt;/strong&gt;：多年来，团队也开始使用 HDFS 作为通用文件存储。我们将主动将这些用例迁移到其他内部 Blob 存储，同时提供透明的迁移路径以避免中断。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;未知的未知&lt;/strong&gt;：最后，凭借大约 7 年历史的本地堆栈，我们肯定会面临意想不到的挑战。我们希望主动发现早期端到端集成的问题，与客户一起完善提议的抽象，积极弃用遗留用例而不是继续推进它们等等，以领先于这些挑战。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;请继续关注我们的旅程，我们将分享我们的详细设计、执行进度以及一路上学到的经验教训！&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Apache &lt;sup&gt;®&lt;/sup&gt; 、Apache Parquet™、Apache Hudi™、Apache Spark™、 &lt;em&gt;Apache Hadoop YARN™&lt;/em&gt;是&lt;/em&gt;&lt;a href="http://www.apache.org/" rel="noreferrer noopener" target="_blank"&gt;&lt;em&gt;Apache Software Foundation&lt;/em&gt;&lt;/a&gt;&lt;em&gt;在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/em&gt;&lt;/p&gt;&lt;p class="has-small-font-size"&gt;封面照片归属： &lt;a href="https://www.flickr.com/photos/55856449@N04" rel="noreferrer noopener" target="_blank"&gt;Infomastern&lt;/a&gt;的“ &lt;a href="https://www.flickr.com/photos/55856449@N04/17510835551" rel="noreferrer noopener" target="_blank"&gt;乡村道路和黄色田野&lt;/a&gt;”已获得&lt;a href="https://creativecommons.org/licenses/by-sa/2.0/?ref=openverse" rel="noreferrer noopener" target="_blank"&gt;CC BY-SA 2.0&lt;/a&gt;许可。&lt;/p&gt;</description><pubDate>Thu, 30 May 2024 07:21:12 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/modernizing-ubers-data-infrastructure-with-gcp/</guid></item><item><title>【Uber Becomes Kotlin™ Foundation Silver Member】</title><link>https://www.uber.com/blog/kotlin-foundation-member/</link><description>&lt;p&gt;我们很高兴地宣布，Uber 已作为银牌会员加入 Kotlin &lt;sup&gt;™&lt;/sup&gt;基金会。&lt;/p&gt;&lt;p&gt; Uber 对 Kotlin 的承诺在我们的代码库中显而易见。我们正在积极为 Kotlin 生态系统做出贡献，包括开发 Kotlin 与 Buck、Bazel 和 Gradle 等构建系统的集成。 Uber 还为 Detekt 的开发做出了贡献，并发起了其编译器插件版本的创建。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;blockquote class="wp-block-quote has-000000-color has-white-background-color has-text-color has-background has-link-color wp-elements-267bc928adce8748455de4dd6b36c501 is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p class="has-000000-color has-text-color has-link-color wp-elements-529663472951b895d728ed42ff0c690e"&gt; “我们很高兴加入 Kotlin 基金会，这突显了我们对 Kotlin 社区的承诺，以及我们对 Kotlin 作为帮助 Uber 成功的技术堆栈核心部分的信念。我们每天有数百万行 Kotlin 代码和数百名热情的开发人员使用它进行编写。作为从 2018 年开始的早期采用者和积极的贡献者，我们很自豪能够帮助成熟生态系统，并期待与这个充满活力、友好和创新的社区继续合作。”&lt;/p&gt; &lt;cite&gt;Ty Smith，Uber 首席工程师&lt;/cite&gt;&lt;/blockquote&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;除了为 Kotlin 做出贡献之外，Uber 还帮助建立了企业 Java 到 Kotlin 工作组，这是 Meta、Google、JetBrains 和 Uber 之间的合作，目标是为公司提供将大型遗留 Java 代码库迁移到 Kotlin 所需的工具和专业知识。 。&lt;/p&gt;&lt;p&gt;作为银牌会员，Uber 将在支持基金会的举措方面发挥至关重要的作用，包括针对开源库作者的资助计划和针对学生的 Kotlin 多平台竞赛。我们很高兴能与 Kotlin 基金会在未来的项目上进行合作。&lt;/p&gt;&lt;p&gt;访问 Kotlin 基金会&lt;a href="http://kotlinfoundation.org/" rel="noreferrer noopener" target="_blank"&gt;网站，&lt;/a&gt;详细了解为支持基金会使命而开展的重要工作。&lt;/p&gt;</description><pubDate>Wed, 22 May 2024 18:37:07 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/kotlin-foundation-member/</guid></item><item><title>【How Uber Accomplishes Job Counting At Scale】</title><link>https://www.uber.com/blog/job-counting-at-scale/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;Uber 运营规模庞大，每个季度为超过 22 亿次出行提供便利。即使是简单的见解也需要规模化的解决方案。在我们的例子中，我们需要计算某人在 Uber 平台上、任意时间窗口内参与的作业数量。本文重点介绍我们将 Apache Pinot™ 集成到我们的解决方案中时面临的挑战和吸取的经验教训。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="h-background-nbsp"&gt;背景&lt;/h2&gt;&lt;p&gt;具体来说，我们的解决方案需要解决：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;职位数量的几种排列，按角色、市场和完整性轴细分&lt;/li&gt;&lt;li&gt;给定行程或给定时间戳的时间点任期（即，按时间顺序，工作 X 位于人员 A 的工作历史记录中的什么位置？）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们之前的解决方案很简单：检索页面大小限制为 50 的给定主题的职位，并对结果进行分页，直到没有更多职位为止。在 Uber 成立之初，由于没有任何一个账户能够获得相对较多的任期，因此这种做法运作良好。然而，Uber 涉足新的垂直领域，一些账户开始出现数以万计的任期，很明显，我们需要一个更强大的解决方案。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-trip-specific-tenures-are-a-narrow-use-case"&gt;特定旅行的任期是一个狭窄的用例&lt;/h3&gt;&lt;p&gt;主要的产品要求是该解决方案必须能够计算任期回顾。这本身是站得住脚的，但伴随着我们的数据保留政策，我们的下游团队认为这是不合理的。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-access-rescission-of-data-older-than-2-years"&gt; 2年以上数据的访问撤销&lt;/h3&gt;&lt;p&gt;出于节省成本的考虑，同一团队确定将超过 2 年的数据隔离到更高延迟的存储层中。然而，项目中期计划的改变导致他们完全放弃了对这些数据的在线访问。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-reduced-complexity"&gt;降低复杂性&lt;/h3&gt;&lt;p&gt;我们当时的解决方案需要为 Uber 的每个市场拼接三个数据源：乘车和外卖。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-similar-use-cases-in-the-broader-team"&gt;更广泛的团队中的类似用例&lt;/h3&gt;&lt;p&gt;在向更广泛的团队展示我们的设计后，我们立即发现 Uber 的各个团队都有类似需求的相邻项目，每个团队都重新实现了自己的解决方案来独立计算工作任期。&lt;/p&gt;&lt;p&gt;考虑到这些限制，我们考虑了几种架构。我们认真考虑过的一个方案是由 Apache Hive™ 和 Docstore（Uber 的内部分布式数据库）支持，最终采用了一种利用 Apache Pinot™ 的解决方案。这里的一个有趣的功能是混合表，它提供了一个将实时和离线数据缝合在一起的无缝界面。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-architecture"&gt;建筑学&lt;/h2&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large is-resized"&gt;&lt;img alt="" class="wp-image-1089197" height="2850" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/05/figure1-1.png" style="width: 700px; height: auto;" width="3617" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：用户权属存储架构图。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-development-challenges"&gt;发展挑战&lt;/h2&gt;&lt;p&gt;Apache Pinot™ 是一款极其强大的产品，为我们的架构提供了无与伦比的灵活性。然而，我们在此过程中遇到了一些障碍，下面，我们详细介绍了这些挑战以及我们对这些问题的解决方案，可能会对读者有所启发。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-challenge-1a-capacity-planning"&gt;&lt;strong&gt;挑战 #1a – 容量规划&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;我们的第一个挑战是制定容量要求，为我们的专用租户提供所需的硬件。 Apache Pinot™ 利用压缩技术，因此很难预先测量磁盘空间。在这里，我们选择采用 10% 的样本数据集，并且根据样本占用的空间来预测磁盘使用情况在我们的案例中就足够了。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-challenge-1b-query-performance"&gt;&lt;strong&gt;挑战 #1b – 查询性能&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;这里一个有趣的旁注是，虽然我们能够通过采样来估计磁盘上的数据集大小，但我们无法准确预测查询性能。在这种情况下，我们必须等到扩大整个数据集之后才能获取关键指标，例如 p99 读取时间、磁盘读取吞吐量等。一旦我们能够这样做，生产规模的流量就会带来我们的专用集群崩溃了，读取时间超过了代理限制 10 秒，SSD 上的读取吞吐量达到最大，CPU 使用率也达到了极限。我们立即着手研究优化，这并不意外，因为每个查询都相当于加载全表扫描。&lt;/p&gt;&lt;p&gt;作为参考，我们的查询具有以下形状：&lt;/p&gt;&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p&gt;&lt;em&gt;选择&lt;/em&gt;&lt;em&gt;&lt;br /&gt;&lt;/em&gt;&lt;em&gt;*&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;从&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;皮诺混合表&lt;br /&gt;其中provider_id = &amp;#39;...&amp;#39;&lt;br /&gt; AND requester_id = &amp;#39;...&amp;#39;&lt;br /&gt; AND 时间戳 &amp;gt;= ... AND 时间戳 &amp;lt;= ...&lt;/em&gt; &lt;/p&gt;&lt;/blockquote&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/mziEvOUPidZxsIp2eyVVTr3vJyvJpPwk-syVG52f6ZIVB6DZIeIxsNlTGW2RzcUFBCJGmw2vJgCNOtBoXggHKwQFIvyv-QvjxLO4oNCyLnrbdD7Sr6ybJfltL3xspF4eZEHrXs-297Y3Mzm-IlR8YHE" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：由于代理超时导致 Apache Pinot™ 查询失败。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;这关系到团队，我们采取了多项措施来提高绩效，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;已排序的&lt;em&gt;provider_id&lt;/em&gt;列&lt;/strong&gt;&lt;br /&gt;这会将同一提供商在同一天进行的所有行程并置，从而最大限度地减少每个查询访问的路段。&lt;br /&gt;如果没有这一点，供应商在某一天完成的所有工作将平均分配给该天的所有部门。因此，如果提供者在同一天执行了多个作业，为了让代理完成我们的读取查询，它将很快收敛到检索提供者每天完成一项工作的所有段。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;在&lt;em&gt;provider_id&lt;/em&gt;和&lt;em&gt;requester_id&lt;/em&gt;上添加倒排索引&lt;br /&gt;&lt;/strong&gt;我们还在&lt;em&gt;provider_id&lt;/em&gt;和&lt;em&gt;requester_id&lt;/em&gt;列上启用了倒排索引。与排序列相结合，这在&lt;em&gt;provider_id&lt;/em&gt;列上提供了排序倒排索引。这允许&lt;em&gt;log(n)&lt;/em&gt;的查找时间复杂度，因为它执行二分搜索来查找与给定的&lt;em&gt;provider_id&lt;/em&gt;值对应的行。&lt;br /&gt;&lt;br /&gt;一个令我们措手不及的令人惊讶的事实是，这些倒排索引是&lt;em&gt;为每个细分市场&lt;/em&gt;创建的。这是与传统 RDBMS 索引之间非常显着的区别。该索引不是所有段共享的全局结构，直接指向正在查询的数据。在我们的例子中，代理仍然必须对表中每个段的一部分进行内存映射才能使用索引。如果不实施额外的段修剪技术，这是非常低效的，我们很快就实施了。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;在&lt;em&gt;provider_id&lt;/em&gt;和&lt;em&gt;requester_id&lt;/em&gt;上添加布隆过滤器&lt;/strong&gt;&lt;br /&gt;布隆过滤器是一种概率数据结构，测试一个元素是否是集合的成员，给出两个答案：可能在集合中，或不在集合中。当为列启用时，Apache Pinot™ 为每个段创建一个布隆过滤器，并允许代理在完成查询时完全跳过段。如果段上的列存在布隆过滤器，并且查询中存在该列的相等谓词，则代理能够快速确定该记录是否存在于段中。由于我们的数据集并不完全适合内存，因此我们选择了 MMAP（内存映射）堆外配置，其中段被延迟加载到内存中，如果操作系统物理内存不足，则先前加载的段将被取消映射（就像我们的例子一样）。然而，该段的关联布隆过滤器可以存储在堆上（内存中），并且将保留在那里，即使它们的底层段不再位于物理内存中。&lt;br /&gt;&lt;br /&gt;观察到的加速应该与跳过的段数相关，因此它有利于读取模式不需要获取大部分段的数据集（例如全表扫描）。&lt;br /&gt;&lt;br /&gt;请参见图 3 和图 4，其中可以观察到启用 Bloom 过滤器后 ( &lt;em&gt;numSegmentsQueried&lt;/em&gt; – &lt;em&gt;numSegmentsProcessed)&lt;/em&gt;显着下降。&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;每天增加的路段&lt;/strong&gt;&lt;br /&gt;为了创建 Apache Pinot™ 段，我们安排每天运行一个 Apache Spark™ 作业，创建并上传组成离线表的新段。每个计划间隔创建的分段数量是可调的，我们最初每天创建四个分段。然而，随着段开始变得非常大（每个段超过 4GB），我们逐渐将其增加到 8 个，然后是 16 个，最后达到每天 32 个段。&lt;br /&gt;&lt;br /&gt;这里所做的权衡是，虽然增加的段数可能会导致 Zookeeper 元数据存储上的负载增加，并增加 Apache Pinot™ 服务器的内存堆使用量，但较小的段大小会导致更快地从磁盘上读取段，并且相应地会增加磁盘上的数据。要包含在结果中的段。根据经验，我们观察到 p99 读取延迟显着减少，并且代理 CPU 使用率增加不明显。&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;向我们的上游消费者添加了跨数据中心缓存&lt;/strong&gt;&lt;br /&gt;虽然不是特定于 Apache Pinot™，但我们的主要上游消费者在临时环境和生产环境之间执行相同的查询。虽然我们期望查询之间的时间延迟最小，但我们认为 30 分钟的陈旧是可以接受的。&lt;/li&gt;&lt;/ul&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;统计&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;在布隆过滤器之前&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;布隆过滤器之后&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;使用时间（毫秒）&lt;/td&gt;&lt;td&gt;第387章&lt;/td&gt;&lt;td&gt;1740&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;已扫描文档数&lt;/td&gt;&lt;td&gt;21&lt;/td&gt;&lt;td&gt; 21&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;总文档数&lt;/td&gt;&lt;td&gt;50,520,067,053&lt;/td&gt;&lt;td&gt; 50,550,326,486&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;查询的服务器数&lt;/td&gt;&lt;td&gt;18&lt;/td&gt;&lt;td&gt; 18&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;响应服务器数&lt;/td&gt;&lt;td&gt;18&lt;/td&gt;&lt;td&gt; 18&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;查询的段数&lt;/td&gt;&lt;td&gt;20,491&lt;/td&gt;&lt;td&gt; 20,488&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;已处理的段数&lt;/td&gt;&lt;td&gt;4,829&lt;/td&gt;&lt;td&gt; 48&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;匹配的段数&lt;/td&gt;&lt;td&gt;17 号&lt;/td&gt;&lt;td&gt;17 号&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;查询的消费段数&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt; 2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;已扫描条目数&lt;/td&gt;&lt;td&gt;16,466,904&lt;/td&gt;&lt;td&gt; 147&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;图 3：通过 Pinot 查询控制台实施布隆过滤器之前和之后的查询统计信息&lt;/em&gt;。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1089225" height="575" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/05/figure5-1024x575.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：有和没有布隆过滤器的性能比较。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-challenge-2-business-edge-cases"&gt;&lt;strong&gt;挑战 #2 – 业务边缘案例&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;随着 Uber 不断向平台添加功能，它们对源数据的下游影响也在不断增加。目前，我们可以通过三种方式接收行程级别信息：Apache Hive™、Apache Kafka™ 主题和 API 响应，每种方式都有不同的模式。以合理的方式在现有模式中改造和表示新功能可能很困难，特别是 Apache Hive™ 模式。历史数据具有很大的惯性，可能会使迁移模式变得不合理。&lt;/p&gt;&lt;p&gt;例如，考虑票价分摊功能，其中乘车费用可以由多个乘客分摊。在此功能之前，一项工作总是有一个骑手，而该骑手始终是付款人，并且每条 Hive 记录都意味着司机在订单上执行了一项工作。这些不变量不再成立。此处选择复制记录并将状态设置为&lt;em&gt;FARE_SPLIT&lt;/em&gt; ，同时将&lt;em&gt;driver_uuid&lt;/em&gt;列设置为&lt;em&gt;NULL&lt;/em&gt; 。&lt;/p&gt;&lt;p&gt;正是这样的复杂性使得执行简单的&lt;em&gt;COUNT DISTINCT&lt;/em&gt;聚合变得不可能。对于每个业务案例，必须清楚地考虑决定记录是否有助于主题的任期：&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;重新调度行程（派遣另一名司机来完成已分配的工作）&lt;/td&gt;&lt;td&gt;工作任期应归属于谁？两位司机？如果这些记录表示为多条记录，那么它是否应该算作骑手的 2 份工作？&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;宾客乘坐&lt;/td&gt;&lt;td&gt;由于这些帐户的性质，它们可能会导致热分片，从而导致表扫描查询的成本高昂。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;未履行的订单&lt;/td&gt;&lt;td&gt;未履行的订单是否应该有助于任期？&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;请求者取消、订单失败等&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;同一订单上同一供应商的多次派送&lt;/td&gt;&lt;td&gt;由同一司机完成多项工作的 1 个订单应为请求者贡献多少任期？&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;预定订单&lt;/td&gt;&lt;td&gt;尚未发生的命令是否应该针对某个主题累积任期？ &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-challenge-3-slow-data"&gt;&lt;strong&gt;挑战 #3 – 数据缓慢&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;我们必须解决的另一个挑战是上游数据缓慢。虽然大多数数据会在几秒钟内到达，但行程可能长达一周不会出现在上游数据源中。为了解决这个问题，我们创建了一个动态生成回填管道的管道，但仅安排在 T – 7d 和 T 之间运行。&lt;/p&gt;&lt;p&gt;除此之外，我们还执行离线数据质量检查，即 T – 1d 日期的简单&lt;em&gt;COUNT(*)&lt;/em&gt;查询，以确保我们的源 Apache Hive™ 表与 Apache Pinot™ 混合表的结果同步。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-challenge-4-bursty-upstream-loads"&gt;&lt;strong&gt;挑战 #4 – 突发的上游负载&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;流量模式尖峰的上游流量也是一个问题。在这种情况下，特定的速率限制实施会导致流量每十秒出现一次大幅峰值，每个流量都违反了十秒的 Apache Pinot™ 代理超时，导致请求失败。&lt;/p&gt;&lt;p&gt;我们通过在请求时向上游客户端添加抖动来解决这个问题，以便随着时间的推移更均匀地分布我们的查询。&lt;/p&gt;&lt;p&gt;克服这些挑战后，我们已经为实时生产流量提供了近一年的服务，并且执行负载测试显示，在包含故障转移流量的缓冲区后，至少有 200% 的空间。我们的 p99 读取延迟约为 1 秒：令人印象深刻，因为我们的一些上游查询可以命中超过 2,000 个段，每个段消耗大约 90 MB 的磁盘空间。在迭代我们的解决方案后，我们开始发布将之前的下游与我们的解决方案进行比较的指标。我们基于 Apache Pinot™ 的解决方案提供了几乎 1:1 的精度，让我们有信心信赖它。我们首先使用配置标志来控制更改，一段时间后，完全切换并弃用以前的实现。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;通过一些简单的补充，我们有信心能够回答更有力的问题。例如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;最近 50 次旅行中多次前往哪个城市？&lt;/li&gt;&lt;li&gt; Uber 的员工中谁是高级职位？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在工作粒度上找到时间点任期的成本很高。提高性能和降低存储成本的途径仍在探索中。虽然仍处于设计过程中，但我们预计通过降低作业粒度要求，我们应该能够显着提高读取吞吐量。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-acknowledgments"&gt;致谢&lt;/h3&gt;&lt;p&gt;特别感谢 Caner Balci、Qiaochu Liu、Jacob Sevart 和 Ujwala Tulshigiri 对本文的贡献。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Apache &lt;sup&gt;®&lt;/sup&gt; 、Apache Hive™、Apache Kafka®、Apache Spark™ 和 Apache Pinot™ 是&lt;/em&gt;&lt;a href="http://www.apache.org/" rel="noreferrer noopener nofollow" target="_blank"&gt;&lt;em&gt;Apache Software Foundation&lt;/em&gt;&lt;/a&gt;&lt;em&gt;在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/em&gt;&lt;/p&gt;&lt;p class="has-small-font-size"&gt;封面照片归属： &lt;a href="https://www.flickr.com/photos/54966739@N00"&gt;blaahhi&lt;/a&gt;的“ &lt;a href="https://www.flickr.com/photos/54966739@N00/3597105175"&gt;Abacus&lt;/a&gt; ”已获得&lt;a href="https://creativecommons.org/licenses/by/2.0/?ref=openverse"&gt;CC BY 2.0&lt;/a&gt;许可。&lt;/p&gt;</description><pubDate>Wed, 22 May 2024 06:41:19 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/job-counting-at-scale/</guid></item><item><title>【Upgrading M3DB from v1.1 to v1.5】</title><link>https://www.uber.com/blog/upgrading-m3db/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;&lt;a href="https://m3db.io/" rel="noreferrer noopener" target="_blank"&gt;M3DB&lt;/a&gt;是一个可扩展的&lt;a href="https://github.com/m3db/m3" rel="noreferrer noopener" target="_blank"&gt;开源&lt;/a&gt;分布式时间序列数据存储。它用作&lt;a href="https://www.uber.com/en-IN/blog/m3/" rel="noreferrer noopener" target="_blank"&gt;M3 堆栈&lt;/a&gt;的持久存储，为所有 Uber 服务提供基于指标的可观察性。这些指标随后用于生成实时警报。&lt;/p&gt;&lt;p&gt;距离我们上次将 M3DB 的开源版本部署到 Uber 云中已经过去了 3 年。自上次部署以来，服务器代码中添加了一系列性能增强功能。其中一些增强功能包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; ( &lt;a href="https://github.com/m3db/m3/releases/tag/v1.2.0" rel="noreferrer noopener" target="_blank"&gt;V1.2.0&lt;/a&gt; ) 和 ( &lt;a href="https://github.com/m3db/m3/releases/tag/v1.5.0" rel="noreferrer noopener" target="_blank"&gt;V1.5.0&lt;/a&gt; ) 中完成的&lt;strong&gt;资源利用率改进&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Bootstrap 性能改进 –&lt;/strong&gt;改进&lt;strong&gt;&amp;nbsp;&lt;/strong&gt; ( &lt;a href="https://github.com/m3db/m3/releases/tag/v1.2.0" rel="noreferrer noopener" target="_blank"&gt;V1.2.0&lt;/a&gt; )&lt;/li&gt;&lt;li&gt;&lt;strong&gt;引导和快照可靠性 –&lt;/strong&gt; ( &lt;a href="https://github.com/m3db/m3/releases/tag/v1.4.0" rel="noreferrer noopener" target="_blank"&gt;V1.4.0&lt;/a&gt; ) 中进行的改进&lt;br /&gt;&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-scope-of-work"&gt;工作范围&lt;/h2&gt;&lt;p&gt;尽管开源项目引入了重大改进，但我们一直在旧版本的 M3DB 上运行的原因之一是，我们没有经过充分测试的 M3DB 验证和部署流程。&lt;/p&gt;&lt;p&gt;这项工作的主要目标之一是找到一种可重复且可靠的方法将 M3DB 部署到 Uber 云中，以便我们能够更一致地进行升级。我们希望自动化尽可能多的步骤，同时为升级 M3DB 队列的下一次迭代提出一系列改进。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-scale-amp-performance-considerations"&gt;&lt;strong&gt;规模和性能考虑因素&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;开源项目中有一个集成套件的基本版本，但不适用于 Uber 规模（10 亿写入 RPS、8000 万读取 RPS 和大约 6,000 台服务器）。&lt;/p&gt;&lt;p&gt;考虑到 M3DB 在 Uber 内部的运营规模，即使性能/效率/可靠性下降 5-10% 也可能对我们的可观察性平台构成严重风险。除非在生产类似规模下进行测试，否则评估 M3DB 新版本的正确性是没有意义的。&lt;/p&gt;&lt;p&gt;此外，在大规模运行时，常见的场景之一是 M3DB 集群处于动态状态，即节点经常且几乎总是由底层基础设施自动化触发添加、删除或替换。因此，集成套件也应该在这些混乱的场景下测试功能、正确性和性能。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-quantifying-concrete-gains-for-uber-workloads"&gt;&lt;strong&gt;量化 Uber 工作负载的具体收益&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;开源版本中的更改已经显示出性能改进，但从未在 Uber 这样庞大和复杂的环境中进行过测试。没有可用的数据来表明我们通过迁移到最新工作负载会看到的确切收益。考虑到在 M3DB 中审查和发布新版本所涉及的工作，我们需要证明进行这项工作的投资回报率是合理的。&lt;/p&gt;&lt;p&gt;因此，新版本测试工作的一部分将包括在 Uber 生产类似流量下运行它，并将关键性能指标与生产中运行的现有版本进行比较，以了解开源版本与 Uber 规模相比如何。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-rollout-challenges"&gt;&lt;strong&gt;推出挑战&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;考虑到集群规模巨大（大约100个集群，总共5500个节点）以及每个节点的高分配（目前每个节点28核和230G内存），M3DB的任何变化的推出也会在可靠性和可操作性方面带来挑战。我们希望评估一个安全、稳定且需要最少人力或干预的发布过程。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-rollout-strategy"&gt;推出策略&lt;/h2&gt;&lt;p&gt;我们有超过数百个 M3DB 集群在生产中运行 - 按保留期和可用区域进行分片。每个集群可以有数百个节点，其中绝大多数平均每个集群有 100 个节点左右。虽然集群本身可以并行升级，但在集群内，我们有一个额外的限制，即一次只能升级一个节点，以避免数据丢失，因为写入是在 Uber 内以三分之二多数仲裁执行的。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-testing-strategy"&gt;测试策略&lt;/h2&gt;&lt;p&gt;我们考虑并实施了两项广泛的测试策略：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;离线模式&lt;/strong&gt;，我们在各种模拟/实验综合测试负载和关键客户端性能指标（如正确性、延迟、成功率）基准测试下运行 M3DB。此外，我们还对服务器性能特征进行基准测试，例如服务器响应时间、引导持续时间、滴答持续时间以及重新启动和替换之间的数据持久性。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;在线模式，&lt;/strong&gt;我们在重复和采样的生产流量下运行 M3DB，以观察现有生产集群的性能和正确性回归。 &lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-offline-mode"&gt;离线模式&lt;/h3&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/XOs_e9tRumTWl2neEx1-qOK17aHObrN3xrkVXsbzqNbLNkWbyeoo9Wfs9_Ia8s7F8Q_MIs-aieAxmUiZ9oo9F2bNSRV0ZEfvS_7ZD0SCMqUhAl20JuSmCgPAXM2DgNGyPpg8ZLBlwT8puQv9SgPGLlc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：离线测试策略。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;对于离线模式，我们需要一个能够大规模生成负载的 M3DB 基准测试工具。通过调整基准工具的输入参数或根据需要调整集群设置来模拟需要测试集群的各种场景。为了扩展我们的基准测试工具以模仿甚至超越我们的生产负载，我们将基准测试工具服务部署为分布式服务。我们部署了功能强大的高容量机器，使系统承受巨大的工作负载。所有基准测试均在新创建的 M3DB 集群上运行，集群大小为 10 个节点。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-test-scenarios"&gt;测试场景&lt;/h4&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;在旧版本上对 M3DB 集群进行基准测试&lt;/strong&gt;– 我们在旧版本上运行多个基准测试，并记录 M3DB 集群的延迟和正确性，以建立基准数字。&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;运行拓扑操作 –&lt;/strong&gt;在集群内发生拓扑操作（节点添加、删除和替换）时运行基准测试套件。&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;推出新版本 –&lt;/strong&gt;当我们在新版本上进行部署时运行基准套件。&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;对新版本进行基准测试 –&lt;/strong&gt;与上述旧版本类似，我们也对新版本运行完全相同的基准测试，并收集相同的指标。&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;基准测试正确性 –&lt;/strong&gt;首先在只写模式下运行基准测试，并将写入的指标记录在文件中 – 随后在验证模式下运行基准测试，一旦新版本的部署完成，它将尝试进行读取。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;当集群位于较旧版本的 M3DB 上时，上面的&lt;strong&gt;“a”&lt;/strong&gt;和&lt;strong&gt;“b”&lt;/strong&gt;点都会执行一次，当集群位于较新版本上时，也会执行一次。&lt;/p&gt;&lt;p&gt;当在传输中测试场景中进行测试时，需要上面的&lt;strong&gt;“c”&lt;/strong&gt;和&lt;strong&gt;“d”&lt;/strong&gt;点。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;“e”&lt;/strong&gt;点讲的是正确性。正确性是一个基本要求：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;当升级发生时，旧服务器会将所有数据刷新到磁盘，新服务器版本将开始读取相同的数据。我们需要确保新节点能够读取旧版本刷新的数据。&lt;/li&gt;&lt;li&gt;我们需要在新版本将数据保存在缓冲状态和刷新状态的情况下进行正确性基准测试。 &lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-online-testing"&gt;在线测试&lt;/h3&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/wtVD6vLneTmdQJjoTCOLl9E9QxlTzW99f22X06IK8oHL3AEB9Vxgi059Uh16_n4lE91SZvm0vrITtr7k4kqsiLFD71UiOcHCfkoJohK37_981kRdDdr_cvtqnMHqeh1nr2NHqN8RC0nzEyO6Pfa3swg" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：在线测试策略。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;虽然离线模式帮助我们在 M3DB 的一些关键性能指标上探索 M3DB 新版本，但它仍然没有让我们对新版本在 Uber 生产规模和指标有效负载方面的表现缺乏信心。&lt;/p&gt;&lt;p&gt;为了获得这种信心，我们最终实现了如下所示的影子流量管道设置，其中我们可以将可配置的写入和读取流量示例复制到具有生产流量的影子 M3DB 集群，尽管规模较小。&lt;/p&gt;&lt;p&gt;考虑两种类型的影子测试：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;影子测试用于比较运行相同百分比生产流量的旧版本和新版本&lt;/li&gt;&lt;li&gt;影子测试具有与生产集群成比例的流量和集群大小并进行比较&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-shadow-testing-against-older-version-vs-newer-version-nbsp"&gt;针对旧版本与新版本的影子测试&lt;/h4&gt;&lt;p&gt;我们首先使用旧版本创建影子 M3DB 集群，并让它运行几周，以便我们获得各种性能指标（如 CPU、内存、引导延迟、滴答持续时间和服务器/客户端延迟）的基线数字。之后影子M3DB集群升级到最新版本，测量相同的性能指标并与基线数字进行比较。&lt;/p&gt;&lt;p&gt;在线测试分为3个阶段：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在旧版本的 M3DB 中运行影子集群以建立基线&lt;/li&gt;&lt;li&gt;在影子设置中推出较新版本的 M3DB&lt;ol&gt;&lt;li&gt;测量推出所需的时间&lt;/li&gt;&lt;li&gt;观察读/写失败&lt;/li&gt;&lt;li&gt;观察性能指标是否有变化&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;在较新版本的 M3DB 中运行影子集群以建立较新的性能指标并与基线数字进行比较&lt;/li&gt;&lt;li&gt;新的性能指标可以帮助量化我们的生产设置通过迁移到新版本可以获得的改进&lt;ol&gt;&lt;li&gt;验证在推出之前发送的写入是否在推出后保留&lt;/li&gt;&lt;li&gt;验证在部署之前发送的写入是否保留以进行节点替换&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-shadow-testing-against-production-cluster"&gt;针对生产集群的影子测试&lt;/h4&gt;&lt;p&gt;根据影子流量将影子集群大小减小到与生产相当的大小，并将性能与生产数量进行比较。&lt;/p&gt;&lt;p&gt;我们希望在大小成比例的集群上发生成比例的读写操作。在此测试设置中，我们还需要对阴影和生产设置运行拓扑操作以获取比较详细信息。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-key-performance-indicators"&gt;关键绩效指标&lt;/h3&gt;&lt;p&gt;我们需要在两种测试策略中观察以下指标：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;系统指标：&lt;/strong&gt; CPU、RSS 内存、总内存、磁盘使用情况、文件描述符以及 M3DB 进程生成的 goroutine 数量。&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;延迟数字：&lt;/strong&gt;客户端和服务器端读/写延迟。&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;成功/失败：&lt;/strong&gt;仲裁成功与失败的读/写请求。&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;节点/对等引导时间：&lt;/strong&gt;每当系统中出现新节点时，都会为其分配系统中可用分片的子集。现在，该节点尝试从其他对等点引导数据，其中也包含这些分片的副本数据。&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;缓冲写入正确性：&lt;/strong&gt;每当数据写入 M3DB 时，数据都会根据命名空间配置（特别是配置的&lt;strong&gt;块大小&lt;/strong&gt;）保存在 M3DB 的内存缓冲区中。如果对 M3DB 的写入成功，我们应该能够在将数据刷新到磁盘之前从 M3DB 查询回相同的数据。&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt; &lt;strong&gt;Flushed Write Correctness：&lt;/strong&gt;与缓冲写入正确性类似，当块刷新到磁盘时，写入在刷新到磁盘后应该是可验证的。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-gains-observed-in-testing-nbsp"&gt;&lt;strong&gt;测试中观察到的收益&lt;/strong&gt;&lt;/h3&gt;&lt;h4 class="wp-block-heading" id="h-memory-improvements-nbsp"&gt;记忆力改善&lt;/h4&gt;&lt;p&gt;我们观察到新版本中 M3DB 的内存利用率提高了大约 20%。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/iw6yy3taG-gCKtsZFmnAx5rhVFCO2l1sRMlZsSjsJIXzzOngdzy8XuBhQhmOOkhAReRlgyE_CuF7qSfihkItMFvDk34engOYipE0-W_OOvp8FgWEt0f3Rz7TJxT1JFhtAA23xzEhcgB035Bd46SDvSA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：内存改进。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-cpu-utilization-improvements-nbsp"&gt; CPU 利用率改进&lt;/h4&gt;&lt;p&gt;同样，我们观察到新版本中 M3DB 的内存利用率提高了大约 20%。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/UF5RX9fSgWn3XvjJU9x58KP-8V7B_PW3C47ZNSVqaPuBPQnd1tyeNaVyqIE6S7WPvnVs9lodzDpt4fKfPZzMgE5fO65Gt8kwnu1UJsFno3sxToEjt_WVsefGOHGH622EANAnRXbSzLeEhKJzs8G8sYs" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：CPU 利用率改进。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-node-bootstrap-time-improvements"&gt;节点引导时间改进&lt;/h4&gt;&lt;p&gt;每当将新节点添加到集群的拓扑中时，就会发生&lt;a href="https://m3db.io/docs/operational_guide/bootstrapping_crash_recovery/" rel="noreferrer noopener" target="_blank"&gt;节点引导&lt;/a&gt;，这可能是在替换旧节点或添加新节点时。在 M3DB 中，当旧节点进行替换时引导新节点是一个长时间运行的操作。&lt;br /&gt;我们在新版本的 M3DB 中一致地引导时看到了更好的性能。这个测试进行了很多轮，结果总是新版本更好。&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;节点大小&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;旧版本（分钟）&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;新版本（分钟）&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;改进％&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 80GiB&lt;/td&gt;&lt;td&gt; 77&lt;/td&gt;&lt;td&gt; 62&lt;/td&gt;&lt;td&gt; 19.48%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 224GiB&lt;/td&gt;&lt;td&gt; 218&lt;/td&gt;&lt;td&gt; 170&lt;/td&gt;&lt;td&gt; 22.00%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 518吉B&lt;/td&gt;&lt;td&gt;第317章&lt;/td&gt;&lt;td&gt;230&lt;/td&gt;&lt;td&gt; 27%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 740吉布&lt;/td&gt;&lt;td&gt;第424章&lt;/td&gt;&lt;td&gt;第365章&lt;/td&gt;&lt;td&gt;14%&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;更换引导时间改进%&lt;/strong&gt; &lt;/figcaption&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-production-rollout-nbsp"&gt;&lt;strong&gt;生产推广&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;当所有测试完成后，我们开始分阶段部署到生产集群。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-challenges-in-production-rollout"&gt;生产推广中的挑战&lt;/h3&gt;&lt;p&gt;即使经过彻底的基准测试和生产样本流量测试，我们在部署的集群中也遇到了一些挑战。下面，我们概述了这些问题，并解释了为什么它们在基准测试过程中难以捉摸，并详细介绍了为解决这些问题而实施的最终解决方案。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-tail-latency-spikes-nbsp"&gt;尾部延迟峰值&lt;/h4&gt;&lt;p&gt;部署后不久，我们注意到写入操作的尾部延迟显着增加，特别是在 P85 百分位数及以上。&lt;/p&gt;&lt;p&gt;为了确定问题的根本原因，我们将集群中的多个节点恢复到以前的版本，同时在其余节点上维护较新的版本。随后，我们对两个版本之间的CPU&lt;a href="https://go.dev/blog/pprof" rel="noreferrer noopener" target="_blank"&gt;性能分析&lt;/a&gt;进行了比较。然后我们能够将其隔离为一个简单的方法，这是有问题的。然后我们解决了导致回归的问题，之后延迟也下降了。&lt;/p&gt;&lt;p&gt;以下是 cpu 分析练习中的一些图像： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-full is-resized"&gt;&lt;img alt="" class="wp-image-1088725" height="591" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/05/Figure-5_-CPU-profile-before-fix.png" style="width: 700px; height: auto;" width="1581" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：修复前的 CPU 配置文件。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/7TqEH_gvJJTSI6-dL2-Nk_Ls1BhN_msDWj10PVCAlzucvwh9LPUPAi-D8M7b1JSU_4vNjndcz47l0omcoiKExxYlLUHy-OM6eStBGCFU9NtncZJ3AB417N7J9_ZJXdWvrR6rq74e2WJ7U91bnUxZa0o" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：修复后的 CPU 配置文件。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;从上图中我们可以看出，有问题的方法在修复后显着减少了其占用空间。&lt;/p&gt;&lt;p&gt;当我们推出这个新版本时，我们的客户端延迟再次恢复正常，如下所示： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/hc4ldFNdM05ZalywrXAWlsLHvHVSLq84hw3hCXoQHEDrCtw9BgXV9k5w-V7leY6FnjBDg_k5sXyPb-WEsX9CP_hS5EweJT1IbFcC_hbn_DTbq2ZlkSUpUCUBTaisqp-GhF6HuDxO3FAuZaJSX-93OaQ" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：修复前后的 P99 写入延迟。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们将此修复贡献回上游开源存储库 - 更改的详细信息可以在： &lt;a href="https://github.com/m3db/m3/pull/4253" rel="noreferrer noopener" target="_blank"&gt;Github Pull Request#4253&lt;/a&gt;中找到。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-data-loss-during-the-upgrade"&gt;升级期间数据丢失&lt;/h4&gt;&lt;p&gt;在上线过程中，集群中的所有节点都会依次进行版本升级。这涉及关闭现有节点并将其在新版本中恢复。因此，节点会丢失其在内存中保存的数据，并且还会错过在其关闭的时间窗口内传入的写入操作。该节点尝试通过&lt;a href="https://m3db.io/docs/operational_guide/bootstrapping_crash_recovery/" rel="noreferrer noopener" target="_blank"&gt;引导&lt;/a&gt;并从对等节点获取数据来恢复该数据。&lt;/p&gt;&lt;p&gt;在集群中发布后，我们的客户发现他们在读取法定人数方面遇到了问题。这基本上意味着客户端观察到读取数量增加，其中集群中只有一个副本有数据，而其他两个副本没有任何数据。&lt;/p&gt;&lt;p&gt;我们从许多查询中分离出单个查询，然后我们能够检查分片的各个副本，并能够发现数据丢失，并且丢失数据的时间范围与节点升级的时间相匹配。我们观察到一个副本有数据，而另外两个副本缺少数据。然后，我们将其与以下事实关联起来：拥有更多数据的副本能够在其他两个副本升级之前将数据刷新到磁盘。刷新取决于&lt;a href="https://m3db.io/docs/operational_guide/namespace_configuration/" rel="noreferrer noopener" target="_blank"&gt;命名空间&lt;/a&gt;配置，因此如果命名空间配置规定刷新应每 24 小时发生一次，则所有节点将几乎同时经历刷新周期。&lt;/p&gt;&lt;p&gt;这个问题最终被证明是一个配置错误的问题，我们必须为数据库指定正确的引导程序模式，只有在这之后它才会尝试引导在从对等点升级期间丢失的数据。我们使用默认的引导配置，但理想情况下我们应该指定模式为“prefer_peers”或“exclude_commitlog”，前者意味着在从提交日志引导之前优先考虑对等点，后者意味着完全排除提交日志引导。我们继续使用后者，因为我们还没有在生产工作负载中真正使用&lt;a href="https://en.wikipedia.org/wiki/Write-ahead_logging" rel="noreferrer noopener" target="_blank"&gt;WAL&lt;/a&gt; 。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-gains-observed-in-production-after-rollout"&gt;推出后生产中观察到的收益&lt;/h3&gt;&lt;p&gt;生产服务器受内存限制而不是 CPU 限制，因此我们能够观察到内存使用量显着下降，而不是 CPU 使用量。下图也可以看到同样的情况： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/SWwyAQHUM00RoVQMX2WCnTYPA_IX9XdO80xLtOdbH0DqfqUHhXwzFZtVcXK0v3KdSC2w2Zl3Na-GMAT-WrICFiSFJcN5lJBef-g990kq17tV066c1HmH3FFa42tqJOpZp6iGpEXWxnWVdRfKoJgoSLU" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：生产中的内存 RSS 改进。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;节点引导时间的改进也与我们在离线测试阶段的发现一致，并帮助我们提高了生产集群的稳定性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;h2 class="wp-block-heading" id="h-plans-for-contribution-back-to-open-source-project"&gt;回馈开源项目的计划&lt;/h2&gt;&lt;p&gt;我们希望为该项目做出一些贡献：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;基准测试实用程序有助于在生产规模上对新版本进行基准测试。&lt;/li&gt;&lt;li&gt;文档中对数据丢失事件（以及如何解决该问题）的描述。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在生产环境中升级高QPS、低延迟时间序列数据库的旅程，尤其是像Uber这样规模的公司，无疑充满了无数的挑战和挣扎。我们的一些主要经验包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;升级应该是一个持续的过程，而不是一次性完成。&lt;/li&gt;&lt;li&gt;处理开源软件总是充满挑战，因此我们应该有办法：&lt;ul&gt;&lt;li&gt;大规模评估正确性/性能。&lt;/li&gt;&lt;li&gt;制定标准的交错推出和回滚机制。&lt;/li&gt;&lt;li&gt;采用数据驱动的方法来验证与两个发行版本之间的比较有关的每个假设/声明。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;从解决复杂的技术问题到管理性能优化和维持正常运行时间之间的微妙平衡，每个障碍都提供了成长和学习的机会。当工程师正面应对这些挑战时，他们对系统架构、可扩展性和弹性有了更深入的了解。&lt;/p&gt;&lt;p&gt;此外，升级此类关键基础设施的过程促进了工程团队内部的创新和协作文化。通过团队合作和集体解决问题，工程师甚至可以克服最艰巨的障碍，最终形成一个更加强大和高效的系统。&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p class="has-small-font-size"&gt;封面照片归属： &lt;a href="https://www.flickr.com/photos/61846758@N02"&gt;ChrisA1995&lt;/a&gt;的“ &lt;a href="https://www.flickr.com/photos/61846758@N02/6331318875"&gt;Nature&lt;/a&gt; ”已获得&lt;a href="https://creativecommons.org/licenses/by/2.0/?ref=openverse"&gt;CC BY 2.0&lt;/a&gt;许可。&lt;/p&gt;</description><pubDate>Thu, 16 May 2024 09:18:05 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/upgrading-m3db/</guid></item><item><title>【DataK9: Auto-categorizing an exabyte of data at field level through AI/ML】</title><link>https://www.uber.com/blog/auto-categorizing-data-through-ai-ml/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;数据分类——根据数据的特征和本质对数据进行分类的过程——是任何隐私或安全计划的基本支柱。细粒度数据分类的有效性对于实施隐私和安全控制（例如访问策略和加密）以及管理数据资产的生命周期（包括保留和删除）至关重要。本博客深入探讨了 Uber 通过利用各种 AI/ML 技术实现大规模数据分类的方法。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-why-auto-categorization"&gt;为什么要自动分类？&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;庞大的规模和成本&lt;/strong&gt;：许多公司管理分布在各种存储系统中的大量数据集。新数据集的定期生成进一步加剧了这一规模。我们面临的挑战的核心是在现场级别标记大量列，每个列可能需要多个标签。手动标记需要大量时间和资源。此外，需要持续投资来标记新创建的数据集。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;数据所有者的参与&lt;/strong&gt;：识别数据所有者并让其参与是一个复杂的现实。由于每个数据元素需要评估多个标签，因此辨别标签定义之间的细微差别变得复杂且耗时，从而导致错误分类。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;考虑到巨大的工程成本以及通过分散的努力进行手动分类的不切实际，我们的经验使我们优先考虑自动分类。为此，我们推出了一种名为&lt;strong&gt;DataK9&lt;/strong&gt;的新颖解决方案，这是 Uber 数据的自动分类平台。主要目标是最大限度地减少和消除用户参与，从而解决规模、成本和数据所有者参与带来的挑战。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-challenges"&gt;挑战&lt;/h2&gt;&lt;p&gt;考虑一个包含纯数字内容的单列表。仅检查数据本身无法辨别这些数字的性质，这些数字可能代表纬度、经度、汇率等。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1088500" height="290" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/05/Screenshot-2024-05-06-at-2.53.45%E2%80%AFPM-1024x290.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：分类中的列名称。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;但是，如果我们了解列名称（例如图 1 中的&lt;em&gt;纬度&lt;/em&gt;和&lt;em&gt;经度）&lt;/em&gt; ，它将极大地有助于准确地对这些列进行分类。&lt;/p&gt;&lt;p&gt;然而，挑战仍然存在，特别是当列名称是通用的时，如图 2 中最近添加的&lt;em&gt;“注释”&lt;/em&gt;列所示。这可能包含从余额和成本到两个位置之间的距离等信息。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1088501" height="345" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/05/Screenshot-2024-05-06-at-2.54.02%E2%80%AFPM-1024x345.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：通用列名称。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;此外，即使在同一类型的位置数据中，分类也可以根据精度进行细微差别。例如，纬度和经度指定为三位或更多小数位的位置可以被视为精确位置。如果与个人身份相关联，则可能会被归类为高度限制类别。&lt;/p&gt;&lt;p&gt;让我们深入研究图 3 中的另一个示例： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1088502" height="240" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/05/Screenshot-2024-05-06-at-2.54.21%E2%80%AFPM-1024x240.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：地址列名称。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;在缺乏明确上下文的情况下，区分&lt;em&gt;个人&lt;/em&gt;地址和&lt;em&gt;企业&lt;/em&gt;地址变得很困难，尽管两者都是地址。&lt;/p&gt;&lt;p&gt;鉴于这些复杂性，没有通用的解决方案可以解决所有分类挑战。因此，我们选择利用基于概率的方法（即人工智能/机器学习）来为此努力提供帮助。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-strategy"&gt;战略&lt;/h2&gt;&lt;p&gt;人工智能/机器学习技术的应用构成了我们自动分类计划的基石。在本节中，我们将提出总体策略，描述新框架内各个系统之间更广泛的流程和依赖关系。&lt;/p&gt;&lt;p&gt;评估新自动化流程的有效性至关重要，并且取决于一小部分（&amp;lt;1%）的标记（黄金）数据集。这些数据集是手动分类的，最好是由领域专家或所有者进行分类。然后，自动分类机制利用经过审查的训练数据来标记剩余的数据集 (&amp;gt;99%)。本质上，该解决方案采用混合方法，将手动分类与自动化相结合，封装在三个相互关联的阶段中，如下图 4 所示。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/wQRv72HPpi7ZE6eo9u0s6UjgYz7wwLExhcEkpdLdHwRZhw1xz1njMh661wIfwvhFGHOw1P9Ac4GLuXKowp-gbqa_-BaQKdwL2LOFHgxAOinjYHauzsEJ-AYPW3uvSEJuTBbsWSUB8RaFYgwTZBkyoLM" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：分类策略。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-building-baseline"&gt;建立基线&lt;/h2&gt;&lt;p&gt;我们建议将 &amp;lt;1% 的数据集（近 1,000 个）分类为由人类在隐私和领域专家的密切监督下关键且高度利用的表。这些数据集被视为“黄金”数据集，具有很高的分类准确性，并用于衡量自动化准确性。虽然“黄金”数据集的数量相对较少，但有一些显着的好处：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;模型训练&lt;/strong&gt;：训练是任何基于监督机器学习的解决方案中最关键的步骤。如果没有经过适当训练的模型，机器甚至不知道首先要理解什么。我们利用手动分类的数据作为人工智能方法的基线。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;风险缓解&lt;/strong&gt;：我们有一些关键业务数据集，我们不想因为错误标记而冒这些风险。这就是为什么我们由所有者或专家手动标记那些具有高度影响力的数据集。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;理想情况下，用于标记的数据集的选择应随机进行，以尽可能避免在标记数据集中插入统计偏差。这种统计偏差降低了离线模型性能测试的可靠性，并可能导致生产中的系统性分类错误。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-training"&gt;训练&lt;/h2&gt;&lt;p&gt;对于其余 99% 的数据集（&amp;gt;400K），我们将主要使用名为 DataK9 的新自动化系统（稍后小节将详细介绍）。首先，DataK9 针对手动分类（黄金）数据集进行训练，直到准确性达到令人满意的水平而不会过度调整。具体来说，将有两个子阶段：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们基于黄金数据集的子集迭代训练模型，然后针对其余黄金数据集（测试数据）运行该模型。我们在每次测试运行后分析标准指标（即准确度、精确度、召回率、F2 分数等）。如果指标不可接受，我们会调整模型并重新运行/重新评估它，直到获得满意的结果。&lt;/li&gt;&lt;li&gt;用于标记数据的检测规则列表由领域专家创建。定义规则后，它会不断进行测试运行和规则调整，直到达到可接受的指标值。最初的规则定义和早期的规则迭代将有更多的人为参与。我们将逐步进入规则的自动调整，使调整过程自动化，并推出规则更改，从而产生更好的预测。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-serving-in-production"&gt;服务于生产&lt;/h2&gt;&lt;p&gt;在 Datak9 展示了其令人满意的训练数据集指标（即准确率 &amp;gt;90%、F2 分数 &amp;gt;85%）后，它将准备好对其余数据集进行生产标记。不过，我们计划在大规模分类的早期阶段采取一些防御流程。它包括在数据集（暂时）自动分类后自动创建票证以进行审查（对于数据所有者或经过培训的隐私专家来说更佳）。当所有者盖章后，分类将被视为最终分类。此外，在这个过渡阶段，我们将密切监控进展情况，尤其是错误分类率。如果审稿人的反馈可以接受，我们将大规模部署数十万个数据集。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-architecture"&gt;建筑学&lt;/h1&gt;&lt;p&gt;本节介绍基于 AI 的核心平台的架构，以及 DataK9 如何在框架的不同部分和阶段采用 ML/AI 技术，如图 5 所示。本节我们重点关注标记数据集的主要用例。首先识别和收集数据集的基本特征，然后使用 ML/AI 技术确定特定标签的列权重/分数。然后，我们讨论如何将特定领域的多个信号组合成最终决策。最后，我们详细介绍了根据原始标记中所犯错误调整规则和 ML 模型的主动学习过程。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/d8h-crQtz9vDMKFyrGRuALVxL8rWsE4srz6RSopnKAU0rfOwdIrIa9X_pY-XR7a4qi6BGiKx1R7UemrVXIwahIopFhKNv6a9SwrclnWzCLVraWsriXdXEjtKz2KmJxLkxEwy_1BFkrCZMPMdvTNcEaQ" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：Data K9 架构。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-key-features-nbsp"&gt;主要特征&lt;/h2&gt;&lt;p&gt;DataK9 使用数据集的以下信息，我们可以将其用作各种 ML/AI 分类技术中的潜在特征：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;元数据&lt;/strong&gt;：它包括数据集中每个字段的名称和类型。例如，数据集“ &lt;em&gt;uber_rides&lt;/em&gt; ”可能有 100 多个字段。 DataK9 利用所有字段的名称，例如“ &lt;em&gt;request_latitude&lt;/em&gt; ”和“ &lt;em&gt;email&lt;/em&gt; ”以及相关的类型，例如&lt;em&gt;double&lt;/em&gt;和&lt;em&gt;string&lt;/em&gt; 。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;数据&lt;/strong&gt;：数据集可能包含数十亿条记录。尽管 DataK9 最终会考虑所有行的内容，但我们将从数据集每次运行/扫描的记录随机样本 (~1%) 开始。更具体地说，我们将利用单元格内容来确定列类别。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;上下文&lt;/strong&gt;：虽然每个单元格值都提供了有价值的信息，但同一记录中的其他值可能会提供额外的信号。此外，上下文（例如表和数据库名称）会呈现有关列标记的提示。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;沿袭&lt;/strong&gt;：数据沿袭是数据旅程的地图，包括其起源、创建过程等。与 DataK9 相关的数据沿袭信息有两种类型。&lt;ul&gt;&lt;li&gt;&lt;em&gt;表级沿袭&lt;/em&gt;：表沿袭将提供更高级别的信息，例如使用哪些表来创建新表。例如，表“ &lt;em&gt;uber_rides&lt;/em&gt; ”是在连接一些表（例如&lt;em&gt;drivers&lt;/em&gt;和&lt;em&gt;riders ）&lt;/em&gt;后创建的。这种类型的沿袭与派生表比原始表更相关。&lt;/li&gt;&lt;li&gt;&lt;em&gt;列级沿袭&lt;/em&gt;：此沿袭是指哪一列派生自不同表的哪一组依赖列。对于各种数据处理平台（例如 Hive™、Spark™ 等）来说，收集这些信息更为复杂。但是，如果有可靠的列级谱系可用，DataK9 可以更好地预测标签。 &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-matching-strategy"&gt;匹配策略&lt;/h2&gt;&lt;p&gt;所提出的解决方案的本质是最终从所有数据存储中抓取数据（表或目录或文件）并定期扫描每个数据元素以获取不同标签的信号。我们在本节中讨论一些基本的匹配技术。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;个体与总体决策&lt;/strong&gt;：DataK9 在单元格级别扫描数据，并从内容和元数据中查找信号。由于有数百万个数据元素，DataK9 将检查每个元素并获取相应的指示。例如，假设单元格值为&lt;em&gt;john@gmail.com&lt;/em&gt; 。我们会将此电子邮件地址与每个标签进行匹配，并为此值生成匹配分数。然而，根据一个匹配分数做出最终决定可能会产生误导。实际上，电子邮件地址可能位于另一列中（例如&lt;em&gt;Promotion_code&lt;/em&gt; ），这可能不会被解释为 PII 数据。此外，我们的主要目标是标记表的列，而不是单个列值。因此，我们将所有列值的这些单独分数合并为全局分数并最终做出决定。例如，如果列的 80% 的值与电子邮件匹配，我们可以安全地假设该列包含电子邮件 PII 数据并相应地对其进行标记。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;概率决策：&lt;/strong&gt; DataK9 寻找特定标签的特定匹配。然而，几乎没有找到匹配就能确保标签分配的情况。因此，我们为每项检查定义一个分数。分数越高，标签关联的可能性就越高。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;负分：&lt;/strong&gt; DataK9 允许负分来表明它不太可能是特定标签的一部分。例如，数据库名称模式“ &lt;em&gt;products&lt;/em&gt; ”下的任何数据不太可能具有任何 PII 数据。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-rule-based-ai"&gt;基于规则的人工智能&lt;/h2&gt;&lt;p&gt;当我们抓取新的数据集时，我们对样本数据应用两种人工智能方法，然后识别每个字段/列类别。我们在本节中解释&lt;em&gt;基于规则的内容&lt;/em&gt;，然后在下一节中&lt;em&gt;解释基于学习的内容&lt;/em&gt;。&lt;/p&gt;&lt;p&gt;我们将从一组手工制定的规则开始，并构建相关的规则语言和引擎。找到具有适当知识和经验（例如对数据内容、分类内部结构和工程能力的深入理解）的领域专家具有挑战性。本质上，设计规则需要考虑两个关键维度：40 多个不同的标签和基本功能。我们支持以下构建块来表达规则：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;布隆过滤器匹配&lt;/strong&gt;：我们根据特定实体的最常见数据值创建&lt;a href="https://en.wikipedia.org/wiki/Bloom_filter" rel="noreferrer noopener" target="_blank"&gt;布隆过滤器&lt;/a&gt;。然后在扫描每个列值的过程中，我们测试成员资格并决定可能的标签。例如，我们可以为 Uber 送货服务上个月使用的所有地址创建布隆过滤器。然后，在扫描过程中，我们可以测试每个数据单元格的成员资格以找到可能的匹配。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;字典匹配&lt;/strong&gt;：我们创建一个包含常用值列表的字典。在扫描过程中，K9为数据集的每个数据元素（单元格）查找字典，并根据规则定义决定匹配分数。例如，我们可以创建一个字典来包含 750 多个&lt;em&gt;机场代码&lt;/em&gt;来匹配位置信息。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;模式匹配&lt;/strong&gt;：我们定义一个正则表达式来查找与列内容或列名称的匹配。例如，我们可以使用模式&lt;em&gt;^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,} $&lt;/em&gt;匹配电子邮件地址，例如&lt;em&gt;john@gmail.com&lt;/em&gt; 。需要注意的是，在某些情况下，模式匹配可能不足以确定最终标签。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;上下文匹配&lt;/strong&gt;：列名称和值本身可能无法提供有关其内容类型的任何强烈信号。因此，我们允许寻找单元格值本身之外的上下文。我们将支持三种不同的上下文：&lt;ul&gt;&lt;li&gt;&lt;em&gt;记录级别&lt;/em&gt;：基本原理是某些数据标签可能与同一数据集中的其他数据标签一起出现。例如，假设列中有一个纬度值。在这种情况下，它被认为是非敏感位置数据，因为相同的纬度可能存在数百万个位置点。因此，我们还应该在同一条记录中查找经度。&lt;/li&gt;&lt;li&gt;&lt;em&gt;表级别&lt;/em&gt;：在某些情况下，表名称模式在确定某些实例的数据类型方面发挥着重要作用。例如，“ &lt;em&gt;virtual_machine&lt;/em&gt; ”表中的全名不敏感，而“ &lt;em&gt;rider&lt;/em&gt; ”表（保存最终用户数据）则非常敏感。&lt;/li&gt;&lt;li&gt;&lt;em&gt;数据库级别&lt;/em&gt;：某些数据库名称模式可能指示数据库可能包含的数据类型。例如，如果数据库的名称中包含“ &lt;em&gt;finance”&lt;/em&gt; ，则它可能会包含一些交易数据。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;数据类型匹配&lt;/strong&gt;：数据类型匹配包括类别的可能数据类型列表。如果任何字段不遵守标签的类型限制，K9 将跳过该标签的该列匹配。例如，个人电子邮件列的类型为&lt;em&gt;string&lt;/em&gt; ；因此，如果列的数据类型是非字符串，我们不需要检查电子邮件类别。这种类型的检查对每个文件或数据集进行一次的频率较低，因为它是在元数据级别。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-rule-language"&gt;规则语言&lt;/h3&gt;&lt;p&gt;定义规则是基于规则的人工智能的第一步，支持标准的规则定义语言或模板势在必行。本节介绍为特定标签定义规则的基本构建块。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;根据其检查的数据类型，规则中包含三个更广泛的子规则：列值匹配 ( &lt;em&gt;columnValueMatch&lt;/em&gt; )、元数据匹配 ( &lt;em&gt;columnNameMatch&lt;/em&gt; ) 和上下文匹配 ( &lt;em&gt;contextMatch&lt;/em&gt; )。&lt;/li&gt;&lt;li&gt;每个子规则都会有一个由规则管理员根据其领域专业知识指定的匹配“分数”。&lt;/li&gt;&lt;li&gt; &lt;em&gt;columnValueMatch&lt;/em&gt;规则主要检查数据集中每个数据元素的值。这些操作成本高昂且复杂，因为数据元素的数量和每个值的检查数量巨大。它需要以下过滤和检查：&lt;ol&gt;&lt;li&gt;&lt;em&gt;布隆过滤器&lt;/em&gt;部分包含查找预先计算的布隆过滤器以检查成员资格和关联分数所需的配置。我们可以将布隆过滤器存储在文件或表中。&lt;/li&gt;&lt;li&gt;&lt;em&gt;字典&lt;/em&gt;匹配从最常用值的预定义列表中查找精确匹配。该字典可以是 HDFS 文件或 Hive 表。&lt;/li&gt;&lt;li&gt; &lt;em&gt;lengthRange&lt;/em&gt;定义内容的长度。此过滤器可以轻松地从昂贵的匹配中早期排除大量值。例如，纬度值的长度可以在3到10之间。K9不应考虑位置数据的该长度范围之外的任何内容。&lt;/li&gt;&lt;li&gt; &lt;em&gt;valueRange&lt;/em&gt;指定标签的有效值范围。例如，一个人的年龄可以在 0-125 之间。如果某列包含超出此范围的数据，K9 将跳过此列进行任何“年龄”类型检查。与 lengthRange 一样，valueRange 也简化了许多复杂的匹配。&lt;/li&gt;&lt;li&gt;&lt;em&gt;模式&lt;/em&gt;匹配指定与值的典型模式匹配的正则表达式。例如，电子邮件始终遵循一种模式，我们可以使用该模式来检查列值是否可能是潜在的电子邮件。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt; &lt;em&gt;columnNameMatch&lt;/em&gt;规则表示列名模式和列类型的匹配。它还可以提及排除的列名称和类型，以帮助避免误报。&lt;/li&gt;&lt;li&gt; &lt;em&gt;ContextMatch&lt;/em&gt;规则查找超出特定列值的特定上下文。目前，DataK9 支持两种不同的上下文以及各自的匹配分数：&lt;ol&gt;&lt;li&gt; &lt;em&gt;ResourceContext&lt;/em&gt;指定是否存在我们想要获取信号的任何表或数据库名称模式。例如，如果数据库名称包含“finance”，则该数据集中很有可能包含交易数据。&lt;/li&gt;&lt;li&gt; &lt;em&gt;categoryContext&lt;/em&gt;概述了哪些其他相关类别可以提供额外的信号。例如，1 级位置数据标签必须在同一数据集中具有可识别的个人类别。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt; DataK9 在一个或多个 YAML 文件中管理规则的定义。或者，DataK9 将支持存储在数据库表中的规则。该表更适合动态更新规则或相关分数。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我们提供了一组“位置纬度”示例规则来识别图 6 中 YAML 格式的标签，这将有助于理解前面部分中描述的概念。绿色的内嵌注释包含了每个键值对的含义。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/4wEm-2So0frIQ5F3byMZNiANyt_bEf_njBgaz2TA3ckBrvkiG4Sn9YpCHNguU9mtB49UyXoU9D59hTEFzyQkjkS2trLvDVyhOmoUYZvOffEqGDmM3q0WrdRtiDzp8hpny5Rx3mMU0DYNtojTGBrjrmo" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：位置纬度分类配置。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-learning-based-ai"&gt;基于学习的人工智能&lt;/h2&gt;&lt;p&gt;分类在 AI/ML 领域得到了很好的研究。我们的分类问题非常适合多标签分类的监督学习。使用标准分类算法，我们打算使用元数据和单元格内容来预测实际标签。关键思想如图 7 所示，描述如下：&lt;/p&gt;&lt;p&gt;图 7：基于学习的人工智能&lt;/p&gt;&lt;ul&gt;&lt;li&gt;使用标记数据集来训练我们的模型。我们可以分别使用元数据和数据值来训练两个模型。&lt;/li&gt;&lt;li&gt;评估训练后的模型的典型准确度、精确度、召回率和 F2 得分指标。如果指标的值不可接受，我们会在调整参数和算法后重新训练我们的模型。否则，我们可以在生产中部署模型。如果模型评分分布一致，则可以采用阈值技术来权衡精度和召回率，并提供更好的控制。对于支持度较低的类别，可以通过额外的手动标记来改进模型。如果额外的手动标记失败，可以考虑合并类别。机器学习模型将接受完整的训练/测试实验，作为部署前的最终健全性检查。该实验还必须通过上述所有指标的既定阈值。 DataK9 检测器将根据训练模型预测列的标签。&lt;/li&gt;&lt;li&gt;机器学习算法和初始实验：大量机器学习算法以及各种输入转换和特征工程策略已经接受了测试。我们已经检查了经典的 ML 程序，例如线性支持向量机 (SVM)、K 最近邻 (KNN) 和朴素贝叶斯。到目前为止，做得最好的是线性 SVM。然而，机器学习建模方面仍然存在艰巨的工作，特别是在这些低支持类别方面。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-aggregating-signals"&gt;聚合信号&lt;/h2&gt;&lt;p&gt;如上所述，DataK9 生成多个信号以及每列的相关分数值。一列可以有多个潜在标签以及通过以下方法估计的分数：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;基于规则的人工智能在为每个类别应用规则后创建标签和分数。&lt;/li&gt;&lt;li&gt;基于学习的人工智能将根据元数据和列值预测每列可能的标签对和分数。&lt;/li&gt;&lt;li&gt;谱系服务还可以为每列提供附加信号。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;收集这些信号后，DataK9 使用加权聚合方法合并每个标签、每列的所有分数。每个匹配的权重是根据经验确定的，并作为规则定义的一部分进行参数化。综合得分与预先指定的阈值进行比较后确定最终标签。该产品的后续版本可能会使用基于 ML 的集成方法。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-learning-feedback-loop"&gt;学习：反馈循环&lt;/h2&gt;&lt;p&gt;DataK9 严重依赖 ML/AI 技术，这些技术可能会在标签预测中出现潜在的错误。我们打算通过采用反馈循环来自动学习以避免类似的错误。本节简要描述我们如何将此方法融入到我们的框架中。&lt;/p&gt;&lt;p&gt;挑战的第一部分是找出错误。自动标记后，所有者或隐私专家可以使用提供的 UI 修改类别。我们将在一个中心位置跟踪所有这些修改的审计跟踪。下一步是找到可以自动调整 AI/ML 平台的典型错误模式。特别是，我们努力调整我们的规则数据库，其中我们使用了许多根据经验指定的参数。我们计划根据错误模式修改这些参数。此外，我们希望根据从错误中学习来改变不同的模型训练参数。虽然我们的最终目标是完全自动化，但我们将从人机交互开始调整规则。我们最终将走向基于我们对现实世界的理解的自动反馈循环。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-measuring-the-accuracy"&gt;测量精度&lt;/h2&gt;&lt;p&gt;在自动分类领域，准确性是至高无上的，因此，我们将精心测量和披露根据受众需求定制的各种级别的指标作为我们的首要任务。在我们报告层次结构的顶峰，我们将公布以下关键指标：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;分类的标准指标&lt;/strong&gt;：我们的自动化框架的质量对于评估和跟踪进度至关重要。然而，如果没有适当的基线，就不可能衡量自动分类的质量。因此，我们还建议所有者/专家对覆盖所有数据标签的 &amp;lt;1% 的数据集进行手动分类将提供现实的基线。在机器学习/人工智能领域，分类是经过深入研究的文献，专家们定义了一组指标来衡量分类方法的质量。我们在图 8 中用混淆矩阵展示了它们，并在下面进行了描述： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/zZ-qtmybdg0JJVBt6e6iQyOeaylKWmOz4qColn-CDR54eKCLGAemdWT5HBXZcoGJyOoO31BfRgcgeotJV1mRMDXiR26iF7_s0fmZYlXqoL3DQKxkEbgWmc1Z_vt0_mY3rA_8kgouIgfdVD9VDS9CvGI" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：准确性混淆矩阵。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;准确度&lt;/strong&gt;：分类准确度是正确预测的总数除以所有数据集上做出的预测的数量。换句话说，这表示机器为标记数据集适当标记了多少列。例如，如果我们有 100 列，K9 正确分类其中 90 列，则准确率为 90%。我们不能仅仅依赖准确性，因为包含 PII 的列只占所有列的一小部分。无法对任何内容进行分类的分类器将具有异常高的准确度，因为真阴性将超过假阴性。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;精度&lt;/strong&gt;：精度是指我们的积极预测的“正确”程度。误报越少，我们的精确度就越高。然而，它并没有讲述完整的故事。例如，如果我们进行单个预测，成功率为 100%，但未能对其他 9 个敏感列进行分类，则我们有 100% 的精确度，但准确度和召回率较低。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;召回率（敏感性）&lt;/strong&gt; ：召回率是指我们识别敏感信息的可能性。假阴性越少，我们的回忆就越好。然而，它并没有讲述完整的故事。例如，如果我们预测所有列都是敏感信息，我们将获得 100% 的召回率，但准确性和精确度较低。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;F2 分数&lt;/strong&gt;：F2 分数是一种在单个可测量指标中偏向于优化召回率而不是精确率的方法。 &lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-precision-vs-recall"&gt;准确率与召回率&lt;/h2&gt;&lt;p&gt;准确率和召回率的影响会影响两个不同的受众。例如，工程师和数据科学家可能会担心低精度指标。较高的误报会不必要地限制对非敏感数据的访问或过早删除它们。如果存在大量漏报，系统可能无法限制敏感数据并强制执行适当的保留，这可能会违反合规性合同。&lt;/p&gt;&lt;p&gt;除了上述指标之外，我们还努力衡量一些额外的指标来跟踪工程进度。这些指标衡量以下观点：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;自动化质量&lt;/strong&gt;：我们想要衡量有多少自动标签被数据所有者/管理员等人类推翻。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;规模&lt;/strong&gt;：由于我们必须标记数十万个数据集，因此我们需要测量每天可以加载多少数据集。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;重新分类&lt;/strong&gt;：何时根据架构更改或何时引入/更新新标签对任何数据集重新分类。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;效率&lt;/strong&gt;：该举措基于数据爬行，计算成本较高。我们将跟踪 Uber 为每个数据元素（即列或表）自动化支付的费用。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;卓越运营&lt;/strong&gt;：开发过程和初始入职结束后，我们将跟踪需要多少运营开销，例如支持、错误修复和待命。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;存储系统覆盖范围&lt;/strong&gt;：如上所述，我们有不同的存储技术和主干网；跟踪有多少存储实例参与分类工作至关重要。 &lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-production-experiences"&gt;生产经验&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-centralized-data-collection-system"&gt;集中数据采集系统&lt;/h3&gt;&lt;p&gt;Uber 在各种基础设施中采用了多种存储系统，每个系统都有自己独特的特点。有些系统遵循特定的模式，而其他系统则不然。即使在基于模式的系统中，模式结构也可能存在很大的差异。&lt;/p&gt;&lt;p&gt;为了简化这些不同系统中存储的数据的分类，我们实施了一个强大的数据收集系统。该系统对来自不同存储系统的数据进行采样，并将它们整合到一个集中式数据湖中。在这种统一方法下，采样数据通过标准化工作流程进行处理。&lt;/p&gt;&lt;p&gt;主要优点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;一致的处理：&lt;/strong&gt;通过将数据集中到公共数据湖中，我们可以促进使用标准化工作流程进行处理。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;简化管理：&lt;/strong&gt;该方法简化了分类作业的管理，提供了集中控制点。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该策略不仅解决了存储系统的不同性质带来的挑战，而且还提高了数据处理和管理的效率。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-advancements-in-accuracy"&gt;准确性的进步&lt;/h3&gt;&lt;p&gt;自首次量产以来，DataK9 在过去几年中的准确性不断提高。我们采用两个关键指标来展示 DataK9 的整体准确性，如图 9 所示： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/tU27ocyWH8-RZAuYulUXribMOk2SxfJZryHDxaqmFB1ixYI4o8NxuolUVKCe3UgHCbTBT1g0nHBbT8fstC4laCj7koByY4rbwoENpB0_z8VmzynA3sXCJygI0HoFJZA2SKvJxofEN2bjg2z2FT7UVQM" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：准确度指标&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;黄金数据集的准确性：&lt;/strong&gt;在这种方法中，我们将标记结果与经过我们内部隐私专家仔细审查的黄金数据集进行比较。该指标反映了 DataK9 相对于隐私专家制定的标准的准确性和可靠性。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;所有者审查的数据集的准确性：&lt;/strong&gt;此外，我们通过将结果与数据所有者执行的分类进行比较来评估准确性。该指标可以深入了解 DataK9 与数据负责人定义的预期分类的一致性。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些指标是强有力的指标，说明了 DataK9 对提高准确性和检查 DataK9 在满足内部隐私标准和数据所有者期望方面的有效性的持续承诺。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-success-metrics-amp-funnel-analysis"&gt;成功指标和漏斗分析&lt;/h3&gt;&lt;p&gt;在追求成功的过程中，我们实施了一套全面的指标来衡量和优化我们的自动化流程。精心设计了详细的漏斗（见下文），以方便调查和识别每个步骤的差距。这个宝贵的工具提供了一种系统方法来跟踪和监控整体分类状态，使我们能够做出明智的决策和改进。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/N0Snd-Ysm8WFVIl1YLVm_d5dDfd-9AKdbOORGr05RIowrgMxD97wBlBFVGmOBCHkHAScS_dxHlC_QF5fXBq_ZBf3Z_VkI0hS7G6gBnpgyeohouXbch4ABmujjZxLdWGx4Mp-2-3x6TZ0c1iNT9T9zYA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 10：数据集分类漏斗。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;主要优点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;精细分析：&lt;/strong&gt;漏斗使我们能够将自动化流程分解为各个步骤，从而对每个阶段的性能进行精细分析。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;差距识别：&lt;/strong&gt;通过使用漏斗，我们可以有效地识别并缩小自动化流程中的差距，从而简化我们提高效率的工作。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可追溯性：&lt;/strong&gt;漏斗作为一种可靠的跟踪机制，提供对分类状态的实时洞察，并允许我们跟踪一段时间内的进度。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这种对成功指标和漏斗分析的细致方法强化了我们对持续改进的承诺，并使我们能够主动应对自动化流程中的挑战。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;Uber 的 DataK9 项目代表了一项开创性的努力，旨在通过实施人工智能和机器学习技术来解决大规模和现场级别的数据分类挑战。认识到数据分类对于隐私和安全举措的根本作用，Uber 采取了这一举措来自动化和简化流程。&lt;/p&gt;&lt;p class="has-small-font-size"&gt;&lt;em&gt;封面图片归属：&lt;/em&gt; &lt;a href="https://commons.wikimedia.org/wiki/User:MCruz_(WMF)"&gt;&lt;em&gt;MCruz (WMF)&lt;/em&gt;&lt;/a&gt;的“&lt;a href="https://commons.wikimedia.org/w/index.php?curid=38171185"&gt;&lt;em&gt;分类系统 2&lt;/em&gt;&lt;/a&gt; &lt;em&gt;”&lt;/em&gt;已获得&lt;a href="https://creativecommons.org/licenses/by-sa/4.0/?ref=openverse"&gt;&lt;em&gt;CC BY-SA 4.0&lt;/em&gt;&lt;/a&gt;&lt;em&gt;许可&lt;/em&gt;&lt;em&gt;。&lt;/em&gt;&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Apache®、Apache Hive、Hive、Apache Spark 和 Spark 是 Apache Software Foundation 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/em&gt;&lt;/p&gt;</description><pubDate>Thu, 09 May 2024 06:56:57 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/auto-categorizing-data-through-ai-ml/</guid></item><item><title>【From Predictive to Generative – How Michelangelo Accelerates Uber’s AI Journey】</title><link>https://www.uber.com/blog/from-predictive-to-generative-ai/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;在过去几年中，机器学习 (ML) 在 Uber 所有业务线的采用和影响都在加速。如今，机器学习在 Uber 的业务中发挥着关键作用，被用来制定关键业务决策，例如预计到达时间、乘客与司机匹配、Eats homefeed 排名和欺诈检测。&lt;/p&gt;&lt;p&gt;作为 Uber 的集中式 ML 平台，自 2016 年首次推出以来， &lt;a href="https://www.uber.com/blog/michelangelo-machine-learning-platform/" rel="noreferrer noopener" target="_blank"&gt;Michelangelo&lt;/a&gt;在推动 Uber ML 发展方面发挥了重要作用。它提供了一套涵盖端到端 ML 生命周期的全面功能，使 Uber 的 ML 从业者能够开发和产品化高-大规模的高质量机器学习应用程序。目前，Michelangelo 管理着大约 400 个活跃的机器学习项目，每月有超过 2 万个模型训练作业。目前有超过 5K 个模型正在生产中，峰值时每秒可提供 1000 万次实时预测。&lt;/p&gt;&lt;p&gt;如下图 1 所示，ML 开发人员经验是一个重要的倍增器，使开发人员能够提供现实世界的业务影响。通过利用米开朗基罗，Uber 的机器学习用例已经从简单的树模型发展到高级深度学习模型，并最终发展到最新的生成式人工智能。在这篇博客中，我们介绍了 Michelangelo 在过去八年中的演变，重点关注 Uber 机器学习开发人员体验的不断增强。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/7H03P6ohPRRzlipNe07kKr3cGsFo3FYOQ1XQNZZbipKWQ5_mLrCuIaDCMtSQyrTGSJ4P-hLG7y7Z_n4C4xIA7Way05VtOWqTigGi1Haq7bBehIOMMi2d7TEW833CMJpgqqXDwBSlq2mGoq_fK8tel14" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：ML 开发人员体验是实现 ML 业务影响的倍增器。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-journey-of-ai-ml-uber"&gt; Uber 的 AI/ML 之旅&lt;/h2&gt;&lt;p&gt;目前，Uber 在 70 多个国家的 10,000 多个城市开展业务，平台每天服务 2500 万次出行，每月活跃用户达 1.37 亿。机器学习几乎已融入 Uber 日常运营的各个方面。事实上，Uber 应用程序中的每一次交互都涉及幕后的机器学习。以骑手应用程序为例：当用户尝试登录时，机器学习用于检测欺诈信号，例如可能的帐户接管。在许多司法管辖区的应用程序中，机器学习被部署来建议目的地自动完成并对搜索结果进行排名。一旦选择了目的地，机器学习就会发挥多种功能，包括预计到达时间计算、行程价格计算、考虑安全措施的乘客与司机匹配以及行程路线选择。行程完成后，机器学习有助于检测支付欺诈、预防退款，并将其范围扩展到为客户服务聊天机器人提供支持。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/p3awCLhFgkOjDsk_T8R0DomPhWJWm9vkP8ZTb2VqKOHi7UN1Ous3e_wqGnM-CBBkOVBnw-pmFRYtF6Ik6kl9e31_t9k-BM6BGs9532Hc3b5u6Bej89QBOlJedgeT23t7mm-iTmTq8RRFKhCpMbWFrYY" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：实时 ML 支撑 Rider 应用程序用户流程。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;如图 2 所示，实时 ML 为骑手应用程序中的用户流程提供动力，对于 Eats 应用程序（以及许多其他应用程序）也是如此，如下图 3 所示。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/Yw8-VN8tnl7p9vyZHpX0l4Su9yIzWGHlF2f3mrYbi569DAiz2us-0FLr5Ti7be5HDUFEpyZrNg7SXfBi8edCm3FpklgTkxpr1jMyhuIkuM-oNrfcZpMUjP1BYMTfy3rhCP6OL98YjobFh6GkWR3v0h0" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：实时机器学习支撑 Eater 应用核心用户流程。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;回顾 Uber 机器学习的演变，可分为三个不同的阶段：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;strong&gt;2016 年至 2019 年：&lt;/strong&gt;在这个初始阶段，Uber 主要将预测机器学习用于表格数据用例。 XGBoost 等算法用于 ETA 预测、风险评估和定价等关键任务。此外，Uber 在自动驾驶汽车的 3D 映射和感知等关键领域深入研究了深度学习 (DL) 领域，因此需要在 GPU 调度和分布式训练方法（如 Horovod®）方面进行大量投资。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;2019 – 2023：&lt;/strong&gt;第二阶段共同推动高影响力机器学习项目采用深度学习和协作模型开发。重点是模型迭代作为 ML monorepo 中的代码，并支持 DL 作为米开朗基罗的一等公民。在此期间，超过60%的一级模型在生产中采用了深度学习，并显着提升了模型性能。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;从 2023 年开始：&lt;/strong&gt;第三阶段代表新一波生成式 AI 的最新发展，重点是改善 Uber 的最终用户体验和内部员工生产力（在&lt;a href="https://www.uber.com/blog/the-transformative-power-of-generative-ai/" rel="noreferrer noopener" target="_blank"&gt;之前的博客&lt;/a&gt;中进行了描述）。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/QNrwoFNrmVffQxsYS6KkqfXjHLJBBT1QHK99UO3o9KmMdC2t3DP_wUNIvUoU0dK2TOI4krdwKwb_EmV71O2Lm3vqqiYjyuzEwFq6oQZBVro17q1Xr45lpIPyEtaGpgYUEcVNXA60CxYwlJ7YJwFGJ28" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：Uber 从 2016 年到 2023 年的机器学习历程。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;在这一变革之旅中，米开朗基罗在提升机器学习能力和帮助团队构建行业领先的机器学习应用程序方面发挥着关键作用。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-michelangelo-1-0-2016-2019"&gt;米开朗基罗 1.0（2016 – 2019）&lt;/h2&gt;&lt;p&gt;当 Uber 于 2015 年踏上 ML 之旅时，应用科学家使用 Jupyter Notebooks™ 来开发模型，而工程师则构建定制管道以将这些模型部署到生产中。没有适当的系统来构建可靠且可重复的管道来大规模创建和管理训练和预测工作流程，也没有简单的方法来存储或比较训练实验结果。更重要的是，没有既定的路径可以在不创建自定义服务容器的情况下将模型部署到生产中。&lt;/p&gt;&lt;p&gt; 2016 年初，Michelangelo 推出，通过端到端系统标准化 ML 工作流程，使 Uber 的 ML 开发人员能够轻松地大规模构建和部署 ML 模型。它首先解决了可扩展模型训练和部署到生产服务容器的挑战（ &lt;a href="https://www.uber.com/blog/michelangelo-machine-learning-platform/" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;）。然后，构建了一个名为 Palette 的特征存储，以更好地管理和跨团队共享特征管道。它支持批量和近实时特征计算用例。目前，Palette 拥有超过 20,000 个功能，Uber 团队可以直接利用这些功能来构建强大的 ML 模型（ &lt;a href="https://www.infoq.com/presentations/michelangelo-palette-uber/" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;发布的其他关键 Michelangelo 组件包括但不限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;图库：&lt;/strong&gt;米开朗基罗的模型和机器学习元数据注册表，为所有类型的机器学习实体提供全面的搜索 API。 （ &lt;a href="https://openproceedings.org/2020/conf/edbt/paper_217.pdf" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;）&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Manifold：&lt;/strong&gt; Uber 的 ML 模型无关的可视化调试工具。 （ &lt;a href="https://www.uber.com/blog/manifold/?uclick_id=91e0edf5-abbe-49f9-b9ee-2a7c598a6a35" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;）&lt;/li&gt;&lt;li&gt; &lt;strong&gt;PyML：&lt;/strong&gt;一个加速 Python ML 模型原型设计、验证和生产周期的框架。 （&lt;a href="https://www.uber.com/blog/michelangelo-pyml/" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;扩展米开朗基罗的模型表示以实现大规模的灵活性。 （ &lt;a href="https://www.uber.com/blog/michelangelo-machine-learning-model-representation/" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;）&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Horovod&lt;/strong&gt;用于分布式训练。 （&lt;a href="https://www.uber.com/blog/horovod/" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;） &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-michelangelo-2-0-2019-2023"&gt;米开朗基罗 2.0（2019 – 2023）&lt;/h2&gt;&lt;p&gt;米开朗基罗的最初目标是在 Uber 引导机器学习并使之民主化。到 2019 年底，Uber 的大多数业务线都已将机器学习集成到他们的产品中。随后，米开朗基罗的重点开始从“让机器学习无处不在”转向“加倍投入高影响力的机器学习项目”，以便开发人员可以提升这些项目的模型性能和质量，从而为 Uber 带来更高的商业价值。考虑到这些项目的复杂性和重要性，需要更先进的机器学习技术，特别是深度学习，并且通常需要许多不同的角色（例如数据科学家和工程师）更快地协作和迭代模型，如图 5 所示这给米开朗基罗 1.0 带来了一些挑战，如下所列。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/2F31vZ3o80U_oyCz7LSHemUXQWNzYy6xLCkn4jIALAjnj83oO6Q8uAiCDOSo3YGDzJBCUOsgI6dKigsqOWqfmKnasgL2vQ3BQP8BOEJZkJBmpj9L4zk9sIMKaYVaHDTO6J7opoEBmGhpIz6OIGvGafU" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：ML 生命周期是迭代的，并且与许多不同的角色协作。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; &lt;strong&gt;1.缺乏全面的机器学习质量定义和项目分层&lt;/strong&gt;：与具有明确定义的质量标准和最佳实践的微服务不同，当时没有一致的方法来衡量全方位的模型质量。例如，许多团队只测量 AUC 和 RMSE 等离线模型性能，而忽略了在线模型性能、训练数据的新鲜度和模型再现性等其他关键指标。这导致模型性能的可见性很低、生产中的模型过时以及数据集覆盖率较差。&lt;/p&gt;&lt;p&gt;此外，重要的是要认识到机器学习项目在业务影响方面存在很大差异。由于缺乏独特的机器学习分层系统，导致在资源分配、支持和管理中断方面采用统一的方法，而不管项目的影响如何。这导致高影响力项目投资不足或没有得到应有的优先考虑。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;2. 对深度学习模型的支持不足：&lt;/strong&gt;直到 2019 年，Uber 的机器学习用例主要使用基于树的模型，这本质上不利于采用自定义损失函数、增量训练和嵌入等先进技术。相反，Uber 拥有适合训练 DL 模型的大量数据，但基础设施和开发人员体验方面的挑战阻碍了这一方向的进展。许多团队（例如 Maps ETA 和 Rider 激励团队）必须花费数月时间来开发自己的 DL 工具包，然后才能成功训练第一个版本的 DL 模型。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;3. 对协作模型开发的支持不足&lt;/strong&gt;：早期，大多数机器学习项目都是小规模的，并且从开始到生产仅由单个开发人员编写和迭代。因此，Michelangelo 1.0 并未针对高度协作的模型开发进行优化，并且 Michelangelo 1.0 UI 和 Jupyter Notebook 中的协作很困难，并且通常通过手动复制和合并来完成，而无需版本控制或分支。  此外，没有针对 UI 模型配置更改或笔记本编辑的代码审查流程，并且缺乏 ML 代码和配置的集中存储库导致它们分散在各个来源中。这些对我们的工程流程构成了重大威胁，并使跨众多机器学习项目的大规模模型探索变得困难。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;4. 碎片化的 ML 工具和开发人员体验：&lt;/strong&gt;自 2015 年以来，除了 Michelangelo 之外，Uber 的不同团队还为 ML 生命周期和用例的子集构建了许多 ML 工具，例如来自数据团队的&lt;a href="https://www.uber.com/blog/evolution-ds-workbench/" rel="noreferrer noopener" target="_blank"&gt;Data Science Workbench&lt;/a&gt; (DSW)，用于托管Jupyter Notebooks、来自 Marketplace 团队的用于 ML 工作流程编排和自动化的 ML Explorer，以及来自 Risk 团队的 uFlow/uScorer，专门用于来自其自己团队的训练和推理模型。为不同的模型类型开发 ML 模型也有不同的方法，例如，用于 SparkML 和 XGBoost 模型的 Michelangelo UI、用于 DL 模型的 Jupyter Notebook 以及用于基于 Python 的自定义模型的&lt;a href="https://www.uber.com/blog/michelangelo-pyml/" rel="noreferrer noopener" target="_blank"&gt;PyML&lt;/a&gt; 。启动一个机器学习项目通常需要在这种半隔离的工具之间不断切换，这些工具是用不同的 UI 模式和用户流程构建的，导致用户体验碎片化并降低了生产力。&lt;/p&gt;&lt;p&gt;为了应对这些挑战，米开朗基罗 2.0 将分散的 ML 平台重新架构为具有统一 UI 和 API 的单一连贯产品，用于端到端 ML 生命周期。 Michelangelo 2.0 有四个面向用户的主题：(1) 模型质量和项目分层，(2) 通过 Canvas 将模型迭代为代码，(3) DL 作为一流的平台公民，(4) 通过 MA 统一 ML 开发人员体验工作室。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-architectural-overview"&gt;架构概览&lt;/h3&gt;&lt;p&gt;米开朗基罗 2.0 以四个支柱为中心。在最底层，我们正在启用一个允许即插即用平台组件的架构。一些组件是内部构建的，其他组件可以是来自开源或第三方的最先进的商品。最重要的是迎合应用科学家和机器学习工程师的开发和生产经验。为了提高模型开发速度，我们正在简化开发体验和支持协作、可重用开发的技术。  我们相信这种方法将使我们能够在平台级别跟踪和执行合规性。  我们正在投资模型的安全部署和自动模型再训练等生产经验，以方便大规模维护和管理模型。最后，我们专注于模型的质量，并投资于能够在所有阶段衡量模型质量并系统地改进模型的工具。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/gRuNaUCrkkMDsG1LwyLo43lqxK0Sl_dtJXQU3o2NX2VKH1wPy9SOvlPbk91_8o6dOGEsbSQz336xH1u9Z_RVi5vfoS9A2TjQg5_T5sQ7-jCrMkfRrxL4supkxIoviPLMvO8Gs0iV0QA2O0p-rxUIk_g" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：米开朗基罗 2.0 架构的高级概念。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;以下是米开朗基罗2.0的一些架构设计原则：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;定义项目分层，并专注于高影响力的用例，以最大限度地提高 Uber 的机器学习影响力。为长尾机器学习用例提供自助服务，以便他们可以利用平台的强大功能。&lt;/li&gt;&lt;li&gt;大多数 ML 用例可以利用 Michelangelo 的核心工作流程和 UI，而 Michelangelo 还支持深度学习等高级用例所需的更多定制工作流程。&lt;/li&gt;&lt;li&gt;单片与即插即用。架构将支持不同组件的即插即用，但托管解决方案将仅支持其中的一部分以获得最佳用户体验。为高级用例带来您自己的组件。&lt;/li&gt;&lt;li&gt; API/代码驱动与 UI 驱动。遵循 API 优先原则，利用 UI 实现可视化和快速迭代。支持模型迭代作为版本控制和代码审查的代码，包括 UI 中所做的更改。&lt;/li&gt;&lt;li&gt;构建与购买决策。利用 OSS 或云或内部构建的一流产品。 OSS 解决方案可能优先于专有解决方案。请谨慎对待云解决方案的容量成本。&lt;/li&gt;&lt;li&gt;将最佳的 ML 实践（例如安全模型部署、模型再训练和平台中的功能监控）编入规范。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;该系统由三个平面组成，即控制平面、离线和在线数据平面。控制平面定义面向用户的 API 并管理系统中所有实体的生命周期。离线数据平面负责大数据处理的繁重工作，例如特征计算、模型训练和评估、离线批量推理等。在线数据平面处理实时模型推理和特征服务，供其他微服务使用。&lt;/p&gt;&lt;p&gt;控制平面采用相同的&lt;a href="https://github.com/cncf/tag-app-delivery/blob/163962c4b1cd70d085107fc579e3e04c2e14d59c/operator-wg/whitepaper/Operator-WhitePaper_v1-0.md" rel="noreferrer noopener" target="_blank"&gt;Kubernetes™ Operator 设计模式，&lt;/a&gt;实现模块化和可扩展性。 Michelangelo API 还遵循相同的&lt;a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md" rel="noreferrer noopener" target="_blank"&gt;Kubernetes API 约定&lt;/a&gt;，并对 ML 相关实体（如项目、管道、PipelineRun、模型、修订、推理服务器、部署等）的操作进行标准化。通过利用 Kubernetes API 机制（包括 API 服务器、 &lt;a href="https://etcd.io/" rel="noreferrer noopener" target="_blank"&gt;etcd&lt;/a&gt;和控制器）管理器中，所有 Michelangelo API 都可以以一致的方式访问，从而带来更加用户友好和简化的用户体验。此外，声明式 API 模式对于 Michelangelo 支持 GIT 存储库中的 UI 和代码变更也至关重要，稍后将详细介绍。&lt;/p&gt;&lt;p&gt;离线数据平面由一组 ML 管道组成，包括训练、评分、评估等，这些管道被定义为步骤的 DAG。 ML 管道支持中间检查点并在步骤之间恢复，以避免重复执行先前的步骤。步骤在 Ray™ 或 Spark™ 等框架之上执行。在线数据平面管理 RPC 服务和流处理作业，为在线预测、在线特征访问和近实时特征计算提供服务。&lt;br /&gt;&lt;/p&gt;&lt;p&gt;图7显示了米开朗基罗2.0系统的详细设计，它降低了工程复杂性，并简化了对其他基础设施组件的外部依赖。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/MqljT9LUabDAsMHNb1k6y5LqyILCQdzWU1zi1ZD_XWneCBiYqo3Wtoda2_ysExjD0prHflRC8yBVK5Cziy2VkrQHuThszXcgvWMS4CfSZDllePznu6UB_Jw_mOZE25UA4o5gPy46woAP9uSFXrJlctI" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：Michelangelo 2.0 的详细系统设计，包括离线、在线和控制平面。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-model-quality-and-project-tiering"&gt;模型质量和项目分层&lt;/h3&gt;&lt;p&gt;生产就绪的机器学习系统的开发和维护非常复杂，涉及模型生命周期的多个阶段和复杂的支持基础设施。通常，ML 模型会经历特征工程、训练、评估和服务等阶段。缺乏全面的 ML 质量测量导致 ML 开发人员对模型生命周期不同阶段的各种质量维度的了解有限。此外，这种差距阻碍了组织领导者就机器学习项目的质量和影响做出充分知情的决策。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/bIbKLbwB7em5FhgTLHym9OHRHcaORl4UASUzEquCX0O11RkyCoOCxYbiANmykUDdFUoAZGfX7EZ_kCLyeloxxy82D_gvWZX7aYpfQmVZWPb68632BR5YjLcCSSLOznLU8Yr-Ei7QbnqSuNYiuTyu33w" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：典型 ML 系统中的 ML 质量维度示例（黄色）。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;为了弥补这些差距，我们推出了模型卓越评分（MES），这是一个用于测量和监控模型生命周期每个阶段的关键维度和指标的框架，例如训练模型准确性、预测准确性、模型新鲜度和预测特征质量，确保采用全面、严格的方法大规模部署机器学习。该框架利用站点可靠性工程师 (SRE) 和 DevOps 专业人员在生产环境中管理微服务可靠性时常用的相同&lt;a href="https://en.wikipedia.org/wiki/Service-level_agreement" rel="noreferrer noopener" target="_blank"&gt;服务级别协议&lt;/a&gt;(SLA) 概念。通过与 SLA 工具集集成，MES 建立了衡量和确保 Uber ML 模型质量的标准。此外，MES 跟踪并可视化模型的合规性和质量，从而为整个组织的 ML 计划提供更清晰、更全面的视图。有关更多详细信息，请参阅&lt;a href="https://www.uber.com/blog/enhancing-the-quality-of-machine-learning-systems-at-scale/" rel="noreferrer noopener" target="_blank"&gt;MES 博客&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;为了区分高影响力和长尾用例，我们引入了定义明确的机器学习项目分层方案。该计划由四层组成，其中第一层是最高的。第 1 级项目由服务于核心出行和核心乘客流程中关键功能的模型组成，例如 ETA 计算、安全性和欺诈检测等。只有直接影响核心业务运营的模型才有资格获得第 1 级状态。相反，第四级项目通常包含实验性和探索性用例，直接业务影响有限。这种分层方案使我们能够就机器学习项目中断处理的资源分配、资源投资、最佳实践实施和合规性事务等方面做出明智的决策。它确保对每个项目的关注和资源投入与其相对优先级和影响相称。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-model-iterations-as-code-nbsp"&gt;将模型迭代作为代码&lt;/h3&gt;&lt;p&gt;为了提高 ML 开发人员的工作效率、促进无缝团队协作并提高 2020 年 ML 应用程序的整体质量，我们推出了 Project Canvas。该项目旨在将软件工程最佳实践应用于 ML 开发生命周期，实施版本控制，利用 Docker 容器的强大功能、集成 CI/CD 工具，并通过引入标准化 ML 应用程序框架来加快模型开发。 Canvas 的关键组件包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;strong&gt;ML 应用程序框架 (MAF)&lt;/strong&gt; ：预定义但可自定义的 ML 工作流程模板，为 ML 开发提供代码和配置驱动的方式，专为深度学习等复杂的 ML 技术量身定制。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;ML Monorepo&lt;/strong&gt; ：一个集中存储库，将所有 ML 开发事实来源存储为代码，具有强大的版本控制功能。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;ML 依赖管理&lt;/strong&gt;：使用 Bazel 和 docker 构建提供软件依赖管理。每个 ML 项目都有自己定制的 docker 镜像。除了软件依赖之外，模型训练和服务代码将被打包到一个不可变的 docker 镜像中，用于生产模型重新训练和服务。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;机器学习开发环境：&lt;/strong&gt;为机器学习开发人员提供一致的本地开发和远程生产执行环境，以便他们可以在本地测试和调试模型，然后在远程生产环境中运行模型，以实现快速模型迭代。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;ML 持续集成/持续交付&lt;/strong&gt;：针对主分支进行持续集成，并通过各种测试和验证将 ML 模型自动部署到 ML monorepo 主分支的生产环境。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;ML 工件管理：&lt;/strong&gt;为工件和沿袭跟踪提供支持。工件是 ML 对象，例如模型、数据集和评估报告及其相应的元数据。对象将存储在分布式存储中，元数据将被完全索引和搜索。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;MA Assistant (MAA)：&lt;/strong&gt;米开朗基罗的 AutoML 解决方案，用于自动模型架构搜索和特征探索/修剪。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/Teij0cWxZToDYuyzL5LIk0iUWeSr1N3cpFnCpJGVHg8M8Hj8twroleP_flTmf6kSCkgHPXcdcTBg8-wuGN2SoaA0squnLErPVSDf2xBqPV6bz9pFlvRRXQz56LOZfWrCau7nHkfqWeTCmxCoXS5eh_A" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：Canvas：简化端到端 ML 开发人员体验。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; Canvas 还通过利用 Bazel 和 docker 构建简化了 ML 依赖项管理。每个 ML 项目都会有其自定义的 docker 镜像，模型训练和服务代码将被打包到一个不可变的 docker 镜像中，用于生产模型重新训练和服务。此外，Canvas 为 ML 开发人员提供了一致的本地和远程开发环境，可以在本地测试和调试模型，然后在远程生产环境中运行模型以实现快速模型迭代。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-deep-learning-as-a-first-class-platform-citizen"&gt;深度学习作为一流平台公民&lt;/h3&gt;&lt;p&gt;采用自定义损失函数、增量训练和嵌入等先进技术带来了重大挑战。深度学习可以更灵活地应对这些挑战。此外，随着数据集变大，深度学习通常会表现出色，因为它可以利用更多数据来学习更复杂的表示。&lt;/p&gt;&lt;p&gt; 2019 年之前，Uber 的大多数 DL 模型都用于&lt;a href="https://www.uber.com/blog/machine-learning-model-life-cycle-version-control/" rel="noreferrer noopener" target="_blank"&gt;自动驾驶汽车&lt;/a&gt;（例如&lt;a href="https://proceedings.mlr.press/v87/yang18b/yang18b.pdf?uclick_id=91e0edf5-abbe-49f9-b9ee-2a7c598a6a35" rel="noreferrer noopener" target="_blank"&gt;3D 映射&lt;/a&gt;、感知）、计算机视觉（例如 &lt;a href="https://www.uber.com/blog/real-time-id-check/" rel="noreferrer noopener" target="_blank"&gt;驾驶员面部识别&lt;/a&gt;）和自然语言处理（例如&lt;a href="https://www.uber.com/en-AU/blog/cota/" rel="noreferrer noopener" target="_blank"&gt;客户痴迷&lt;/a&gt;）用例。然而，针对核心业务的深度学习模型非常少，特别是针对表格数据用例。阻碍深度学习采用的一个重要原因是米开朗基罗1.0缺乏端到端的深度学习支持。与基于树的模型不同，深度学习模型通常需要更复杂的机器学习平台支持，从特征转换和模型训练到模型服务和 GPU 资源管理。本节的其余部分将概述我们在 Michelangelo 2.0 中对深度学习支持的投资。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-feature-transformation"&gt;特征变换&lt;/h4&gt;&lt;p&gt;米开朗基罗 1.0 实现了用于特征转换的 DSL，例如在模型训练和服务路径中使用的标准化和分桶化。该转换与&lt;a href="https://www.uber.com/blog/michelangelo-machine-learning-model-representation/" rel="noreferrer noopener" target="_blank"&gt;Spark PipelineModel&lt;/a&gt;模型捆绑在一起，从而&lt;a href="https://developers.google.com/machine-learning/guides/rules-of-ml#training-serving_skew" rel="noreferrer noopener" target="_blank"&gt;消除了训练服务偏差的根源。&lt;/a&gt;然而，DSL 转换是作为 Spark 转换器实现的，无法在用于低延迟服务的 DL 模型的 GPU 上运行。在 Michelangelo 2.0 中，我们实现了一种新的 DL 原生转换解决方案，允许用户使用 Keras 或 PyTorch 运算符转换其特征，并为高级用户提供使用 Python 代码定义自定义特征转换的灵活性。与&lt;a href="https://blog.research.google/2017/02/preprocessing-for-machine-learning-with.html" rel="noreferrer noopener" target="_blank"&gt;TensorFlow 变换&lt;/a&gt;类似，变换图与 TensorFlow 或 TorchScript 中的模型推理图相结合，以在 GPU 上提供低延迟服务。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-model-training"&gt;模型训练&lt;/h4&gt;&lt;p&gt;Michelangelo 2.0 通过利用我们的分布式训练框架 Horovod，支持 TensorFlow 和 PyTorch 框架进行大规模深度学习模型训练。此外，我们还进行了以下改进，以实现更好的可扩展性、容错性和效率。&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;strong&gt;Ray 上的分布式 GPU 训练和调优。&lt;/strong&gt; （ &lt;a href="https://www.youtube.com/watch?v=gMT_ONmI9RM&amp;amp;list=PLzTswPQNepXmLUiL4F_1VHrPcCz1OeILw&amp;amp;index=47" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;）。从历史上看，Michelangelo 的模型训练是在 Spark 上运行的。然而，DL 给 Spark 带来了新的挑战，例如缺乏 GPU 执行器、mini-batch shuffle 和 all-reduce。 &lt;a href="https://horovod.readthedocs.io/en/stable/spark_include.html" rel="noreferrer noopener" target="_blank"&gt;Horovod on Spark&lt;/a&gt;使用 Spark 估计器语法封装了深度学习训练，并提供了与训练管道的轻松集成。然而，它也引入了许多操作复杂性，例如单独的集群作业、生命周期管理和故障场景。在 Michelangelo 2.0 中，我们用基于 Ray 的训练器取代了基于 Spark 的 XGBoost 和 DL 训练器，以实现更好的可扩展性和可靠性。我们还从内部超参数调整解决方案切换到 RayTune。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;具有自动缩放和容错功能的 Elastic Horovod&lt;/strong&gt; 。 （&lt;a href="https://www.uber.com/blog/horovod-ray/" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;）。  Elastic Horovod 允许分布式训练，在整个训练过程中动态扩展工作人员数量。现在，当机器来回工作时，工作人员可以在最小程度地中断的情况下继续培训。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;资源高效的增量培训&lt;/strong&gt;。深度学习的优点之一是能够使用额外的数据集增量训练模型，而无需从头开始训练。这显着提高了生产重新训练的资源效率，并增加了数据集覆盖范围以提高模型准确性。&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Canvas 中的声明式深度学习训练管道&lt;/strong&gt;。深度学习模型需要自定义模型代码和损失函数等。在 Canvas 中，我们将训练管道设计为声明式和可扩展的，以便用户插入自定义模型代码，例如估计器、优化器和损失函数，如图 9 所示。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/wq4mV9-lSpxnYgUrC91PzO7JaMnSawey2wir-Ai0odqHzIaTkMA8erWscsRHZl22fpCQvzipR86Tkw_jgzFs3jokhk86Zqnc2OfeY882_3ChONlnLYAtEQpMCi8u6lMAw9PS8oOD-0WmtSsbEvs1bZA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：Canvas 中深度学习模型的示例训练管道。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-model-serving"&gt;模特服务&lt;/h4&gt;&lt;p&gt;大多数采用深度学习的 Uber 一级 ML 项目对服务延迟非常敏感，例如地图 ETA 和 Eats homefeed 排名。此外，模型服务必须支持 TensorFlow 和 PyTorch DL 框架，但要从用户那里抽象出框架级细节。从历史上看， &lt;a href="https://github.com/uber/neuropod" rel="noreferrer noopener" target="_blank"&gt;Neuropod&lt;/a&gt;一直是 Michelangelo 中默认的深度学习服务引擎。然而，它缺乏持续的社区支持，并且正在被弃用。在 Michelangelo 2.0 中，我们将&lt;a href="https://github.com/triton-inference-server/server" rel="noreferrer noopener" target="_blank"&gt;Triton&lt;/a&gt;作为下一代模型服务引擎集成到我们的在线预测服务 (OPS) 中，作为新的 Spark 变压器。 Triton 是 Nvidia 开发的开源推理服务器，支持包括 TensorFlow、PyTorch、Python 和 XGBoost 在内的多种框架，它针对 GPU 进行了高度优化，可实现低延迟服务。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-gpu-resource-management"&gt; GPU资源管理&lt;/h4&gt;&lt;p&gt;深度学习训练和服务都需要大规模的 GPU 资源。如今，Uber 在本地数据中心和 OCI 和 GCP 等云提供商中管理着 5000 多个 GPU。这些 GPU 分布在多个区域、许多专区和集群中。计算集群正在从&lt;a href="https://kccna18.sched.com/event/GrTx/peloton-a-unified-scheduler-for-web-scale-workloads-on-mesos-kubernetes-min-cai-nitin-bahadur-uber" rel="noreferrer noopener" target="_blank"&gt;Peloton / Mesos&lt;/a&gt;迁移到&lt;a href="https://kccncna19.sched.com/event/Uaad/kubernetizing-big-data-and-ml-workloads-at-uber-mayank-bansal-min-cai-uber" rel="noreferrer noopener" target="_blank"&gt;Kubernetes&lt;/a&gt; 。为了最大限度地提高资源利用率，Uber 投资于不同团队之间的弹性 CPU 和 GPU 资源共享，以便每个团队都可以机会性地使用其他团队的闲置资源。在计算集群之上，我们跨多个 Kubernetes 集群构建了一个作业联合层，以隐藏区域、区域和集群详细信息，以实现更好的作业可移植性和轻松的云迁移。作业联合层采用与 Kubernetes 运算符相同的设计模式，并在 Michelangelo 的统一 API 框架中作为作业 CRD 控制器实现，如图 7 所示。目前，作业控制器支持 Spark 和 Ray 作业。&lt;/p&gt;&lt;p&gt;凭借 Michelangelo 2.0 中对深度学习的端到端支持，Uber 在不同业务线的深度学习采用方面取得了显着进步。在过去几年中，一级项目中的深度学习采用率从几乎为零增加到 60% 以上。例如， &lt;a href="https://www.uber.com/blog/deepeta-how-uber-predicts-arrival-times/" rel="noreferrer noopener" target="_blank"&gt;DeepETA&lt;/a&gt;模型拥有超过 1 亿个参数，训练次数超过 10 亿次。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-ma-studio-one-unified-web-ui-tool-for-everything-ml-uber"&gt; MA Studio – 一个统一的 Web UI 工具，适用于所有 ML @ Uber&lt;/h3&gt;&lt;p&gt;为了解决上述机器学习开发人员体验中的挑战，开发了 Michelangelo (MA) Studio，将现有的 Michelangelo 产品和新建的平台功能统一到一个用户旅程中，通过完全重新设计的 UI 和 UX 提供无缝的用户体验。 MA Studio 提供了简化的用户流程，涵盖了 ML 旅程的每一步，从特征/数据准备、模型训练、部署，一直到生产性能监控和模型 CI/CD，全部集中在一个地方，以提高 ML 开发人员的工作效率。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/23NZpcegPdWpU-kpA3971k3KKYGxjh-AMVlljf26FeKV1eAga8tCkU3vuZCgWOwlDYwDbkWXFJ0wDX-8DDsXKBGT1-ucOZbA375Pg7aectkscLfD01kJbB0EEp5vX1LSQ4ba6NhbS_N1fpX89-Dit9Y" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 10：MA Studio 项目登陆页面涵盖端到端 ML 开发生命周期。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; MA Studio 拥有一系列额外优势：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;版本控制和代码审查&lt;/strong&gt;：所有与 ML 相关的代码和配置均受版本控制，所有更改都经过代码审查流程，包括从 UI 创建的模型。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;现代化的模型部署堆栈&lt;/strong&gt;：安全和增量的区域部署、自动回滚触发器和生产运行时验证。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;内置统一的ML可观测性工具包&lt;/strong&gt;：模型性能监控、特征监控、在线/离线特征一致性检查和MES。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;统一的 ML 实体生命周期管理&lt;/strong&gt;：用户受益于直观的 UI 和结构良好的用户流程，用于管理从模型和管道到数据集和报告的所有 ML 实体。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;增强的调试功能&lt;/strong&gt;：MA Studio 增强了调试功能并加速了 ML 管道故障的恢复。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/v2Dr41DHAjWT4JcMTHMRZ-EFv51edbx8RPw4BJ0MsqrnNAlI0lKoZJ-ZGRvUAZ5ez9VjNeKizUBwq-Hlxzp3uVs9i4NahPqDmgI9bOrJyBM_MC1NZjz7FD2Q46MJ_H32lP6VN3zqgEeeghht_r3mdrk" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 11：适用于标准和高级 ML 用例的 MA Studio 和 Canvas。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;对于 Uber 的任何机器学习需求，您只需要两个工具：Canvas 和 MA Studio。 MA Studio 的用户友好型 UI 涵盖了标准 ML 工作流程，可促进 XGB 模型训练和标准模型重新训练流程等任务，而无需编写任何代码。在处理更复杂的场景时，例如深度学习训练或定制的再训练流程，Canvas 是首选工具。无论您是通过 Canvas 还是 UI 构建管道，您都可以无缝执行和管理这些管道、部署经过训练的模型以及监控和调试模型性能 - 所有这些都可以通过 MA Studio UI 进行。值得注意的是，所有模型代码和相关配置现在都受到版本控制，任何更改都经过细致的代码审查过程，这极大地提高了 Uber 生产中的 ML 应用程序的质量。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-generative-ai-2023-now"&gt;生成式人工智能（2023 年至今）&lt;/h2&gt;&lt;p&gt;生成式人工智能的最新进展，特别是在大语言模型（LLM）领域，能够从根本上改变我们通过自然语言与机器的交互。 Uber 的多个团队正在积极研究使用法学硕士来通过助理提高内部生产力，通过自动化简化业务运营，并通过神奇的用户体验改进最终用户产品，同时解决&lt;a href="https://en.wikipedia.org/wiki/Wikipedia:Large_language_models" rel="noreferrer noopener" target="_blank"&gt;与使用法学硕士相关的问题&lt;/a&gt;。图 12 显示了 Uber 这三类生成式 AI 用例的潜在价值。 &lt;a href="https://www.uber.com/blog/the-transformative-power-of-generative-ai/" rel="noreferrer noopener" target="_blank"&gt;了解更多&lt;/a&gt;。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/ymra4p74-37pbRET_WeL_zvyEI6I9LOg8RICp0dVRQYBEYEllRz9psRc7omJcLe6ohyJrEztIFvOK7egSKiev_hgSpI8L4CmZ_pntoRdOOaJT9DAAgWWOMonlGcLDZl0oC3OpEs21Te5R-hr7KLdG-I" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 12：Uber 的三类生成人工智能用例。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;为了开发生成式人工智能应用程序，团队需要通过第三方 API 访问外部法学硕士和/或内部托管的开源法学硕士。这是因为外部模型在需要常识和复杂推理的任务中具有卓越的性能，同时通过利用丰富的专有数据，我们可以微调开源模型，以在以 Uber 为中心的任务上实现高水平的准确性和性能，成本的一小部分和更低的延迟。这些经过微调的开源模型由内部托管。&lt;/p&gt;&lt;p&gt;因此，我们开发了 Gen AI Gateway，为团队提供统一的界面，以遵守安全标准和保护隐私的方式访问外部法学硕士和内部托管的法学硕士。 Gen AI 网关的一些功能包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;记录和审计：&lt;/strong&gt;确保全面的跟踪和问责。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;成本护栏和归因：&lt;/strong&gt;在归因使用情况的同时管理费用，并对过度使用发出警报。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;安全和政策护栏：&lt;/strong&gt;确保法学硕士的使用符合我们的内部准则。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;个人身份信息 (PII) 编辑：&lt;/strong&gt;对个人数据进行识别和分类，并在将输入发送到外部法学硕士之前对其进行编辑。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了加速 Uber 生成式 AI 应用程序的开发，我们对 Michelangelo 进行了扩展，以支持完整的 LLMOps 功能，例如微调数据准备、即时工程、LLM 微调和评估、LLM 部署和服务以及生产性能监控。一些关键组件包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;模型目录包含一系列预构建且随时可用的 LLM，可通过第三方 API（例如 GPT4、Google PaLM）或 Michelangelo 上内部托管的开源 LLM（例如 Llama2）访问。用户可以在目录中探索有关这些法学硕士的广泛信息并启动各种工作流程。这包括在 MA Studio 中微调模型或将模型部署到在线服务环境。该目录提供了多种预训练模型的选择，增强了平台的多功能性。&lt;/li&gt;&lt;li&gt; LLM 评估框架使用户能够比较不同方法的 LLM（例如，内部与带有提示的 3P 与经过微调的 3P），并通过提示和模型的迭代来评估改进。&lt;/li&gt;&lt;li&gt; Prompt Engineering Toolkit 允许用户创建和测试提示、验证输出并将提示模板保存在集中存储库中，并具有完整的版本控制和代码审查流程。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了实现经济高效的 LLM 微调和低延迟 LLM 服务，我们对 Michelangelo 训练和服务堆栈实施了多项重大增强功能：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;与 Hugging Face 集成&lt;/strong&gt;：我们利用&lt;a href="https://huggingface.co/models" rel="noreferrer noopener" target="_blank"&gt;Hugging Face Hub&lt;/a&gt;上提供的开源 LLM 以及&lt;a href="https://huggingface.co/docs/peft/index" rel="noreferrer noopener" target="_blank"&gt;PEFT&lt;/a&gt;等相关库，为 LLM 实现了基于 Ray 的培训器。经过微调的 LLM 和相关元数据存储在 Uber 的模型存储库中，可从模型推理基础设施访问该存储库。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;启用模型并行性&lt;/strong&gt;：米开朗基罗之前不支持训练深度学习模型的模型并行性。这一限制将可训练模型的大小限制在可用 GPU 内存范围内，例如，在 16 GB GPU 上理论上最多允许 40 亿个参数。在更新的 LLM 培训框架中，我们集成了 Deepspeed 以实现模型并行性。这一突破消除了 GPU 内存限制，并允许训练更大的深度学习模型。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;弹性 GPU 资源管理：&lt;/strong&gt;我们使用 Michelangelo 作业控制器在 GPU 上配置 Ray 集群。此规定允许在本地可用的最强大的 GPU 上训练 LLM 模型。此外，这种集成为未来使用云 GPU 进行扩展奠定了基础，增强了可扩展性和灵活性。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;利用米开朗基罗提供的这些平台功能，Uber 的团队正在积极开发由 LLM 驱动的应用程序。我们期待尽快分享我们在法学硕士生产化方面的进展。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;机器学习已发展成为 Uber 关键业务领域的基本驱动力。本博客深入探讨了 Uber 机器学习平台 Michelangelo 八年来的变革历程，强调了机器学习开发人员体验的显着增强。这一旅程分为三个不同的阶段：2016 年至 2019 年表格数据预测机器学习的基础阶段，2019 年至 2023 年逐步转向深度学习，以及最近从 2023 年开始涉足生成人工智能。&lt;/p&gt;&lt;p&gt;在构建如此复杂的大规模端到端机器学习平台、支持 Uber 规模的机器学习用例方面，我们吸取了重要的经验教训。主要要点包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;建立集中式机器学习平台，而不是让各个产品团队构建自己的机器学习基础设施，可以显着提高中型或大型公司内的机器学习开发效率。理想的 ML 组织结构包括一个集中的 ML 平台团队，并辅以嵌入每个产品团队的专门数据科学家和 ML 工程师。&lt;/li&gt;&lt;li&gt;以统一的方式提供基于 UI 和代码/配置驱动的用户流对于提供无缝的 ML 开发体验至关重要，尤其是对于 ML 开发人员对开发工具的偏好因不同群体而有很大差异的大型组织。&lt;/li&gt;&lt;li&gt;事实证明，为大多数用户提供具有预定义工作流模板和配置的高级抽象层，同时允许高级高级用户直接访问低级基础设施组件以构建定制管道和模板的策略是有效的。&lt;/li&gt;&lt;li&gt;以模块化方式设计平台架构，以便每个组件都可以通过即插即用的方式构建，从而可以快速采用开源、第三方供应商或内部的最先进技术发展。&lt;/li&gt;&lt;li&gt;虽然深度学习在解决复杂的机器学习问题方面被证明是强大的，但挑战在于支持大规模深度学习基础设施并维护这些模型的性能。仅当深度学习的优点符合特定要求时才使用它。 Uber 的经验表明，在一些情况下，XGBoost 在性能和成本方面都优于 DL。&lt;/li&gt;&lt;li&gt;并非所有机器学习项目都是一样的。拥有清晰的机器学习分层系统可以有效指导资源和支持的分配。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt; Michelangelo 的使命是为 Uber 的 ML 开发人员提供一流的 ML 功能和工具，以便他们能够快速构建、部署和大规模迭代高质量的 ML 应用程序。作为人工智能平台团队，我们提供深入的机器学习专业知识，推动机器学习技术的标准化和创新，与合作伙伴团队建立信任和协作，培养充满活力的机器学习文化，从而使机器学习得到充分利用并发挥其最大潜力。我们坚定不移地致力于这一使命，我们对前方充满希望的未来充满热情。&lt;/p&gt;&lt;p&gt;如果您有兴趣加入我们这个令人兴奋的事业，请查看我们的&lt;a href="https://www.uber.com/us/en/careers/" rel="noreferrer noopener" target="_blank"&gt;招聘网站&lt;/a&gt;以了解空缺职位。此外，我们期待与 AI/ML 领域的其他团队合作，建立强大的 ML 社区，共同加速 AI/ML 技术的进步。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Apache®、Apache Spark、Spark 和星形徽标是 Apache Software Foundation 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Horovod 和 Kubenetes 是 Linux Foundation® 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Linux Foundation® 的认可。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Ray 是 Anyscale, Inc 在美国和/或其他国家/地区的注册商标或商标。&lt;/p&gt;</description><pubDate>Thu, 02 May 2024 09:46:07 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/from-predictive-to-generative-ai/</guid></item></channel></rss>