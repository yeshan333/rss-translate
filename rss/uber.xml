<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>优步工程博客</title><link>https://www.uber.com/blog/engineering</link><description>Uber 工程背后的技术 - 由 RSSHub 用爱制作(https://github.com/DIYgod/RSSHub)</description><lastBuildDate>Tue, 02 Jul 2024 03:05:31 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>【Introduction to Kafka Tiered Storage at Uber】</title><link>https://www.uber.com/blog/kafka-tiered-storage/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;Apache Kafka® 是 Uber 技术堆栈的基石。它在支持多个关键用例方面发挥着重要作用，并且是 Uber 批处理和实时系统的基础。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXePSpSp72unfaVqK7tofbbbOpMaZLJ7qYJ2Es-Chg3CHBeZ9kcJDZ9ouvPRYs-CarI8bAqXs2459rJ0_QrsgBaUwqikE5fwYSianNkl1u6Ehbjz_yH6XuWJGn54P5kCaRSaBrCgeVPN4q2QC_RDu9ag1YgU?key=kis14CJAvWJjUiCdmN0jHg" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：Uber 的数据管道。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; Kafka 将消息存储在代理本地存储上的仅附加日志段中。每个主题都可以根据大小或时间配置目标保留。即使各个消费应用程序由于多种原因出现故障或变慢，它也可以保证用户在保留期限或大小内消费数据。集群上的总存储取决于主题分区总数、生产吞吐量和保留配置等因素。 Kafka 代理通常需要更大的存储来支持代理上托管的所需主题分区。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-motivation-background-behind-project"&gt;项目背后的动机/背景&lt;/h3&gt;&lt;p&gt;Kafka 集群存储通常通过向集群添加更多代理节点来扩展。但这也为集群增加了不必要的内存和 CPU，与将旧数据存储在外部存储中相比，使得整体存储成本效率较低。由于存储和处理的紧密耦合，具有更多节点的更大集群也会增加部署复杂性并增加运营成本。因此，它带来了与可扩展性、效率和操作相关的几个问题。&lt;/p&gt;&lt;p&gt;我们提出了 Kafka 分层存储（ &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage" rel="noreferrer noopener" target="_blank"&gt;KIP-405&lt;/a&gt; ）来避免代理中存储和处理的紧密耦合。它提供两层存储，称为本地存储和远程存储。这两个层可以根据各自的用例有各自的保留策略。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdrkDm5z8lSbIzR0Xure8R4qrXa8JqczXMcNyQs17yede4tKZScrbVWTc4PjScxs-k_qrcks2cLmf2nOJi9x4tf2Zyzyql2Ql7jA3Ty4qNQoth7NeTL9itjkQnaJKIwm3zZVYUgYXx_2yr4lgyAF-9eLr-i?key=kis14CJAvWJjUiCdmN0jHg" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：Kafka 代理与分层存储的端到端交互。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-goals"&gt;目标&lt;/h2&gt;&lt;p&gt;以下是我们为分层存储设定的主要目标：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;将存储扩展到代理之外&lt;ul&gt;&lt;li&gt;内存/页面缓存&lt;/li&gt;&lt;li&gt;本地存储&lt;/li&gt;&lt;li&gt;远程存储支持（包括云/对象存储，如 S3/GCS/Azure）&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;类似于本地存储的持久性和一致性语义&lt;/li&gt;&lt;li&gt;最新数据和历史数据的读取隔离&lt;/li&gt;&lt;li&gt;客户无需进行任何更改&lt;/li&gt;&lt;li&gt;轻松调整和配置集群&lt;/li&gt;&lt;li&gt;提高运营和成本效率&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-architecture"&gt;建筑学&lt;/h2&gt;&lt;p&gt;启用分层存储的 Kafka 集群配置有本地和远程两层存储。本地层是代理的本地存储，当前存储段。新的远程层是扩展存储，例如HDFS/S3/GCS/Azure。这两个层都将根据大小和时间具有各自的保留配置。本地层的保留期可以从几天显着缩短到几个小时。远程层的保留期可能更长——几天，甚至几个月。对延迟敏感的应用程序进行尾部读取，并从本地层进行满足，利用 Kafka 高效的页面缓存利用率进行数据检索。另一方面，诸如回填或从故障中恢复的应用程序需要比本地可用数据更旧的数据，这些应用程序是从远程层提供服务的。&lt;/p&gt;&lt;p&gt;这种方法可以实现 Kafka 集群中存储的可扩展性，而无需依赖内存和 CPU 资源，从而将 Kafka 转变为可行的长期存储选项。此外，它还减少了 Kafka 代理的本地存储负担，从而减少了恢复和重新平衡期间要传输的数据。在远程层中可访问的日志段不需要在代理上恢复，并且可以直接从远程层访问。它消除了在延长保留期限时扩展Kafka集群存储和添加新节点的必要性。此外，它允许显着延长数据保留时间，而不需要单独的数据管道将数据从 Kafka 传输到外部存储（许多当前设置中的常见做法）。&lt;/p&gt;&lt;p&gt;分层存储将主题分区的日志分为两个不同的逻辑组件，称为本地日志和远程日志。本地日志包含本地日志段的列表，远程日志包含远程日志段的列表。远程日志子系统将每个主题分区的合格段从本地存储复制到远程存储。当段的结束偏移量小于分区的&lt;em&gt;LastStableOffset&lt;/em&gt;时，该段就有资格被复制。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdDJEudzpCrGDSR9yN0sNZ5YU_AM1ExXihNssXH0d5SGi01nOJ4R6xY0yY7frm6ESriC5o6XFiqQMVSCVDWpRK0l6nFxaF8CBCdY0ZpN1beZUsmqpSe4VragjX8kjUjh5VXGKMD-g2i9GMOaIJ99if2dJkj?key=kis14CJAvWJjUiCdmN0jHg" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：本地日志偏移量和远程日志偏移量。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt; Lz = 本地日志结束偏移量&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;Lx = 本地日志起始偏移量&lt;/td&gt;&lt;td&gt;Ly = 最后稳定偏移量(LSO)&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt; Ry = 远程日志结束偏移量&lt;/td&gt;&lt;td&gt;Rx = 远程日志起始偏移量&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;em&gt;Lz &amp;gt;= Ly &amp;gt;= Lx 且 Ly &amp;gt;= Ry &amp;gt;= Rx&lt;/em&gt; &lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; Apache Kafka 存储子系统维护主题分区的本地和远程日志段的上述偏移量约束。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcnNa5SMjEkpYEOgrEV8WQaKzXNhUFy5I1iuFKcHifODuPUg26arhCP8wvWpPsm7onOA8jTn2IS7_tTF9VXmg2NHC2p5IPSFLXw39fP8b4c47ksowG9dYI-iyFHE2szvRfNMn-QBQc4s_lgOg0tMYH3sKw?key=kis14CJAvWJjUiCdmN0jHg" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：Kafka 分层存储组件的高级架构。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;上图给出了带有新引入组件的新架构的高级概述：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;远程存储管理器&lt;/li&gt;&lt;li&gt;远程日志元数据管理器&lt;/li&gt;&lt;li&gt;远程日志管理器&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们在存储层中引入了两个可插入组件，称为&lt;em&gt;RemoteStorageManager&lt;/em&gt;和&lt;em&gt;RemoteLogMetadataManager&lt;/em&gt; 。这些可以由开发人员根据他们的目标存储系统来实现，并插入到他们的 Kafka 环境中。&lt;/p&gt;&lt;p&gt; &lt;em&gt;RemoteStorageManager&lt;/em&gt;接口提供远程日志段的操作，包括从远程存储复制、获取和删除。&lt;/p&gt;&lt;p&gt; &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt;接口提供了具有强一致语义的远程日志段元数据的生命周期操作。有一个使用内部主题的默认实现。如果用户打算使用另一个系统来存储远程日志段元数据，则可以插入其实现。&lt;/p&gt;&lt;p&gt; &lt;em&gt;RemoteLogManager&lt;/em&gt;是一个逻辑层，负责管理远程日志段的生命周期。包括了：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;将段复制到远程存储&lt;/li&gt;&lt;li&gt;清理远程存储中过期的段&lt;/li&gt;&lt;li&gt;从远程存储中获取数据&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;它还在需要时使用可插拔的远程存储组件。每个远程日志段都使用名为&lt;em&gt;RemoteLogSegmentId&lt;/em&gt;的唯一标识符进行标识，即使对于相同的主题分区和偏移量也是如此。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-copying-segments-to-remote-storage"&gt;将段复制到远程存储&lt;/h3&gt;&lt;p&gt;每个主题分区将数据存储在逻辑日志中，其中包含一系列物理日志段以及相应的辅助文件，例如段索引、生产者状态快照和领导者纪元检查点。每个分区副本都会创建这些日志段，将它们刷新到磁盘，并根据基于大小或时间的段滚动配置滚动该段。如果日志段的结束偏移量小于分区的&lt;em&gt;最后稳定偏移量&lt;/em&gt;，则该日志段是合格的。充当主题分区领导者的代理负责将符合条件的日志段复制到远程存储。它将日志段按顺序从最早的段复制到最新的段。它使用&lt;em&gt;RemoteStorageManager&lt;/em&gt;来复制段及其索引，如偏移量、时间戳、生产者快照及其各自的领导者纪元缓存。它还添加和更新&lt;em&gt;RemoteLogMetadataManager&lt;/em&gt;中的条目以及每个复制段的相应状态。&lt;/p&gt;&lt;p&gt;下图显示了通过维护本地和远程日志段来复制段的顺序： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcf2ufqsgcmWb4xf9M4813H55wCn9NC_n8HxCRK5nOT12LvqY5GNmRP_Rh4fqfiDk0SYdJ-63XaxZU5bTrleU-Ap77XBl0eyvjYc1_RIME_6AxlIGXWu9oLOoa3j9PQWyICHXjeOqISivV5Rcx2AhuAHGaU?key=kis14CJAvWJjUiCdmN0jHg" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：上图描述了主题分区的日志段及其各自的起始偏移量。在启用分层存储之前，远程存储中不会有任何段。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXc26wPlPeq7XR91GrM_6-QfWh0y6rKGCpGvA1islRticBFGAx33pR0Wm5cMl8OZSoDFm1RNKtpNcRKlj6Bcvuke-cdXBhNEGImxFphNDUBYoI3zb0XTYUek87oPOzV7OfcLoO86FkTeqyFrgFZpfzmAKT0?key=kis14CJAvWJjUiCdmN0jHg" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：上图描述了在为该主题启用分层存储后，合格的段开始复制到远程存储。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-full"&gt;&lt;img alt="" class="wp-image-1091633" height="333" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png" width="899" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：上图描述了根据本地保留配置删除了本地存储中的一些段。我们可以看到偏移量 300 之前的段已被删除，但这些段在远程存储中可用。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-cleaning-up-of-remote-segments"&gt;清理远程段&lt;/h3&gt;&lt;p&gt;如前所述，每个主题都会根据本地数据和远程数据的大小和时间进行保留配置。通过专用线程池计算符合条件的段，定期清理远程数据。这与本地日志段的异步清理不同。删除主题时，远程日志段的清理是异步完成的，不会阻塞现有的删除操作或重新创建新主题。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXczW4_RY_MyEEv6A1X0Rw2k7Yr-bPzt139veWuSaeGKqD_27xKyhqivZW609v4GUADtafNrZBmdzC9S9xj72tOTtqbKl9n_ivg9vkIdTJb4Lt7sK7I6UNt20kjrDUP2dwODaVr7rERXZgMfeazr9nxKJhe8?key=kis14CJAvWJjUiCdmN0jHg" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：上图描述了基于完整日志保留配置的远程日志段清理。此处，偏移量 200 之前的段已被删除。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-fetching-segments-from-remote-storage"&gt;从远程存储中获取段&lt;/h3&gt;&lt;p&gt;当接收到消费者获取请求并且该请求仅在远程存储中可用时，则使用专用线程池来提供服务。如果目标偏移量在代理的本地存储中可用，则使用现有的本地获取机制提供服务。因此，代理将本地读取与远程读取分开，并且它们不会互相阻塞。&lt;/p&gt;&lt;p&gt; &lt;em&gt;RemoteLogManager&lt;/em&gt;通过使用&lt;em&gt;RemoteLogMetadataManager&lt;/em&gt;查看元数据存储，根据所需的偏移量和领导纪元确定目标远程段。它使用&lt;em&gt;RemoteStorageManager&lt;/em&gt;查找段内的位置并开始获取所需的数据。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfCCN3aludPERABf77NGITGxCPFcslvI11RammENhBCFoxUSl4XtWKzILkalB2GRWE4MO6WxBxw0QWLV8shK8Y1IVbUKUAQueS3mnZLbVx1E-T_rq_udar088WHjkWVIEt7xhf2xq5tCNBwZrsk4PuzIli8?key=kis14CJAvWJjUiCdmN0jHg" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：远程获取路径。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-follower-replication"&gt;追随者复制&lt;/h3&gt;&lt;p&gt;追随者从领导者复制数据以成为同步副本。他们需要作为领导者维护一系列日志段中的消息沿袭。如果需要维持消息顺序，他们还可以截断段。&lt;/p&gt;&lt;p&gt;使用分层存储，追随者副本需要复制领导者本地存储上可用的段。每个日志还需要辅助数据，例如领导者纪元状态和生产者 ID 快照。因此，追随者需要在开始从领导者那里获取任何消息之前构建这些辅助数据。 follower fetch 协议确保维护所有副本之间消息的一致性和顺序，而不管集群中的更改（如代理替换、故障等）。如果您有兴趣了解增强型 follower fetch 协议的内部工作原理，您可以阅读&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage#KIP405:KafkaTieredStorage-FollowerReplication" rel="noreferrer noopener" target="_blank"&gt;原始文档&lt;/a&gt;以了解详细设计以及它如何处理多种场景。&lt;/p&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;在这篇博客中，我们介绍了 Uber 分层存储的简介和高级架构。如果您对更多细节感兴趣，可以阅读&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage" rel="noreferrer noopener" target="_blank"&gt;KIP-405&lt;/a&gt;中的详细设计。大部分工作是与 Apache Kafka 社区合作完成的。此功能的主要部分可在 Apache Kafka 3.6.0 中提前访问。  该功能已分别在不同的工作负载下在生产环境中运行了约 1-2 年。在本博客系列的下一部分中，我们将介绍我们的生产经验以及它如何帮助我们提高集群的可靠性、可扩展性和效率。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Apache®、Apache Kafka™ 和 Kafka™ 是 Apache Software Foundation 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/p&gt;</description><pubDate>Mon, 01 Jul 2024 10:58:33 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/kafka-tiered-storage/</guid></item><item><title>【Modernizing Logging at Uber with CLP (Part II)】</title><link>https://www.uber.com/blog/modernizing-logging-with-clp-ii/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;这是我们系列的第二部分，详细介绍了使用&lt;a href="https://github.com/y-scope/clp" rel="noreferrer noopener" target="_blank"&gt;CLP&lt;/a&gt;实现 Uber 日志基础设施的现代化。 &lt;a href="https://www.uber.com/en-US/blog/reducing-logging-cost-by-two-orders-of-magnitude-using-clp" rel="noreferrer noopener" target="_blank"&gt;在上一篇博客中&lt;/a&gt;，我们描述了如何将 CLP 的压缩算法分为两个阶段：(1) 分布式、基于行的流式压缩，在每个容器或主机上生成压缩的中间表示，以及 (2) 全列压缩为更高效的存档。我们开发了一个使用流压缩的 Log4j 附加程序，并将其集成到我们的 Spark 平台中。这带来了相当大的压缩比（169:1），有助于解决因写入大量日志数据而导致的 SSD 烧坏问题，同时允许我们将日志保留期延长 10 倍。&lt;/p&gt;&lt;p&gt;我们与 CLP 的开发人员合作，进一步开发了一种创新的端到端系统，用于管理 Uber 各种数据和机器学习平台上的非结构化日志。许多日志管理系统，包括&lt;a href="https://www.uber.com/blog/logging/" rel="noreferrer noopener" target="_blank"&gt;上一篇博客&lt;/a&gt;中描述的系统，往往只关注搜索和聚合，这对于开发人员引导调试会话很有用（例如，定位错误事件或检测在某个时间点发生的异常） 。但是，要了解错误发生的方式和原因，开发人员需要进一步查看导致该事件的日志序列。因此，搜索只有与方便的日志文件查看相结合才有用，而这一功能经常被现有工具所忽视。我们的新系统包括直接对压缩日志进行高级日志查看和可编程分析，从而使用 CLP 释放文本日志的全部潜力。  下图 1 显示了我们当前的端到端部署。本博客中描述的大多数核心工具和基本功能现在都是&lt;a href="https://github.com/y-scope/clp" rel="noreferrer noopener" target="_blank"&gt;开源的&lt;/a&gt;。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfssVNYjd66JKnkJRxGEC8980IxP8rDsweshb_36DETnG5pGsONCOeY_BJeGEtc4pPq0XZRt7HXSfRmVnLxKn_7_ZkdsZFIJhn5DMsFKPSDxT2qZLPJ8oZEp37_5j2LZ9rs35_WMiWhU9L8pCWB1A2WmraD?key=6KS8UuwM_zrmkURjL-jcyQ" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：Uber 当前部署的 CLP 生态系统。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-unstructured-amp-semi-structured-logs-their-role-and-associated-challenges"&gt;非结构化和半结构化日志：它们的作用和相关挑战&lt;/h2&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXeND5RFoGztFr9Rw7LDu3h96JyG7BnwUrW5bSYIdonxvvbQdidi3IOtd3WaCjGemEh0U3zZsXlfil_8YjtnRdUWpUv6caVAI3gJwX7wUeh3GW79mVzmpcU5AqG0pYFIJZXH7BD0Ap5DvWoMkJu5vr-1E3PM?key=6KS8UuwM_zrmkURjL-jcyQ" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：Uber 日志的多样性以及适合处理每种类型的系统。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;在 Uber，日志多种多样，并且呈现出不同程度的结构，如上图 2 所示。每个非结构化或半结构化日志事件都由包含与变量值交织在一起的消息的单个字符串主导。与各种形式的结构化日志相比，自由文本日志不仅方便且具有普遍的文化接受度，而且它们的用途也不同。开发人员通常使用此类日志来描述系统的顺序操作，以便他们能够通过某些上下文重建执行流程。相比之下，大多数结构化日志都具有跟踪点的属性，用于记录某些指标、重要的奇异事件和周期性统计信息。一般来说，结构化日志事件大多彼此独立，而非结构化日志事件根据开发人员想要跟踪的代码路径共同记录执行情况。因此，结构化日志通常用于监视目的（例如，检测系统错误，而非结构化日志用于调试错误发生的&lt;strong&gt;原因&lt;/strong&gt;）。这表明两种类型的日志需要不同类型的管理解决方案。&lt;/p&gt;&lt;p&gt;当系统较小时，使用非结构化日志进行调试并不太困难。只需通过 SSH 连接到每个节点、查看或 grep 日志并诊断根本原因即可完成调试。然而，随着系统的增长，通过 SSH 连接到数十万个节点变得难以管理。在我们发起这项计划之前，Apache Spark®、YARN®、Flink®、许多基于 Hadoop 生态系统的平台以及在这些平台上运行的许多 ML 应用程序都使用古老的 MapReduce 作业历史记录服务器来直接查看每个主机上的日志。 Uber 也有一个自定义的节点浏览界面（类似于 SSH），但是这两种工具对于 Uber 目前的规模来说都不够。由于日志文件数量过多，超出了底层 HDFS 存储的文件限制，加上用户界面过于缓慢且反应迟钝，无法处理典型大型日志文件的显示，因此作业历史记录服务器无法有效扩展。后一种方法虽然可用且经常被平台维护人员使用，但很麻烦，充其量也不安全，并且不会向应用程序最终用户公开。因此，工程师需要更好的工具。&lt;/p&gt;&lt;p&gt;不幸的是，针对结构化日志的可观察性工具有很多，但针对非结构化日志的可观察性工具却很少。这可能是因为结构化日志适合存储在类似数据库的后端中，在后端可以通过表格数据上的索引来执行和加速搜索和分析（我们使用术语“数据库”来指代其主要功能的任何数据管理工具）。接口是搜索；这包括传统的 RDBMS、具有本机 JSON 支持的系统、Pinot 等 NoSQL 数据库以及为 Elasticsearch 等一系列工具提供支持的反向索引工具（例如 Apache Lucene®）。因此，开发人员经常尝试将他们的非结构化日志硬塞到当今流行的可观察工具中；但由于数据库不是为存储和分析非结构化日志而设计的，因此开发人员通常更多地与数据库打交道，而不是调试系统。例如，在存储非结构化数据时，数据库索引的大小可能会迅速膨胀，从而导致磁盘存储和每个查询的内存使用量相应增加。实际上，在这样的工具中保留和搜索 Uber 的所有非结构化日志成本高昂。更重要的是，它将剥夺用户习惯的功能，即访问、快速查看和分析单个日志文件。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-log-viewing"&gt;日志查看&lt;/h2&gt;&lt;p&gt;查看和分析原始日志文件的能力仍然是一项基本要求，遗憾的是，许多现有的可观察性工具忽视了这一点。为了解决这个问题，我们与 CLP 开发团队合作，实现并定制了一个无服务器日志查看器，允许用户通过在浏览器中动态解压缩来直接查看压缩日志。日志查看器构建在 Microsoft Visual Studio Code 的高性能 Monaco 编辑器之上，提供了直观且熟悉的界面来查看压缩日志文件。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdbtS2LwlhA0rgmG8BvTEMHtOZwJQB4lCtLz_odrb-aJ9_4Bu2zISkgoAgXyIy-mzHaq4oD3NtLgO2_hDKn7raUfREPt46MpNbqVf6AFIpC-Kt3FKK2n7sYnLjbnOqxZetGWI37aAOdVU75Z-S2lQNlLL-W?key=6KS8UuwM_zrmkURjL-jcyQ" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：使用日志查看器过滤关键（错误或以下）日志事件。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;它还具有许多特定于日志的功能。例如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;智能分页&lt;/strong&gt;可有效处理大型日志文件，而这些文件在标准文本编辑器或 VIM 等命令行工具中会很笨重。分页功能降低了浏览器的内存使用量，同时允许其他功能（例如搜索）跨页面工作。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;日志级别过滤&lt;/strong&gt;允许工程师轻松隐藏特定级别以上的日志。例如，用户最初关注关键错误，然后探索性地将其视图扩展到信息级日志，以了解周围的上下文（日志查看器确保在日志级别之间切换时将光标保持在同一日志事件上，即使分页会改变）。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;高级搜索&lt;/strong&gt;允许跨日志文件页面快速查询子字符串或正则表达式（用户可以单击结果并快速导航到相应的日志事件）。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;多行支持&lt;/strong&gt;在多行事件（例如堆栈跟踪）之间搜索和导航。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;同步查看&lt;/strong&gt;允许并排查看日志，并按时间戳同步滚动以在不同日志文件之间交叉引用事件。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;永久链接&lt;/strong&gt;，压缩日志文件中的每个日志事件都有一个可共享和可嵌入的永久链接，无需复制粘贴日志或截取屏幕截图，从而简化了协作和问题跟踪。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;日志美化&lt;/strong&gt;可自动将日志事件中的缩小 JSON 字符串、代码片段和长列表转换为更易读的格式。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;文本着色&lt;/strong&gt;支持类似于 Visual Studio Code 中的各种语言模式，以及定制模式以使典型的 Uber 日志更具可读性。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上面的 GIF 显示了用户如何按日志级别过滤日志，并且 CLP 日志查看器正确地将包含堆栈跟踪的多行错误日志识别为单个日志事件。提供这些专门的日志查看功能的能力源于使用 CLP 来解析和压缩日志，因为它会自动识别时间戳、日志级别、变量值等。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-analytics-libraries"&gt;分析库&lt;/h2&gt;&lt;p&gt;除了满足用户基本需求的日志查看之外，我们还提供库供用户进行可编程分析。这些库的核心是用 C++ 开发的，具有 Python、Go 和 Java 的本机绑定。由于 CLP 在压缩日志时对其进行解析，因此该库能够为用户提供对结构化数据的直接访问，例如 Unix 纪元时间戳、日志类型（即日志消息的静态文本部分）、消息中的变量、当然还有解压缩的日志消息本身。这种方法减轻了用户为原始消息编写额外文本解析逻辑的负担，并降低了与此类解析相关的运行时性能成本，特别是对于多行日志消息，使他们能够专注于日志分析程序的核心逻辑。如今，各种各样的用户将图书馆用于各种目的。&lt;/p&gt;&lt;p&gt;对于平台维护人员来说，分析库简化了复杂的编程查询，例如分析过去 30 天内特定应用程序中的日志类型和权限错误的频率。用户经常进行子字符串搜索，然后对 CLP 分析库提供的结果应用进一步的聚合和重复数据删除逻辑。例如，用户可以使用每个匹配事件的日志类型作为识别重复项的方法，而不是使用解压缩的消息，解压缩的消息可能会因变量值而发生变化。这有助于轻松地对具有相似结构的不同非结构化日志事件进行分组。&lt;/p&gt;&lt;p&gt;对于值班职责或根本原因分析，用户可以创建脚本式搜索，检测一系列特定的已知有问题的日志事件或满足用户定义标准的日志事件序列，从而帮助快速自动缩小分析范围。当发现可疑日志事件时，用户可以从CLP日志事件对象中获取其永久链接，单击该链接可以直接在日志查看器中转到相应日志文件中的特定匹配事件，以进行进一步的深入分析。&lt;/p&gt;&lt;p&gt;对于 ML 团队来说，分析库有助于在 Jupyter Notebook、生产脚本等各种环境中或在本地用户的开发笔记本电脑上从日志中快速提取和处理有价值的训练或推理数据。一旦分析结果可用，数据就可以用作自动化脚本的输入，例如，作为下一个训练批次的一部分，或编译成分析报告以用于评估和决策目的。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-ingesting-a-huge-number-of-log-files"&gt;摄取大量日志文件&lt;/h2&gt;&lt;p&gt;依赖于 HDFS 的初始日志摄取管道对我们的日志记录工作负载有一些重大限制。首先，由于 NameNode 难以维护大量小日志文件的索引，HDFS 无法扩展以满足我们的日志保留要求。此外，数据访问，尤其是在隔离生产环境之外的开发人员笔记本电脑或开发机器上的数据访问，主要受到复杂的 Kerberos 身份验证和其他访问障碍的阻碍。相比之下，S3 和 GCS 等现代对象存储解决方案专为大规模可扩展性而设计，可以容纳 PB 级数据和数十亿个对象。这些平台消除了 HDFS 集群维护的需要，从而减轻了我们的管理负担，并提供增强的安全功能，例如静态和传输过程中的加密，以及集成的 ACL 和其他访问控制功能、自动对象生命周期（即保留时间）管理。提供更高的可靠性和可用性。我们还受益于即用即付模式，以及暂时显着提高存储需求的灵活性，例如，在重大安全事件后延长日志保留期。因此，我们从在 HDFS 上上传和存储日志转向将它们存储在对象存储中。&lt;/p&gt;&lt;p&gt; HDFS 和常见对象存储之间的一个关键区别是 HDFS 采用文件系统层次结构，而对象存储则充当平面键值存储。幸运的是，在大型分布式系统中，日志文件通常具有基于系统中日志记录实体的层次结构的唯一的、不变的文件系统路径，因此该路径可以很好地作为压缩日志的密钥。此外，对象存储提供 API，以类似于文件系统导航的方式促进密钥访问，从而保持熟悉的日志浏览体验。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-ensuring-and-guaranteeing-log-freshness"&gt;确保并保证原木新鲜度&lt;/h2&gt;&lt;p&gt;YARN 和流应用程序（包括 Flink 作业）等服务通常是为长时间执行而设计的，只有在发生故障、硬件更换或升级时才会偶尔关闭。因此，日志上传不能推迟到作业“结束”，这在第一阶段对于持续时间较短的 Spark 应用程序是可行的。此外，对象存储系统通常缺乏对附加操作的支持，这在处理大型日志文件的上传时对日志新鲜度提出了挑战。&lt;/p&gt;&lt;p&gt;我们的日志管理包括轮换功能，可将大量日志文件分割成更小、更实用的块。当现有文件达到 16MB 标记时，我们会触发创建新的压缩日志文件。选择的大小是对象存储的战略折衷，最大化压缩比，最小化存储和同步开销，同时仅略微提高 API 访问成本。请注意，尽管压缩日志文件大小较小，但高压缩比意味着 16MB 的压缩数据块代表大量未压缩数据。&lt;/p&gt;&lt;p&gt;为了增强日志收集的近实时行为和弹性，同时最大限度地降低与每个上传请求相关的 API 成本，我们的日志库采用了针对日志记录需求定制的刷新和上传策略。我们最初考虑在每次刷新日志时上传日志，但默认情况下，每次附加日志事件时日志库都会刷新。这太贵了。库也可以配置为定期刷新，但这对于日志来说太通用了。理想情况下，我们需要一种根据日志记录工作负载的特征而变化的方法。例如，当发生重要日志事件（例如，错误级别）时尽早上传，或者当一段时间内没有日志时上传。&lt;/p&gt;&lt;p&gt;我们的上传政策可总结如下。记录事件后，应在延迟一段时间后上传文件，但如果在延迟到期之前发生更多日志事件，则可以将 𝑆 推送到稍后的时间。我们称之为软截止日期。相比之下，我们还维持一个严格的截止日期𝐻，以便在上传文件之前有保证的延迟𝐻（𝐻应该比𝑆长）。例如，如果 𝑆 设置为 10 秒，𝐻 为 300 秒，则意味着当事件 𝐸 在时间 𝑇 记录时，如果 [𝑇, 𝑇 + 10] 之间没有其他事件到达，则该事件将在 𝑇 + 10 上传。否则，𝐸 的上传将被延迟，但不会晚于 𝑇 + 300。这些延迟可以根据日志级别进行配置，例如，用户可以为 ERROR 事件设置比 INFO 事件更短的期限。一旦上传发生，延迟也会重置。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-effective-log-file-filtering-with-tags"&gt;使用标签进行有效的日志文件过滤&lt;/h2&gt;&lt;p&gt;Uber 在各个平台上运营着大量的内部服务，每个平台上都有数十名用户每天运行许多作业。得益于集成平台设施或外部监控工具的综合指标和监控，用户通常对系统故障及其时间有深入的了解。因此，在大多数情况下，用户希望立即将其日志搜索和查看限制为压缩日志的特定子集（例如，来自特定作业、应用程序、用户、时间片及其组合的日志）。&lt;/p&gt;&lt;p&gt;我们的系统可以使用多个标识符灵活地标记压缩日志，例如服务 ID、作业 ID、应用程序 ID、用户 ID 和时间戳范围。标签可以合并到对象存储文件路径中，记录在外部数据库中，或者简单地附加为对象元数据并由对象存储维护。用于搜索和查看日志的用户界面利用这些标签，使 CLP 能够有效地缩小与每个用户的搜索或查看请求相关的日志文件的范围。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-cross-platform-integration-of-clp"&gt; CLP跨平台集成&lt;/h2&gt;&lt;p&gt;我们最初将 CLP 与 Spark 集成，利用 Java 重新实现 CLP 的 C++ 代码库，以便与 Spark 的默认日志记录框架 (Log4j) 快速集成。它的成功、可靠性和用户体验的改进引起了其他平台团队和应用程序最终用户（包括许多 Marketplace 和 ML 团队）的集成请求。然而，这种集成路径对使用其他日志框架（例如 Logback）和其他编程语言（例如 Python）的不同应用程序的采用提出了挑战。相反，我们利用各种语言（包括 Java、Go 和 Python）的外部函数接口 (FFI) 库，通过本机绑定与 CLP 的 C++ 库进行交互。通过将这些集成到每种语言的各种日志库中，我们能够将 CLP 的分布式流压缩无缝集成到平台团队的代码库中，而无需更改应用程序代码。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-impact"&gt;影响&lt;/h2&gt;&lt;p&gt;经济高效的分布式 CLP 压缩和摄取管道已成为 Uber 数据团队的首选日志摄取和管理解决方案。正如我们在&lt;a href="https://www.uber.com/en-US/blog/reducing-logging-cost-by-two-orders-of-magnitude-using-clp" rel="noreferrer noopener" target="_blank"&gt;之前的博客&lt;/a&gt;中提到的，该系统帮助我们轻松地将日志保留期延长至行业标准的 30 天，显着减少了对存储成本、维护复杂性和可用性的担忧。此外，日志查看器和程序化分析功能在 ML 和 Marketplace 团队等最终用户以及 Uber 数据团队内部维护的平台中广受欢迎。例如，开源 Python CLP 日志分析库已被下载 141,880 次，Python 日志库插件在过去六个月内已被下载 4,845 次。与实施日志库插件的服务所有者（“生产者”）的数量相比，分析库的下载率较高反映出其在分析日志的工程师（“消费者”）中使用更广泛。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-next-steps"&gt;下一步&lt;/h2&gt;&lt;p&gt;我们的目标是将未来的努力集中在三个关键领域：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可观测性平台集成&lt;/strong&gt;：将 CLP 与可观测性团队现有的日志收集基础设施集成，该基础设施在应用程序容器之外运行，减少 OOM 场景期间日志丢失的严重性，并捕获不直接由应用程序生成的日志（例如 bash 脚本）。通过统一和简化对非结构化和结构化日志的访问，还可以增强用户体验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;将合适的冷日志迁移到 CLP&lt;/strong&gt; ：CLP 擅长处理不需要近实时搜索功能的日志。虽然 CLP 非常高效并提供快速搜索性能，但它并不是要取代现有的基于在线索引的解决方案。将合适的日志迁移到CLP平台应该可以降低成本并提高可靠性和用户体验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结构化日志支持&lt;/strong&gt;：CLP 引入了对结构化日志的本机支持，其有效性记录在即将发布的 OSDI &amp;#39;24 论文中，该论文展示了与现有解决方案相比，结构化日志数据的出色压缩和搜索功能。&lt;/p&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;通过将 CLP 与日志查看、可编程分析和高效日志摄取等高级功能无缝集成，Uber 彻底改变了我们的非结构化日志管理。这个综合系统不仅解决了 Uber 巨大规模的可扩展性和调试挑战，还为各个团队的工程师提供了简化工作流程的工具。因此，Uber 实现了显着的成本节省、改进的日志保留并提高了开发人员的工作效率。核心工具和功能的开源可用性进一步巩固了 CLP 的影响力，促进了行业内更广泛的采用和创新。通过持续致力于平台集成、日志迁移和结构化日志支持，Uber 准备继续在高效和有效的日志管理方面保持领先地位。&lt;/p&gt;</description><pubDate>Thu, 27 Jun 2024 07:06:56 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/modernizing-logging-with-clp-ii/</guid></item><item><title>【How Uber ensures Apache Cassandra®’s tolerance for single-zone failure】</title><link>https://www.uber.com/blog/single-zone-failure-tolerance/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;&lt;a href="https://www.uber.com/blog/how-uber-optimized-cassandra-operations-at-scale/" rel="noreferrer noopener" target="_blank"&gt;Uber 已经运行开源 Apache Cassandra &lt;sup&gt;®&lt;/sup&gt;数据库即服务&lt;/a&gt;，为各种关键任务在线事务处理 (OLTP) 工作负载提供支持，目前已达到 Uber 规模，每秒有数百万次查询和 PB 级数据。由于 Uber 在多个地区的多个专区运营数据中心，因此 Uber 的 Cassandra 集群的节点通常分布在多个专区和地区。由于高可用性对于 Uber 的业务至关重要，因此我们希望 Cassandra 的可用性在单个区域出现故障的情况下不受影响。本博客展示了我们如何确保 Cassandra 的单区容错能力，特别是我们如何将大型 Cassandra 队列以零停机时间实时从非区域容错转换为单区容错。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-terminology"&gt;术语&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;SZFT&lt;/strong&gt; ：单区容错&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-background"&gt;背景&lt;/h2&gt;&lt;p&gt;Cassandra 天然支持数据的多副本。拥有多个数据副本的最大好处之一是高可用性：如果少数副本不可用，大多数副本仍然可以访问。当 Cassandra 集群跨多个可用区部署时，我们希望理想情况下将所有副本均匀分布在这些区域中，以便对区域的影响不会影响用户请求。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcSTnDyAkLVo_Z0_2lEv-UqaswqOQAZup6hMZKsVASGPumgKy0uf5wCQdcYGmCaI2vFl0U-bVkUY8dz3hfPZATIx7Hzr-HbtdDc53mSvXCfAMUoWI8-kx3MghC73muhugYyr71fk18Au-vNl8eGN5W5uFm9?key=AZe-MVriCM2tBK0R_Gauew" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：单区域故障和可用性影响。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;图 1 说明了该问题。在此示例中，复制因子为 3。当数据记录的大部分副本可用时，该数据记录被视为可用。当区域 1 关闭时，数据记录 1 将变得不可用，因为它丢失了大部分（两个）副本。但与此同时，数据记录 2 仍然可用，因为它恰好将少数（只有一个）副本放置在故障区域中。如果所有数据记录的副本都以与数据记录 2 相同的方式放置，即&lt;strong&gt;副本&lt;/strong&gt;&lt;strong&gt;均匀分布在各个区域中，使得每个区域仅包含少数副本&lt;/strong&gt;，则任何单个区域的故障都不会影响整个数据记录。整体可用性。&lt;/p&gt;&lt;p&gt; Cassandra 本质上支持通过对节点进行逻辑分组的功能来分离副本。然后副本按组分开。分组是通过名为&lt;em&gt;cassandra-rackdc.properties&lt;/em&gt;的文件完成的。&lt;/p&gt;&lt;p&gt;在此功能中，每个 Cassandra 节点都分配有两个属性： &lt;em&gt;dc&lt;/em&gt;和&lt;em&gt;rack&lt;/em&gt; 。例如，区域 1 中的 Cassandra 节点将配置如下： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090731" height="377" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1-1024x377.png" width="1024" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;当复制策略为&lt;a href="https://cassandra.apache.org/doc/4.1/cassandra/architecture/dynamo.html#network-topology-strategy" rel="noreferrer noopener" target="_blank"&gt;&lt;em&gt;NetworkTopologyStrategy&lt;/em&gt;&lt;/a&gt;时，在&lt;em&gt;DC&lt;/em&gt;内，&lt;strong&gt;对于任何数据记录，Cassandra 的副本放置算法会将副本放置到尽可能多的&lt;em&gt;机架&lt;/em&gt;上&lt;/strong&gt;。如下图所示： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXegRc24Cr4H85C9-HrRQ-xwAG1MIjpD5JJssb_oLn96JwP4lqx631rWoB5Vq_0vzWcCJmrOmFx5fLvimGURLmBi18tWM_LyYbngSsFq9oEJopiGCtpi1BxEsrVDHC2UU_7ADVBMbc457vFs1rkOXj81_Co?key=AZe-MVriCM2tBK0R_Gauew" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：所需的设置：按区域对节点进行分组。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;图 2 中的设置（假设复制因子为 3）是理想的 SZFT（单区域容错）设置。无论哪个区域出现故障，其他区域中仍然会有两个健康的副本为任何数据记录提供读取和写入服务。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-why-was-cassandra-at-uber-not-szft"&gt;为什么 Uber 的 Cassandra 不是 SZFT&lt;/h2&gt;&lt;p&gt; Uber 没有使用图 3 中的设置——我们只是没有利用“机架”属性。所有 Cassandra 节点都被分配了相同的机架属性“默认”值，导致该区域中只有一个唯一的机架值。无法正确分离副本，因为要分离副本，需要多个机架属性值。因此，大多数或可能所有副本都可以放置在同一个区域中，如下图所示： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfHvNOqIU6eb_3TL4Xjq32UOYUMe-vrXXI-ZriBakzeWwFkn2FuW-BUakKJAIujnE3tS8zljn1XXGk9w9pVglzfMur7NB8PNxhlcGHGHRqQzy6ZeVFWoPG3QjRNZCoKlpHitu14LgFXiBSvIpNaClZ6qHsn?key=AZe-MVriCM2tBK0R_Gauew" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：Uber 的旧设置：单个独特的机架。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;从较高层面来看，解决 Uber 的问题本质上意味着从单机架设置（如图 3 所示）过渡到采用基于区域的机架分配策略的多机架设置（如图 2 所示）。这一转变带来了多重挑战。让我们看看它们是什么以及我们在 Uber 如何克服它们。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-challenge-1-in-place-transition-not-an-option"&gt;挑战 1：就地过渡不是一种选择&lt;/h1&gt;&lt;p&gt;事实证明，将区域中的现有节点从单机架设置&lt;strong&gt;过渡&lt;/strong&gt;到多机架设置是&lt;strong&gt;不切实际的&lt;/strong&gt;。这是因为，如果将与新机架关联的节点引入到现有的单机架节点设置中，它将立即使新成员成为热点。如前所述，Cassandra 的副本放置算法将副本放置到尽可能多的独特机架上。当节点将第二个机架引入 Cassandra 时，所有数据记录都会将一个副本放置到新机架上，即使其中只有一个节点！图4很好地说明了这个问题： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090555" height="1024" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4-1007x1024.png" width="1007" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：在单机架设置中引入新机架时的热点问题。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;由于副本放置算法的限制，我们只剩下一个选项，从高层次来看，如下所示：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在同一区域内创建一个新的 Cassandra 环，或一个新的“dc”（如 NetworkTopologyStrategy 中所示）。新环是通过多机架设置创建的，以满足 SZFT 要求。&lt;/li&gt;&lt;li&gt;通过从旧的活动环&lt;a href="https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/rebuild.html" rel="noreferrer noopener" target="_blank"&gt;重建&lt;/a&gt;来重建新创建的环。&lt;/li&gt;&lt;li&gt;通过将客户流量从一个环移动到另一个环，透明地交换新环与旧环。&lt;/li&gt;&lt;li&gt;取下旧环。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我们为整个迁移制定了以下原则：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;零客户参与——我们的利益相关者不得参与或暴露于迁移（例如，更改服务逻辑、客户端代码或路由）&lt;/li&gt;&lt;li&gt;高可用性——迁移期间无停机时间&lt;/li&gt;&lt;li&gt;维护预先存在的性能 SLO，例如延迟&lt;/li&gt;&lt;li&gt;回滚功能，以便我们可以在旧环和新环之间来回切换，作为紧急措施&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-the-rebuild-procedure"&gt;重建程序&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-phase-1-provision-a-new-set-of-offline-multi-rack-nodes-in-the-region"&gt;第一阶段：在该地区提供一组新的“离线”多机架节点&lt;/h3&gt;&lt;p&gt;在选定的区域中，将新的节点环添加到集群中。分配给新节点的硬件资源（例如，节点数、CPU 核心、内存、磁盘大小）需要与该区域中的现有环相同。将新节点均匀分布在各个区域中。通过配置每个节点的&lt;em&gt;cassandra-rackdc.properties&lt;/em&gt;文件，使用基于区域的策略对它们进行分组，如下所示： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcH74hsYf-WXgoNrypJz7LTOJWRLDvYZIIguWfE3jCblgpTyxzh28JN2ORfhR_odddRm1wXerjO-rUZj0A0qruZ6TXDxTHwvWHxBXnebkbT4fGIEfLhcEa5s9LsNCnzmWVoJ7gmv0t0MAhSgBAirKebyVxP?key=AZe-MVriCM2tBK0R_Gauew" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;最后，所有新节点应在&lt;a href="https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/disablebinary.html" rel="noreferrer noopener" target="_blank"&gt;禁用本机传输的&lt;/a&gt;情况下创建，以防止与它们的 CQL 连接。这对于以后从现有环到新环的无缝流量切换至关重要。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090556" height="729" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5-1024x729.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：第 1 阶段：配置一组新的禁用二进制的多机架节点。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-phase-2-data-sync-for-live-writes"&gt;第 2 阶段：实时写入的数据同步&lt;/h3&gt;&lt;p&gt;由于我们的最终目标是让新环取代旧环，因此我们需要将所有数据复制并存在于两个环中。这包括实时写入的数据以及历史数据。对于来自实时写入的数据，我们需要将新环添加到所有键空间的复制设置中，以便借助 Cassandra 的跨 DC 复制，它们可以开始间接接收实时写入。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090732" height="381" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333-1024x381.png" width="1024" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090557" height="720" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6-1024x720.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：第 2 阶段：在复制中包含新的节点集。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-phase-3-data-sync-for-historical-data"&gt;第三阶段：历史数据同步&lt;/h3&gt;&lt;p&gt;对于历史数据，我们需要让新环从旧环中流式传输。尽管新节点现在正在接收实时写入，但它们仍然缺少过去的所有数据。 Cassandra 提供了一个工具，可以使用 nodetool重建命令来流式传输此类数据。需要在&lt;em&gt;region1_new&lt;/em&gt;的每个新节点上运行以下命令以流式传输来自&lt;em&gt;region1&lt;/em&gt;的数据： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090734" height="138" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild-1024x138.png" width="1024" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXft9Qy90P61zHHyDGRk1L-IrXN866dHr8WMyGbEe-_05rtLUdE_171HSBDlkFowzOnG9Ka40w79XsIiT91h2md32ikNehFv86ncC0xmN-G6aDa7S5yUS1eRhB_-sfHRy7veOzNTt0lSRc9FjuzEMpFDDD9D?key=AZe-MVriCM2tBK0R_Gauew" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：第 3 阶段：同步旧数据。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-phase-4-traffic-switch"&gt;第四阶段：流量切换&lt;/h3&gt;&lt;p&gt;历史数据传输完毕后，我们就可以让 Cassandra 客户端连接到新的节点环并停止连接到旧的节点环。这是通过在新环中的所有节点上&lt;a href="https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/enablebinary.html" rel="noreferrer noopener" target="_blank"&gt;启用本机传输&lt;/a&gt;，然后在旧环中的所有节点上&lt;a href="https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/disablebinary.html" rel="noreferrer noopener" target="_blank"&gt;禁用本机传输来&lt;/a&gt;完成的。我们已经消除了在客户端执行任何操作的需要，其原因将在下一节中讨论，我们将看到我们在 Uber 所做的 Cassandra 客户端增强。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXf6wcyJD06iUE8_JWw81JUucwUyHl-xEeQRmUNftN2rLvtBeU0vgE53GWTIYQvWhGvMFM7Stbz4hUuuBGTpQX1qBDikqwrHNa__Y3tkcvdnoRk3MA3f97eyOHW0sXJahDq2I1PaxzPxcNet7SNYvVGpoNiP?key=AZe-MVriCM2tBK0R_Gauew" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：第 4 阶段：流量切换。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-phase-5-remove-old-nodes"&gt;第 5 阶段：删除旧节点&lt;/h3&gt;&lt;p&gt;首先，需要更改所有键空间的复制设置，以便旧环不再是数据复制的一部分。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090735" height="339" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333-1024x339.png" width="1024" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;完成此操作后，旧环中的节点将退役。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcDvHs74P1MCQgreqSpD_eOglh3jidW2ydJN4TthFJGd5BOMq6tTk-FE04jLk-LFacE1cRXKQGH6nvmXzP1FDpO7TiQefYYl8dhEV34zSMIZ1uPfQZu66743WCZrHkz3aloDsPF8qVOs_fZhgUM_TyoncnY?key=AZe-MVriCM2tBK0R_Gauew" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：第 5 阶段：删除旧的节点集。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-phase-6-repeat-for-the-other-regions"&gt;第 6 阶段：对其他区域重复&lt;/h3&gt;&lt;p&gt;所选区域中的 Cassandra 集群现在是 SZFT。其他区域需要重复相同的过程。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-cassandra-client-enhancement"&gt; Cassandra 客户端增强&lt;/h2&gt;&lt;p&gt;在上述过程中，不涉及客户端操作。这是因为在 Uber，我们有一个 GoCQL 和 Java 驱动程序的分支，我们对它们进行了增强，使其能够动态地将流量从一个环切换到另一个环，而无需重新启动。&lt;/p&gt;&lt;p&gt;为了实现无缝流量切换，Cassandra 客户端的期望是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;始终从客户端所在的同一区域提供初始 Cassandra 联系点（即用于初始拓扑发现的 Cassandra 节点）。&lt;/li&gt;&lt;li&gt;始终从客户端所在的同一区域选择协调器节点。&lt;/li&gt;&lt;li&gt;在启用本地传输并在旧环的节点上禁用本机传输后，自动连接到新环的节点，如重建过程的阶段 4 所示。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;需求#1 是通过一个新的微服务来满足的，该服务致力于发布 Cassandra 集群的联系信息。它与我们的 Cassandra 控制平面集成，从而了解每个 Cassandra 集群的拓扑。该服务的使用者（在本例中为 Cassandra 客户端）发送仅包含目标 Cassandra 集群名称的请求。该服务返回&lt;strong&gt;属于与消费者位于同一区域的&lt;/strong&gt;集群的所有节点的联系信息（例如，IP 和端口）。&lt;/p&gt;&lt;p&gt;上述逻辑对客户端 API 是隐藏的，我们的 Cassandra 用户只需更改为客户端提供联系点的方式，如下所示： &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090736" height="91" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder-1024x91.png" width="1024" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;要求 #2 是通过我们在 Uber 在 Cassandra 客户端中实施的新主机过滤器来完成的。这个新的主机过滤器排除了位于客户端远程区域的所有协调器节点。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090737" height="105" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy-1024x105.png" width="1024" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;要求 #3 是通过将负载平衡策略指定为 TokenAware + RoundRobin 来实现的。真正重要的不是这些策略的使用，而是消除 DCAwarePolicy 的使用。 DCAwarePolicy 曾经出现在 Uber 的许多 Cassandra 应用程序中，它将协调器节点选择固定到旧环。开源客户端已经能够及时捕获与本机传输相关的更改，自动断开与禁用本机传输的节点的连接并自动连接到新启用本机传输的节点。因此，我们需要做的就是允许客户端连接到同一区域中的任何环。&lt;/p&gt;&lt;p&gt;最后，我们在 Uber 标准化了 Cassandra 客户端配置，如下所示： &lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="" class="wp-image-1090738" height="337" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder-1024x337.png" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;客户端中的这些增强功能巧妙地将用户与 Cassandra 集群的低级拓扑细节分离，例如 IP、端口、dc（如 NetworkTopologyStrategy 中的）等。它为重建第 4 阶段的无缝流量切换铺平了道路程序。此外，基于区域的协调器选择与“LOCAL_QUORUM”读写相结合，可确保在一个区域的重建过程中，其他区域的 Cassandra 客户端不会受到任何影响，因为它们始终直接与其他区域的 Cassandra 节点交换数据。他们当地的区域，允许逐个区域的 SZFT 过渡。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-challenge-2-nbsp-lack-of-uniform-spare-server-capacity-across-zones"&gt;挑战2：跨区域缺乏统一的备用服务器容量&lt;/h1&gt;&lt;p&gt;对于每个 Cassandra 机架都是一个区域的多机架设置，我们需要确保始终有足够的可用区域（即区域数量≥replication_factor）。此外，每个可用区的备用容量需要统一，以便在集群扩展时每个机架均等扩展。&lt;/p&gt;&lt;p&gt;如果集群规模较小，因此所需的扩展量较小，或者所有区域中的备用容量都有更强的保证，则这似乎不那么具有挑战性。然而在实践中，可用容量很可能不均匀地分布在各个区域中。在这种情况下，执行集群的潜在紧急水平扩展将不可避免地导致牺牲集群的 SZFT 属性。&lt;/p&gt;&lt;p&gt;无论容量情况如何，我们都应该做好应对这种情况的准备。当SZFT属性和对水平扩展的迫切需求无法同时满足时，我们必须通过水平扩展来优先考虑集群的即时性能需求。重要的是要记住，一旦额外的容量最终到达其他区域，我们应该能够以最少的节点替换数量将扩展过程中添加的节点“重新定位”到所需的区域，最终实现 SZFT。整个过程对操作要求相当高，我们需要精细化的自动化来大幅减少人工工作量。&lt;/p&gt;&lt;p&gt;我们不会在本博客中详细讨论这一挑战，因为它涉及服务器容量管理方面。得益于运行底层存储管理和控制平面平台的&lt;em&gt;状态平台&lt;/em&gt;团队，Uber 确保准备好以完全自动化的方式应对此类场景。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-highlights"&gt;强调&lt;/h2&gt;&lt;p&gt;这一关键项目的成功衡量标准如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;绝大多数 Cassandra 机群已完成部署。推出后的几个月里，没有发现任何问题。&lt;/li&gt;&lt;li&gt;推广期间，未发生重大事故。&lt;/li&gt;&lt;li&gt;整个过程对我们的利益相关者来说是完全透明的。&lt;/li&gt;&lt;li&gt;我们进行了多次测试，几乎关闭了整个生产区，而 Cassandra 的利益相关者没有受到影响！ &lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;在本文中，我们展示了 Uber 的 Cassandra 部署。我们还强调了实现单区容错的挑战，并深入研究了解决方案。&lt;/p&gt;&lt;p class="has-small-font-size"&gt;&lt;strong&gt;封面照片归属&lt;/strong&gt;：该图像是使用 ChatGPT 生成的。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Apache® 和 Apache Cassandra® 是 Apache Software Foundation 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; Oracle、Java、MySQL 和 NetSuite 是 Oracle 和/或其附属公司的注册商标。其他名称可能是其各自所有者的商标。&lt;/p&gt;</description><pubDate>Thu, 20 Jun 2024 07:33:46 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/single-zone-failure-tolerance/</guid></item><item><title>【Debugging with Production Neighbors – Powered by SLATE】</title><link>https://www.uber.com/blog/debugging-with-production-neighbors/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;软件开发是一个迭代的分阶段过程，需要在功能、组件和服务级别进行验证和测试。在基于微服务的架构中，与依赖服务结合开发变得更加重要。基于微服务的架构提供了独特的优势，使我们能够扩展、维护和抽象职责。越抽象，我们就越容易开发和定义业务逻辑。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.uber.com/blog/simplifying-developer-testing-through-slate/" rel="noreferrer noopener" target="_blank"&gt;SLATE&lt;/a&gt;是一种端到端测试工具，它允许部署被测服务并与生产上游和下游服务一起工作，从而弥补了这一差距。这允许开发人员生成镜像生产调用流程的测试请求，但目标是测试中的服务。此类功能有助于各种用例，包括生产环境中的功能开发或复制生产错误，这通常需要对代码和配置进行故障排除。为了帮助或简化故障排除过程并使其更接近本地体验，我们开发了一些功能来支持对 SLATE 环境中部署的服务进行调试。&lt;/p&gt;&lt;p&gt;在本博客中，我们将探索在 SLATE 上开发的不同调试选项，这些选项可模拟生产上游和下游的测试中服务的行为。&lt;/p&gt;&lt;p&gt;让我们详细检查以下三个高级选项：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;远程调试 SLATE 部署的实例&lt;/li&gt;&lt;li&gt;笔记本电脑/开发 Pod 机器中的本地调试&lt;/li&gt;&lt;li&gt;通过过滤监控来调试问题&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-debugging-until-now"&gt;调试到现在&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-debug-via-logs"&gt;通过日志调试&lt;/h3&gt;&lt;p&gt;使用日志进行调试是一种基本实践，可以深入了解程序的执行情况。日志使开发人员能够识别问题。然而，低效的日志记录可能会用不相关的信息使系统变得混乱，从而导致调试过程变得复杂而不是有帮助。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-debug-via-staging"&gt;通过暂存进行调试&lt;/h3&gt;&lt;p&gt;暂存环境是开发人员控制的环境，反映了生产设置。&lt;/p&gt;&lt;p&gt;虽然登台环境非常有益，但它们仍然可能与现场环境不同，并且会提供较长周转时间的错误信心。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-debug-locally"&gt;本地调试&lt;/h3&gt;&lt;p&gt;本地调试对于更快地迭代以隔离测试服务至关重要。然而，由于同时调试多个服务的限制，调试用户场景可能具有挑战性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-remote-debugging-of-slate-instance"&gt; SLATE实例的远程调试&lt;/h2&gt;&lt;p&gt;SLATE 上的测试和调试依赖于正在测试的服务的日志。仅仅依靠日志来理解复杂的过程是不切实际的。此外，添加新日志需要新的部署，从而导致延迟。远程调试可以通过让开发人员逐步执行语句和监视变量来解决这些问题，从而消除提交和部署迭代的需要。与生产基础设施协作，需要平衡安全性和开发人员体验。&lt;/p&gt;&lt;p&gt;这就需要增强代码的可见性以进行运行时调试，这可以通过断点、单步执行或动态跟踪点来实现。远程调试仅限于处理测试请求的 SLATE 实例，以确保生产安全。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-high-level-goals"&gt;高层次目标&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;在 SLATE 容器上部署可调试的二进制文件/代码&lt;/li&gt;&lt;li&gt;能够向被测服务添加断点和跟踪点&lt;/li&gt;&lt;li&gt;能够在遇到断点的控件上查看不同参数的值&lt;/li&gt;&lt;li&gt;创建类似于远程调试的无缝开发人员体验&lt;/li&gt;&lt;li&gt;设计符合安全和隐私问题的解决方案&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-design"&gt;设计&lt;/h3&gt;&lt;p&gt;SLATE 利用生产基础设施来生成容器、编译代码和执行服务。然而，需要对构建和部署基础设施进行修改，以便于调试部署在 SLATE 上的服务的功能。这涉及三项重大改进。首先，使用集成的调试工具和功能生成构建。其次，使用远程调试选项配置软件执行。第三，通过分配和公开所述容器的端口，促进开发人员访问远程容器。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-debuggable-deployment"&gt;可调试部署&lt;/h3&gt;&lt;p&gt;当前的部署管道不灵活，无法支持生成可调试和生产二进制文件的不同选项。为了能够生成和部署可调试的二进制文件，管道的多个组件应该实现二进制文件的类型并相应地配置其功能。该图指示了功能开发期间将涉及的组件。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090425" height="285" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2-1024x285.jpeg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：对部署管道进行修改以支持 SLATE 调试。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-allocating-ports"&gt;分配端口&lt;/h3&gt;&lt;p&gt;SLATE 容器与生产主机一起创建。为了能够连接到调试器，我们必须公开一个新的调试端口，类似于 gRPC/HTTP 端口。目前UP负责分配随机端口并将其映射到主机端口。新端口的公开将仅针对可调试的 SLATE 部署开放，并且 SLATE 按设计隐式处理​​测试请求。这个新的端口暴露需要进行安全审查。下图显示了高层交互。&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-"&gt;&lt;img height="173.47872782612586" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfNB42pjNG_DCuxWPz9gEvHHrE9XBFFcsEvj1tsaIr7Hn2pTk6nl3ghqed81UCUzrhbtFUaWYoageTGPGBuZJXXTNq_Zx8lT-RoppYjT3hjsjxuViujT4oCun8CeDLuQqzNyIV2C8GjgTr6m1Hs73MActat?key=Ermx74NMIF5DAzxh8Wqoiw" width="695.85121602289" /&gt;&lt;/h2&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090426" height="283" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1-1024x283.jpeg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：分配和安全公开调试端口。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-reaching-debuggable-service"&gt;实现可调试服务&lt;/h3&gt;&lt;p&gt;为了提高安全性，避免恶意访问，SLATE调试需要进行访问控制。这将确保只有服务所有者才能连接调试器。下图显示了将访问权限限制为仅服务的 LDAP 用户的访问控制。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090429" height="357" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1-1024x357.jpeg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：从开发人员计算机到远程主机的基于密码的 SSH 隧道。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-debugger-execution"&gt;调试器执行&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;调试器在专用调试服务器中运行应用程序&lt;/li&gt;&lt;li&gt;进程阻塞，等待调试器客户端附加&lt;/li&gt;&lt;li&gt;调试器进程侦听特定的 TCP/IP 网络端口（称为调试端口）&lt;/li&gt;&lt;/ul&gt;&lt;h4 class="wp-block-heading" id="h-controlling-program-execution"&gt;控制程序执行&lt;/h4&gt;&lt;p&gt;调试客户端（例如 VSCode、GoLand、JetBrains）通过调试端口连接。客户端发出命令来执行各种调试任务，例如设置断点、显示局部变量和函数参数、打印 CPU 寄存器内容等。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-remote-debugging-with-debug-port"&gt;使用调试端口进行远程调试&lt;/h4&gt;&lt;p&gt;远程调试支持在不同的环境、配置或架构上进行调试。对于解决无法本地复制的特定场景或硬件/软件相关问题非常有用。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-access-control"&gt;访问控制&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-restricting-for-ldap-users"&gt;限制 LDAP 用户&lt;/h3&gt;&lt;p&gt;在调试会话期间，用户将调试器附加到应用程序以干预程序执行并收集调试信息。这也意味着尝试识别并解决程序中的错误。这意味着如果允许每个用户访问一些敏感的服务信息。因此，限制 LDAP 用户（服务开发人员/所有者）对于确保最低安全性非常重要。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-secure-ssh-connection"&gt;安全 SSH 连接&lt;/h3&gt;&lt;p&gt;对于远程调试，在本地和远程系统之间建立安全的 SSH 连接。这将允许本地端口转发并通过 SSH 隧道重定向调试请求。该隧道将确保加密通信和安全数据传输。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-ssh-authorization"&gt; SSH授权&lt;/h3&gt;&lt;p&gt;要开始 SSH 连接，用户需要链接到“slatedev”帐户的正确密码。该密码是服务容器内文件中随机生成的 16 位代码。密码是在主服务应用程序运行之前容器启动期间生成的。该密码只能由容器访问组（即服务所有者 LDAP）访问。 LDAP 用户可以通过 Compute CLI 访问密码，从而使他们能够建立 SSH 连接并执行调试任务。计算 CLI 确保对非 LDAP 用户的访问受到限制，即不允许密码访问。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-limitations"&gt;局限性&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;生产基础设施上的远程调试对动态修改有限制，因此仅限于只读&lt;/li&gt;&lt;li&gt;迭代时间长，因为每次更改都涉及构建、部署和测试&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-local-debugging-using-slate-attach"&gt;使用 SLATE Attach 进行本地调试&lt;/h2&gt;&lt;p&gt;远程调试允许在生产基础设施上进行只读调试。处于生产基础设施中可以实现与上游和下游服务/工具的无缝连接。对于开发人员来说，体验可调试环境以及更快的迭代来修复和测试相同的环境非常重要。这一差距可以通过创建与生产上游和下游服务相关的本地调试体验来填补。 SLATE Attach 填补了这一空白，并允许在附加本地环境上快速开发。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-high-level-goals-0"&gt;高层次目标&lt;/h3&gt;&lt;p&gt;主要目标是通过使用本地开发实例（笔记本电脑或开发机器）提供端到端测试来缩短代码部署测试周期（从而缩短验证迭代更改的时间），确保生产隔离和安全。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-iteration-cycle"&gt;迭代周期&lt;/h3&gt;&lt;p&gt;在这种情况下，迭代周期是指更改代码和验证代码之间的时间。迭代周期越小，开发人员对后续变更进行端到端验证的时间就越有效。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-full"&gt;&lt;img alt="" class="wp-image-1090430" height="221" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig4.jpeg" width="820" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：使用 SLATE 进行开发的迭代步骤。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-need-for-slate-attach"&gt;需要 SLATE Attach&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;迭代开发以更快的速度生成构建二进制文件&lt;/li&gt;&lt;li&gt;缩短代码部署测试周期&lt;/li&gt;&lt;li&gt;更快地识别和解决本地、端到端故障&lt;/li&gt;&lt;li&gt;更快的设置时间&lt;/li&gt;&lt;li&gt;避免服务变更或入职培训的需要&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-design-0"&gt;设计&lt;/h2&gt;&lt;p&gt;此设计旨在引入一个 SLATE 代理，用于处理针对 SLATE 实例的所有测试请求以进行本地调试。然后，这些请求将被重定向到适当的本地开发人员计算机以进行调试和开发。这使得用户能够更快地迭代并提高开发人员的生产力。&lt;/p&gt;&lt;p&gt;该功能主要在 SLATE 环境生命周期的 2 个上下文中启用：&lt;/p&gt;&lt;ol&gt;&lt;li&gt; &lt;strong&gt;SLATE 将本地笔记本电脑/devpod 映射到 slate 环境的控制平面&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;测试请求数据平面&lt;/strong&gt;，将请求重定向到开发人员的笔记本电脑&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-control-plane"&gt;控制平面&lt;/h2&gt;&lt;p&gt;控制平面的主要功能是使本地笔记本电脑或 devpod 中运行的服务能够附加到 SLATE 环境。打算运行该服务的本地笔记本电脑/devpod 必须将本地环境凭据附加到 SLATE 环境，以便测试请求在本地路由。此附件的先决条件是创建 SLATE 环境。这将允许路由控制数据库和本地路由数据库中的映射更新。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090431" height="560" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5-1024x560.jpg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：用于测试在开发人员计算机上运行的代码的请求调用流程&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-call-flow"&gt;通话流程&lt;/h4&gt;&lt;ol&gt;&lt;li&gt;用户从本地笔记本电脑/devpod 启动 SLATE 连接&lt;/li&gt;&lt;li&gt;SLATE CLI 调用 SLATE 后端的 Attach() API&lt;/li&gt;&lt;li&gt; SLATE 后端从 SLATE 代理获取代理信息（主机：端口）&lt;/li&gt;&lt;li&gt; SLATE 后端使用获取的代理信息更新路由控制数据库中的路由覆盖&lt;/li&gt;&lt;li&gt;用户使用 Cerberus CLI 启动 SSH 会话&lt;/li&gt;&lt;li&gt;Cerberus 网关将代理租赁/UUID 的映射添加到 Flipr DB 中的笔记本电脑凭据，并为笔记本电脑创建 SSH 会话&lt;/li&gt;&lt;/ol&gt;&lt;h4 class="wp-block-heading" id="h-routing-control-db"&gt;路由控制数据库&lt;/h4&gt;&lt;p&gt;路由控制数据库将测试租用映射到路由覆盖，将用户帐户 UUID 映射到测试租用。它针对测试中的服务存储 SLATE 代理主机：端口，并确保针对特定 SLATE 环境的所有请求都到达 SLATE 代理。 SLATE Proxy 最终将请求路由到在用户计算机中运行的开发实例。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-local-routing-db"&gt;本地路由数据库&lt;/h4&gt;&lt;p&gt;本地路由数据库包含已附加到 SLATE 环境的开发实例的凭据。 SLATE Proxy 与本地路由数据库交互以获取路由凭证，并最终将请求路由到在本地环境中运行的被测服务&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-data-plane"&gt;数据平面&lt;/h2&gt;&lt;p&gt;本节主要讨论来自不同客户端（移动端、工作室、Web 等）的测试请求的流程。该数据平面主要涉及2个实体：路由覆盖标头和主机租赁映射。下图显示了不同的测试请求如何通过 SLATE 代理到达本地笔记本电脑。控制平面确保路由覆盖和主机映射维护在不同的数据库中。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090432" height="520" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6-1024x520.jpeg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：用于将测试请求路由到开发人员计算机的代理设置。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;以上是针对本地笔记本电脑以及生产上游和下游的测试请求流程：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;测试帐户请求来自移动客户端&lt;/li&gt;&lt;li&gt;E2E测试代理检索路由覆盖并将路由标头注入测试请求&lt;/li&gt;&lt;li&gt;测试请求通过 Mutley 在生产服务中传播，直到请求具有服务 3 目标&lt;/li&gt;&lt;li&gt;请求重定向到 SLATE 代理，因为路由覆盖具有针对服务 3 的 slate 代理主机：端口&lt;/li&gt;&lt;li&gt;SLATE 代理根据 Cerberus-deputy Flipr 命名空间中的主机：端口配置将请求转发到 Cerberus-gateway 上的开放端口，该配置由用户在运行 Cerberus CLI 时设置&lt;/li&gt;&lt;li&gt;Cerberus-gateway将请求转发到用户本地开发机，供用户调试&lt;/li&gt;&lt;li&gt;从本地笔记本电脑，请求最终将通过 Cerberus 转发到生产下游&lt;/li&gt;&lt;/ol&gt;&lt;h3 class="wp-block-heading" id="h-limitations-0"&gt;局限性&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;对于某些复杂的服务来说，在本地运行服务可能不可行，因为它们需要支持某些依赖项，例如只能存在于生产基础设施中的扳手&lt;/li&gt;&lt;li&gt;这仅限于测试请求，因为它可以动态更改请求，从而保护生产流量&lt;/li&gt;&lt;li&gt;本地等待调试请求时间较长时请求超时&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-impact"&gt;影响&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;即插即用的开发环境，提高开发人员的工作效率&lt;/li&gt;&lt;li&gt;能够为开发者创造与生产协同的本地体验&lt;/li&gt;&lt;li&gt;提高开发人员速度：生产调试可以帮助开发人员更有效地识别和修复问题&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1090433" height="280" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7-1024x280.jpeg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7. 使用 SLATE 附加功能提高开发速度的影响数据。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-what-s-next"&gt;下一步是什么&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;SLATE Sniffer 通过监控来调试问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;远程和本地调试主要允许测试请求进行调试。除了 uMonitor 工具中出现的日志之外，还需要对生产进行可观察性。我们的目标是使用 SLATE Sniffer 精确地按需创建这种可观察性。  SLATE Sniffer 的主要目标包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;捕获请求和响应作为服务和 UUID 的过滤器&lt;/li&gt;&lt;li&gt;能够支持和过滤生产和测试请求&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;我们的目标是增强 SLATE 平台，将其定位为调试生产问题的主要工具。集成到 SLATE 中的调试功能在安全性和开发人员的要求之间取得了平衡。 SLATE 为开发人员的代码相关活动和服务引导引入了新的范例。我们期待与不同的团队合作，将质量左移并在开发的早期阶段就潜在问题建立可见性。&lt;/p&gt;</description><pubDate>Tue, 18 Jun 2024 07:21:37 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/debugging-with-production-neighbors/</guid></item><item><title>【Personalized Marketing at Scale: Uber’s Out-of-App Recommendation System】</title><link>https://www.uber.com/blog/personalized-marketing-at-scale/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;应用外 (OOA) 通信（例如电子邮件、推送和短信）是 Uber 的重要增长杠杆。它允许营销人员、产品所有者和运营团队就大量主题与用户建立联系，包括用户促销、新餐厅和最喜欢的餐厅等。构建一个系统来个性化这些通信提出了独特且令人兴奋的挑战。在这篇博文中，我们将介绍这些挑战以及我们应对这些挑战的历程。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-challenges-nbsp"&gt;挑战&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-lack-of-recommendation-context"&gt;缺乏推荐上下文&lt;/h3&gt;&lt;p&gt;第一个挑战是 OOA 通信中缺乏用户上下文。这些个性化通信的核心是餐厅推荐和商家报价推荐。这些推荐是高度本地化的（即用户只能从附近的餐馆订购）。在标准产品推荐系统中，用户在进入应用程序时会看到推荐。用户的位置和意图通常都是已知的。另一方面，OOA 通信中的推荐会主动推送给用户，以供不确定的未来观看。即使在没有关键用户上下文的情况下，确保推荐保持相关性也是我们系统面临的一项重大挑战。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-incorporating-campaign-objectives"&gt;纳入活动目标&lt;/h3&gt;&lt;p&gt;第二个挑战是 OOA 通信中的建议需要与最终用户和通信上下文相关。关于会员福利的电子邮件应包括独家餐厅的促销活动，而庆祝城市社区的电子邮件应突出当地人最喜欢的餐厅。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-system-costs"&gt;系统成本&lt;/h3&gt;&lt;p&gt;最后，能够以具有成本效益的方式大规模应对上述挑战是我们面临的另一个挑战。该系统目前负责向所有地理区域和业务线的用户发送超过 40 亿条个性化消息。生成 OOA 建议的成本主要包括三个方面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;在线特征存储&lt;/strong&gt;：这涉及与推荐系统中使用的特征的存储、检索和管理相关的费用。在线特征存储有助于快速访问和处理用户、项目和交互特征，这对于实时个性化至关重要。这里的成本是由对可扩展、高性能数据库的需求驱动的，这些数据库可以以低延迟处理大量数据。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;在线预测：&lt;/strong&gt;运行复杂的模型进行实时预测会产生巨大的成本。这些模型比我们之前的架构中的模型更加复杂，需要大量的计算资源来进行连续的数据处理和分析。与运行这些模型所需的计算能力相关的费用，包括服务器成本以及用于实验目的的额外计算资源的维护和扩展。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;高吞吐量和广泛的受众：&lt;/strong&gt;为迎合更多受众和处理更高消息吞吐量而进行的扩展进一步增加了成本。随着系统扩展以适应更多用户和更广泛的营销场景，基础设施也必须扩展。要处理超过数十亿条消息的实时个性化，所需的吞吐量可以达到应用内推荐系统的10倍。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;有效管理这些成本对于我们新架构的可持续性至关重要，需要在性能、可扩展性和成本效率之间取得平衡。优化算法以获得更好的性能、利用经济高效的自动扩展基础设施以及优化功能策略等技术可以显着帮助控制这些费用。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-nbsp-architecture-overview-nbsp"&gt;架构概述&lt;/h2&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfgrQtPFPJjdzvNKpMosLG74j6oOD8dEA602cpHo6_OeMD6HJ-2NJBPXMWB5ApZFJASs1SRJCniWle1RK8JOjxusx10elXiP1mdX2oHl6sdV17iS2d-Ijaz4z4P0_QNXdyx5bPRRD-1FXDVhpS9ghLK0q8?key=DgmRI0YIzHZkraGCSk9ZeA" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：营销个性化架构。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;&lt;strong&gt;候选检索&lt;/strong&gt;：此过程涉及为每个用户确定一组广泛的潜在推荐。该系统使用基于位置的首次通过排名算法，扫描大量商品，考虑用户历史记录、商店受欢迎程度和上下文数据等各种因素，以检索候选推荐的初步列表。&lt;/p&gt;&lt;p&gt;&lt;em&gt;核心技术：Local Graph（Uber的知识图谱）&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;混合&lt;/strong&gt;：一旦检索到候选者，它们就会经历过滤和混合过程。该步骤根据预定义的业务规则和标准淘汰不太相关或不需要的选项。它确保最终的建议符合用户的偏好和任何业务限制。&lt;/p&gt;&lt;p&gt;&lt;em&gt;核心技术：&lt;/em&gt;&lt;a href="https://github.com/google/cel-spec" rel="noreferrer noopener" target="_blank"&gt;&lt;em&gt;基于CEL的&lt;/em&gt;&lt;/a&gt;&lt;em&gt;规则引擎&lt;/em&gt;（使用&lt;a href="https://www.uber.com/blog/flipr/" rel="noreferrer noopener" target="_blank"&gt;Flipr&lt;/a&gt; ）&lt;/p&gt;&lt;p&gt;&lt;strong&gt;排名&lt;/strong&gt;：在排名阶段，对候选者进行排名以确定其呈现给用户的顺序。该排名基于一整套排名功能，用于评估每个项目与用户上下文和偏好的相关性。目的是将最相关和最具吸引力的推荐放在顶部，最大限度地提高用户参与的可能性。&lt;/p&gt;&lt;p&gt;&lt;em&gt;核心技术： &lt;a href="https://www.uber.com/blog/palette-meta-store-journey/" rel="noreferrer noopener" target="_blank"&gt;Palette Feature Store&lt;/a&gt; 、 &lt;a href="https://www.uber.com/blog/michelangelo-machine-learning-platform/" rel="noreferrer noopener" target="_blank"&gt;Michelangelo&lt;/a&gt;&lt;/em&gt; &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-solution-formulation-nbsp"&gt;溶液配方&lt;/h2&gt;&lt;p&gt;为了解决我们的三个主要挑战，我们对架构的每个部分都进行了增强，以便在高效且可扩展的系统中向用户提供相关且主题一致的内容。我们将在下面详细讨论每项增强功能。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-candidate-list-generation-nbsp"&gt;候选列表生成&lt;/h3&gt;&lt;p&gt;Uber Eats 优食推荐的一个独特部分是针对用户位置高度本地化的候选列表。当用户打开 Uber Eats 优食应用程序时，系统会向他们推荐可以送货到当前位置或最近订单位置的餐厅、杂货店和零售店。对于我们的 OOA 推荐系统，我们的候选列表生成中缺少这一关键上下文。我们开发了两种解决方案来克服这一障碍。&lt;/p&gt;&lt;p&gt;对于一般推荐用例，我们开发了一个机器学习解决方案来确定用户接下来最有可能收到订单的社区。由于我们的系统支持针对频繁、不频繁和新 Uber Eats 用户的营销活动，因此该 ML 解决方案需要集成来自 Uber Eats 和 Uber 应用程序多年时间范围内的高和低吞吐量信号。为了确保该解决方案的可扩展性，以适应与活动所有者沟通的数亿 Uber 用户，我们专注于将这些信号减少到一小组约 10 个功能，机器学习解决方案利用这些功能来定义用户的下一个可能的订单位置。利用这个可能的位置，通过查找向该位置送货的所有餐馆、杂货店或零售店来生成用户的候选列表。&lt;/p&gt;&lt;p&gt;虽然这个基本解决方案为我们的 OOA 推荐系统提供了重要的上下文，但它并不总是为每个活动提供正确的上下文。在用户可能旅行的活动设置中（例如，机场旅行、Uber Reserve、Uber for Business），上述 ML 解决方案可能没有必要的上下文来反映用户最近的行为变化。在此设置中，我们利用基于事件的覆盖来更新用户的候选列表，以包含送货到最近社区的餐馆、杂货店和零售店。通过更新此候选列表，我们提高了用户沟通的相关性，并为活动所有者提供了控制这些候选列表的灵活性，以确保其活动的主题一致性。&lt;/p&gt;&lt;p&gt;这些解决方案共同将关键的用户元数据注入用户的候选列表中，确保我们的建议与用户相关并反映他们最近的行为。通过为所有 Uber 用户提供通用的机器学习解决方案，活动所有者可以确信用户的候选列表是准确的，并且可以满足他们的活动目标。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-first-pass-ranking"&gt;首过排名&lt;/h3&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcpvTCnINAXH7xDcMWM5D7jUOEVwOrEsKKugQ4byxZxyT47qLsOM8tcHZwRhy6n-0YCXX4AbYrvS80h2tFTkka94fyYIEZpYxFZ_rrFj5GuBBpvEZlgEkgWSC7Qnrawk0sHnUfLyH4p1OpyapRuYIsUI1IM?key=DgmRI0YIzHZkraGCSk9ZeA" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图2：首次通过排名。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;首遍排名的主要目标是快速将所有符合条件的候选商户集合减少到每个用户的较小的潜在商户集合。这有助于节省系统带宽并降低与机器学习相关的成本。&lt;/p&gt;&lt;p&gt;根据用户位置检索到所有候选者后，我们启动初步过滤过程。此阶段根据不可用和无效送达能力（例如跨境商家）等标准排除候选者。&lt;/p&gt;&lt;p&gt;在某些广告系列中，我们会展示各种餐厅类型。为了完善我们的选择，候选人会根据特定用例进行额外的筛选。例如，我们的主要推荐策略是根据用户过去与 Uber Eats 优食的互动来评估候选者的相关性。我们还介绍提供促销活动的候选者，并通过向用户推荐尚未订购但可能有吸引力的餐厅的候选者来激励用户。&lt;/p&gt;&lt;p&gt;对于每个用例，我们都会对所有符合条件的候选商家应用低成本评分功能。该函数是一小组特征的简单线性组合，包括用户和商家之间过去的交互。调整权重以最大化召回指标。&lt;/p&gt;&lt;p&gt;最后，为了确保用户有多种选择，我们运行了重复数据删除过程。此步骤删除属于同一父链的候选者，避免重复推荐。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-second-pass-ranking"&gt;第二关排名&lt;/h3&gt;&lt;p&gt;第二排名阶段的目标是对从第一次排名中检索到的一小组商家进行排名，以最大化用户参与的可能性。为此，我们利用一些功能来捕获用户过去的订单历史记录、应用内和应用外的参与度以及商家的质量、可靠性和承受能力。其中许多功能也被家庭提要排名系统所利用，并通过 Uber 的在线功能商店&lt;a href="https://www.uber.com/blog/palette-meta-store-journey/" rel="noreferrer noopener" target="_blank"&gt;Palette&lt;/a&gt;共享。通过在推荐服务之间共享功能集，我们促进了应用内和应用外界面的用户体验的平等。这些功能在学习排名 LTR 建模框架中使用，并具有自定义相关权重，以鼓励理想的用户行为。&lt;/p&gt;&lt;p&gt;虽然以用户为中心的功能对于经常使用的用户来说很丰富，但对于新用户和流失的用户来说通常无法使用。由于 OOA 系统主要迎合不频繁的用户群体，因此我们必须依赖长期的用户信号才能提供良好的推荐。此外，我们需要能够以经济高效的方式存储和使用此类信号。为了通过餐厅推荐克服这一挑战，我们构建了一个轻量级功能集，总结了用户在整个 Uber Eats 优食历史中的美食偏好。在 Uber，我们为每家餐厅标记了商家提供的一组美食，我们利用这些美食创建一个总结用户美食偏好的特征向量。我们每天使用贝叶斯更新逻辑更新此功能，并增加最近订单的权重，以反映用户最近的行为变化。在最近的在线实验中，将此功能纳入我们的第二次排名系统中，电子邮件的点击率提高了 4%。&lt;/p&gt;&lt;p&gt;我们的第二遍排名系统中使用的许多功能有效地总结了用户过去的订单行为，但没有透露用户接下来可能有兴趣尝试哪些餐厅。由于 Uber Eats 优食订单的地理限制，协作推荐系统技术很难学习餐厅相似性。例如，不同社区的两家餐馆可能以相似的价格提供相似的菜肴，但由于地理差异而没有共同的顾客。虽然通过基于协作的方法很难了解餐厅的相似性，但利用基于内容的推荐方法和餐厅的美食标签可以提供了解餐厅相似性的机会，并鼓励用户在 Uber Eats 优食上探索新餐厅。我们假设用户会对提供与他们过去订购的菜肴相似的菜肴的新餐厅感兴趣。在此前提下，我们进行了一项分析来量化菜系之间的相似性。我们对正则化的美食共现矩阵进行了谱聚类，该矩阵捕获了同一家餐厅经常提供哪些菜肴。从这个聚类练习中，我们发现，虽然商家可以提供数百种菜肴，但这些菜肴可以自然地归入少数几个类别。在图 3 中，我们可视化通过 t-SNE 映射到二维空间的每种美食的嵌入向量，突出显示了这些自然美食集群。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXclTIOVrXS9GosD3MlTmw3WJ6vNDCKLZ5P8yDa5Fru2bv4mhA4sGVo29-KyGWF7GZpO8axvCO52o_w_Xs4IwW_wW3rYodhyYhan-2PRcl5NBdd6mBWGKWIQifmwnWmtHePk-5xBREjN3xNW10pp9C54_As?key=DgmRI0YIzHZkraGCSk9ZeA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：基于相似性分析的美食分类。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;这些分组促使我们根据这些菜肴的相似性来平滑每个用户的菜肴偏好特征。在我们的第二次排名系统中利用这个平滑的特征向量为我们的系统提供了一个探索杠杆，鼓励用户尝试与他们喜欢的美食相似的新美食，同时保持推荐相关性。除了这种探索杠杆之外，这些分组还为我们提供了降低系统成本的机会。通过根据这些菜系分组嵌入菜系偏好功能，我们将该功能的大小缩小了 10 倍，降低了在线存储成本，同时保留了该功能的大部分信号。此外，通过利用轻量级嵌入方案，我们能够通过简单的分布式矩阵乘法有效地执行此特征嵌入，这可以在任何标准 ETL 管道框架中执行。&lt;/p&gt;&lt;p&gt;通过构建一个轻量级的功能集来总结用户在整个 Uber Eats 优食历史中的美食偏好，我们为我们的第二次通过排名模型提供了重要的背景。这种背景为我们的推荐系统提供了探索杠杆，鼓励用户探索新的美食和商家，并确保不常使用 Uber Eats 优食的用户收到相关的餐厅推荐。通过嵌入这些美食偏好功能，我们可以大大降低在线存储成本，并确保推荐系统可以支持针对任何 Uber 用户群的活动。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-re-ranking-amp-blending-nbsp"&gt;重新排名和混合&lt;/h3&gt;&lt;p&gt;由于 CRM 沟通来自不同的内部利益相关者，系统需要一种机制来针对不同的品牌战略和营销优先事项定制嵌入式建议。因此，我们在基于机器学习的第二遍排名后引入了重新排名和混合层。例如，我们允许利益相关者根据特定的营销策略来提高商家的知名度（图4）。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfaBCsP7f9PtQJIas64-wKhFJSRYAN7bn0uOjMvJfrKrAmIK-BN5YuVxqKTy2UWASUp8PwClRpu5GsXceUirADVn2Wpy_I-N3953rek6wl5T1Yxx_pmchFXQFMzWlvSp2EyzPa4ac565MAjz5TaPqNAujEa?key=DgmRI0YIzHZkraGCSk9ZeA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图4：提升精选商户的知名度。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;通过我们的配置引擎，本地营销团队可以以最少的工作灵活地定义自己的策略。这是通过不同地理区域级别的自动分层配置合并和覆盖来实现的。例如，纽约市可以继承美国的大部分重新排名策略，但纽约市本地营销团队可以对特定参数应用一些部分覆盖。图 5 演示了增强图 4 中所选商家的配置。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdJ5NWHGLcrbj4jUtlNt2EQ5D2ZC11o_EJnaOArqzUgVf3-iKqGbyrULBZ5OpxAH_H7OrkQhFrFBn5sNlYOCtq6gW8elbCvzVAPLf7f42NxPVeqDomvf54fiS5myotklOMEPHLi15npddLftZtdb6pGmGrf?key=DgmRI0YIzHZkraGCSk9ZeA" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：通过分层覆盖增强选定商家的配置。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-next-steps"&gt;下一步&lt;/h1&gt;&lt;p&gt;虽然早期的大部分工作都集中在提供商家推荐上，但 Uber 对个性化营销的需求超出了我们的送货业务范围。我们平台的后续步骤是将相同的个性化功能引入其他业务领域，特别是乘客和赚钱者通信。为了更好地服务这些新的业务面，该团队计划扩展我们的个性化内容存储库，并向 Uber 的合作伙伴团队采购。新的发展包括动态创意，以统一个性化推荐和其他营销创意；个性化的旅游推荐；以及个性化的盈利机会来推动市场需求和供应。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="h-acknowledgements"&gt;致谢&lt;/h2&gt;&lt;p&gt;如果没有多个增长和营销团队的贡献，这是不可能实现的。我们要感谢以下人员的贡献：Isabella Huang、Ajit Pawar、Apoorv Sharma、Jennifer Li、Hari Thadakamalla、Cameron Kalegi、Nikhil Anantharaman、Vladimir Schipunov、Denis Perino、Shelley Hatting、April Chu、Nora Murphy、Fernanda戈麦斯、艾比·布莱克、卡罗莱纳·阿普雷亚、玛丽·奥奎特、安·帕登、迈克尔·谭。&lt;/p&gt;&lt;p&gt;特别感谢 LocalGraph 团队（Jiaxin Lin、Kaymyar Arbabifard、Santosh Golecha）、Delivery Intelligence 团队（Yifan Ma、Tiejun Wang）、Michelangelo 团队（Jin Sun、Paarth Chothani、Nicholas Marcott、Victoria Wu）和 Offers 的技术合作伙伴&amp;amp; 可负担性团队（Shirley Ye、Boyang Li、Jun Yao）帮助我们设计系统并利用 Uber 范围内的人工智能构建模块。&lt;/p&gt;</description><pubDate>Thu, 13 Jun 2024 07:02:17 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/personalized-marketing-at-scale/</guid></item><item><title>【Flaky Tests Overhaul at Uber】</title><link>https://www.uber.com/blog/flaky-tests-overhaul/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;几年前，我们开始&lt;a href="https://www.uber.com/en-US/blog/handling-flaky-tests-java/" rel="noreferrer noopener" target="_blank"&gt;解决不稳定的测试&lt;/a&gt;，以稳定我们单一存储库中的 CI 体验。该项目首先在我们的 Java monorepo 中首次亮相，并在减少开发人员工作流程中的摩擦方面取得了良好的效果。然而，随着我们发展 CI 基础设施并开始将其加入我们拥有最多用户的最大存储库&lt;a href="https://www.uber.com/blog/how-we-halved-go-monorepo-ci-build-time/" rel="noreferrer noopener" target="_blank"&gt;Go Monorepo&lt;/a&gt; ，权宜之计的解决方案在扩展到范围方面变得越来越具有挑战性。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-visibility"&gt;&lt;strong&gt;能见度&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;遗留服务内置了一个分析器，它根据历史测试运行的窗口对测试进行分类。然而，大多数时候它在沙箱中工作，几乎无法了解细节，例如它检查了测试的历史记录、决策背后的原因是什么或有关测试的其他信息。因此，经常有一些测试被错误分类，但我们不知道原因，不得不手动重新分类。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-customization"&gt;&lt;strong&gt;定制化&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;它也几乎没有支持不同策略来对测试进行分类的可扩展性。它仅支持滑动窗口策略对测试进行分类。遗留测试模型是专门为 Java 定制的，假设输入如测试套件、参数、注释等，而这些输入在其他语言中并不总是可用。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-complexity"&gt;&lt;strong&gt;复杂&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;“串行”和“并行”概念在每个 monorepo 的 CI 端添加了额外的逻辑，以做出不同的响应。此外，由于它封装了许多场景——分类、转换、CI 中的恢复、通知等——当它需要足够通用以容纳每个存储库并且足够有效以不错过任何脆弱性时，复杂性会大大增加。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-actionability"&gt;&lt;strong&gt;可操作性&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;当时我们还没有就如何定义跨存储库的所有权达成共识。因此，我们最终在 CI 中忽略了许多不稳定的测试，但没有负责任的跟踪。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-the-big-picture"&gt;大局观&lt;/h2&gt;&lt;p&gt;在 Uber，我们在不同的开发阶段在 CI 管道中运行了大量的测试。通常，我们每天会验证 2,500 多个差异（代码更改，又名拉取请求），并且平均每个差异运行超过 10k 次测试。我们的最终目标是通过&lt;a href="https://www.uber.com/blog/research/keeping-master-green-at-scale/" rel="noreferrer noopener" target="_blank"&gt;保持主分支始终绿色来&lt;/a&gt;确保开发人员对主分支有信心。不稳定的测试破坏了 CI 管道的可靠性，导致开发人员体验混乱——一个错误会变成更多错误。&lt;/p&gt;&lt;p&gt;此外，通过我们的&lt;a href="https://www.uber.com/blog/bypassing-large-diffs-in-submitqueue/" rel="noreferrer noopener" target="_blank"&gt;SubmitQueue 推测&lt;/a&gt;架构，修订失败可能会产生级联效应，使队列中的其他修订无效并导致阻塞。当横切更改影响整个存储库并触发所有测试时，情况会变得更糟，这对于进行代码更改将是一场噩梦。这可能会导致开发人员不断重试他们的构建，直到构建变得绿色，从而浪费工程时间和 CI 资源。&lt;/p&gt;&lt;p&gt;迫切需要开发一个有效的、可扩展的、可配置的系统，该系统可以轻松采用并响应数千个测试的状态变化。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-introducing-testopedia"&gt;睾丸介绍&lt;/h2&gt;&lt;p&gt;我们需要了解在 Uber 中运行的所有测试，以验证用户的更改。这种可见性包括可靠性特征（即，不稳定控制）和性能特征（即，延迟控制）。因此，我们需要一个集中式系统来跟踪所有测试，并为 CI 或任何其他消费者提供足够的背景信息，以便就这些测试做出决策。我们将这些职责分离到一个独立的服务 Testopedia 中。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-design-overview"&gt;设计概述&lt;/h3&gt;&lt;p&gt;Testopedia 位于报告和消费者之间的 CI 基础设施中，如下所示： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfgB7JBfGgSObLdUa7d6nIlquv_YK9ctd5SfEZbKGIsvHozIPyvlh4Tt3vZAQSW5WmiH4xkalc01ZcY_cOTyFHtbFa2gcuyIp-oWqoWRcLQ-5vlSW-rjSFBJyh4u2YqUmd_LItqVcMO_-WekoYw0-sTqTua?key=6gZ2dLlV7xzsqb0CRMkSGA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：示例管道。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-what-it-does"&gt;它能做什么&lt;/h3&gt;&lt;p&gt;我们决定让它与语言/存储库无关，而不是让 Testopedia 处理片状测试的所有方面。这意味着该服务不关心它是什么类型的测试，是测试套件还是测试用例，名称的格式如何，如何报告，如何在 CI 中处理等。它只是在“测试实体， ”，它是系统中的最小基本单元，由“完全限定名称”(FQN) 唯一标识。此外，我们还引入了 FQNs 的分组概念——realm，它封装了特定使用域下的所有测试，例如 Golang 单元测试、Java 单元测试、Docker 集成测试等。 Realms 属于特定平台团队所有，每个团队都可以构建根据自己的喜好进行 FQN。&lt;/p&gt;&lt;p&gt;接下来，在较高的层面上，我们为服务分配了 3 个功能域：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;读&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;检索单个测试的统计数据，包括不稳定状态、可靠性、陈旧性、聚合执行时间、历史运行统计数据和其他元数据（如果有）。&lt;/li&gt;&lt;li&gt;检索一组测试的统计数据，即上述列表。&lt;/li&gt;&lt;li&gt;检索测试的状态更改。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;写&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;将测试运行结果上传至系统。&lt;/li&gt;&lt;li&gt;它可以是文件或流的形式，但需要遵循预定义的模式。&lt;/li&gt;&lt;li&gt;禁用/启用/删除系统中某些测试的管理操作。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;通知&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;每当测试变得不健康时，我们需要触发 JIRA 票证，并将截止日期分配给所属团队。 &lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-how-it-works"&gt;怎么运行的&lt;/h3&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdQvxdjfAvik1VtI7t-b2HiGn1Wk5CeNvZFhe2QBoHN7S_Bsid3wZV-fKRW3SLudKuP0KfcIA4vQDi0zd8txYN95hqLVktKT7tMjp2tcIS5Pg8-XCT_yaM5Vef7MeQm0_Wh8mnXKySoP93kE0Hxm-DKKe4?key=6gZ2dLlV7xzsqb0CRMkSGA" style="width: 700px; height: auto;" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：Testopedia 架构图。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt; Testopedia 通过历史数据来推断测试是否健康。但 Testopedia 并没有专注于定期作业，而是接受所有测试数据源，无论它是来自定期验证作业还是常规验证作业。每份报告都将相应地标有其来源。然后每个分析器都可以访问所有这些信息，并采取不同的策略来响应它们（稍后将详细介绍“分析器”）。&lt;/p&gt;&lt;p&gt;分析器完成对测试的运行分析后，结果将具体化到存储中以供稍后查询，并且根据结果，将按照领域的分组规则将票证提交给测试的所属团队（更多信息请参阅通知）。&lt;/p&gt;&lt;p&gt;请注意，从分析器到票务，每种策略都可以在 Testopedia 核心逻辑之外进行扩展和配置，从而为领域所有者提供最大程度的可定制性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-implementation-highlights"&gt;实施亮点&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-fully-qualified-name-fqn"&gt;&lt;strong&gt;完全限定名称 (FQN)&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt; Testopedia 设计的关键部分是能够使用名为“完全限定名称”或简称 FQN 的唯一字符串标识符来处理我们在 Uber 执行的每个测试。系统只需要专注于FQN的分析和记账，而将处理实现留给各自的平台，而无需了解每个测试框架的任何细节。&lt;/p&gt;&lt;p&gt;所有测试都分为&lt;em&gt;领域&lt;/em&gt;。领域名称以 FQN 字符串开头，代表测试所属的更广泛的域。领域的一个示例是“golang.unit_test”或“android.integration_test”。&lt;/p&gt;&lt;p&gt;作为“Golang 单元测试”领域下有效 FQN 的示例，我们可以将如下所示的字符串放在一起： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdwZlzY61MzQ6qnqQP7nlyAoUcTSIcRFIUVgDPADDe9qg0Z6o2zvD-N2KVItlya7T7SAA7KlAUouQJ0p6gGVIyWmw1wyM5DyfFtIQPggGE8hUtL9za1BNIT9WjvH32gPt4yWoNyBo5tiSs3DLsyXtyBqCM?key=6gZ2dLlV7xzsqb0CRMkSGA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：完全限定名称示例。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;整个 FQN 可以由领域所有者自定义为任何格式。通常根据测试代码所在的文件系统结构来对标识符进行建模。毫不奇怪，FQN 看起来非常像 Internet URL，因为它具有唯一标识资源的类似目的。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-finite-state-machine-fsm-model"&gt;&lt;strong&gt;有限状态机 (FSM) 模型&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;Testopedia 利用强大的有限状态机实现来捕获和记录测试的事务状态。允许测试实体在以下状态之间进行交易：新的、稳定的、不稳定的、禁用的和已删除的。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcXC3fSUSBxx6UimzGX5-eCWvAIxT8GjmpP1o7M-BtFAxVQaTipK4mEkvNUNglokw3lhVe07hG2qNVUy2t5OlVE8FpsrTj2bkmOaF2aj977cXflVwvBBCTFOONK_VLgejYZVyHmY4783oVBCRbyLd1kBNPf?key=6gZ2dLlV7xzsqb0CRMkSGA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：Testopedia 状态机。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;每个状态都可以自定义自己的进入和退出操作。例如，当 FSM 进入不稳定状态时，会触发一个操作来提交 JIRA 票证；当 FSM 进入稳定或已删除状态时，关联的 JIRA 票证将关闭。&lt;/p&gt;&lt;p&gt;坚持 FSM 设计，我们能够节省样板代码，否则我们必须编写和支持这些代码。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-scalability"&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXf_fs9-Fg36HOnQqalDoe134ZcOVaRT4vbMCEdBG1aRd7-OZ8Sff4CP9oRkvptXWULIw2gbhfg4QHiw4R2hBBHXZ_U_Qh6wV4-iKvi9GOofM0jaoKSAxwSJ1FGEl8KWd9u-OP9QyO4N5qudDX_U7EMzxBgJ?key=6gZ2dLlV7xzsqb0CRMkSGA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：通过线程池的数据流示例。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;为了最大限度地提高效率，我们选择使用 gRPC 流来实现导入 API，而不是要求用户上传大块数据。除此之外，我们还实现了线程池来消耗数据流。这不仅允许通过长期连接进行更易于管理的数据传输，而且还通过客户端和服务器端的并行处理确保更好的资源利用率。&lt;/p&gt;&lt;p&gt;此外，我们在设计后端数据库时考虑了可扩展性，通过允许灵活的分区，以便支持更复杂的读取场景（下一节将详细介绍这一点）。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-cone-queries-and-dynamic-partitioning"&gt;&lt;strong&gt;锥体查询和动态分区&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;因为片状测试会受到 CI 的大量查询，所以支持按前缀查询是很自然的要求，例如“golang.unit/src/uber.com/infrastruct/*”，在 Testopedia API 模型中称为&lt;em&gt;锥体查询&lt;/em&gt;。&lt;/p&gt;&lt;p&gt;在非常常见的 Monorepo 设置中，CI 构建作为多个并行作业执行，并按相似的路径前缀划分。因此，每个 CI 作业只对了解特定存储库文件夹下的片状测试感兴趣，而不是全部。&lt;/p&gt;&lt;p&gt;当我们跟踪数百万个测试时，迭代整个数据库来查找前缀匹配的性能并不好。我们自然会想到分片，但是，我们不想只在固定长度的前缀上进行分片，因为锥体查询可以是任意长度，例如“golang.unit/a/b/c/*”、“ golang.unit/a/b/*”、“golang.unit/a/*”等。为了有效地做到这一点，我们实现了一种灵活的分桶算法：&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;写：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;当新的 FQN 到达系统时，请说“golang.unit/a/b/c/d:test”，&lt;/li&gt;&lt;li&gt;首先我们为它随机生成一个整数桶ID，比如说10&lt;/li&gt;&lt;li&gt;然后我们剥离领域并识别前 3 个前缀：&lt;ul&gt;&lt;li&gt; [a/b/c，a/b，a]&lt;/li&gt;&lt;li&gt; （这里的3是深度的可配置值，只是一个例子）&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;接下来，我们通过附加将存储桶 ID 以及所有前缀存储在单独的表中：&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;前缀表&lt;/td&gt;&lt;td&gt;插入之前（其他 FQN 创建的现有存储桶 ID）&lt;/td&gt;&lt;td&gt;插入后&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;a/b/c&lt;/td&gt;&lt;td&gt; []&lt;/td&gt;&lt;td&gt; [ &lt;strong&gt;10&lt;/strong&gt; ]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; a/b&lt;/td&gt;&lt;td&gt; [2]&lt;/td&gt;&lt;td&gt; [2, &lt;strong&gt;10&lt;/strong&gt; ]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; A&lt;/td&gt;&lt;td&gt; [2, 3]&lt;/td&gt;&lt;td&gt; [ &lt;strong&gt;2,3,10&lt;/strong&gt; ]&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class="wp-element-caption"&gt;在上面的示例中，前缀为“a/b”的 FQN 必须位于存储桶 2 或 10 下。&lt;/figcaption&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;ul&gt;&lt;li&gt;最后，我们将存储桶 ID 与 FQN 本身一起存储在按存储桶 ID 分区的单独 FQN 表中&lt;/li&gt;&lt;/ul&gt;&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p&gt;# FQN 表&lt;/p&gt;&lt;p&gt;golang.unit/a/b/c/d:测试，10&lt;/p&gt;&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;不同的存储桶可能可以持久保存到不同的数据库服务器中，从而使设置几乎可以无限扩展&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;读：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;当我们发出锥体查询时，说“golang.unit/a/b/*”&lt;/li&gt;&lt;li&gt;我们首先找到领域“golang.unit”，然后找到前缀“a/b”&lt;/li&gt;&lt;li&gt;然后我们引用分区表并获取所有桶ID [2, 10]&lt;/li&gt;&lt;li&gt;然后我们可以快速查找FQN表中桶ID为2或10的记录；读取应该非常快，因为它是分区键；我们还可以并行执行此类查找&lt;/li&gt;&lt;li&gt;最后，我们迭代选定的记录并过滤那些满足查询要求的记录&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;请注意，我们跟踪存储桶 ID 的路径深度是 config.json 中的预定义值。因此，对于较长的查询，例如“golang.unit/a/b/c/d/e/*”，我们在最大深度“a/b/c”处停止并读取桶ID为10的所有记录。&lt;/p&gt;&lt;p&gt;这样我们就可以显着减少从数据库读取的记录数量。此外，每个领域可以根据其查询模式配置自己的深度和存储桶数量。由于存储桶 ID 是动态生成的，而不是依赖于静态输入，因此它有助于在存储桶之间更均匀地分配数据，而不管它们在存储库中的物理位置如何。&lt;/p&gt;&lt;p&gt;这种设计实现了一个重要的好处：非常传统的关系数据库（例如多分片配置中的 MySQL）可用于为存储后端提供动力并以亚秒级延迟执行复杂的锥形查询。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-data-agnostic-ingestion"&gt;&lt;strong&gt;与数据无关的摄取&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;目前，Uber 为每种主要语言托管了一个 monorepo，每种语言都有自己专用的 CI 管道。我们对 Testopedia 的愿景是创建一个与语言无关的平台，使所有 CI 管道受益。每个语言存储库都拥有一个领域，定义自己的 FQN 格式，并负责启动监视作业，该作业将测试历史数据流发送到 Testopedia。数据必须遵循预定义的通用模式，这是报告者和服务之间的唯一协议。&lt;/p&gt;&lt;p&gt;消费者可以自由决定如何从 Testopedia 进行消费。这种方法有效地将系统逻辑与任何特定于语言的概念（例如 Java 中的测试套件或 Go 中的子测试）解耦，从而确保无论格式如何，都具有适应性。因此，开发人员可以将该服务无缝集成到他们的 CI 基础设施中。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-configurable-analyzers"&gt;&lt;strong&gt;可配置的分析仪&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;Testopedia 中的分析模块也是高度可配置的。它提供了一个通用接口，每个领域的所有者可以使用我们的默认线性分析器或提交根据其特定检测要求定制的自己的实现。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfXR6FbFHBhtN50OQzqS604yTm6dfdZqED0A7D0igC6a4VR9ZS9OTznHMl831T1H7H1T41bE_iKk7-D5Fh5il6LK-gb9COoe8JMdXRsU4hvxQj7UzLcG92tC33Pv0YY6TXcG7pQpmOV3Y3KUt16oHb1_5Ns?key=6gZ2dLlV7xzsqb0CRMkSGA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：分析仪界面。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;此外，用户可以重用任何分析器实现，并根据结果、回溯窗口、阈值、状态模式定义规则，以有效地识别特定于其自己领域的片状测试（下一节将详细介绍这一点）。&lt;/p&gt;&lt;p&gt;这种定制在最大限度地减少误报和捕获真正的片状测试之间取得了适当的平衡。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-configurable-ticketing-system-and-storage"&gt;&lt;strong&gt;可配置的票务系统和存储&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;我们还对该系统进行了模块化，以适应 Uber 不断发展的基础设施。这样用户就可以连接其他 Scrum 解决方案，例如 JIRA、Phabricator 以及用于存储测试和历史记录的各种 DB 解决方案。有关此内容的更多信息，请参阅“管理不稳定测试”部分。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-visibility-and-usage"&gt;&lt;strong&gt;可见性和使用情况&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;Testopedia 的主要功能之一是它能够提供测试历史记录的全面可见性。每个状态转换以及相关的作业和元数据都会被记录下来，为测试所有者创建透明的审计跟踪，以便调试和调查异常发生的时间和地点、错误是什么、错误的频率、提交的时间等。此外，我们还在其之上构建了 CLI 和 Web UI，以便每个人都可以轻松检查他们的测试。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-analyzing-flaky-tests"&gt;分析片状测试&lt;/h2&gt;&lt;p&gt;在识别单一存储库设置中的脆弱性时，我们希望足够准确，以便我们及时捕获它们，从而防止它们的爆炸半径扩展到其他工程师的工作流程，并且足够宽容，以便我们不会忽略它们，并且仍然有足够的覆盖范围在我们的代码中进行保护。&lt;/p&gt;&lt;p&gt;在 Go Monorepo 中，我们使用有限的资源定期执行主分支下的所有测试。通过这种方式，我们可以在资源密集型测试中暴露出更多的脆弱性。然后，我们将结果按原样发送到 Testopedia，后者通过线性分析器运行结果，根据其历史记录确定测试状态。&lt;/p&gt;&lt;p&gt;如果测试在运行的最后一个 X 窗口中失败一次，则将其归类为不稳定。另一方面，由于机器上的资源被故意损害，某些测试可能会更频繁地超时，但这不是他们的错。在这种情况下，分析器还为每个测试授予超时阈值 M。要将测试分类为稳定，测试必须连续通过 N 次。我们还认识到，测试可能会因错误而持续失败，并相应地对其进行标记，因此稍后将通知用户此更改。&lt;/p&gt;&lt;p&gt;此外，我们还发送来自常规登陆 CI 管道的结果数据。因为我们在那里有重试逻辑，如果测试第一次失败但通过了相同的重试，我们就知道这个测试是不稳定的。我们对导入流进行不同的标记，并使分析器 Testopedia 能够感知，因此它们不会相互干扰。&lt;/p&gt;&lt;p&gt;有了上述所有内容，我们将有一个如下所示的配置： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXeMCzGfKOmguHaw5yyslTacjboR8yIY7TytrD8OqSdyd4Q44BVTCPSWFg9HTJ4oTmCDsxBwr5aq_QVf3rMci0ZsIfv87RJh4fzZKT-b1wIRmhXWEp99gwMoroFjGaMonto9_TVxoY99CN6Dz1-5wPpMjKc?key=6gZ2dLlV7xzsqb0CRMkSGA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：分析仪配置。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;如上所述，分析器的所有这些行为都是高度可扩展的。例如，集成测试可能更容易出现超时和不稳定的情况。标准线性分析仪不太合适。在这种情况下，将为它们实施不同的基于百分比的分析器。如果最后 N 次运行的失败百分比超过特定阈值，它将测试归类为片状测试。其他分析器也可以轻松插入。这些分析器可能包括设计用于检查特定错误消息的分析器、对超时敏感的分析器或优先检测故障趋势的分析器等。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-managing-flaky-tests-nbsp"&gt;管理不稳定的测试&lt;/h2&gt;&lt;p&gt;发现这些不稳定的测试后，我们需要对其进行处理并通知所属团队。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-treating-flaky-tests"&gt;处理不稳定的测试&lt;/h3&gt;&lt;p&gt;在 Monorepo 设置中，影响许多库及其测试的大型差异可能非常具有挑战性，而且当它们的测试不稳定时，情况会更糟。不是由差异本身引起的一种片状故障可能会导致整个作业的完全重建。&lt;/p&gt;&lt;p&gt;我们的一般指导是避免在 CI 中运行不稳定的测试。然而，当工程师尝试修复不稳定的测试并提交差异时，问题很快就会出现。如果它在 CI 中仍然被忽略，那么我们不知道该修复是否有效。或者更糟糕的是，它可能完全破坏了测试，但因为 CI 不验证它，所以我们永远不知道它被破坏了。&lt;/p&gt;&lt;p&gt;因此，我们围绕此实施了多种策略：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;无论是否不稳定，都会在 CI 作业上运行专门标记为“关键”的测试&lt;/li&gt;&lt;li&gt;工程师可以在差异中专门添加标签或关键字来选择退出该行为&lt;/li&gt;&lt;li&gt;其他片状测试（例如集成测试）以非阻塞模式运行，仅供参考&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-reducing-impact-of-flaky-tests"&gt;减少不稳定测试的影响&lt;/h3&gt;&lt;p&gt;在 CI 阶段跳过不稳定测试的策略由每个领域所有者实施。例如，Golang 和 Java 可能具有非常不同的测试运行器模式，因此使用不同的测试过滤器机制。&lt;/p&gt;&lt;p&gt;例如，在 Go Monorepo 中，我们有不同的方法来跳过测试用例和测试目标。为了跳过测试目标，我们排除直接在 CI 中运行片状测试目标，但仍然确保目标是可构建的。如果目标仅包含某些片状测试用例而其他测试用例仍然有用怎么办？我们在&lt;a href="https://github.com/bazelbuild/rules_go/blob/master/docs/go/core/rules.md#go_test"&gt;rules_go&lt;/a&gt;中实现了一个功能，通过&lt;a href="https://tip.golang.org/doc/go1.20#go-command"&gt;Go 1.20 -skip&lt;/a&gt;测试标志并解析&lt;a href="https://github.com/bazelbuild/rules_go/pull/3618"&gt;TESTBRIDGET_TEST_ONLY&lt;/a&gt;环境变量来跳过测试用例。这样，有关片状测试的信息与 Bazel 规则的输入隔离，并且无论片状情况如何，测试缓存都可以保持稳定。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-accountability"&gt;问责制&lt;/h3&gt;&lt;p&gt;现在我们发现了一些不稳定的测试并在 CI 中采取了相应的行动。下一步是什么？&lt;/p&gt;&lt;p&gt;我们需要将这些发现通知测试作者，并鼓励他们尽快修复测试。我们可以通过立即调用 JIRA、Slack 等票务模块来做到这一点。然而，在 Uber，即使是最小的领域也有数千次测试，显然我们无法承受等待外部系统的延迟和成本。为每一个人做出回应或提交票据。因此，我们在 Testopedia 中设计了一个异步系统，可以根据分组规则提交票证。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXefNJ-bMu_P-R7GsX8K7fqdWfWwcOMx8HDY1RZom-bf92pEGA9FSKufI5KEuoPsq6ZCnLR_pokvWi8i45Vg9q9Ta9fS8plpLT_mNbXDlq4O7uXQP7SqdwYuD-hmK4tItY_XEc73ucAql6xJIoxwjncBwLNl?key=6gZ2dLlV7xzsqb0CRMkSGA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：票据归档图。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;当分析器确定测试不健康时，除了在数据库中更新之外，还会将其插入消息队列中。然后，节奏工作流程会触发队列，再次检查这些测试，并调用 JIRA 向所属团队提交票据。 Bazel 测试目标可以有多个测试用例，我们将每个测试用例作为 FQN 进行跟踪，但我们只想为每组类似测试提交一张票以减少噪音。因此，我们提出了一个分组概念，通过构建目标或正则表达式将所有不健康的 FQN 放入每个组的一张票据中。&lt;/p&gt;&lt;p&gt;我们还对整个模块进行了可定制，用户可以自定义分组规则、工单类型、优先级，甚至工单描述模板。典型的任务配置如下所示： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcOx9cAS4GShBGqQ2zpaS0C0nOYLfRj6oITaJzZS1zphl94Xa8Yh_F3CgcWaiiCgVe5PmdjrwZdkjG-XhDHvqzymBqPDBp6oPS1bm7dtuNKJje1tSzcv_e-JttdXGfhtrTimkxGKj-nP3mbUNjavDYVeSAB?key=6gZ2dLlV7xzsqb0CRMkSGA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 9：票据归档配置。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;这样，团队将拥有不同的测试结构，并根据用户体验定义自己的通知策略。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-future-plans"&gt;未来的计划&lt;/h2&gt;&lt;p&gt;Uber 正在积极&lt;a href="https://www.uber.com/blog/generative-ai-for-high-quality-mobile-testing/" rel="noreferrer noopener" target="_blank"&gt;开发各种法学硕士&lt;/a&gt;，以改善我们的开发者体验。我们设想未来将这些尖端技术融入到系统中：&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-integrate-genai-for-automated-flaky-tests-resolution"&gt;&lt;strong&gt;集成 GenAI 以实现自动化片状测试解决方案&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;导入和分析 FQN 并访问其所有历史数据和其他测试失败模式后，我们可以使用 GenAI 自动生成该测试的修复程序。我们正在探索 Uber 内部构建的 GenAI 集成，以帮助集中减少 Monorepos 中不健全测试的数量，而测试所有者的投入最少。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-more-granular-failure-categorization-and-sub-categorization"&gt;&lt;strong&gt;更细粒度的故障分类和子分类&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;当前的 FSM 模型提供了通用的分类桶，但是，并非所有测试失败都是相同的。子分类是在领域级别明确完成的。通过利用人工智能分析故障模式，我们可以根据错误日志和类型、测试环境或故障代码上下文等因素自动将测试故障分类为更具体的子组。这种增强的分类系统将使我们能够更有效地进行故障排除和解决。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;现在，Uber 的所有主要 Monorepos 都已加入 Testopedia，并且随着内部算法和基础设施组件的大量优化，它比以往任何时候都更加稳定。在 Go Monorepo 中，我们在总共 600K 测试中稳定地检测到大约 1000 个片状测试，其中 Java 测试中有 1K/350K。我们还观察到 CI 可靠性显着提高，重试次数大幅减少。使用包含正确信息的 Jira 票据来烦扰开发人员，极大地帮助扭转了不稳定测试数量不断增加的趋势。&lt;/p&gt;</description><pubDate>Tue, 04 Jun 2024 07:25:02 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/flaky-tests-overhaul/</guid></item><item><title>【Modernizing Uber’s Batch Data Infrastructure with Google Cloud Platform】</title><link>https://www.uber.com/blog/modernizing-ubers-data-infrastructure-with-gcp/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;Uber 运行着世界上最大的 Hadoop 安装之一。我们的&lt;a href="https://www.uber.com/blog/uber-big-data-platform/" rel="noreferrer noopener" target="_blank"&gt;Hadoop 生态系统&lt;/a&gt;在两个区域的数万台服务器上托管着超过 1EB 的数据。开源数据生态系统，包括之前&lt;a href="https://www.uber.com/blog/engineering/data/" rel="noreferrer noopener" target="_blank"&gt;工程博客&lt;/a&gt;中讨论的Hadoop生态系统，一直是我们数据平台的核心。&lt;/p&gt;&lt;p&gt;在过去的几个月里，我们一直在评估我们的平台和基础设施需求，以确保我们能够很好地实现大数据基础设施的现代化，以满足 Uber 不断增长的需求。&lt;/p&gt;&lt;p&gt;今天，我们很高兴地宣布，我们正在与 Google Cloud Platform (GCP) 合作，将批量数据分析和机器学习训练堆栈迁移到 GCP。&lt;/p&gt;&lt;p&gt; Uber 数据平台的使命是通过直观、可靠且高效的数据产品，使数据驱动的业务决策民主化。使用 GCP 进行现代化将大大提高用户生产力、工程速度、提高成本效率、获得新创新并扩展数据治理。&lt;/p&gt;&lt;h1 class="wp-block-heading" id="h-strategy"&gt;战略&lt;/h1&gt;&lt;p&gt;我们最初迁移到 GCP 的策略是利用云的对象存储作为数据湖存储，同时将其余数据堆栈迁移到云 IaaS（基础设施即服务）。这种方法有助于实现快速迁移路径，同时最大限度地减少对现有作业和管道的干扰，因为我们可以在 IaaS 上复制本地软件堆栈、引擎和安全模型的精确版本。我们计划在最初迁移到 GCP 后采用适用的 PaaS（平台即服务）产品，例如 GCP Dataproc 或 BigQuery，以充分利用云原生服务提供的弹性和性能优势。我们的计划是在接下来的几个季度执行这一战略，通过一系列博客文章（这是第一篇）记录我们的进展并分享我们的经验教训。因此，请将此博客添加为书签并继续关注！ &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/Wx5iHeuUr_MaCochwvxq39y6wvy3aP3z8euxLBVPwOIujVTJ7GPvI8jyKFH4-JhfSps-0dQeWb9PJ7-fMn2Qgs1LXnmnOfxg8XeodrfTcnrrj8S8OZLEx_taJfS1JTrJ0c2_MZ27nPTq_6JfxFk6BWc" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/vJcumVtF5yY4yqe5-7chOwkB6uyypCxfeuj9YVNhO3Xyi3YBjdig7sYRDC4RAU5IUh9XWbcWH-1D8KJs9ilaWkwsOAPKKmsbpV23AR5mxSGPRYXbSlREjembU5CMm4FLq_1RYHvloRng1Jz7xADjq6E" /&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-migration-principles"&gt;迁移原则&lt;/h2&gt;&lt;p&gt;以下是我们在这次艰巨的迁移中牢记的核心原则：&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-avoid-painful-migrations-for-data-users"&gt;避免数据用户痛苦的迁移&lt;/h3&gt;&lt;p&gt;通过将大部分批处理数据堆栈按原样转移到云 IaaS 上，我们希望保护仪表板所有者、管道作者、机器学习从业者等用户免于对其工件或服务进行任何更改。我们将利用众所周知的抽象和开放标准，使迁移对数据用户尽可能透明。&lt;/p&gt;&lt;p&gt;我们将严重依赖云存储连接器，该连接器实现 Google Cloud Storage 的 Hadoop 文件系统接口，提供 HDFS 兼容性。我们将利用&lt;a href="https://parquet.apache.org/" rel="noreferrer noopener" target="_blank"&gt;Apache Parquet&lt;/a&gt; ™ 文件格式、 &lt;a href="https://hudi.apache.org/" rel="noreferrer noopener" target="_blank"&gt;Apache Hudi&lt;/a&gt; ™ 表格式、 &lt;a href="https://spark.apache.org/"&gt;Apache Spark&lt;/a&gt; ™、 &lt;a href="https://prestodb.io/" rel="noreferrer noopener" target="_blank"&gt;Presto 的&lt;/a&gt;SQL 方言、 &lt;a href="https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html" rel="noreferrer noopener" target="_blank"&gt;Apache Hadoop YARN&lt;/a&gt; ™ 和&lt;a href="https://kubernetes.io/" rel="noreferrer noopener" target="_blank"&gt;K8s&lt;/a&gt;等开放标准，最大限度地减少数据平台组织内团队的迁移挑战。我们将标准化我们的&lt;a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" rel="noreferrer noopener" target="_blank"&gt;Apache Hadoop HDFS&lt;/a&gt; ™ 客户端，以抽象本地 HDFS 实施细节。因此，现在访问本地 HDFS 的所有服务都将与基于 GCP 托管的对象存储的存储层无缝集成，无需任何更改。标准化 HDFS 客户端将被修改为通过“路径转换服务”将 HDFS 路径转换为基于对象存储的路径。我们将在未来的博客文章中分享更多相关细节。 &lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-enhance-data-access-proxies-to-federate-traffic-across-on-prem-or-cloud"&gt;增强数据访问代理以联合本地或云端的流量&lt;/h3&gt;&lt;p&gt;我们开发了数据访问代理（适用于&lt;a href="https://www.uber.com/blog/presto/" rel="noreferrer noopener" target="_blank"&gt;Presto&lt;/a&gt; 、 &lt;a href="https://www.uber.com/blog/uscs-apache-spark/" rel="noreferrer noopener" target="_blank"&gt;Spark&lt;/a&gt;和 Hive），可以抽象出底层物理计算集群的详细信息。在测试阶段，这些代理将支持有选择地将测试流量路由到相应的基于云的 Presto 或 YARN（适用于 Spark 和 Hive）集群。在完全迁移期间，提交给这些代理的所有查询或作业都将路由到基于云的堆栈。 &lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-leverage-uber-s-existing-cloud-agnostic-container-and-deployment-infrastructure"&gt;利用 Uber 现有的与云无关的容器和部署基础设施&lt;/h3&gt;&lt;p&gt;批量数据堆栈位于 Uber 的基础设施构建块之上，例如 Uber 的&lt;a href="https://www.uber.com/blog/hadoop-container-blog/" rel="noreferrer noopener" target="_blank"&gt;容器环境&lt;/a&gt;、计算平台和部署工具，这些工具的构建&lt;a href="https://www.uber.com/blog/crane-ubers-next-gen-infrastructure-stack/" rel="noreferrer noopener" target="_blank"&gt;与云和本地之间无关&lt;/a&gt;。这些平台使我们能够轻松地将批量数据生态系统微服务扩展到云IaaS上。 &lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-forecast-potential-data-governance-issues-from-cloud-services"&gt;预测云服务中潜在的数据治理问题&lt;/h3&gt;&lt;p&gt;作为一个平台团队，我们将构建和增强现有的数据管理服务，以仅支持云供应商产品组合中选定和批准的数据服务，以避免未来数据治理的复杂性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-major-workstreams"&gt;主要工作流程&lt;/h2&gt;&lt;h3 class="wp-block-heading" id="h-bucket-mapping-and-cloud-resources-layout"&gt;桶映射与云资源布局&lt;/h3&gt;&lt;p&gt;在迁移数据时，我们需要将源集群中的HDFS文件和目录映射到驻留在一个或多个存储桶中的云对象。我们还需要在不同的粒度级别（例如存储桶、前缀或对象级别）应用 IAM 策略。对存储桶和对象的常见约束包括每个组织的存储桶数量、存储桶的读/写吞吐量、IOPS 限制以及 ACL 数量（可通过存储桶策略应用）。&lt;/p&gt;&lt;p&gt;该工作流的目标是制定满足这些约束的映射算法并创建相应的云存储桶。我们还计划结合&lt;a href="https://martinfowler.com/articles/data-mesh-principles.html" rel="noreferrer noopener" target="_blank"&gt;数据网格原则，&lt;/a&gt;以以组织为中心的分层方式组织这些数据资源，从而实现更好的数据管理和管理。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-security-integration"&gt;安全集成&lt;/h3&gt;&lt;p&gt;我们现有的基于 Kerberos 的令牌和 Hadoop 委托令牌将无法直接与云 PaaS（特别是 GCS 对象存储）配合使用。云提供商通常没有现成的 PaaS 解决方案来实现此类互操作性。&lt;/p&gt;&lt;p&gt;此工作流的目标是为所有用户、组和服务帐户提供无缝支持，以便继续根据对象存储数据湖和任何其他云 PaaS 进行&lt;a href="https://www.uber.com/blog/scaling-adoption-of-kerberos-at-uber/" rel="noreferrer noopener" target="_blank"&gt;身份验证&lt;/a&gt;。从此以后还要保持与本地相同的授权访问级别。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-data-replication"&gt;数据复制&lt;/h3&gt;&lt;p&gt;HiveSync 是 Uber 构建的权限感知、双向数据复制服务（基于&lt;a href="https://github.com/airbnb/reair" rel="noreferrer noopener" target="_blank"&gt;ReAir&lt;/a&gt; / &lt;a href="https://hadoop.apache.org/docs/stable/hadoop-distcp/DistCp.html" rel="noreferrer noopener" target="_blank"&gt;distcp&lt;/a&gt; ）。 HiveSync 允许我们以主动-主动模式运行，并具有批量和增量复制功能，使两个区域的数据湖保持同步。&lt;/p&gt;&lt;p&gt;该工作流的目标是扩展 HiveSync 的功能和 Hudi 库功能，以将本地数据湖的数据复制到基于云的数据湖和相应的 Hive Metastore。这包括一次性引导（批量迁移），然后持续增量更新，直到基于云的堆栈成为主要堆栈。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-yarn-and-presto-clusters"&gt; YARN 和 Presto 集群&lt;/h3&gt;&lt;p&gt;我们将从 GCP 在 IaaS 上配置新的 YARN 和 Presto 集群。然后，将查询和作业流量联合到这些集群的现有数据访问代理将通过迁移将流量路由到基于云的堆栈。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-challenges-and-initiatives"&gt;挑战与举措&lt;/h2&gt;&lt;p&gt;这次迁移是一项艰巨的任务，我们意识到我们面临的典型挑战&lt;/p&gt;&lt;p&gt;可能会面临。以下是我们预计将面临的一些大类挑战以及应对这些挑战的缓解措施和举措：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;性能&lt;/strong&gt;：对象存储和 HDFS 之间的功能和性能特征存在一些众所周知的差异。 （例如，原子重命名、文件列表性能等）。我们将利用开源的 Hadoop 连接器并帮助它们发展以最大限度地提高性能。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;使用治理&lt;/strong&gt;：如果我们不&lt;a href="https://www.uber.com/blog/cost-efficient-big-data-platform/" rel="noreferrer noopener" target="_blank"&gt;有效&lt;/a&gt;、主动地管理云相关的使用成本，它们可能会失控。我们将利用云的弹性来抵消这些成本。我们还将与内部容量工程团队合作，建立更精细的归因机制和跟踪。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;应用程序&lt;/strong&gt;&lt;strong&gt;对 HDFS 的非分析/ML 特定使用&lt;/strong&gt;：多年来，团队也开始使用 HDFS 作为通用文件存储。我们将主动将这些用例迁移到其他内部 Blob 存储，同时提供透明的迁移路径以避免中断。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;未知的未知&lt;/strong&gt;：最后，凭借大约 7 年历史的本地堆栈，我们肯定会面临意想不到的挑战。我们希望主动发现早期端到端集成的问题，与客户一起完善提议的抽象，积极弃用遗留用例而不是继续推进它们等等，以保持领先于这些挑战。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;请继续关注我们的旅程，我们将分享我们的详细设计、执行进度以及一路上学到的经验教训！&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Apache &lt;sup&gt;®&lt;/sup&gt; 、Apache Parquet™、Apache Hudi™、Apache Spark™、 &lt;em&gt;Apache Hadoop YARN™&lt;/em&gt;是&lt;/em&gt;&lt;a href="http://www.apache.org/" rel="noreferrer noopener" target="_blank"&gt;&lt;em&gt;Apache Software Foundation&lt;/em&gt;&lt;/a&gt;&lt;em&gt;在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/em&gt;&lt;/p&gt;&lt;p class="has-small-font-size"&gt;封面照片归属： &lt;a href="https://www.flickr.com/photos/55856449@N04" rel="noreferrer noopener" target="_blank"&gt;Infomastern&lt;/a&gt;的“ &lt;a href="https://www.flickr.com/photos/55856449@N04/17510835551" rel="noreferrer noopener" target="_blank"&gt;乡村道路和黄色田野&lt;/a&gt;”已获得&lt;a href="https://creativecommons.org/licenses/by-sa/2.0/?ref=openverse" rel="noreferrer noopener" target="_blank"&gt;CC BY-SA 2.0&lt;/a&gt;许可。&lt;/p&gt;</description><pubDate>Thu, 30 May 2024 07:21:12 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/modernizing-ubers-data-infrastructure-with-gcp/</guid></item><item><title>【Uber Becomes Kotlin™ Foundation Silver Member】</title><link>https://www.uber.com/blog/kotlin-foundation-member/</link><description>&lt;p&gt;我们很高兴地宣布，Uber 已作为银牌会员加入 Kotlin &lt;sup&gt;™&lt;/sup&gt;基金会。&lt;/p&gt;&lt;p&gt; Uber 对 Kotlin 的承诺在我们的代码库中显而易见。我们正在积极为 Kotlin 生态系统做出贡献，包括开发 Kotlin 与 Buck、Bazel 和 Gradle 等构建系统的集成。 Uber 还为 Detekt 的开发做出了贡献，并发起了其编译器插件版本的创建。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;blockquote class="wp-block-quote has-000000-color has-white-background-color has-text-color has-background has-link-color wp-elements-267bc928adce8748455de4dd6b36c501 is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p class="has-000000-color has-text-color has-link-color wp-elements-529663472951b895d728ed42ff0c690e"&gt; “我们很高兴加入 Kotlin 基金会，这突显了我们对 Kotlin 社区的承诺，以及我们对 Kotlin 作为帮助 Uber 成功的技术堆栈核心部分的信念。我们每天有数百万行 Kotlin 代码和数百名热情的开发人员使用它进行编写。作为从 2018 年开始的早期采用者和积极的贡献者，我们很自豪能够帮助成熟生态系统，并期待与这个充满活力、友好和创新的社区继续合作。”&lt;/p&gt; &lt;cite&gt;Ty Smith，Uber 首席工程师&lt;/cite&gt;&lt;/blockquote&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;除了为 Kotlin 做出贡献之外，Uber 还帮助建立了企业 Java 到 Kotlin 工作组，这是 Meta、Google、JetBrains 和 Uber 之间的合作，目标是为公司提供将大型遗留 Java 代码库迁移到 Kotlin 所需的工具和专业知识。 。&lt;/p&gt;&lt;p&gt;作为银牌会员，Uber 将在支持基金会的举措方面发挥至关重要的作用，包括针对开源库作者的资助计划和针对学生的 Kotlin 多平台竞赛。我们很高兴能与 Kotlin 基金会在未来的项目上进行合作。&lt;/p&gt;&lt;p&gt;访问 Kotlin 基金会&lt;a href="http://kotlinfoundation.org/" rel="noreferrer noopener" target="_blank"&gt;网站，&lt;/a&gt;详细了解为支持基金会使命而开展的重要工作。&lt;/p&gt;</description><pubDate>Wed, 22 May 2024 18:37:07 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/kotlin-foundation-member/</guid></item><item><title>【How Uber Accomplishes Job Counting At Scale】</title><link>https://www.uber.com/blog/job-counting-at-scale/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;Uber 运营规模庞大，每个季度为超过 22 亿次出行提供便利。即使是简单的见解也需要规模化的解决方案。在我们的例子中，我们需要计算某人在 Uber 平台上、任意时间窗口内参与的作业数量。本文重点介绍我们将 Apache Pinot™ 集成到我们的解决方案中时面临的挑战和吸取的经验教训。&lt;/p&gt;&lt;h2 class="wp-block-heading" id="h-background-nbsp"&gt;背景&lt;/h2&gt;&lt;p&gt;具体来说，我们的解决方案需要解决：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;职位数量的几种排列，按角色、市场和完整性轴细分&lt;/li&gt;&lt;li&gt;给定行程或给定时间戳的时间点任期（即，按时间顺序，工作 X 位于人员 A 的工作历史记录中的什么位置？）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们之前的解决方案很简单：检索页面大小限制为 50 的给定主题的职位，并对结果进行分页，直到没有更多职位为止。在 Uber 成立之初，由于没有任何一个账户能够获得相对较多的任期，因此这种做法运作良好。然而，Uber 涉足新的垂直领域，一些账户开始出现数以万计的任期，很明显，我们需要一个更强大的解决方案。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-trip-specific-tenures-are-a-narrow-use-case"&gt;特定旅行的任期是一个狭窄的用例&lt;/h3&gt;&lt;p&gt;主要的产品要求是该解决方案必须能够计算任期回顾。这本身是站得住脚的，但伴随着我们的数据保留政策，我们的下游团队认为这是不合理的。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-access-rescission-of-data-older-than-2-years"&gt; 2年以上数据的访问撤销&lt;/h3&gt;&lt;p&gt;出于节省成本的考虑，同一团队确定将超过 2 年的数据隔离到更高延迟的存储层中。然而，项目中期计划的改变导致他们完全放弃了对这些数据的在线访问。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-reduced-complexity"&gt;降低复杂性&lt;/h3&gt;&lt;p&gt;我们当时的解决方案需要为 Uber 的每个市场拼接三个数据源：乘车和外卖。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-similar-use-cases-in-the-broader-team"&gt;更广泛的团队中的类似用例&lt;/h3&gt;&lt;p&gt;在向更广泛的团队展示我们的设计后，我们立即发现 Uber 的各个团队都有类似需求的相邻项目，每个团队都重新实现了自己的解决方案来独立计算工作任期。&lt;/p&gt;&lt;p&gt;考虑到这些限制，我们考虑了几种架构。我们认真考虑过的一个方案是由 Apache Hive™ 和 Docstore（Uber 的内部分布式数据库）支持，最终采用了一种利用 Apache Pinot™ 的解决方案。这里的一个有趣的功能是混合表，它提供了一个将实时和离线数据缝合在一起的无缝界面。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-architecture"&gt;建筑学&lt;/h2&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large is-resized"&gt;&lt;img alt="" class="wp-image-1089197" height="2850" src="https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/05/figure1-1.png" style="width: 700px; height: auto;" width="3617" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：用户权属存储架构图。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-development-challenges"&gt;发展挑战&lt;/h2&gt;&lt;p&gt;Apache Pinot™ 是一款极其强大的产品，为我们的架构提供了无与伦比的灵活性。然而，我们在此过程中遇到了一些障碍，下面我们详细介绍了这些挑战以及我们对这些问题的解决方案，读者可能会有所了解。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-challenge-1a-capacity-planning"&gt;&lt;strong&gt;挑战 #1a – 容量规划&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;我们的第一个挑战是制定容量要求，为我们的专用租户提供所需的硬件。 Apache Pinot™ 利用压缩技术，因此很难预先测量磁盘空间。在这里，我们选择采用 10% 的样本数据集，并且根据样本占用的空间来预测磁盘使用情况在我们的案例中就足够了。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-challenge-1b-query-performance"&gt;&lt;strong&gt;挑战 #1b – 查询性能&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;这里一个有趣的旁注是，虽然我们能够通过采样来估计磁盘上的数据集大小，但我们无法准确预测查询性能。在这种情况下，我们必须等到扩大整个数据集之后才能获取关键指标，例如 p99 读取时间、磁盘读取吞吐量等。一旦我们能够这样做，生产规模的流量就会带来我们的专用集群崩溃了，读取时间超过了代理限制 10 秒，SSD 上的读取吞吐量达到最大，CPU 使用率也达到了极限。我们立即着手研究优化，这并不意外，因为每个查询都相当于加载全表扫描。&lt;/p&gt;&lt;p&gt;作为参考，我们的查询具有以下形式：&lt;/p&gt;&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;p&gt;&lt;em&gt;选择&lt;/em&gt;&lt;em&gt;&lt;br /&gt;&lt;/em&gt;&lt;em&gt;*&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;从&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;皮诺混合表&lt;br /&gt;其中provider_id = &amp;#39;...&amp;#39;&lt;br /&gt; AND requester_id = &amp;#39;...&amp;#39;&lt;br /&gt; AND 时间戳 &amp;gt;= ... AND 时间戳 &amp;lt;= ...&lt;/em&gt; &lt;/p&gt;&lt;/blockquote&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/mziEvOUPidZxsIp2eyVVTr3vJyvJpPwk-syVG52f6ZIVB6DZIeIxsNlTGW2RzcUFBCJGmw2vJgCNOtBoXggHKwQFIvyv-QvjxLO4oNCyLnrbdD7Sr6ybJfltL3xspF4eZEHrXs-297Y3Mzm-IlR8YHE" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：由于代理超时导致 Apache Pinot™ 查询失败。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;这关系到团队，我们采取了多项措施来提高绩效，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;已排序的&lt;em&gt;provider_id&lt;/em&gt;列&lt;/strong&gt;&lt;br /&gt;这会将同一提供商在同一天进行的所有行程并置，从而最大限度地减少每个查询访问的路段。&lt;br /&gt;如果没有这一点，供应商在某一天完成的所有工作将平均分配给该天的所有部门。因此，如果提供者在同一天执行了多个作业，为了让代理完成我们的读取查询，它将很快收敛到检索提供者每天完成一项工作的所有段。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;在&lt;em&gt;provider_id&lt;/em&gt;和&lt;em&gt;requester_id&lt;/em&gt;上添加倒排索引&lt;br /&gt;&lt;/strong&gt;我们还在&lt;em&gt;provider_id&lt;/em&gt;和&lt;em&gt;requester_id&lt;/em&gt;列上启用了倒排索引。与排序列相结合，这在&lt;em&gt;provider_id&lt;/em&gt;列上提供了排序倒排索引。这允许&lt;em&gt;log(n)&lt;/em&gt;的查找时间复杂度，因为它执行二分搜索来查找与给定的&lt;em&gt;provider_id&lt;/em&gt;值对应的行。&lt;br /&gt;&lt;br /&gt;一个令我们措手不及的令人惊讶的事实是，这些倒排索引是&lt;em&gt;为每个细分市场&lt;/em&gt;创建的。这是与传统 RDBMS 索引之间非常显着的区别。该索引不是所有段共享的全局结构，直接指向正在查询的数据。在我们的例子中，代理仍然必须对表中每个段的一部分进行内存映射才能使用索引。如果不实施额外的段修剪技术，这是非常低效的，我们很快就实施了。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;在&lt;em&gt;provider_id&lt;/em&gt;和&lt;em&gt;requester_id&lt;/em&gt;上添加布隆过滤器&lt;/strong&gt;&lt;br /&gt;布隆过滤器是一种概率数据结构，测试一个元素是否是集合的成员，给出两个答案：可能在集合中，或不在集合中。当为列启用时，Apache Pinot™ 为每个段创建一个布隆过滤器，并允许代理在完成查询时完全跳过段。如果段上的列存在布隆过滤器，并且查询中存在该列的相等谓词，则代理能够快速确定该记录是否存在于段中。由于我们的数据集并不完全适合内存，因此我们选择了 MMAP（内存映射）堆外配置，其中段被延迟加载到内存中，如果操作系统物理内存不足，则先前加载的段将被取消映射（就像我们的例子一样）。然而，该段的关联布隆过滤器可以存储在堆上（内存中），并且将保留在那里，即使它们的底层段不再位于物理内存中。&lt;br /&gt;&lt;br /&gt;观察到的加速应该与跳过的段数相关，因此它有利于读取模式不需要获取大部分段的数据集（例如全表扫描）。&lt;br /&gt;&lt;br /&gt;请参见图 3 和图 4，其中可以观察到启用 Bloom 过滤器后 ( &lt;em&gt;numSegmentsQueried&lt;/em&gt; – &lt;em&gt;numSegmentsProcessed)&lt;/em&gt;显着下降。&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;每天增加的路段&lt;/strong&gt;&lt;br /&gt;为了创建 Apache Pinot™ 段，我们安排每天运行一个 Apache Spark™ 作业，创建并上传组成离线表的新段。每个计划间隔创建的分段数量是可调的，我们最初每天创建四个分段。然而，随着段开始变得非常大（每个段超过 4GB），我们逐渐将其增加到 8 个，然后是 16 个，最后达到每天 32 个段。&lt;br /&gt;&lt;br /&gt;这里所做的权衡是，虽然增加的段数可能会导致 Zookeeper 元数据存储上的负载增加，并增加 Apache Pinot™ 服务器的内存堆使用量，但较小的段大小会导致更快地从磁盘上读取段，并且相应地会增加磁盘上的数据。要包含在结果中的段。根据经验，我们观察到 p99 读取延迟显着减少，并且代理 CPU 使用率增加不明显。&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;向我们的上游消费者添加了跨数据中心缓存&lt;/strong&gt;&lt;br /&gt;虽然不是特定于 Apache Pinot™，但我们的主要上游消费者在临时环境和生产环境之间执行相同的查询。虽然我们期望查询之间的时间延迟最小，但我们认为 30 分钟的陈旧是可以接受的。&lt;/li&gt;&lt;/ul&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;统计&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;在布隆过滤器之前&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;布隆过滤器之后&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;使用时间（毫秒）&lt;/td&gt;&lt;td&gt;第387章&lt;/td&gt;&lt;td&gt;1740&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;已扫描文档数&lt;/td&gt;&lt;td&gt;21&lt;/td&gt;&lt;td&gt; 21&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;总文档数&lt;/td&gt;&lt;td&gt;50,520,067,053&lt;/td&gt;&lt;td&gt; 50,550,326,486&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;查询的服务器数&lt;/td&gt;&lt;td&gt;18&lt;/td&gt;&lt;td&gt; 18&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;响应服务器数&lt;/td&gt;&lt;td&gt;18&lt;/td&gt;&lt;td&gt; 18&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;查询的段数&lt;/td&gt;&lt;td&gt;20,491&lt;/td&gt;&lt;td&gt; 20,488&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;已处理的段数&lt;/td&gt;&lt;td&gt;4,829&lt;/td&gt;&lt;td&gt; 48&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;匹配的段数&lt;/td&gt;&lt;td&gt;17 号&lt;/td&gt;&lt;td&gt;17 号&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;已查询的消费段数&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt; 2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;已扫描条目数&lt;/td&gt;&lt;td&gt;16,466,904&lt;/td&gt;&lt;td&gt; 147&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;图 3：通过 Pinot 查询控制台实施布隆过滤器之前和之后的查询统计信息&lt;/em&gt;。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-1089225" height="575" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/05/figure5-1024x575.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：有和没有布隆过滤器的性能比较。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-challenge-2-business-edge-cases"&gt;&lt;strong&gt;挑战 #2 – 业务边缘案例&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;随着 Uber 不断向平台添加功能，它们对源数据的下游影响也在不断增加。目前，我们可以通过三种方式接收行程级别信息：Apache Hive™、Apache Kafka™ 主题和 API 响应，每种方式都有不同的模式。以合理的方式在现有模式中改造和表示新功能可能很困难，特别是 Apache Hive™ 模式。历史数据具有很大的惯性，可能会使迁移模式变得不合理。&lt;/p&gt;&lt;p&gt;例如，考虑票价分摊功能，其中乘车费用可以由多个乘客分摊。在此功能之前，一项工作总是有一个骑手，而该骑手始终是付款人，并且每条 Hive 记录都意味着司机在订单上执行了一项工作。这些不变量不再成立。此处选择复制记录并将状态设置为&lt;em&gt;FARE_SPLIT&lt;/em&gt; ，同时将&lt;em&gt;driver_uuid&lt;/em&gt;列设置为&lt;em&gt;NULL&lt;/em&gt; 。&lt;/p&gt;&lt;p&gt;正是这样的复杂性使得执行简单的&lt;em&gt;COUNT DISTINCT&lt;/em&gt;聚合变得不可能。对于每个业务案例，必须清楚地考虑决定记录是否有助于主题的任期：&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;重新调度行程（派遣另一名司机来完成已分配的工作）&lt;/td&gt;&lt;td&gt;工作任期应归属于谁？两位司机？如果这些记录表示为多条记录，那么它是否应该算作骑手的 2 份工作？&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;宾客乘坐&lt;/td&gt;&lt;td&gt;由于这些帐户的性质，它们可能会导致热分片，从而导致表扫描查询的成本高昂。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;未履行的订单&lt;/td&gt;&lt;td&gt;未履行的订单是否应该有助于任期？&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;请求者取消、订单失败等&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;同一订单上同一供应商的多次派送&lt;/td&gt;&lt;td&gt;由同一司机完成多项工作的 1 个订单应为请求者贡献多少任期？&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;预定订单&lt;/td&gt;&lt;td&gt;尚未发生的命令是否应该针对某个主题累积任期？ &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-challenge-3-slow-data"&gt;&lt;strong&gt;挑战 #3 – 数据缓慢&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;我们必须解决的另一个挑战是上游数据缓慢。虽然大多数数据会在几秒钟内到达，但行程可能长达一周不会出现在上游数据源中。为了解决这个问题，我们创建了一个动态生成回填管道的管道，但仅安排在 T – 7d 和 T 之间运行。&lt;/p&gt;&lt;p&gt;除此之外，我们还执行离线数据质量检查，即 T – 1d 日期的简单&lt;em&gt;COUNT(*)&lt;/em&gt;查询，以确保我们的源 Apache Hive™ 表与 Apache Pinot™ 混合表的结果同步。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-challenge-4-bursty-upstream-loads"&gt;&lt;strong&gt;挑战 #4 – 突发的上游负载&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;流量模式尖峰的上游流量也是一个问题。在这种情况下，特定的速率限制实施会导致流量每十秒出现一次大幅峰值，每个流量都违反了十秒的 Apache Pinot™ 代理超时，导致请求失败。&lt;/p&gt;&lt;p&gt;我们通过在请求时向上游客户端添加抖动来解决这个问题，以便随着时间的推移更均匀地分布我们的查询。&lt;/p&gt;&lt;p&gt;克服这些挑战后，我们已经为实时生产流量提供了近一年的服务，并且执行负载测试显示，在包含故障转移流量的缓冲区后，至少有 200% 的空间。我们的 p99 读取延迟约为 1 秒：令人印象深刻，因为我们的一些上游查询可以命中超过 2,000 个段，每个段消耗大约 90 MB 的磁盘空间。在迭代我们的解决方案后，我们开始发布将之前的下游与我们的解决方案进行比较的指标。我们基于 Apache Pinot™ 的解决方案提供了几乎 1:1 的精度，让我们有信心信赖它。我们首先使用配置标志来控制更改，一段时间后，完全切换并弃用以前的实现。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;p&gt;通过一些简单的补充，我们有信心能够回答更有力的问题。例如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;最近 50 次旅行中多次前往哪个城市？&lt;/li&gt;&lt;li&gt; Uber 的员工中谁是高级职位？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在工作粒度上找到时间点任期的成本很高。提高性能和降低存储成本的途径仍在探索中。虽然仍处于设计过程中，但我们预计通过降低作业粒度要求，我们应该能够显着提高读取吞吐量。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-acknowledgments"&gt;致谢&lt;/h3&gt;&lt;p&gt;特别感谢 Caner Balci、Qiaochu Liu、Jacob Sevart 和 Ujwala Tulshigiri 对本文的贡献。&lt;/p&gt;&lt;p class="has-small-font-size"&gt; &lt;em&gt;Apache &lt;sup&gt;®&lt;/sup&gt; 、Apache Hive™、Apache Kafka®、Apache Spark™ 和 Apache Pinot™ 是&lt;/em&gt;&lt;a href="http://www.apache.org/" rel="noreferrer noopener nofollow" target="_blank"&gt;&lt;em&gt;Apache Software Foundation&lt;/em&gt;&lt;/a&gt;&lt;em&gt;在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/em&gt;&lt;/p&gt;&lt;p class="has-small-font-size"&gt;封面照片归属： &lt;a href="https://www.flickr.com/photos/54966739@N00"&gt;blaahhi&lt;/a&gt;的“ &lt;a href="https://www.flickr.com/photos/54966739@N00/3597105175"&gt;Abacus&lt;/a&gt; ”已获得&lt;a href="https://creativecommons.org/licenses/by/2.0/?ref=openverse"&gt;CC BY 2.0&lt;/a&gt;许可。&lt;/p&gt;</description><pubDate>Wed, 22 May 2024 06:41:19 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/job-counting-at-scale/</guid></item><item><title>【Upgrading M3DB from v1.1 to v1.5】</title><link>https://www.uber.com/blog/upgrading-m3db/</link><description>&lt;h1 class="wp-block-heading" id="h-introduction"&gt;介绍&lt;/h1&gt;&lt;p&gt;&lt;a href="https://m3db.io/" rel="noreferrer noopener" target="_blank"&gt;M3DB&lt;/a&gt;是一个可扩展的&lt;a href="https://github.com/m3db/m3" rel="noreferrer noopener" target="_blank"&gt;开源&lt;/a&gt;分布式时间序列数据存储。它用作&lt;a href="https://www.uber.com/en-IN/blog/m3/" rel="noreferrer noopener" target="_blank"&gt;M3 堆栈&lt;/a&gt;的持久存储，为所有 Uber 服务提供基于指标的可观察性。这些指标随后用于生成实时警报。&lt;/p&gt;&lt;p&gt;距离我们上次将 M3DB 的开源版本部署到 Uber 云中已经过去了 3 年。自上次部署以来，服务器代码中添加了一系列性能增强功能。其中一些增强功能包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; ( &lt;a href="https://github.com/m3db/m3/releases/tag/v1.2.0" rel="noreferrer noopener" target="_blank"&gt;V1.2.0&lt;/a&gt; ) 和 ( &lt;a href="https://github.com/m3db/m3/releases/tag/v1.5.0" rel="noreferrer noopener" target="_blank"&gt;V1.5.0&lt;/a&gt; ) 中完成的&lt;strong&gt;资源利用率改进&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Bootstrap 性能改进 –&lt;/strong&gt;改进&lt;strong&gt;&amp;nbsp;&lt;/strong&gt; ( &lt;a href="https://github.com/m3db/m3/releases/tag/v1.2.0" rel="noreferrer noopener" target="_blank"&gt;V1.2.0&lt;/a&gt; )&lt;/li&gt;&lt;li&gt;&lt;strong&gt;引导和快照可靠性 –&lt;/strong&gt; ( &lt;a href="https://github.com/m3db/m3/releases/tag/v1.4.0" rel="noreferrer noopener" target="_blank"&gt;V1.4.0&lt;/a&gt; ) 中进行的改进&lt;br /&gt;&lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-scope-of-work"&gt;工作范围&lt;/h2&gt;&lt;p&gt;尽管开源项目引入了重大改进，但我们一直在旧版本的 M3DB 上运行的原因之一是，我们没有经过充分测试的 M3DB 验证和部署流程。&lt;/p&gt;&lt;p&gt;这项工作的主要目标之一是找到一种可重复且可靠的方法将 M3DB 部署到 Uber 云中，以便我们能够更一致地进行升级。我们希望自动化尽可能多的步骤，同时为升级 M3DB 队列的下一次迭代提出一系列改进。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-scale-amp-performance-considerations"&gt;&lt;strong&gt;规模和性能考虑因素&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;开源项目中有一个集成套件的基本版本，但不适用于 Uber 规模（10 亿写入 RPS、8000 万读取 RPS 和大约 6,000 台服务器）。&lt;/p&gt;&lt;p&gt;考虑到 M3DB 在 Uber 内部的运营规模，即使性能/效率/可靠性下降 5-10% 也可能对我们的可观察性平台构成严重风险。除非在生产类似规模下进行测试，否则评估 M3DB 新版本的正确性是没有意义的。&lt;/p&gt;&lt;p&gt;此外，在大规模运行时，常见的场景之一是 M3DB 集群处于动态状态，即节点经常且几乎总是由底层基础设施自动化触发添加、删除或替换。因此，集成套件也应该在这些混乱的场景下测试功能、正确性和性能。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-quantifying-concrete-gains-for-uber-workloads"&gt;&lt;strong&gt;量化 Uber 工作负载的具体收益&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;开源版本中的更改已经显示出性能改进，但从未在 Uber 这样庞大和复杂的环境中进行过测试。没有可用的数据来表明我们通过迁移到最新工作负载会看到的确切收益。考虑到在 M3DB 中审查和发布新版本所涉及的工作，我们需要证明进行这项工作的投资回报率是合理的。&lt;/p&gt;&lt;p&gt;因此，新版本测试工作的一部分将包括在 Uber 生产类似流量下运行它，并将关键性能指标与生产中运行的现有版本进行比较，以了解开源版本与 Uber 规模相比如何。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-rollout-challenges"&gt;&lt;strong&gt;推出挑战&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;考虑到集群规模巨大（大约100个集群，总共5500个节点）以及每个节点的高分配（目前每个节点28核和230G内存），M3DB的任何变化的推出也会在可靠性和可操作性方面带来挑战。我们希望评估一个安全、稳定且需要最少人力或干预的发布过程。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-rollout-strategy"&gt;推出策略&lt;/h2&gt;&lt;p&gt;我们有超过数百个 M3DB 集群在生产中运行 - 按保留期和可用区域进行分片。每个集群可以有数百个节点，其中绝大多数平均每个集群有 100 个节点左右。虽然集群本身可以并行升级，但在集群内，我们有一个额外的限制，即一次只能升级一个节点，以避免数据丢失，因为写入是在 Uber 内以三分之二多数仲裁执行的。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-testing-strategy"&gt;测试策略&lt;/h2&gt;&lt;p&gt;我们考虑并实施了两种广泛的测试策略：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;离线模式&lt;/strong&gt;，我们在各种模拟/实验综合测试负载和关键客户端性能指标（如正确性、延迟、成功率）的基准下运行 M3DB。此外，我们还对服务器性能特征进行基准测试，例如服务器响应时间、引导持续时间、滴答持续时间以及重新启动和替换之间的数据持久性。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;在线模式，&lt;/strong&gt;我们在重复和采样的生产流量下运行 M3DB，以观察现有生产集群的性能和正确性回归。 &lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-offline-mode"&gt;离线模式&lt;/h3&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/XOs_e9tRumTWl2neEx1-qOK17aHObrN3xrkVXsbzqNbLNkWbyeoo9Wfs9_Ia8s7F8Q_MIs-aieAxmUiZ9oo9F2bNSRV0ZEfvS_7ZD0SCMqUhAl20JuSmCgPAXM2DgNGyPpg8ZLBlwT8puQv9SgPGLlc" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 1：离线测试策略。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;对于离线模式，我们需要一个能够大规模生成负载的 M3DB 基准测试工具。通过调整基准工具的输入参数或根据需要调整集群设置来模拟需要测试集群的各种场景。为了扩展我们的基准测试工具以模仿甚至超越我们的生产负载，我们将基准测试工具服务部署为分布式服务。我们部署了功能强大的高容量机器，使系统承受巨大的工作负载。所有基准测试均在新创建的 M3DB 集群上运行，集群大小为 10 个节点。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-test-scenarios"&gt;测试场景&lt;/h4&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;在旧版本上对 M3DB 集群进行基准测试&lt;/strong&gt;– 我们在旧版本上运行多个基准测试，并记录 M3DB 集群的延迟和正确性，以建立基线数字。&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;运行拓扑操作 –&lt;/strong&gt;在集群内发生拓扑操作（节点添加、删除和替换）时运行基准测试套件。&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;推出新版本 –&lt;/strong&gt;当我们在新版本上进行部署时运行基准套件。&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;对新版本进行基准测试 –&lt;/strong&gt;与上述旧版本类似，我们也对新版本运行完全相同的基准测试，并收集相同的指标。&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;基准测试正确性 –&lt;/strong&gt;首先在只写模式下运行基准测试，并将写入的指标记录在文件中 – 随后在验证模式下运行基准测试，一旦新版本的部署完成，它将尝试进行读取。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;当集群位于较旧版本的 M3DB 上时，上面的&lt;strong&gt;“a”&lt;/strong&gt;和&lt;strong&gt;“b”&lt;/strong&gt;点都会执行一次，当集群位于较新版本上时，也会执行一次。&lt;/p&gt;&lt;p&gt;当在传输中测试场景中进行测试时，需要上面的&lt;strong&gt;“c”&lt;/strong&gt;和&lt;strong&gt;“d”&lt;/strong&gt;点。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;“e”&lt;/strong&gt;点讲的是正确性。正确性是一个基本要求：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;当升级发生时，旧服务器会将所有数据刷新到磁盘，新服务器版本将开始读取相同的数据。我们需要确保新节点能够读取旧版本刷新的数据。&lt;/li&gt;&lt;li&gt;我们需要在新版本将数据保存在缓冲状态和刷新状态的情况下进行正确性基准测试。 &lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-online-testing"&gt;在线测试&lt;/h3&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/wtVD6vLneTmdQJjoTCOLl9E9QxlTzW99f22X06IK8oHL3AEB9Vxgi059Uh16_n4lE91SZvm0vrITtr7k4kqsiLFD71UiOcHCfkoJohK37_981kRdDdr_cvtqnMHqeh1nr2NHqN8RC0nzEyO6Pfa3swg" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 2：在线测试策略。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;虽然离线模式帮助我们在 M3DB 的一些关键性能指标上探索 M3DB 新版本，但它仍然没有让我们对新版本在 Uber 生产规模和指标有效负载方面的表现缺乏信心。&lt;/p&gt;&lt;p&gt;为了获得这种信心，我们最终实现了如下所示的影子流量管道设置，其中我们可以将可配置的写入和读取流量示例复制到具有生产流量的影子 M3DB 集群，尽管规模较小。&lt;/p&gt;&lt;p&gt;考虑两种类型的影子测试：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;影子测试用于比较运行相同百分比生产流量的旧版本和新版本&lt;/li&gt;&lt;li&gt;影子测试具有与生产集群成比例的流量和集群大小并进行比较&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-shadow-testing-against-older-version-vs-newer-version-nbsp"&gt;针对旧版本与新版本的影子测试&lt;/h4&gt;&lt;p&gt;我们首先使用旧版本创建影子 M3DB 集群，并让它运行几周，以便我们获得各种性能指标（如 CPU、内存、引导延迟、滴答持续时间和服务器/客户端延迟）的基线数字。之后，影子M3DB集群升级到最新版本，测量相同的性能指标并与基线数字进行比较。&lt;/p&gt;&lt;p&gt;在线测试分为3个阶段：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在旧版本的 M3DB 中运行影子集群以建立基线&lt;/li&gt;&lt;li&gt;在影子设置中推出较新版本的 M3DB&lt;ol&gt;&lt;li&gt;测量推出所需的时间&lt;/li&gt;&lt;li&gt;观察读/写失败&lt;/li&gt;&lt;li&gt;观察性能指标是否有变化&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;在较新版本的 M3DB 中运行影子集群以建立较新的性能指标并与基线数字进行比较&lt;/li&gt;&lt;li&gt;新的性能指标可以帮助量化我们的生产设置通过迁移到新版本可以获得的改进&lt;ol&gt;&lt;li&gt;验证在推出之前发送的写入是否在推出后保留&lt;/li&gt;&lt;li&gt;验证在部署之前发送的写入是否保留以进行节点替换&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-shadow-testing-against-production-cluster"&gt;针对生产集群的影子测试&lt;/h4&gt;&lt;p&gt;根据影子流量将影子集群大小减小到与生产相当的大小，并将性能与生产数量进行比较。&lt;/p&gt;&lt;p&gt;我们希望在大小成比例的集群上发生成比例的读写操作。在此测试设置中，我们还需要对阴影和生产设置运行拓扑操作以获取比较详细信息。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-key-performance-indicators"&gt;关键绩效指标&lt;/h3&gt;&lt;p&gt;我们需要在两种测试策略中观察以下指标：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;系统指标：&lt;/strong&gt; CPU、RSS 内存、总内存、磁盘使用情况、文件描述符以及 M3DB 进程生成的 goroutine 数量。&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;延迟数字：&lt;/strong&gt;客户端和服务器端读/写延迟。&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;成功/失败：&lt;/strong&gt;仲裁成功与失败的读/写请求。&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;节点/对等引导时间：&lt;/strong&gt;每当系统中出现新节点时，都会为其分配系统中可用分片的子集。现在，该节点尝试从其他对等点引导数据，其中也包含这些分片的副本数据。&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;缓冲写入正确性：&lt;/strong&gt;每当数据写入 M3DB 时，数据都会根据命名空间配置（特别是配置的&lt;strong&gt;块大小&lt;/strong&gt;）保存在 M3DB 的内存缓冲区中。如果对 M3DB 的写入成功，我们应该能够在将数据刷新到磁盘之前从 M3DB 查询回相同的数据。&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt; &lt;strong&gt;Flushed Write Correctness：&lt;/strong&gt;与缓冲写入正确性类似，当块刷新到磁盘时，写入在刷新到磁盘后应该是可验证的。 &lt;/li&gt;&lt;/ul&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h3 class="wp-block-heading" id="h-gains-observed-in-testing-nbsp"&gt;&lt;strong&gt;测试中观察到的收益&lt;/strong&gt;&lt;/h3&gt;&lt;h4 class="wp-block-heading" id="h-memory-improvements-nbsp"&gt;记忆力改善&lt;/h4&gt;&lt;p&gt;我们观察到新版本中 M3DB 的内存利用率提高了大约 20%。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/iw6yy3taG-gCKtsZFmnAx5rhVFCO2l1sRMlZsSjsJIXzzOngdzy8XuBhQhmOOkhAReRlgyE_CuF7qSfihkItMFvDk34engOYipE0-W_OOvp8FgWEt0f3Rz7TJxT1JFhtAA23xzEhcgB035Bd46SDvSA" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 3：内存改进。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-cpu-utilization-improvements-nbsp"&gt; CPU 利用率改进&lt;/h4&gt;&lt;p&gt;同样，我们观察到新版本中 M3DB 的内存利用率提高了大约 20%。 &lt;/p&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/UF5RX9fSgWn3XvjJU9x58KP-8V7B_PW3C47ZNSVqaPuBPQnd1tyeNaVyqIE6S7WPvnVs9lodzDpt4fKfPZzMgE5fO65Gt8kwnu1UJsFno3sxToEjt_WVsefGOHGH622EANAnRXbSzLeEhKJzs8G8sYs" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 4：CPU 利用率改进。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h4 class="wp-block-heading" id="h-node-bootstrap-time-improvements"&gt;节点引导时间改进&lt;/h4&gt;&lt;p&gt;每当将新节点添加到集群的拓扑中时，就会发生&lt;a href="https://m3db.io/docs/operational_guide/bootstrapping_crash_recovery/" rel="noreferrer noopener" target="_blank"&gt;节点引导&lt;/a&gt;，这可能是在替换旧节点或添加新节点时。在 M3DB 中，当旧节点进行替换时引导新节点是一个长时间运行的操作。&lt;br /&gt;我们在新版本的 M3DB 中一致地引导时看到了更好的性能。这个测试进行了很多轮，结果总是新版本更好。&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;节点大小&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;旧版本（分钟）&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;新版本（分钟）&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;改进％&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 80GiB&lt;/td&gt;&lt;td&gt; 77&lt;/td&gt;&lt;td&gt; 62&lt;/td&gt;&lt;td&gt; 19.48%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 224GiB&lt;/td&gt;&lt;td&gt; 218&lt;/td&gt;&lt;td&gt; 170&lt;/td&gt;&lt;td&gt; 22.00%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 518吉B&lt;/td&gt;&lt;td&gt;第317章&lt;/td&gt;&lt;td&gt;230&lt;/td&gt;&lt;td&gt; 27%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 740吉布&lt;/td&gt;&lt;td&gt;第424章&lt;/td&gt;&lt;td&gt;365&lt;/td&gt;&lt;td&gt; 14%&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;更换引导时间改进%&lt;/strong&gt; &lt;/figcaption&gt;&lt;/figure&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h2 class="wp-block-heading" id="h-production-rollout-nbsp"&gt;&lt;strong&gt;生产推广&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;当所有测试完成后，我们开始分阶段部署到生产集群。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-challenges-in-production-rollout"&gt;生产推广中的挑战&lt;/h3&gt;&lt;p&gt;即使经过彻底的基准测试和生产样本流量测试，我们在部署的集群中也遇到了一些挑战。下面，我们概述了这些问题，并解释了为什么它们在基准测试过程中难以捉摸，并详细介绍了为解决这些问题而实施的最终解决方案。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-tail-latency-spikes-nbsp"&gt;尾部延迟峰值&lt;/h4&gt;&lt;p&gt;部署后不久，我们注意到写入操作的尾部延迟显着增加，特别是在 P85 百分位数及以上。&lt;/p&gt;&lt;p&gt;为了确定问题的根本原因，我们将集群中的多个节点恢复到之前的版本，同时在其余节点上维护较新的版本。随后，我们对两个版本之间的CPU&lt;a href="https://go.dev/blog/pprof" rel="noreferrer noopener" target="_blank"&gt;性能分析&lt;/a&gt;进行了比较。然后我们能够将其隔离为一个简单的方法，这是有问题的。然后我们解决了导致回归的问题，之后延迟也下降了。&lt;/p&gt;&lt;p&gt;以下是 cpu 分析练习中的一些图像： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-full is-resized"&gt;&lt;img alt="" class="wp-image-1088725" height="591" src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/05/Figure-5_-CPU-profile-before-fix.png" style="width: 700px; height: auto;" width="1581" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 5：修复前的 CPU 配置文件。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/7TqEH_gvJJTSI6-dL2-Nk_Ls1BhN_msDWj10PVCAlzucvwh9LPUPAi-D8M7b1JSU_4vNjndcz47l0omcoiKExxYlLUHy-OM6eStBGCFU9NtncZJ3AB417N7J9_ZJXdWvrR6rq74e2WJ7U91bnUxZa0o" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 6：修复后的 CPU 配置文件。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;从上图中我们可以看出，有问题的方法在修复后显着减少了其占用空间。&lt;/p&gt;&lt;p&gt;当我们推出这个新版本时，我们的客户端延迟再次恢复正常，如下所示： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/hc4ldFNdM05ZalywrXAWlsLHvHVSLq84hw3hCXoQHEDrCtw9BgXV9k5w-V7leY6FnjBDg_k5sXyPb-WEsX9CP_hS5EweJT1IbFcC_hbn_DTbq2ZlkSUpUCUBTaisqp-GhF6HuDxO3FAuZaJSX-93OaQ" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 7：修复前后的 P99 写入延迟。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;我们将此修复贡献回上游开源存储库 - 更改的详细信息可以在： &lt;a href="https://github.com/m3db/m3/pull/4253" rel="noreferrer noopener" target="_blank"&gt;Github Pull Request#4253&lt;/a&gt;中找到。&lt;/p&gt;&lt;h4 class="wp-block-heading" id="h-data-loss-during-the-upgrade"&gt;升级期间数据丢失&lt;/h4&gt;&lt;p&gt;在上线过程中，集群中的所有节点都会依次进行版本升级。这涉及关闭现有节点并将其在新版本中恢复。因此，节点会丢失其在内存中保存的数据，并且还会错过在其关闭的时间窗口内传入的写入操作。该节点尝试通过&lt;a href="https://m3db.io/docs/operational_guide/bootstrapping_crash_recovery/" rel="noreferrer noopener" target="_blank"&gt;引导&lt;/a&gt;并从对等节点获取数据来恢复该数据。&lt;/p&gt;&lt;p&gt;在集群中发布后，我们的客户发现他们在读取法定人数方面遇到了问题。这基本上意味着客户端观察到读取数量增加，其中集群中只有一个副本有数据，而其他两个副本没有任何数据。&lt;/p&gt;&lt;p&gt;我们从许多查询中分离出单个查询，然后我们能够检查分片的各个副本，并能够发现数据丢失，并且丢失数据的时间范围与节点升级的时间相匹配。我们观察到一个副本有数据，而另外两个副本缺少数据。然后，我们将其与以下事实关联起来：拥有更多数据的副本能够在其他两个副本升级之前将数据刷新到磁盘。刷新取决于&lt;a href="https://m3db.io/docs/operational_guide/namespace_configuration/" rel="noreferrer noopener" target="_blank"&gt;命名空间&lt;/a&gt;配置，因此如果命名空间配置规定刷新应每 24 小时发生一次，则所有节点将几乎同时经历刷新周期。&lt;/p&gt;&lt;p&gt;这个问题最终被证明是一个配置错误的问题，我们必须为数据库指定正确的引导程序模式，只有在这之后它才会尝试引导在从对等点升级期间丢失的数据。我们使用默认的引导配置，但理想情况下我们应该指定模式为“prefer_peers”或“exclude_commitlog”，前者意味着在从提交日志引导之前优先考虑对等点，后者意味着完全排除提交日志引导。我们继续使用后者，因为我们还没有在生产工作负载中真正使用&lt;a href="https://en.wikipedia.org/wiki/Write-ahead_logging" rel="noreferrer noopener" target="_blank"&gt;WAL&lt;/a&gt; 。&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-gains-observed-in-production-after-rollout"&gt;推出后生产中观察到的收益&lt;/h3&gt;&lt;p&gt;生产服务器受内存限制而不是 CPU 限制，因此我们能够观察到内存使用量显着下降，而不是 CPU 使用量。下图也可以看到同样的情况： &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh7-us.googleusercontent.com/SWwyAQHUM00RoVQMX2WCnTYPA_IX9XdO80xLtOdbH0DqfqUHhXwzFZtVcXK0v3KdSC2w2Zl3Na-GMAT-WrICFiSFJcN5lJBef-g990kq17tV066c1HmH3FFa42tqJOpZp6iGpEXWxnWVdRfKoJgoSLU" /&gt;&lt;figcaption class="wp-element-caption"&gt;图 8：生产中的内存 RSS 改进。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p&gt;节点引导时间的改进也与我们在离线测试阶段的发现一致，并帮助我们提高了生产集群的稳定性。 &lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;h1 class="wp-block-heading" id="h-conclusion"&gt;结论&lt;/h1&gt;&lt;h2 class="wp-block-heading" id="h-plans-for-contribution-back-to-open-source-project"&gt;回馈开源项目的计划&lt;/h2&gt;&lt;p&gt;我们希望为该项目做出一些贡献：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;基准测试实用程序有助于在生产规模上对新版本进行基准测试。&lt;/li&gt;&lt;li&gt;文档中对数据丢失事件（以及如何解决该问题）的描述。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在生产环境中升级高QPS、低延迟时间序列数据库的旅程，尤其是像Uber这样规模的公司，无疑充满了无数的挑战和挣扎。我们的一些主要经验包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;升级应该是一个持续的过程，而不是一次性完成。&lt;/li&gt;&lt;li&gt;处理开源软件总是充满挑战，因此我们应该有办法：&lt;ul&gt;&lt;li&gt;大规模评估正确性/性能。&lt;/li&gt;&lt;li&gt;制定标准的交错推出和回滚机制。&lt;/li&gt;&lt;li&gt;采用数据驱动的方法来验证与两个发行版本之间的比较有关的每个假设/声明。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;从解决复杂的技术问题到管理性能优化和维持正常运行时间之间的微妙平衡，每个障碍都提供了成长和学习的机会。当工程师正面应对这些挑战时，他们对系统架构、可扩展性和弹性有了更深入的了解。&lt;/p&gt;&lt;p&gt;此外，升级此类关键基础设施的过程促进了工程团队内部的创新和协作文化。通过团队合作和集体解决问题，工程师甚至可以克服最艰巨的障碍，最终形成更强大、更高效的系统。&lt;/p&gt;&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;&lt;p class="has-small-font-size"&gt;封面照片归属： &lt;a href="https://www.flickr.com/photos/61846758@N02"&gt;ChrisA1995&lt;/a&gt;的“ &lt;a href="https://www.flickr.com/photos/61846758@N02/6331318875"&gt;Nature&lt;/a&gt; ”已获得&lt;a href="https://creativecommons.org/licenses/by/2.0/?ref=openverse"&gt;CC BY 2.0&lt;/a&gt;许可。&lt;/p&gt;</description><pubDate>Thu, 16 May 2024 09:18:05 GMT</pubDate><guid isPermaLink="true">https://www.uber.com/blog/upgrading-m3db/</guid></item></channel></rss>